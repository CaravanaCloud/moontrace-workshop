{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Forecasting with DeepAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll prevent battery outages using Amazon Sagemaker and [DeepAR Forecasting](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The Amazon SageMaker DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the required libraries and recovering stored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the battery time series for a single device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8e4a851ed2317a249a0903f29d894361'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_loc = 1\n",
    "sample_device_id = data.iloc[device_loc][\"device_id\"]\n",
    "sample_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data[data[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery = sample_data[\"battery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [DeepAR input format](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput) requires data to be sampled at regular time intervals. Here is a sample input:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>{\"start\": \"2009-11-01 00:00:00\", \"target\": [4.3, \"NaN\", 5.1, ...], \"cat\": [0, 1], \"dynamic_feat\": [[1.1, 1.2, 0.5, ...]]}\n",
    "{\"start\": \"2012-01-30 00:00:00\", \"target\": [1.0, -5.0, ...], \"cat\": [2, 3], \"dynamic_feat\": [[1.1, 2.05, ...]]}\n",
    "{\"start\": \"1999-01-30 00:00:00\", \"target\": [2.0, 1.0], \"cat\": [1, 4], \"dynamic_feat\": [[1.3, 0.4]]}\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, we can see that the sample timestamps are no regularly spaced, but actualy reflects the observation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2020-02-25 20:50:37    75\n",
       "2020-02-25 21:07:07    75\n",
       "2020-02-25 21:23:15    75\n",
       "2020-02-25 21:38:36    75\n",
       "2020-02-25 22:03:11    75\n",
       "Name: battery, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "battery.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='timestamp'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery.tail(20).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note that observation are taken about every 5 minutes, but changing little.\n",
    "Pandas offers a convenient resampling function to create a uniform hourly dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4672/400584912.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .resample(\"H\")\n"
     ]
    }
   ],
   "source": [
    "hourly = data[data[\"battery\"] > 0]\n",
    "hourly = (hourly.groupby(\"device_id\")\n",
    "          .battery\n",
    "          .resample(\"h\")\n",
    "          .min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                         timestamp          \n",
       "0001495ce5f079703599a94c32dab2b0  2020-02-24 15:00:00    75.0\n",
       "                                  2020-02-24 16:00:00    75.0\n",
       "                                  2020-02-24 17:00:00    75.0\n",
       "                                  2020-02-24 18:00:00    75.0\n",
       "                                  2020-02-24 19:00:00    75.0\n",
       "                                                         ... \n",
       "fffaee1fbb9c96703850f64d3262e843  2020-02-25 17:00:00    64.0\n",
       "                                  2020-02-25 18:00:00    68.0\n",
       "                                  2020-02-25 19:00:00    75.0\n",
       "                                  2020-02-25 20:00:00    76.0\n",
       "                                  2020-02-25 21:00:00    76.0\n",
       "Name: battery, Length: 532029, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly.reset_index().set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-24 15:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 16:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 17:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 18:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532029 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-24 15:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 16:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 17:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 18:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 19:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "...                                               ...      ...\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843     64.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843     68.0\n",
       "2020-02-25 19:00:00  fffaee1fbb9c96703850f64d3262e843     75.0\n",
       "2020-02-25 20:00:00  fffaee1fbb9c96703850f64d3262e843     76.0\n",
       "2020-02-25 21:00:00  fffaee1fbb9c96703850f64d3262e843     76.0\n",
       "\n",
       "[532029 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again visualize a sample tame series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsample = hourly[hourly[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='timestamp'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0r0lEQVR4nO3deXxU1f3/8fcwWQhLEsRACJNMkIRIAK0KKqDsEvwi4PIFqxWJIIsGEbC00FrR+i2gRYVSF+I3DSitfGsFRFQUNKCVHdwoWwKEEBYRJRnZAmbO7w9/jI4hkISQyUlez8fjPnzcc8+cfObkIfedc++dcRhjjAAAACxVJ9AFAAAAXAjCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1YICXcDPeb1e7d+/Xw0bNpTD4Qh0OQAAoAyMMfruu+8UExOjOnWqdq2k2oWZ/fv3KzY2NtBlAACACti7d69cLleV/sxqF2YaNmwo6YfJCA8PD3A1AACgLDwej2JjY33n8apU7cLMmUtL4eHhhBkAACwTiFtEuAEYAABYjTADAACsRpgBAABWq3b3zAAA8HNer1enTp0KdBm1XnBwsJxOZ6DLKIEwAwCo1k6dOqXdu3fL6/UGuhRIioyMVHR0dLX6LDjCDACg2jLG6MCBA3I6nYqNja3yD2PDj4wxOn78uA4dOiRJatasWYAr+hFhBgBQbX3//fc6fvy4YmJiVK9evUCXU+uFhYVJkg4dOqQmTZpUm0tORFwAQLVVXFwsSQoJCQlwJTjjTKg8ffp0gCv5EWEGAFDtVaf7M2q76vi7IMwAAACrlSvMxMfHy+FwlNjS0tJ8fVavXq0ePXqofv36Cg8PV5cuXXTixIlKLxwAAEAqZ5hZv369Dhw44NuWLVsmSRo4cKCkH4JMnz591Lt3b61bt07r16/X6NGjufscAGqI/Px8ZWVlKT8/P9ClVGvdunXT2LFjA11GrVGulBEVFaXo6GjftmTJErVs2VJdu3aVJI0bN05jxozRxIkT1aZNGyUlJWnQoEEKDQ29KMUDAKpORkaG3G63evToIbfbrYyMjECXVGOtWLFCDodDBQUFfu2EpLOr8JLJqVOnNG/ePA0dOlQOh0OHDh3S2rVr1aRJE3Xq1ElNmzZV165d9e9///uc4xQVFcnj8fhtAIDqJT8/XyNGjPB9cJ3X69XIkSOtWqFhVelHNe3TlCscZhYtWqSCggKlpqZKknbt2iVJevzxxzV8+HAtXbpUV199tXr27Kns7OxSx5k6daoiIiJ8W2xsbEVLAgBcJNnZ2SU+gbe4uFg5OTkBqqh8ArGq9P3332v06NGKiIjQpZdeqj/84Q8yxkiSXn31VbVv314NGzZUdHS07r77bt+H0eXm5qp79+6SpEaNGsnhcCg1NVWpqalauXKlZs6c6btnNTc3V5K0efNm3XzzzWrQoIGaNm2qwYMH6/Dhw75aunXrptGjR2vs2LG69NJLlZKSoqFDh+qWW27xq/n06dNq0qSJfatupoJ69+5tbrnlFt/+J598YiSZSZMm+fVr166dmThxYqnjnDx50hQWFvq2vXv3GkmmsLCwoqUBACrZ3r17TZ06dYwk3+Z0Os3evXsv6s89ceKE2bJlizlx4kSFxwhE7V27djUNGjQwDz/8sNm2bZuZN2+eqVevnklPTzfGGJORkWHeeecds3PnTrN69WrTsWNHc/PNNxtjjPn+++/NG2+8YSSZ7du3mwMHDpiCggJTUFBgOnbsaIYPH24OHDhgDhw4YL7//ntz5MgRExUVZSZNmmS2bt1qNm3aZG666SbTvXv3EvVMmDDBbNu2zWzbts188sknxul0mv379/v6LViwwNSvX9989913pb630n4nhYWFATt/V+gTgPfs2aPly5drwYIFvrYzH2ucnJzs17d169bKy8srdazQ0FDuqQGAas7lcik9PV0jR45UcXGxnE6nZs+eLZfLFejSzutcq0oXs/7Y2Fg999xzcjgcSkpK0pdffqnnnntOw4cP19ChQ339LrvsMv3lL39Rhw4ddPToUTVo0ECXXHKJJKlJkyaKjIz09Q0JCVG9evUUHR3ta/vrX/+qq666SlOmTPG1/e1vf1NsbKx27NihVq1aSZISExP19NNP+9WYlJSkV199Vb/5zW8kSZmZmRo4cKAaNGhQ6fNxMVXoMlNmZqaaNGmivn37+tri4+MVExOj7du3+/XdsWOH3G73hVUJAAi4YcOGKTc3V1lZWcrNzdWwYcMCXVKZJCYmlniq1ul0KiEh4aL+3Ouvv97vA+Y6duyo7OxsFRcXa+PGjerXr5/i4uLUsGFD34M05/rjvzSff/65srKy1KBBA992+eWXS5J27tzp63fNNdeUeO3999+vzMxMSdJXX32ld9991y9o2aLcKzNer1eZmZkaMmSIgoJ+fLnD4dCECRM0efJkXXnllfrFL36huXPnatu2bfrXv/5VqUUDAALD5XJZsRrzU9VtVenkyZNKSUlRSkqK/v73vysqKkp5eXlKSUmp0I25R48eVb9+/fTUU0+VOPbTL4OsX79+ieP33nuvJk6cqNWrV2vVqlVq0aKFbrzxxnLXEGjlDjPLly9XXl7eWZPb2LFjdfLkSY0bN07ffvutrrzySi1btkwtW7aslGIBAKiIYcOGKSUlRTk5OUpISKiSILN27Vq//TVr1igxMVHbtm3TN998o2nTpvkeetmwYYNf3zPfRXXmu6l+2v7ztquvvlpvvPGG4uPj/RYZyqJx48a69dZblZmZqdWrV+u+++4r1+uri3JfZurdu7eMMb5rcD83ceJE7d27V8eOHdOqVat0ww03XHCRAABcKJfLpW7dulXZikxeXp7Gjx+v7du367XXXtOsWbP08MMPKy4uTiEhIZo1a5Z27dqlxYsX68knn/R7rdvtlsPh0JIlS/T111/r6NGjkn64pWPt2rXKzc3V4cOH5fV6lZaWpm+//VZ33XWX1q9fr507d+q9997TfffdVyL4nM3999+vuXPnauvWrRoyZMhFmYuLjY/mBQDgIrj33nt14sQJXXvttUpLS9PDDz+sESNGKCoqSnPmzNHrr7+u5ORkTZs2TdOnT/d7bfPmzfXEE09o4sSJatq0qUaPHi1J+vWvfy2n06nk5GTf5amYmBh98sknKi4uVu/evdWuXTuNHTtWkZGRZfoE/l69eqlZs2ZKSUlRTEzMRZmLi81hzP9/6L2a8Hg8ioiIUGFhocLDwwNdDgAggE6ePKndu3erRYsWqlu3bqDLqZGOHj2q5s2bKzMzU7fffvt5+5f2Ownk+btCj2YDAAC7eb1eHT58WM8884wiIyPVv3//QJdUYYQZAABqoby8PLVo0UIul0tz5swp983D1Ym9lQMAgAqLj49XNbvTpMK4ARgAUO3VlJNuTVAdfxeEGQBAteV0OiXVvG95ttnx48clScHBwQGu5EdcZgIAVFtBQUGqV6+evv76awUHB5fpUWNcHMYYHT9+XIcOHVJkZKQvaFYHhBkAQLXlcDjUrFkz7d69W3v27Al0OZAUGRnp90WX1QFhBgBQrYWEhCgxMZFLTdVAcHBwtVqROYMwAwCo9urUqcOH5qFUXHwEAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAqNHy8/OVlZWl/Pz8QJdSZjbWvG/fvoD9bMIMAKDGysjIkNvtVo8ePeR2u5WRkRHoks7L1prbtGkTsJ/vMNXsu7w9Ho8iIiJUWFio8PDwQJcDALBUfn6+3G63vF6vr83pdCo3N1culyuAlZWuJtQciPM3KzMAgBopOzvbLxRIUnFxsXJycgJU0fnVlJqrGmEGAFAjJSYmqk4d/9Oc0+lUQkJCgCo6v5pSc1UjzAAAaiSXy6X09HTftzw7nU7Nnj272l6ukeyuOZCBhntmAAA1Wn5+vnJycpSQkFCtQ8FP2Vjz1q1blZycHJDzN2EGAABcsECev7nMBAAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKuVK8zEx8fL4XCU2NLS0vz6GWN08803y+FwaNGiRZVZLwAAgJ+g8nRev369iouLffubN2/WTTfdpIEDB/r1mzFjhhwOR+VUCAAAcA7lCjNRUVF++9OmTVPLli3VtWtXX9tnn32mZ555Rhs2bFCzZs0qp0oAAIBSlCvM/NSpU6c0b948jR8/3rcKc/z4cd199916/vnnFR0dXaZxioqKVFRU5Nv3eDwVLQkAANRCFb4BeNGiRSooKFBqaqqvbdy4cerUqZMGDBhQ5nGmTp2qiIgI3xYbG1vRkgAAQC1U4TCTkZGhm2++WTExMZKkxYsX68MPP9SMGTPKNc6kSZNUWFjo2/bu3VvRkgAAQC1UoctMe/bs0fLly7VgwQJf24cffqidO3cqMjLSr+8dd9yhG2+8UStWrDjrWKGhoQoNDa1IGQAAABULM5mZmWrSpIn69u3ra5s4caLuv/9+v37t2rXTc889p379+l1YlQAAAKUod5jxer3KzMzUkCFDFBT048ujo6PPetNvXFycWrRocWFVAgAAlKLc98wsX75ceXl5Gjp06MWoBwAAoFzKvTLTu3dvGWPK1Les/QAAACqK72YCAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgtXKFmfj4eDkcjhJbWlqavv32Wz300ENKSkpSWFiY4uLiNGbMGBUWFl6s2gEAABRUns7r169XcXGxb3/z5s266aabNHDgQO3fv1/79+/X9OnTlZycrD179mjUqFHav3+//vWvf1V64QAAAJLkMMaYir547NixWrJkibKzs+VwOEocf/3113XPPffo2LFjCgoqW27yeDyKiIhQYWGhwsPDK1oaAACoQoE8f5drZeanTp06pXnz5mn8+PFnDTKSfG/oXEGmqKhIRUVFvn2Px1PRkgAAQC1U4RuAFy1apIKCAqWmpp71+OHDh/Xkk09qxIgR5xxn6tSpioiI8G2xsbEVLQkAANRCFb7MlJKSopCQEL311lsljnk8Ht1000265JJLtHjxYgUHB5c6ztlWZmJjY7nMBACARay7zLRnzx4tX75cCxYsKHHsu+++U58+fdSwYUMtXLjwnEFGkkJDQxUaGlqRMgAAACp2mSkzM1NNmjRR3759/do9Ho969+6tkJAQLV68WHXr1q2UIgEAAEpT7pUZr9erzMxMDRkyxO/G3jNB5vjx45o3b548Ho/vZt6oqCg5nc7KqxoAAOD/K3eYWb58ufLy8jR06FC/9k2bNmnt2rWSpISEBL9ju3fvVnx8fMWrBAAAKMUFfc7MxcDnzAAAYJ9Anr/5biYAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWK1eYiY+Pl8PhKLGlpaVJkk6ePKm0tDQ1btxYDRo00B133KGvvvrqohQOAAAglTPMrF+/XgcOHPBty5YtkyQNHDhQkjRu3Di99dZbev3117Vy5Urt379ft99+e+VXDQA1QH5+vrKyspSfnx/oUgCrlSvMREVFKTo62rctWbJELVu2VNeuXVVYWKiMjAw9++yz6tGjh6655hplZmZq1apVWrNmzcWqHwCslJGRIbfbrR49esjtdisjIyPQJQHWqvA9M6dOndK8efM0dOhQORwObdy4UadPn1avXr18fS6//HLFxcVp9erVpY5TVFQkj8fjtwFATZafn68RI0bI6/VKkrxer0aOHMkKDVBBFQ4zixYtUkFBgVJTUyVJBw8eVEhIiCIjI/36NW3aVAcPHix1nKlTpyoiIsK3xcbGVrQkALBCdna2L8icUVxcrJycnABVBNitwmEmIyNDN998s2JiYi6ogEmTJqmwsNC37d2794LGA4DqLjExUXXq+P/z63Q6lZCQEKCKALtVKMzs2bNHy5cv1/333+9ri46O1qlTp1RQUODX96uvvlJ0dHSpY4WGhio8PNxvA4CazOVyKT09XU6nU9IPQWb27NlyuVwBrgywU4XCTGZmppo0aaK+ffv62q655hoFBwfrgw8+8LVt375deXl56tix44VXCgA1yLBhw5Sbm6usrCzl5uZq2LBhgS4JsFZQeV/g9XqVmZmpIUOGKCjox5dHRERo2LBhGj9+vC655BKFh4froYceUseOHXX99ddXatEAUBO4XC5WY4BKUO4ws3z5cuXl5Wno0KEljj333HOqU6eO7rjjDhUVFSklJUUvvPBCpRQKAABwNg5jjAl0ET/l8XgUERGhwsJC7p8BAMASgTx/891MAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArFbuMLNv3z7dc889aty4scLCwtSuXTtt2LDBd/zo0aMaPXq0XC6XwsLClJycrJdeeqlSiwYAADgjqDydjxw5os6dO6t79+569913FRUVpezsbDVq1MjXZ/z48frwww81b948xcfH6/3339eDDz6omJgY9e/fv9LfAAAAqN3KFWaeeuopxcbGKjMz09fWokULvz6rVq3SkCFD1K1bN0nSiBEjNHv2bK1bt44wAwAAKl25LjMtXrxY7du318CBA9WkSRNdddVVevnll/36dOrUSYsXL9a+fftkjFFWVpZ27Nih3r17n3XMoqIieTwevw0AAKCsyhVmdu3apRdffFGJiYl677339MADD2jMmDGaO3eur8+sWbOUnJwsl8ulkJAQ9enTR88//7y6dOly1jGnTp2qiIgI3xYbG3th7wgAANQqDmOMKWvnkJAQtW/fXqtWrfK1jRkzRuvXr9fq1aslSdOnT9fLL7+s6dOny+1266OPPtKkSZO0cOFC9erVq8SYRUVFKioq8u17PB7FxsaqsLBQ4eHhF/LeAABAFfF4PIqIiAjI+btc98w0a9ZMycnJfm2tW7fWG2+8IUk6ceKEfve732nhwoXq27evJOmKK67QZ599punTp581zISGhio0NLSi9QMAgFquXJeZOnfurO3bt/u17dixQ263W5J0+vRpnT59WnXq+A/rdDrl9XovsFQAAICSyrUyM27cOHXq1ElTpkzRoEGDtG7dOqWnpys9PV2SFB4erq5du2rChAkKCwuT2+3WypUr9corr+jZZ5+9KG8AAADUbuW6Z0aSlixZokmTJik7O1stWrTQ+PHjNXz4cN/xgwcPatKkSXr//ff17bffyu12a8SIERo3bpwcDsd5xw/kNTcAAFAxgTx/lzvMXGyEGQAA7BPI8zffzQQAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAaoQZAABgNcIMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBq5Q4z+/bt0z333KPGjRsrLCxM7dq104YNG/z6bN26Vf3791dERITq16+vDh06KC8vr9KKBgAAOCOoPJ2PHDmizp07q3v37nr33XcVFRWl7OxsNWrUyNdn586duuGGGzRs2DA98cQTCg8P13/+8x/VrVu30osHgDPy8/OVnZ2txMREuVyuQJcDoAo5jDGmrJ0nTpyoTz75RB9//HGpfX75y18qODhYr776aoUK8ng8ioiIUGFhocLDwys0BoDaJSMjQyNGjJDX61WdOnWUnp6uYcOGBbosoFYJ5Pm7XJeZFi9erPbt22vgwIFq0qSJrrrqKr388su+416vV2+//bZatWqllJQUNWnSRNddd50WLVpU6phFRUXyeDx+GwCUVX5+vi/ISD/8OzRy5Ejl5+cHuDIAVaVcYWbXrl168cUXlZiYqPfee08PPPCAxowZo7lz50qSDh06pKNHj2ratGnq06eP3n//fd122226/fbbtXLlyrOOOXXqVEVERPi22NjYC39XAGqN7OxsX5A5o7i4WDk5OQGqCEBVK9dlppCQELVv316rVq3ytY0ZM0br16/X6tWrtX//fjVv3lx33XWX/vGPf/j69O/fX/Xr19drr71WYsyioiIVFRX59j0ej2JjY7nMBKBM8vPz5Xa7/QKN0+lUbm4u984AVciay0zNmjVTcnKyX1vr1q19TypdeumlCgoKOmefnwsNDVV4eLjfBgBl5XK5lJ6eLqfTKemHIDN79myCDFCLlOtpps6dO2v79u1+bTt27JDb7Zb0w8pNhw4dztkHACrbsGHDlJKSopycHCUkJBBkgFqmXGFm3Lhx6tSpk6ZMmaJBgwZp3bp1Sk9PV3p6uq/PhAkTdOedd6pLly7q3r27li5dqrfeeksrVqyo7NoBwMflchFigFqqXPfMSNKSJUs0adIkZWdnq0WLFho/fryGDx/u1+dvf/ubpk6dqvz8fCUlJemJJ57QgAEDyjQ+j2YDAGCfQJ6/yx1mLjbCDAAA9rHmBmAAAIDqhjADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArFZtw8y+ffsCXUK55OfnKysrS/n5+YEuBQCAWqXahpk2bdooIyMj0GWUSUZGhtxut3r06CG3221N3QAA1AQOY4wJdBE/5fF4FBERIUlyOp3Kzc2Vy+UKcFWly8/Pl9vtltfr9bXZUDcAAJXpzPm7sLBQ4eHhVfqzq+3KjCQVFxcrJycn0GWcU3Z2tl+QkeyoGwCAmqJahxmn06mEhIRAl3FOiYmJqlPHfxptqBsAgJqi2oaZOnXqaPbs2dX+Uo3L5VJ6erqcTqekH4KMDXUDAFBTVNt7ZrZs2aLWrVsHupwyy8/PV05OjhISEggyAIBaJ5D3zARV6U8rh+bNmwe6hHJxuVyEGAAAAqDaXmYCAAAoC8IMAACwGmEGAABYjTADAACsRpgBAABWI8wAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYjzAAAAKsRZgAAgNUIMwAAwGqEGQAAYDXCDAAAsBphBgAAWK3cYWbfvn2655571LhxY4WFhaldu3basGHDWfuOGjVKDodDM2bMuNA6AQAAziqoPJ2PHDmizp07q3v37nr33XcVFRWl7OxsNWrUqETfhQsXas2aNYqJiam0YlG58vPzlZ2drcTERLlcrkCXUybUXDVsrBlA7VWulZmnnnpKsbGxyszM1LXXXqsWLVqod+/eatmypV+/ffv26aGHHtLf//53BQcHV2rBqBwZGRlyu93q0aOH3G63MjIyAl3SeVFz1bCxZgC1m8MYY8raOTk5WSkpKcrPz9fKlSvVvHlzPfjggxo+fLivj9frVa9evTRgwAA9/PDDio+P19ixYzV27NizjllUVKSioiLfvsfjUWxsrAoLCxUeHl7xd4ZS5efny+12y+v1+tqcTqdyc3Or7V/h1Fw1bKwZQPXg8XgUERERkPN3uVZmdu3apRdffFGJiYl677339MADD2jMmDGaO3eur89TTz2loKAgjRkzpkxjTp06VREREb4tNja2fO8A5Zadne13spKk4uJi5eTkBKii86PmqmFjzQBQrntmvF6v2rdvrylTpkiSrrrqKm3evFkvvfSShgwZoo0bN2rmzJnatGmTHA5HmcacNGmSxo8f79s/szKDiycxMVF16tQp8dd3QkJCAKs6N2quGjbWDADlWplp1qyZkpOT/dpat26tvLw8SdLHH3+sQ4cOKS4uTkFBQQoKCtKePXv0yCOPKD4+/qxjhoaGKjw83G/DxeVyuZSeni6n0ynph5PV7Nmzq/VlBGquGjbWDADlumfm7rvv1t69e/Xxxx/72saNG6e1a9dq1apV+uabb3TgwAG/16SkpGjw4MG67777lJSUdN6fEchrbrVNfn6+cnJylJCQYM3Jipqrho01AwisQJ6/y3WZady4cerUqZOmTJmiQYMGad26dUpPT1d6erokqXHjxmrcuLHfa4KDgxUdHV2mIIOq5XK5rDtRUXPVsLFmALVXuS4zdejQQQsXLtRrr72mtm3b6sknn9SMGTP0q1/96mLVBwAAcE7lusxUFbjMBACAfax5NBsAAKC6IcwAAACrEWYAAIDVCDMAAMBqhBkAAGA1wgwAALAaYQYAAFiNMAMAAKxGmAEAAFYr13czVYUzH0js8XgCXAkAACirM+ftQHyxQLULM998840kKTY2NsCVAACA8vrmm28UERFRpT+z2oWZSy65RJKUl5dX5ZNxoTp06KD169cHuowaj3muGsxz1WCeqwbzfPEVFhYqLi7Odx6vStUuzNSp88NtPBEREdZ90aTT6bSuZhsxz1WDea4azHPVYJ6rzpnzeJX+zCr/iTVYWlpaoEuoFZjnqsE8Vw3muWowzzWbwwTiTp1zCORXiAMAgIoJ5Pm72q3MhIaGavLkyQoNDQ10KQAAoIwCef6udiszAAAA5VHtVmYAAADKgzADAACsVuvDzEcffaR+/fopJiZGDodDixYt8h07ffq0fvvb36pdu3aqX7++YmJidO+992r//v3nHXfFihW6+uqrFRoaqoSEBM2ZM6dEn+eff17x8fGqW7eurrvuOq1bt64S31n1cq55/rlRo0bJ4XBoxowZ5x2XeS6pLHO9detW9e/fXxEREapfv746dOigvLy8c477xRdf6MYbb1TdunUVGxurp59+ukSf119/XZdffrnq1q2rdu3a6Z133qmst1XtnG+ejx49qtGjR8vlciksLEzJycl66aWXzjsu8/yjqVOnqkOHDmrYsKGaNGmiW2+9Vdu3b/frc/LkSaWlpalx48Zq0KCB7rjjDn311VfnHft8c2iM0WOPPaZmzZopLCxMvXr1UnZ2dqW+P1QiU8u988475ve//71ZsGCBkWQWLlzoO1ZQUGB69epl/u///s9s27bNrF692lx77bXmmmuuOeeYu3btMvXq1TPjx483W7ZsMbNmzTJOp9MsXbrU12f+/PkmJCTE/O1vfzP/+c9/zPDhw01kZKT56quvLtZbDahzzfNPLViwwFx55ZUmJibGPPfcc+cck3k+u/PNdU5OjrnkkkvMhAkTzKZNm0xOTo558803zzknhYWFpmnTpuZXv/qV2bx5s3nttddMWFiYmT17tq/PJ598YpxOp3n66afNli1bzKOPPmqCg4PNl19+ebHeakCdb56HDx9uWrZsabKysszu3bvN7NmzjdPpNG+++WapYzLP/lJSUkxmZqbZvHmz+eyzz8x//dd/mbi4OHP06FFfn1GjRpnY2FjzwQcfmA0bNpjrr7/edOrU6ZzjlmUOp02bZiIiIsyiRYvM559/bvr3729atGhhTpw4cdHeLyqu1oeZnzrXSfaMdevWGUlmz549pfb5zW9+Y9q0aePXduedd5qUlBTf/rXXXmvS0tJ8+8XFxSYmJsZMnTq1YsVbpLR5zs/PN82bNzebN282brf7vGGGeT6/s831nXfeae65555yjfPCCy+YRo0amaKiIl/bb3/7W5OUlOTbHzRokOnbt6/f66677jozcuTI8hdumbPNc5s2bcwf//hHv7arr77a/P73vy91HOb53A4dOmQkmZUrVxpjfviDMzg42Lz++uu+Plu3bjWSzOrVq0sd53xz6PV6TXR0tPnzn//sO15QUGBCQ0PNa6+9VplvqdqYMmWKad++vWnQoIGJiooyAwYMMNu2bfMd/+abb8zo0aNNq1atTN26dU1sbKx56KGHTEFBwXnH/uc//2mSkpJMaGioadu2rXn77bf9jnu9XvOHP/zBREdHm7p165qePXuaHTt2lKv+Wn+ZqbwKCwvlcDgUGRnpa+vWrZtSU1N9+6tXr1avXr38XpeSkqLVq1dLkk6dOqWNGzf69alTp4569erl61PbeL1eDR48WBMmTFCbNm3O2od5vnBer1dvv/22WrVqpZSUFDVp0kTXXXddiUskqamp6tatm29/9erV6tKli0JCQnxtKSkp2r59u44cOeLrc67fR23TqVMnLV68WPv27ZMxRllZWdqxY4d69+7t68M8l09hYaGkH7/2ZuPGjTp9+rTffFx++eWKi4vzm4/4+Hg9/vjjvv3zzeHu3bt18OBBvz4RERG67rrrauw8r1y5UmlpaVqzZo2WLVum06dPq3fv3jp27Jgkaf/+/dq/f7+mT5+uzZs3a86cOVq6dKmGDRt2znFXrVqlu+66S8OGDdOnn36qW2+9Vbfeeqs2b97s6/P000/rL3/5i1566SWtXbtW9evXV0pKik6ePFnm+gkz5XDy5En99re/1V133eX3gUBxcXFq1qyZb//gwYNq2rSp32ubNm0qj8ejEydO6PDhwyouLj5rn4MHD17cN1FNPfXUUwoKCtKYMWNK7cM8X7hDhw7p6NGjmjZtmvr06aP3339ft912m26//XatXLnS169Zs2aKi4vz7Zc212eOnatPbZ3rWbNmKTk5WS6XSyEhIerTp4+ef/55denSxdeHeS47r9ersWPHqnPnzmrbtq2kH+YiJCTE749LqeR8tGzZUpdeeqlv/3xzeOa/tWmely5dqtTUVLVp00ZXXnml5syZo7y8PG3cuFGS1LZtW73xxhvq16+fWrZsqR49euhPf/qT3nrrLX3//feljjtz5kz16dNHEyZMUOvWrfXkk0/q6quv1l//+ldJP9ybNGPGDD366KMaMGCArrjiCr3yyivav3//Oe+t/Llq991M1dXp06c1aNAgGWP04osv+h175ZVXAlRVzbBx40bNnDlTmzZtksPhKLUf83zhvF6vJGnAgAEaN26cJOkXv/iFVq1apZdeekldu3aV9MONl7gws2bN0po1a7R48WK53W599NFHSktLU0xMjO8vfua57NLS0rR582b9+9//LvdrP/jgg4tQUc3281Ww0vqEh4crKOjHKBEfH6/U1FTfStjq1as1fvx4v9elpKT4gsr5VsF++ctflqleVmbK4EyQ2bNnj5YtW3bej2mOjo4ucTf9V199pfDwcIWFhenSSy+V0+k8a5/o6OhKr7+6+/jjj3Xo0CHFxcUpKChIQUFB2rNnjx555BHFx8eX+jrmufwuvfRSBQUFKTk52a+9devW53yaqbS5PnPsXH1q41yfOHFCv/vd7/Tss8+qX79+uuKKKzR69Gjdeeedmj59eqmvY57PbvTo0VqyZImysrLkcrl87dHR0Tp16pQKCgr8+p9vPs43h2f+W9vm+YyzrYL93OHDh/Xkk09qxIgRfu2BWgUjzJzHmSCTnZ2t5cuXq3Hjxud9TceOHUv8JbBs2TJ17NhRkhQSEqJrrrnGr4/X69UHH3zg61ObDB48WF988YU+++wz3xYTE6MJEybovffeK/V1zHP5hYSEqEOHDiUeb92xY4fcbnepr+vYsaM++ugjnT592te2bNkyJSUlqVGjRr4+5/p91CanT5/W6dOnS3x7sNPp9K2OnQ3z7M8Yo9GjR2vhwoX68MMP1aJFC7/j11xzjYKDg/3mY/v27crLyzvnfJxvDlu0aKHo6Gi/Ph6PR2vXrq2R8/xzZ1bB5s+ff9bjHo9Hffv2VXJyst+9SNIPq2CjR4+ugip/ply3C9dA3333nfn000/Np59+aiSZZ5991nz66admz5495tSpU6Z///7G5XKZzz77zBw4cMC3/fRpg8GDB5uJEyf69s88MjxhwgSzdetW8/zzz5/1keHQ0FAzZ84cs2XLFjNixAgTGRlpDh48WKXvv6qca57P5mxPMzHPZXO+uV6wYIEJDg426enpJjs72/dI+8cff+wbY+LEiWbw4MG+/YKCAtO0aVMzePBgs3nzZjN//nxTr169Eo8MBwUFmenTp5utW7eayZMn19hHho05/zx37drVtGnTxmRlZZldu3aZzMxMU7duXfPCCy/4xmCez+2BBx4wERERZsWKFX7//h4/ftzXZ9SoUSYuLs58+OGHZsOGDaZjx46mY8eOfuP06NHDzJo1y7dfljmcNm2aiYyMNG+++ab54osvzIABA2rFo9lpaWnG5XKZXbt2nfW4x+MxHTt2ND179izTXMTGxpb4t/yxxx4zV1xxhTHGmJ07dxpJ5tNPP/Xr06VLFzNmzJgy113rw0xWVpaRVGIbMmSI2b1791mPSTJZWVm+Mbp27WqGDBlSYtxf/OIXJiQkxFx22WUmMzOzxM+eNWuWiYuLMyEhIebaa681a9asubhvNoDONc9nc7YwwzyXTVnmOiMjwyQkJJi6deuaK6+80ixatMhvjCFDhpiuXbv6tX3++efmhhtuMKGhoaZ58+Zm2rRpJX72P//5T9OqVSsTEhJi2rRpU+IRzJrkfPN84MABk5qaamJiYkzdunVNUlKSeeaZZ4zX6/WNwTyfW2n//v70//MTJ06YBx980DRq1MjUq1fP3HbbbebAgQN+47jdbjN58mS/tvPN4ZnHhZs2bWpCQ0NNz549zfbt2y/WWw04r9dr0tLSTExMTKmPRRcWFprrr7/edO3a1Rw7dqxM4w4aNMjccsstfm0dO3Ys8Rj89OnT/X5OeR+D54smAQCo5R588EH94x//0JtvvqmkpCRfe0REhMLCwuTxeNS7d28dP35cCxcuVP369X19oqKi5HQ6JUk9e/bUbbfd5rvUtGrVKnXt2lXTpk1T3759NX/+fE2ZMkWbNm3y3Y/z1FNPadq0aZo7d65atGihP/zhD/riiy+0ZcsW1a1bt0z18zQTAAC13JmndH/6uUeSlJmZqdTUVG3atElr166VJCUkJPj12b17t+9hjZ07d+rw4cO+Y506ddI//vEPPfroo/rd736nxMRELVq0yO/G4t/85jc6duyYRowYoYKCAt1www1aunRpmYOMJLEyAwAArMbTTAAAwGqEGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzQC2zYsUKORwOFRQUBLoUAKgUhBmghuvWrZvGjh3r2+/UqZMOHDigiIiIgNVEoAJQmfhuJqCWCQkJUXR0dKDLAIBKw8oMUIOlpqZq5cqVmjlzphwOhxwOh+bMmeO3KjJnzhxFRkZqyZIlSkpKUr169fTf//3fOn78uObOnav4+Hg1atRIY8aMUXFxsW/soqIi/frXv1bz5s1Vv359XXfddVqxYoXv+J49e9SvXz81atRI9evXV5s2bfTOO+8oNzdX3bt3lyQ1atRIDodDqampkqSlS5fqhhtuUGRkpBo3bqxbbrlFO3fu9I2Zm5srh8Ohf/7zn7rxxhsVFhamDh06aMeOHVq/fr3at2+vBg0a6Oabb9bXX3/tNw+33nqrnnjiCUVFRSk8PFyjRo3SqVOnLt7kA6gyrMwANdjMmTO1Y8cOtW3bVn/84x8lSf/5z39K9Dt+/Lj+8pe/aP78+fruu+90++2367bbblNkZKTeeecd7dq1S3fccYc6d+6sO++8U5I0evRobdmyRfPnz1dMTIwWLlyoPn366Msvv1RiYqLS0tJ06tQpffTRR6pfv762bNmiBg0aKDY2Vm+88YbuuOMObd++XeHh4QoLC5MkHTt2TOPHj9cVV1yho0eP6rHHHtNtt92mzz77THXq/Pi31+TJkzVjxgzFxcVp6NChuvvuu9WwYUPNnDlT9erV06BBg/TYY4/5vglYkj744APVrVtXK1asUG5uru677z41btxYf/rTny7mrwBAVTAAarSuXbuahx9+2LeflZVlJJkjR44YY4zJzMw0kkxOTo6vz8iRI029evXMd99952tLSUkxI0eONMYYs2fPHuN0Os2+ffv8flbPnj3NpEmTjDHGtGvXzjz++ONnrennNZTm66+/NpLMl19+aYwxZvfu3UaS+d///V9fn9dee81IMh988IGvberUqSYpKcm3P2TIEHPJJZeYY8eO+dpefPFF06BBA1NcXHzOGgBUf1xmAqB69eqpZcuWvv2mTZsqPj5eDRo08Gs7dOiQJOnLL79UcXGxWrVqpQYNGvi2lStX+i4LjRkzRv/zP/+jzp07a/Lkyfriiy/OW0d2drbuuusuXXbZZQoPD1d8fLwkKS8vz6/fFVdc4VeXJLVr1+6stZ5x5ZVXql69er79jh076ujRo9q7d+956wJQvXGZCYCCg4P99h0Ox1nbvF6vJOno0aNyOp3auHGjnE6nX78zAej+++9XSkqK3n77bb3//vuaOnWqnnnmGT300EOl1tGvXz+53W69/PLLiomJkdfrVdu2bUvc2/LT2hwOx1nbztQKoOZjZQao4UJCQvxu3K0MV111lYqLi3Xo0CElJCT4bT99Uio2NlajRo3SggUL9Mgjj+jll1/21STJr65vvvlG27dv16OPPqqePXuqdevWOnLkSKXV/Pnnn+vEiRO+/TVr1vju4QFgN8IMUMPFx8dr7dq1ys3N1eHDhytlxaJVq1b61a9+pXvvvVcLFizQ7t27tW7dOk2dOlVvv/22JGns2LF67733tHv3bm3atElZWVlq3bq1JMntdsvhcGjJkiX6+uuvdfToUTVq1EiNGzdWenq6cnJy9OGHH2r8+PEXXOsZp06d0rBhw7Rlyxa98847mjx5skaPHu13YzEAO/F/MVDD/frXv5bT6VRycrKioqJK3H9SUZmZmbr33nv1yCOPKCkpSbfeeqvWr1+vuLg4ST+suqSlpal169bq06ePWrVqpRdeeEGS1Lx5cz3xxBOaOHGimjZt6gsV8+fP18aNG9W2bVuNGzdOf/7znyulVknq2bOnEhMT1aVLF915553q37+/Hn/88UobH0DgOIwxJtBFAMDFlJqaqoKCAi1atCjQpQC4CFiZAQAAViPMAAAAq3GZCQAAWI2VGQAAYDXCDAAAsBphBgAAWI0wAwAArEaYAQAAViPMAAAAqxFmAACA1QgzAADAav8PKZ9/Qb333voAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.tail(12).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='timestamp'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the last hours in the dataset for testing against predictions. This lets you evaluate how your model will perform on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 21:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time = hourly.tail(1).index[0]\n",
    "last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 18:00:00')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_time = last_time - pd.Timedelta('3 hour')\n",
    "cut_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 14:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 15:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 16:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843     64.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843     68.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = hourly.loc[hourly.index <= cut_time]\n",
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 19:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 20:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 21:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 19:00:00  00134c004e33e830e5dbce3355a485b9     76.0\n",
       "2020-02-25 20:00:00  00134c004e33e830e5dbce3355a485b9     76.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = hourly.loc[hourly.index > cut_time]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = train_set[train_set[\"device_id\"] == sample_device_id][\"battery\"]\n",
    "sample_test = test_set[test_set[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2020-02-25 14:00:00    64.0\n",
       "2020-02-25 15:00:00    64.0\n",
       "2020-02-25 16:00:00    64.0\n",
       "2020-02-25 17:00:00    66.0\n",
       "2020-02-25 18:00:00    70.0\n",
       "Name: battery, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 22:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 19:00:00  8e4a851ed2317a249a0903f29d894361     76.0\n",
       "2020-02-25 20:00:00  8e4a851ed2317a249a0903f29d894361     75.0\n",
       "2020-02-25 21:00:00  8e4a851ed2317a249a0903f29d894361     75.0\n",
       "2020-02-25 22:00:00  8e4a851ed2317a249a0903f29d894361     75.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='timestamp'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sample_train.plot()\n",
    "sample_test.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data from pandas DataFrame to the expected JSON Lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def df_to_tss(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df[\"timeindex\"] = df.index\n",
    "    cats = {}\n",
    "    tss = {}\n",
    "    for index, row in df.iterrows():\n",
    "        target = row[\"battery\"]\n",
    "        if not(math.isnan(target)):\n",
    "            identity = row[\"device_id\"]\n",
    "            cat = cats.get(identity)\n",
    "            if not cat:\n",
    "                cat = len(cats)\n",
    "                start = str(row[\"timeindex\"])\n",
    "                ts = {\n",
    "                    \"start\": start,\n",
    "                    \"cat\": [cat],\n",
    "                    \"target\": [],\n",
    "                }\n",
    "                cats[identity] = cat\n",
    "                tss[cat] = ts\n",
    "            ts = tss.get(cat)\n",
    "            ts[\"target\"].append(target)\n",
    "    return tss\n",
    "\n",
    "def tss_to_jsonl(tss):  \n",
    "    result = \"\"\n",
    "    for key, value in tss.items():\n",
    "        jsonll = json.dumps(value)\n",
    "        result += jsonll\n",
    "        result += \"\\n\"\n",
    "    return result[:-1]\n",
    "\n",
    "def df_to_jsonl(dataframe):\n",
    "    return tss_to_jsonl(df_to_tss(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006284475326538086\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [0], \"target\": [75.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [1], \"target\": [76.0, 75.0, 75.0, 74.0, 74.0, 75.0, 75.0, 75.0, 73.0, 72.0, 71.0, 71.0, 70.0, 69.0, 69.0, 68.0, 68.0, 67.0, 66.0, 66.0, 65.0, 65.0, 64.0, 64.0, 63.0, 64.0, 65.0, 69.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [2], \"target\": [75.0, 75.0, 75.0, 74.0, 74.0, 75.0, 75.0, 75.0, 73.0, 72.0, 71.0, 71.0, 70.0, 69.0, 68.0, 68.0, 67.0, 67.0, 66.0, 66.0, 65.0, 64.0, 64.0, 63.0, 63.0, 63.0, 65.0, 68.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [3], \"target\": [76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 73.0, 72.0, 72.0, 71.0, 70.0, 70.0, 69.0, 69.0]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "jsonl = df_to_jsonl(train_set.head(100))\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)\n",
    "print(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.82814931869507\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_tss = df_to_tss(train_set)\n",
    "train_jsonl = tss_to_jsonl(train_tss)\n",
    "\n",
    "test_tss = df_to_tss(test_set)\n",
    "test_jsonl = tss_to_jsonl(test_tss)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the json lines files locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mt-battery-deepar/input/train.json', './mt-battery-deepar/input/test.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "prefix = \"mt-battery-deepar\"\n",
    "input_path = \"./{}/input\".format(prefix)\n",
    "\n",
    "train_path = \"{}/train.json\".format(input_path)\n",
    "test_path = \"{}/test.json\".format(input_path)\n",
    "(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(input_path, ignore_errors=True)\n",
    "pathlib.Path(input_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"w\") as text_file:\n",
    "    print(train_jsonl, file=text_file)\n",
    "\n",
    "with open(test_path, \"w\") as text_file:\n",
    "    print(test_jsonl, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.0M\n",
      " 637534592 drwxr-xr-x 2 gitpod gitpod   41 Mar  4 16:24 .\n",
      "2384462632 drwxr-xr-x 3 gitpod gitpod   19 Mar  4 16:23 ..\n",
      " 637534594 -rw-r--r-- 1 gitpod gitpod 1.3M Mar  4 16:24 test.json\n",
      " 637534593 -rw-r--r-- 1 gitpod gitpod 3.8M Mar  4 16:24 train.json\n"
     ]
    }
   ],
   "source": [
    "! ls -liah \"{input_path}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload train and test sets to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: mt-battery-deepar/input/test.json to s3://mt-ml-workshop-0fsf9ksf/mt-battery-deepar/test.json\n",
      "upload: mt-battery-deepar/input/train.json to s3://mt-ml-workshop-0fsf9ksf/mt-battery-deepar/train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync \"{input_path}/\" \"s3://{bucket}/{prefix}/\" --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-04 16:24:09    1325499 test.json\n",
      "2024-03-04 16:24:09    3906490 train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls \"s3://{bucket}/{prefix}/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://mt-ml-workshop-0fsf9ksf/mt-battery-deepar/train.json',\n",
       " 'test': 's3://mt-ml-workshop-0fsf9ksf/mt-battery-deepar/test.json'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_input = {\n",
    "    \"train\": \"s3://{}/{}/train.json\".format(bucket,prefix),\n",
    "    \"test\": \"s3://{}/{}/test.json\".format(bucket,prefix)\n",
    "}\n",
    "dar_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different [ML instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/) in training lets you control how efficiently models learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You can train DeepAR on both GPU and CPU instances and in both single and multi-machine settings. We recommend starting with a single CPU instance (for example, ml.c4.2xlarge or ml.c4.4xlarge), and switching to GPU instances and multiple machines only when necessary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_instance_type='ml.c5.2xlarge' #Estimated Training Time: 10m\n",
    "train_instance_type='ml.t3.medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'522234722520.dkr.ecr.us-east-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "dar_image_name = sagemaker.image_uris.retrieve('forecasting-deepar', boto3.Session().region_name)\n",
    "# dar_image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')\n",
    "dar_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "dar_estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_uri=dar_image_name,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=train_instance_type,\n",
    "    base_job_name=prefix,\n",
    "    output_path=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 'H'\n",
    "prediction_length = 4\n",
    "context_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dar_hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"3\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"20\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"cardinality\": \"auto\",\n",
    "    \"num_dynamic_feat\":\"ignore\"\n",
    "}\n",
    "dar_estimator.set_hyperparameters(**dar_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 07:10:08 Starting - Starting the training job...\n",
      "2021-05-11 07:10:10 Starting - Launching requested ML instancesProfilerReport-1620717008: InProgress\n",
      ".........\n",
      "2021-05-11 07:12:07 Starting - Preparing the instances for training......\n",
      "2021-05-11 07:13:07 Downloading - Downloading input data\n",
      "2021-05-11 07:13:07 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'prediction_length': '4', 'dropout_rate': '0.05', 'time_freq': 'H', 'context_length': '12', 'cardinality': 'auto', 'early_stopping_patience': '10', 'num_dynamic_feat': 'ignore', 'num_cells': '40', 'likelihood': 'gaussian', 'num_layers': '3', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '32'}\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'gaussian', 'mini_batch_size': '32', 'num_cells': '40', 'num_dynamic_feat': 'ignore', 'num_eval_samples': '100', 'num_layers': '3', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'prediction_length': '4', 'time_freq': 'H', 'context_length': '12', 'epochs': '20'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] [num_dynamic_feat=ignore] Not using any `dynamic_feat` feature that may be in the data.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] random_seed is None\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:46 INFO 140281140962944] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] [cardinality=auto] Inferred value of cardinality=[16945] from dataset.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] Integer time series\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] number of time series: 16945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] number of observations: 480294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] mean target length: 28.344290351136028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] min/mean/max target: 1.0/69.71937396677868/100.0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] mean abs(target): 69.71937396677868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:48 INFO 140281140962944] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Test set statistics:\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Integer time series\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] number of time series: 16826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] number of observations: 51669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] mean target length: 3.070783311541662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] min/mean/max target: 13.0/75.99527763262304/100.0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] mean abs(target): 75.99527763262304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] #memory_usage::<batchbuffer> = 0.2696990966796875 mb\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] nvidia-smi took: 0.025206327438354492 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717230.602632, \"EndTime\": 1620717230.6990495, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 92.74125099182129, \"count\": 1, \"min\": 92.74125099182129, \"max\": 92.74125099182129}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:50 INFO 140281140962944] #memory_usage::<model> = 5 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717230.7003257, \"EndTime\": 1620717230.8314598, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 228.66511344909668, \"count\": 1, \"min\": 228.66511344909668, \"max\": 228.66511344909668}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[0] avg_epoch_loss=4.792031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.7920308113098145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[5] avg_epoch_loss=4.253761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.253761331240336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [5]#011Speed: 1201.89 samples/sec#011loss=4.253761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[10] avg_epoch_loss=4.123760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.9677584648132322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [10]#011Speed: 728.68 samples/sec#011loss=3.967758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[15] avg_epoch_loss=3.973623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=3.643320178985596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [15]#011Speed: 1320.82 samples/sec#011loss=3.643320\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[20] avg_epoch_loss=3.839406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=3.4099145412445067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [20]#011Speed: 815.25 samples/sec#011loss=3.409915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[25] avg_epoch_loss=3.690249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=3.063789129257202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [25]#011Speed: 1329.97 samples/sec#011loss=3.063789\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch[30] avg_epoch_loss=3.546492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=2.798953056335449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:51 INFO 140281140962944] Epoch[0] Batch [30]#011Speed: 841.68 samples/sec#011loss=2.798953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[35] avg_epoch_loss=3.404605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=2.5249051570892336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [35]#011Speed: 1331.16 samples/sec#011loss=2.524905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[40] avg_epoch_loss=3.278701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=2.3721914768218992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [40]#011Speed: 810.79 samples/sec#011loss=2.372191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[45] avg_epoch_loss=3.159435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=2.1814605712890627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [45]#011Speed: 1247.77 samples/sec#011loss=2.181461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[50] avg_epoch_loss=3.077431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=2.3229851722717285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [50]#011Speed: 697.59 samples/sec#011loss=2.322985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch[55] avg_epoch_loss=3.009260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=2.31392297744751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:52 INFO 140281140962944] Epoch[0] Batch [55]#011Speed: 901.37 samples/sec#011loss=2.313923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[60] avg_epoch_loss=2.938695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=2.148361015319824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [60]#011Speed: 527.44 samples/sec#011loss=2.148361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[65] avg_epoch_loss=2.872689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=2.0674139499664306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [65]#011Speed: 841.05 samples/sec#011loss=2.067414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[70] avg_epoch_loss=2.812543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=2.0186251640319823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [70]#011Speed: 518.24 samples/sec#011loss=2.018625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch[75] avg_epoch_loss=2.761023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=2.029439687728882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:53 INFO 140281140962944] Epoch[0] Batch [75]#011Speed: 817.20 samples/sec#011loss=2.029440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[80] avg_epoch_loss=2.719674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=2.0911667108535767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [80]#011Speed: 516.36 samples/sec#011loss=2.091167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[85] avg_epoch_loss=2.674815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=1.9481003046035767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [85]#011Speed: 885.15 samples/sec#011loss=1.948100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[90] avg_epoch_loss=2.641667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=2.071513295173645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [90]#011Speed: 515.84 samples/sec#011loss=2.071513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch[95] avg_epoch_loss=2.600862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=1.858212447166443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:54 INFO 140281140962944] Epoch[0] Batch [95]#011Speed: 813.25 samples/sec#011loss=1.858212\u001b[0m\n",
      "\n",
      "2021-05-11 07:14:07 Training - Training image download completed. Training in progress.\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[100] avg_epoch_loss=2.562705\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=1.8300957918167113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [100]#011Speed: 511.65 samples/sec#011loss=1.830096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[105] avg_epoch_loss=2.526629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=1.7978889703750611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [105]#011Speed: 1362.47 samples/sec#011loss=1.797889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[110] avg_epoch_loss=2.511212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=2.184369373321533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [110]#011Speed: 785.12 samples/sec#011loss=2.184369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[115] avg_epoch_loss=2.488637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=1.9874833822250366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [115]#011Speed: 1343.38 samples/sec#011loss=1.987483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[120] avg_epoch_loss=2.466922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=1.9631194591522216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [120]#011Speed: 720.48 samples/sec#011loss=1.963119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch[125] avg_epoch_loss=2.438233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=1.7439706325531006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:55 INFO 140281140962944] Epoch[0] Batch [125]#011Speed: 862.72 samples/sec#011loss=1.743971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[130] avg_epoch_loss=2.410829\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=1.7202335834503173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [130]#011Speed: 791.22 samples/sec#011loss=1.720234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[135] avg_epoch_loss=2.432928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=3.0119275093078612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [135]#011Speed: 1344.18 samples/sec#011loss=3.011928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[140] avg_epoch_loss=2.414597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=1.9160011529922485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [140]#011Speed: 769.37 samples/sec#011loss=1.916001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[145] avg_epoch_loss=2.396969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=1.8998450994491578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [145]#011Speed: 1272.23 samples/sec#011loss=1.899845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[150] avg_epoch_loss=2.377983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=1.8236025333404542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [150]#011Speed: 864.56 samples/sec#011loss=1.823603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch[155] avg_epoch_loss=2.362726\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=1.9019527196884156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:56 INFO 140281140962944] Epoch[0] Batch [155]#011Speed: 1251.36 samples/sec#011loss=1.901953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[160] avg_epoch_loss=2.344710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=1.7826276302337647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [160]#011Speed: 809.09 samples/sec#011loss=1.782628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[165] avg_epoch_loss=2.327062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=1.7587870836257935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [165]#011Speed: 1193.38 samples/sec#011loss=1.758787\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[170] avg_epoch_loss=2.309988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=1.7431488275527953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [170]#011Speed: 820.59 samples/sec#011loss=1.743149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[175] avg_epoch_loss=2.288556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=1.5555837869644165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [175]#011Speed: 1353.68 samples/sec#011loss=1.555584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[180] avg_epoch_loss=2.306567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=2.9405394315719606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [180]#011Speed: 860.42 samples/sec#011loss=2.940539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch[185] avg_epoch_loss=2.295510\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=1.895247459411621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:57 INFO 140281140962944] Epoch[0] Batch [185]#011Speed: 1336.40 samples/sec#011loss=1.895247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[190] avg_epoch_loss=2.284570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=1.8776071548461915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [190]#011Speed: 838.72 samples/sec#011loss=1.877607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[195] avg_epoch_loss=2.275550\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=1.930997657775879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [195]#011Speed: 1346.31 samples/sec#011loss=1.930998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[200] avg_epoch_loss=2.265024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=1.8523955345153809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [200]#011Speed: 843.40 samples/sec#011loss=1.852396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[205] avg_epoch_loss=2.255457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=1.8708555221557617\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [205]#011Speed: 1256.21 samples/sec#011loss=1.870856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[210] avg_epoch_loss=2.246064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=1.8590858459472657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [210]#011Speed: 859.79 samples/sec#011loss=1.859086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch[215] avg_epoch_loss=2.233850\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=1.7184139966964722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:58 INFO 140281140962944] Epoch[0] Batch [215]#011Speed: 1344.48 samples/sec#011loss=1.718414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[220] avg_epoch_loss=2.220490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=1.6433300256729126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [220]#011Speed: 867.59 samples/sec#011loss=1.643330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[225] avg_epoch_loss=2.208736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=1.6892305850982665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [225]#011Speed: 1306.86 samples/sec#011loss=1.689231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[230] avg_epoch_loss=2.196277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=1.6331115007400512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [230]#011Speed: 788.98 samples/sec#011loss=1.633112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[235] avg_epoch_loss=2.204023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=2.5619029998779297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [235]#011Speed: 1216.92 samples/sec#011loss=2.561903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[240] avg_epoch_loss=2.193974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=1.7196455717086792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [240]#011Speed: 844.29 samples/sec#011loss=1.719646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[245] avg_epoch_loss=2.183490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=1.6781803846359253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [245]#011Speed: 1355.60 samples/sec#011loss=1.678180\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch[250] avg_epoch_loss=2.173952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=1.704652762413025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:13:59 INFO 140281140962944] Epoch[0] Batch [250]#011Speed: 854.20 samples/sec#011loss=1.704653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[255] avg_epoch_loss=2.163006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=1.6135135889053345\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [255]#011Speed: 1275.18 samples/sec#011loss=1.613514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[260] avg_epoch_loss=2.156838\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=1.8410661697387696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [260]#011Speed: 816.35 samples/sec#011loss=1.841066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[265] avg_epoch_loss=2.146766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=1.6210114002227782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [265]#011Speed: 1344.68 samples/sec#011loss=1.621011\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[270] avg_epoch_loss=2.137026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=1.618810272216797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [270]#011Speed: 806.13 samples/sec#011loss=1.618810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[275] avg_epoch_loss=2.127519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=275 train loss <loss>=1.6122395038604735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [275]#011Speed: 1248.92 samples/sec#011loss=1.612240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch[280] avg_epoch_loss=2.117771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=280 train loss <loss>=1.5796887874603271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:00 INFO 140281140962944] Epoch[0] Batch [280]#011Speed: 697.04 samples/sec#011loss=1.579689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[285] avg_epoch_loss=2.106786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=285 train loss <loss>=1.4894686698913575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [285]#011Speed: 780.22 samples/sec#011loss=1.489469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[290] avg_epoch_loss=2.096892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=290 train loss <loss>=1.530920386314392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [290]#011Speed: 535.99 samples/sec#011loss=1.530920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[295] avg_epoch_loss=2.086427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=295 train loss <loss>=1.4773511648178101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [295]#011Speed: 1032.97 samples/sec#011loss=1.477351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch[300] avg_epoch_loss=2.080882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=300 train loss <loss>=1.7526219606399536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:01 INFO 140281140962944] Epoch[0] Batch [300]#011Speed: 808.39 samples/sec#011loss=1.752622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[305] avg_epoch_loss=2.073094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=305 train loss <loss>=1.604297137260437\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [305]#011Speed: 572.84 samples/sec#011loss=1.604297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[310] avg_epoch_loss=2.066571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=310 train loss <loss>=1.6673192739486695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [310]#011Speed: 530.16 samples/sec#011loss=1.667319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[315] avg_epoch_loss=2.061965\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=315 train loss <loss>=1.7755264520645142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [315]#011Speed: 798.05 samples/sec#011loss=1.775526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[320] avg_epoch_loss=2.136728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=320 train loss <loss>=6.861711764335633\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [320]#011Speed: 833.18 samples/sec#011loss=6.861712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch[325] avg_epoch_loss=2.130938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=325 train loss <loss>=1.7592074871063232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:02 INFO 140281140962944] Epoch[0] Batch [325]#011Speed: 1224.07 samples/sec#011loss=1.759207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[330] avg_epoch_loss=2.127709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=330 train loss <loss>=1.9172049760818481\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [330]#011Speed: 823.47 samples/sec#011loss=1.917205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[335] avg_epoch_loss=2.126024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=335 train loss <loss>=2.01447536945343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [335]#011Speed: 1367.52 samples/sec#011loss=2.014475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[340] avg_epoch_loss=2.123646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=340 train loss <loss>=1.9638386249542237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [340]#011Speed: 818.07 samples/sec#011loss=1.963839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[345] avg_epoch_loss=2.119917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=345 train loss <loss>=1.8656052827835083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [345]#011Speed: 1253.32 samples/sec#011loss=1.865605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[350] avg_epoch_loss=2.116175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=350 train loss <loss>=1.8572309970855714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [350]#011Speed: 850.90 samples/sec#011loss=1.857231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch[355] avg_epoch_loss=2.112205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=355 train loss <loss>=1.8334973573684692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:03 INFO 140281140962944] Epoch[0] Batch [355]#011Speed: 1327.34 samples/sec#011loss=1.833497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[360] avg_epoch_loss=2.107910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=360 train loss <loss>=1.802099919319153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [360]#011Speed: 825.78 samples/sec#011loss=1.802100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[365] avg_epoch_loss=2.102364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=365 train loss <loss>=1.7019759893417359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [365]#011Speed: 871.12 samples/sec#011loss=1.701976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[370] avg_epoch_loss=2.095232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=370 train loss <loss>=1.5731580018997193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [370]#011Speed: 487.62 samples/sec#011loss=1.573158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch[375] avg_epoch_loss=2.089086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=375 train loss <loss>=1.6330088138580323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:04 INFO 140281140962944] Epoch[0] Batch [375]#011Speed: 803.01 samples/sec#011loss=1.633009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[380] avg_epoch_loss=2.083411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=380 train loss <loss>=1.6566533327102662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [380]#011Speed: 550.58 samples/sec#011loss=1.656653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[385] avg_epoch_loss=2.075975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=385 train loss <loss>=1.5094160079956054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [385]#011Speed: 1165.64 samples/sec#011loss=1.509416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[390] avg_epoch_loss=2.068005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=390 train loss <loss>=1.4526726245880126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [390]#011Speed: 857.11 samples/sec#011loss=1.452673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[395] avg_epoch_loss=2.061293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=395 train loss <loss>=1.5364232540130616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [395]#011Speed: 1363.51 samples/sec#011loss=1.536423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch[400] avg_epoch_loss=2.054233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=400 train loss <loss>=1.4951149463653564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:05 INFO 140281140962944] Epoch[0] Batch [400]#011Speed: 510.48 samples/sec#011loss=1.495115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[405] avg_epoch_loss=2.046635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=405 train loss <loss>=1.4372469186782837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [405]#011Speed: 803.92 samples/sec#011loss=1.437247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[410] avg_epoch_loss=2.043941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=410 train loss <loss>=1.8252071619033814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [410]#011Speed: 506.29 samples/sec#011loss=1.825207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[415] avg_epoch_loss=2.042814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=415 train loss <loss>=1.9501867055892945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [415]#011Speed: 581.33 samples/sec#011loss=1.950187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch[420] avg_epoch_loss=2.038569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=420 train loss <loss>=1.685364055633545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:06 INFO 140281140962944] Epoch[0] Batch [420]#011Speed: 437.04 samples/sec#011loss=1.685364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch[425] avg_epoch_loss=2.035098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=425 train loss <loss>=1.7428502559661865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch [425]#011Speed: 639.74 samples/sec#011loss=1.742850\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch[430] avg_epoch_loss=2.030740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=430 train loss <loss>=1.6594168901443482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch [430]#011Speed: 416.75 samples/sec#011loss=1.659417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch[435] avg_epoch_loss=2.026942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=435 train loss <loss>=1.6995966196060182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:07 INFO 140281140962944] Epoch[0] Batch [435]#011Speed: 714.23 samples/sec#011loss=1.699597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[440] avg_epoch_loss=2.023175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=440 train loss <loss>=1.6946352481842042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [440]#011Speed: 677.22 samples/sec#011loss=1.694635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[445] avg_epoch_loss=2.018560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=445 train loss <loss>=1.6115394592285157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [445]#011Speed: 1224.38 samples/sec#011loss=1.611539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[450] avg_epoch_loss=2.012465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=450 train loss <loss>=1.4687692642211914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [450]#011Speed: 856.14 samples/sec#011loss=1.468769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[455] avg_epoch_loss=2.007270\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=455 train loss <loss>=1.5387062549591064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [455]#011Speed: 1310.53 samples/sec#011loss=1.538706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[460] avg_epoch_loss=2.001341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=460 train loss <loss>=1.4606382608413697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [460]#011Speed: 813.20 samples/sec#011loss=1.460638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch[465] avg_epoch_loss=1.996224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=465 train loss <loss>=1.5244105577468872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:08 INFO 140281140962944] Epoch[0] Batch [465]#011Speed: 1293.00 samples/sec#011loss=1.524411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[470] avg_epoch_loss=1.991548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=470 train loss <loss>=1.5557206630706788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [470]#011Speed: 719.64 samples/sec#011loss=1.555721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[475] avg_epoch_loss=1.985435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=475 train loss <loss>=1.4095767498016358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [475]#011Speed: 1285.00 samples/sec#011loss=1.409577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[480] avg_epoch_loss=1.978741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=480 train loss <loss>=1.3414634466171265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [480]#011Speed: 814.65 samples/sec#011loss=1.341463\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[485] avg_epoch_loss=1.972810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=485 train loss <loss>=1.4023170709609984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [485]#011Speed: 1333.74 samples/sec#011loss=1.402317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[490] avg_epoch_loss=1.969359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=490 train loss <loss>=1.633875799179077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [490]#011Speed: 777.01 samples/sec#011loss=1.633876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch[495] avg_epoch_loss=1.965981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=495 train loss <loss>=1.6342413425445557\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:09 INFO 140281140962944] Epoch[0] Batch [495]#011Speed: 1310.91 samples/sec#011loss=1.634241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[500] avg_epoch_loss=1.959264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=500 train loss <loss>=1.2930211544036865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [500]#011Speed: 789.81 samples/sec#011loss=1.293021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[505] avg_epoch_loss=1.956631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=505 train loss <loss>=1.692733359336853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [505]#011Speed: 1331.66 samples/sec#011loss=1.692733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[510] avg_epoch_loss=1.950971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=510 train loss <loss>=1.3782354593276978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [510]#011Speed: 817.68 samples/sec#011loss=1.378235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[515] avg_epoch_loss=1.945114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=515 train loss <loss>=1.3465110301971435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [515]#011Speed: 1342.75 samples/sec#011loss=1.346511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[520] avg_epoch_loss=1.939237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=520 train loss <loss>=1.3327265739440919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [520]#011Speed: 773.21 samples/sec#011loss=1.332727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch[525] avg_epoch_loss=1.935257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=525 train loss <loss>=1.5205334186553956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:10 INFO 140281140962944] Epoch[0] Batch [525]#011Speed: 1352.41 samples/sec#011loss=1.520533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[530] avg_epoch_loss=1.930956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=530 train loss <loss>=1.4785178661346436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [530]#011Speed: 842.52 samples/sec#011loss=1.478518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[535] avg_epoch_loss=1.927342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=535 train loss <loss>=1.5435444593429566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [535]#011Speed: 1305.92 samples/sec#011loss=1.543544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[540] avg_epoch_loss=1.923324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=540 train loss <loss>=1.4925101041793822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [540]#011Speed: 556.04 samples/sec#011loss=1.492510\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[545] avg_epoch_loss=1.918348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=545 train loss <loss>=1.3799579620361329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [545]#011Speed: 865.52 samples/sec#011loss=1.379958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch[550] avg_epoch_loss=1.913447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, batch=550 train loss <loss>=1.3782785177230834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Epoch[0] Batch [550]#011Speed: 575.87 samples/sec#011loss=1.378279\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] processed a total of 17673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717230.8316145, \"EndTime\": 1620717251.928023, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 21096.277713775635, \"count\": 1, \"min\": 21096.277713775635, \"max\": 21096.277713775635}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=837.7220895257026 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=0, train loss <loss>=1.9114706076506465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:11 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_1425e237-4baf-4d26-94fa-48405fb2084c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717251.928198, \"EndTime\": 1620717251.9401839, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 11.311769485473633, \"count\": 1, \"min\": 11.311769485473633, \"max\": 11.311769485473633}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[0] avg_epoch_loss=1.369514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.3695135116577148\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[5] avg_epoch_loss=1.263467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.263467252254486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [5]#011Speed: 1315.05 samples/sec#011loss=1.263467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[10] avg_epoch_loss=1.302598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=1.3495543003082275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [10]#011Speed: 799.28 samples/sec#011loss=1.349554\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[15] avg_epoch_loss=1.343551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=1.4336491346359252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [15]#011Speed: 1335.10 samples/sec#011loss=1.433649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[20] avg_epoch_loss=1.387540\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=1.5283031463623047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [20]#011Speed: 841.38 samples/sec#011loss=1.528303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch[25] avg_epoch_loss=1.399762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=1.4510964393615722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:12 INFO 140281140962944] Epoch[1] Batch [25]#011Speed: 1167.03 samples/sec#011loss=1.451096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[30] avg_epoch_loss=1.408250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=1.4523878812789917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [30]#011Speed: 841.17 samples/sec#011loss=1.452388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[35] avg_epoch_loss=1.463595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=1.8067344427108765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [35]#011Speed: 1358.36 samples/sec#011loss=1.806734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[40] avg_epoch_loss=1.493730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=1.7107026338577271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [40]#011Speed: 850.72 samples/sec#011loss=1.710703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[45] avg_epoch_loss=1.515551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=1.6944804906845092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [45]#011Speed: 1367.47 samples/sec#011loss=1.694480\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[50] avg_epoch_loss=1.521246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=1.5736440420150757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [50]#011Speed: 849.82 samples/sec#011loss=1.573644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[55] avg_epoch_loss=1.514277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=1.4431875467300415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [55]#011Speed: 1271.46 samples/sec#011loss=1.443188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch[60] avg_epoch_loss=1.518559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=1.5665199041366578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:13 INFO 140281140962944] Epoch[1] Batch [60]#011Speed: 840.61 samples/sec#011loss=1.566520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[65] avg_epoch_loss=1.531600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=1.69069664478302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [65]#011Speed: 1314.84 samples/sec#011loss=1.690697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[70] avg_epoch_loss=1.530597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=1.5173661947250365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [70]#011Speed: 829.08 samples/sec#011loss=1.517366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[75] avg_epoch_loss=1.532687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=1.5623605012893678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [75]#011Speed: 1278.62 samples/sec#011loss=1.562361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[80] avg_epoch_loss=1.533323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=1.542988395690918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [80]#011Speed: 844.37 samples/sec#011loss=1.542988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[85] avg_epoch_loss=1.528975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=1.458538866043091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [85]#011Speed: 1337.46 samples/sec#011loss=1.458539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch[90] avg_epoch_loss=1.577565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=2.4133167266845703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:14 INFO 140281140962944] Epoch[1] Batch [90]#011Speed: 796.70 samples/sec#011loss=2.413317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[95] avg_epoch_loss=1.570816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=1.447972559928894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [95]#011Speed: 1349.40 samples/sec#011loss=1.447973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[100] avg_epoch_loss=1.563253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=1.4180488348007203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [100]#011Speed: 848.43 samples/sec#011loss=1.418049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[105] avg_epoch_loss=1.555073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=1.3898352146148683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [105]#011Speed: 1275.37 samples/sec#011loss=1.389835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[110] avg_epoch_loss=1.561493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=1.6975998878479004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [110]#011Speed: 827.82 samples/sec#011loss=1.697600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[115] avg_epoch_loss=1.556779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=1.452137565612793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [115]#011Speed: 1366.56 samples/sec#011loss=1.452138\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[120] avg_epoch_loss=1.550063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=1.3942543268203735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [120]#011Speed: 773.64 samples/sec#011loss=1.394254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch[125] avg_epoch_loss=1.546719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=1.4657721281051637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:15 INFO 140281140962944] Epoch[1] Batch [125]#011Speed: 1290.12 samples/sec#011loss=1.465772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[130] avg_epoch_loss=1.539504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=1.3576850891113281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [130]#011Speed: 820.80 samples/sec#011loss=1.357685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[135] avg_epoch_loss=1.532305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=1.3436964511871339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [135]#011Speed: 1371.94 samples/sec#011loss=1.343696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[140] avg_epoch_loss=1.523429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=1.28200044631958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [140]#011Speed: 819.91 samples/sec#011loss=1.282000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[145] avg_epoch_loss=1.524857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=1.5651230096817017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [145]#011Speed: 1332.60 samples/sec#011loss=1.565123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[150] avg_epoch_loss=1.521715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=1.4299713373184204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [150]#011Speed: 727.42 samples/sec#011loss=1.429971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch[155] avg_epoch_loss=1.526253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=1.663305926322937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:16 INFO 140281140962944] Epoch[1] Batch [155]#011Speed: 1031.03 samples/sec#011loss=1.663306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[160] avg_epoch_loss=1.526920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=1.5477361917495727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [160]#011Speed: 625.40 samples/sec#011loss=1.547736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[165] avg_epoch_loss=1.528751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=1.5877223014831543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [165]#011Speed: 1343.30 samples/sec#011loss=1.587722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[170] avg_epoch_loss=1.528774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=1.5295167684555053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [170]#011Speed: 808.53 samples/sec#011loss=1.529517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[175] avg_epoch_loss=1.526317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=1.442301082611084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [175]#011Speed: 1354.42 samples/sec#011loss=1.442301\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[180] avg_epoch_loss=1.522830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=1.4000888347625733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [180]#011Speed: 786.15 samples/sec#011loss=1.400089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch[185] avg_epoch_loss=1.523610\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=1.5518368482589722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:17 INFO 140281140962944] Epoch[1] Batch [185]#011Speed: 1318.69 samples/sec#011loss=1.551837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[190] avg_epoch_loss=1.525922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=1.611915612220764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [190]#011Speed: 832.56 samples/sec#011loss=1.611916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[195] avg_epoch_loss=1.535303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=1.8936836481094361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [195]#011Speed: 1363.73 samples/sec#011loss=1.893684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[200] avg_epoch_loss=1.653113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=6.271257901191712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [200]#011Speed: 851.69 samples/sec#011loss=6.271258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[205] avg_epoch_loss=1.657066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=1.8159664869308472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [205]#011Speed: 1306.37 samples/sec#011loss=1.815966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[210] avg_epoch_loss=1.662772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=1.8978551626205444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [210]#011Speed: 840.91 samples/sec#011loss=1.897855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch[215] avg_epoch_loss=1.667641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=1.8731024503707885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:18 INFO 140281140962944] Epoch[1] Batch [215]#011Speed: 1243.37 samples/sec#011loss=1.873102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[220] avg_epoch_loss=1.671303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=1.8295164585113526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [220]#011Speed: 850.01 samples/sec#011loss=1.829516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[225] avg_epoch_loss=1.676344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=1.8991571187973022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [225]#011Speed: 1353.20 samples/sec#011loss=1.899157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[230] avg_epoch_loss=1.678243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=1.7640895605087281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [230]#011Speed: 678.33 samples/sec#011loss=1.764090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[235] avg_epoch_loss=1.678691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=1.6993945598602296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [235]#011Speed: 1364.86 samples/sec#011loss=1.699395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[240] avg_epoch_loss=1.677861\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=1.6386559724807739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [240]#011Speed: 862.74 samples/sec#011loss=1.638656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch[245] avg_epoch_loss=1.675647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=1.568963885307312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:19 INFO 140281140962944] Epoch[1] Batch [245]#011Speed: 1257.68 samples/sec#011loss=1.568964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[250] avg_epoch_loss=1.670945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=1.4396028995513916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [250]#011Speed: 801.01 samples/sec#011loss=1.439603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[255] avg_epoch_loss=1.667560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=1.4976226329803466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [255]#011Speed: 1319.00 samples/sec#011loss=1.497623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[260] avg_epoch_loss=1.662022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=1.3784498214721679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [260]#011Speed: 802.18 samples/sec#011loss=1.378450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[265] avg_epoch_loss=1.661418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=1.629911518096924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [265]#011Speed: 1363.43 samples/sec#011loss=1.629912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[270] avg_epoch_loss=1.661936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=270 train loss <loss>=1.6894856929779052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [270]#011Speed: 850.08 samples/sec#011loss=1.689486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch[275] avg_epoch_loss=1.683916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=275 train loss <loss>=2.875211787223816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:20 INFO 140281140962944] Epoch[1] Batch [275]#011Speed: 1235.59 samples/sec#011loss=2.875212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[280] avg_epoch_loss=1.679892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=280 train loss <loss>=1.457804274559021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [280]#011Speed: 828.17 samples/sec#011loss=1.457804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[285] avg_epoch_loss=1.676648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=285 train loss <loss>=1.4943412780761718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [285]#011Speed: 1353.15 samples/sec#011loss=1.494341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[290] avg_epoch_loss=1.673689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=290 train loss <loss>=1.504419469833374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [290]#011Speed: 844.21 samples/sec#011loss=1.504419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[295] avg_epoch_loss=1.673634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=295 train loss <loss>=1.6704499483108521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [295]#011Speed: 1320.13 samples/sec#011loss=1.670450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[300] avg_epoch_loss=1.672054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=300 train loss <loss>=1.5784913539886474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [300]#011Speed: 855.48 samples/sec#011loss=1.578491\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[305] avg_epoch_loss=1.671022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=305 train loss <loss>=1.6088905811309815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [305]#011Speed: 1334.45 samples/sec#011loss=1.608891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch[310] avg_epoch_loss=1.667113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=310 train loss <loss>=1.427865481376648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:21 INFO 140281140962944] Epoch[1] Batch [310]#011Speed: 800.91 samples/sec#011loss=1.427865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[315] avg_epoch_loss=1.664361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=315 train loss <loss>=1.4931926727294922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [315]#011Speed: 1141.69 samples/sec#011loss=1.493193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[320] avg_epoch_loss=1.669447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=320 train loss <loss>=1.9908847093582154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [320]#011Speed: 692.36 samples/sec#011loss=1.990885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[325] avg_epoch_loss=1.665821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=325 train loss <loss>=1.4330280780792237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [325]#011Speed: 1351.89 samples/sec#011loss=1.433028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[330] avg_epoch_loss=1.663912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=330 train loss <loss>=1.5394382715225219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [330]#011Speed: 847.25 samples/sec#011loss=1.539438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[335] avg_epoch_loss=1.660347\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=335 train loss <loss>=1.4243502616882324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [335]#011Speed: 1328.47 samples/sec#011loss=1.424350\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch[340] avg_epoch_loss=1.655902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=340 train loss <loss>=1.3572373390197754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:22 INFO 140281140962944] Epoch[1] Batch [340]#011Speed: 783.35 samples/sec#011loss=1.357237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[345] avg_epoch_loss=1.650312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=345 train loss <loss>=1.269053292274475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [345]#011Speed: 1302.82 samples/sec#011loss=1.269053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[350] avg_epoch_loss=1.646858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=350 train loss <loss>=1.4078591823577882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [350]#011Speed: 775.89 samples/sec#011loss=1.407859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[355] avg_epoch_loss=1.642359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=355 train loss <loss>=1.3265487909317017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [355]#011Speed: 1361.88 samples/sec#011loss=1.326549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[360] avg_epoch_loss=1.641760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=360 train loss <loss>=1.5990564584732057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [360]#011Speed: 847.95 samples/sec#011loss=1.599056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[365] avg_epoch_loss=1.637926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=365 train loss <loss>=1.361120581626892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [365]#011Speed: 1325.73 samples/sec#011loss=1.361121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch[370] avg_epoch_loss=1.633746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=370 train loss <loss>=1.3278100728988647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:23 INFO 140281140962944] Epoch[1] Batch [370]#011Speed: 801.87 samples/sec#011loss=1.327810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[375] avg_epoch_loss=1.628802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=375 train loss <loss>=1.2619062662124634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [375]#011Speed: 1317.38 samples/sec#011loss=1.261906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[380] avg_epoch_loss=1.626597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=380 train loss <loss>=1.4608033418655395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [380]#011Speed: 833.20 samples/sec#011loss=1.460803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[385] avg_epoch_loss=1.625836\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=385 train loss <loss>=1.5678786754608154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [385]#011Speed: 1331.31 samples/sec#011loss=1.567879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[390] avg_epoch_loss=1.622939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=390 train loss <loss>=1.3992878675460816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [390]#011Speed: 825.01 samples/sec#011loss=1.399288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[395] avg_epoch_loss=1.622595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=395 train loss <loss>=1.5956680297851562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [395]#011Speed: 1353.73 samples/sec#011loss=1.595668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch[400] avg_epoch_loss=1.624224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=400 train loss <loss>=1.7532394409179688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:24 INFO 140281140962944] Epoch[1] Batch [400]#011Speed: 849.83 samples/sec#011loss=1.753239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[405] avg_epoch_loss=1.623553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=405 train loss <loss>=1.5697765350341797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [405]#011Speed: 1187.18 samples/sec#011loss=1.569777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[410] avg_epoch_loss=1.623635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=410 train loss <loss>=1.6302501678466796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [410]#011Speed: 843.81 samples/sec#011loss=1.630250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[415] avg_epoch_loss=1.622176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=415 train loss <loss>=1.5022634983062744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [415]#011Speed: 1284.78 samples/sec#011loss=1.502263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[420] avg_epoch_loss=1.619728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=420 train loss <loss>=1.4160707473754883\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [420]#011Speed: 844.32 samples/sec#011loss=1.416071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[425] avg_epoch_loss=1.620753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=425 train loss <loss>=1.707046341896057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [425]#011Speed: 1361.08 samples/sec#011loss=1.707046\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[430] avg_epoch_loss=1.619268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=430 train loss <loss>=1.4927309513092042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [430]#011Speed: 838.08 samples/sec#011loss=1.492731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch[435] avg_epoch_loss=1.617256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=435 train loss <loss>=1.4438570976257323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:25 INFO 140281140962944] Epoch[1] Batch [435]#011Speed: 1222.10 samples/sec#011loss=1.443857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[440] avg_epoch_loss=1.617207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=440 train loss <loss>=1.6128944873809814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [440]#011Speed: 842.23 samples/sec#011loss=1.612894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[445] avg_epoch_loss=1.614905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=445 train loss <loss>=1.4118463039398192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [445]#011Speed: 1335.02 samples/sec#011loss=1.411846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[450] avg_epoch_loss=1.612143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=450 train loss <loss>=1.3658392906188965\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [450]#011Speed: 851.12 samples/sec#011loss=1.365839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[455] avg_epoch_loss=1.611004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=455 train loss <loss>=1.5082474946975708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [455]#011Speed: 1345.65 samples/sec#011loss=1.508247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[460] avg_epoch_loss=1.612243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=460 train loss <loss>=1.7251936435699462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [460]#011Speed: 850.68 samples/sec#011loss=1.725194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch[465] avg_epoch_loss=1.610813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=465 train loss <loss>=1.4789905786514281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:26 INFO 140281140962944] Epoch[1] Batch [465]#011Speed: 1358.36 samples/sec#011loss=1.478991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[470] avg_epoch_loss=1.617401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=470 train loss <loss>=2.2313797950744627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [470]#011Speed: 813.40 samples/sec#011loss=2.231380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[475] avg_epoch_loss=1.616021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=475 train loss <loss>=1.4860722541809082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [475]#011Speed: 1352.90 samples/sec#011loss=1.486072\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[480] avg_epoch_loss=1.616529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=480 train loss <loss>=1.6648213386535644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [480]#011Speed: 674.00 samples/sec#011loss=1.664821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[485] avg_epoch_loss=1.615570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=485 train loss <loss>=1.5233737230300903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [485]#011Speed: 1343.00 samples/sec#011loss=1.523374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[490] avg_epoch_loss=1.613008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=490 train loss <loss>=1.363983392715454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [490]#011Speed: 841.79 samples/sec#011loss=1.363983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch[495] avg_epoch_loss=1.610116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=495 train loss <loss>=1.3261117458343505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:27 INFO 140281140962944] Epoch[1] Batch [495]#011Speed: 1348.73 samples/sec#011loss=1.326112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[500] avg_epoch_loss=1.608609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=500 train loss <loss>=1.4591218471527099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [500]#011Speed: 749.16 samples/sec#011loss=1.459122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[505] avg_epoch_loss=1.605476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=505 train loss <loss>=1.2915805578231812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [505]#011Speed: 1311.71 samples/sec#011loss=1.291581\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[510] avg_epoch_loss=1.604800\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=510 train loss <loss>=1.5363088607788087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [510]#011Speed: 834.31 samples/sec#011loss=1.536309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[515] avg_epoch_loss=1.602785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=515 train loss <loss>=1.3968477964401245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [515]#011Speed: 1347.23 samples/sec#011loss=1.396848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[520] avg_epoch_loss=1.600252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=520 train loss <loss>=1.3389395475387573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [520]#011Speed: 832.82 samples/sec#011loss=1.338940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch[525] avg_epoch_loss=1.596674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=525 train loss <loss>=1.223785924911499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:28 INFO 140281140962944] Epoch[1] Batch [525]#011Speed: 1348.80 samples/sec#011loss=1.223786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[530] avg_epoch_loss=1.592983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=530 train loss <loss>=1.2047465801239015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [530]#011Speed: 798.44 samples/sec#011loss=1.204747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[535] avg_epoch_loss=1.590833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=535 train loss <loss>=1.3624425888061524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [535]#011Speed: 1369.39 samples/sec#011loss=1.362443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[540] avg_epoch_loss=1.588823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=540 train loss <loss>=1.3733328819274901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [540]#011Speed: 843.90 samples/sec#011loss=1.373333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[545] avg_epoch_loss=1.587583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=545 train loss <loss>=1.4534337043762207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [545]#011Speed: 1318.96 samples/sec#011loss=1.453434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch[550] avg_epoch_loss=1.583761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, batch=550 train loss <loss>=1.1663749933242797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[1] Batch [550]#011Speed: 1272.95 samples/sec#011loss=1.166375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] processed a total of 17624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717251.9402602, \"EndTime\": 1620717269.5696063, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17629.251718521118, \"count\": 1, \"min\": 17629.251718521118, \"max\": 17629.251718521118}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=999.6948553477905 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.5837606747656683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_b61a6d21-ea94-4364-a26b-38e70bf85bc4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717269.5696685, \"EndTime\": 1620717269.5796854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.355306625366211, \"count\": 1, \"min\": 9.355306625366211, \"max\": 9.355306625366211}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch[0] avg_epoch_loss=1.138234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.1382344961166382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch[5] avg_epoch_loss=1.260678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.2606775959332783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch [5]#011Speed: 1353.52 samples/sec#011loss=1.260678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch[10] avg_epoch_loss=1.266130\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=1.2726739645004272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:29 INFO 140281140962944] Epoch[2] Batch [10]#011Speed: 861.31 samples/sec#011loss=1.272674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[15] avg_epoch_loss=1.270963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=1.2815942764282227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [15]#011Speed: 1200.97 samples/sec#011loss=1.281594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[20] avg_epoch_loss=1.266155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=1.250770592689514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [20]#011Speed: 825.97 samples/sec#011loss=1.250771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[25] avg_epoch_loss=1.284785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=1.3630294799804688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [25]#011Speed: 1104.94 samples/sec#011loss=1.363029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[30] avg_epoch_loss=1.295014\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=1.3482066869735718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [30]#011Speed: 834.26 samples/sec#011loss=1.348207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[35] avg_epoch_loss=1.309439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=1.3988702058792115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [35]#011Speed: 1338.17 samples/sec#011loss=1.398870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch[40] avg_epoch_loss=1.313752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=1.3448086738586427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:30 INFO 140281140962944] Epoch[2] Batch [40]#011Speed: 821.50 samples/sec#011loss=1.344809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[45] avg_epoch_loss=1.317590\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=1.3490566253662108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [45]#011Speed: 1216.02 samples/sec#011loss=1.349057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[50] avg_epoch_loss=1.324175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=1.3847608804702758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [50]#011Speed: 837.50 samples/sec#011loss=1.384761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[55] avg_epoch_loss=1.328741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=1.375312042236328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [55]#011Speed: 1336.87 samples/sec#011loss=1.375312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[60] avg_epoch_loss=1.322438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=1.2518461704254151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [60]#011Speed: 840.55 samples/sec#011loss=1.251846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[65] avg_epoch_loss=1.323277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=1.3335097551345825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [65]#011Speed: 1302.08 samples/sec#011loss=1.333510\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch[70] avg_epoch_loss=1.328642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=1.3994640111923218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:31 INFO 140281140962944] Epoch[2] Batch [70]#011Speed: 813.30 samples/sec#011loss=1.399464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[75] avg_epoch_loss=1.319889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=1.1955992460250855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [75]#011Speed: 1336.27 samples/sec#011loss=1.195599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[80] avg_epoch_loss=1.332848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=1.5298214197158813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [80]#011Speed: 786.06 samples/sec#011loss=1.529821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[85] avg_epoch_loss=1.411082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=2.6784728288650514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [85]#011Speed: 1358.38 samples/sec#011loss=2.678473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[90] avg_epoch_loss=1.452391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=2.1628992557525635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [90]#011Speed: 658.63 samples/sec#011loss=2.162899\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[95] avg_epoch_loss=1.460977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=1.6172483444213868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [95]#011Speed: 1238.75 samples/sec#011loss=1.617248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch[100] avg_epoch_loss=1.484386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=1.9338458061218262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:32 INFO 140281140962944] Epoch[2] Batch [100]#011Speed: 839.66 samples/sec#011loss=1.933846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[105] avg_epoch_loss=1.495211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=1.7138755798339844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [105]#011Speed: 1346.70 samples/sec#011loss=1.713876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[110] avg_epoch_loss=1.509535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=1.8131894588470459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [110]#011Speed: 785.59 samples/sec#011loss=1.813189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[115] avg_epoch_loss=1.516926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=1.6810055017471313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [115]#011Speed: 1333.36 samples/sec#011loss=1.681006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[120] avg_epoch_loss=1.520541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=1.6044179916381835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [120]#011Speed: 848.86 samples/sec#011loss=1.604418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[125] avg_epoch_loss=1.520589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=1.5217445135116576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [125]#011Speed: 1375.44 samples/sec#011loss=1.521745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[130] avg_epoch_loss=1.525867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=1.6588895797729493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [130]#011Speed: 859.57 samples/sec#011loss=1.658890\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch[135] avg_epoch_loss=1.520211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=1.3720224857330323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:33 INFO 140281140962944] Epoch[2] Batch [135]#011Speed: 1309.83 samples/sec#011loss=1.372022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[140] avg_epoch_loss=1.565724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=2.8036691427230833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [140]#011Speed: 786.31 samples/sec#011loss=2.803669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[145] avg_epoch_loss=1.604069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=2.685393738746643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [145]#011Speed: 1320.21 samples/sec#011loss=2.685394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[150] avg_epoch_loss=1.607658\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=1.7124679803848266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [150]#011Speed: 799.56 samples/sec#011loss=1.712468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[155] avg_epoch_loss=1.610776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=1.704916501045227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [155]#011Speed: 1365.07 samples/sec#011loss=1.704917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[160] avg_epoch_loss=1.611923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=1.6477223634719849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [160]#011Speed: 858.15 samples/sec#011loss=1.647722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch[165] avg_epoch_loss=1.613485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=1.6637871026992799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:34 INFO 140281140962944] Epoch[2] Batch [165]#011Speed: 1331.21 samples/sec#011loss=1.663787\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[170] avg_epoch_loss=1.614954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=1.6637309312820434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [170]#011Speed: 747.35 samples/sec#011loss=1.663731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[175] avg_epoch_loss=1.614056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=1.58334379196167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [175]#011Speed: 1349.77 samples/sec#011loss=1.583344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[180] avg_epoch_loss=1.610185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=1.4739161729812622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [180]#011Speed: 793.38 samples/sec#011loss=1.473916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[185] avg_epoch_loss=1.606306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=1.4658845901489257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [185]#011Speed: 1369.34 samples/sec#011loss=1.465885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[190] avg_epoch_loss=1.602217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=1.4501205444335938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [190]#011Speed: 847.77 samples/sec#011loss=1.450121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch[195] avg_epoch_loss=1.627498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=2.5932279586791993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:35 INFO 140281140962944] Epoch[2] Batch [195]#011Speed: 1369.40 samples/sec#011loss=2.593228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[200] avg_epoch_loss=1.627756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=1.6378451824188232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [200]#011Speed: 826.76 samples/sec#011loss=1.637845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[205] avg_epoch_loss=1.625394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=1.5304742336273194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [205]#011Speed: 1204.75 samples/sec#011loss=1.530474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[210] avg_epoch_loss=1.622722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=1.5126061201095582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [210]#011Speed: 832.74 samples/sec#011loss=1.512606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[215] avg_epoch_loss=1.617128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=1.3810546398162842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [215]#011Speed: 1326.29 samples/sec#011loss=1.381055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[220] avg_epoch_loss=1.611857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=1.384175181388855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [220]#011Speed: 816.13 samples/sec#011loss=1.384175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch[225] avg_epoch_loss=1.609363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=1.4991249561309814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:36 INFO 140281140962944] Epoch[2] Batch [225]#011Speed: 1357.58 samples/sec#011loss=1.499125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[230] avg_epoch_loss=1.602616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=1.297652268409729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [230]#011Speed: 856.90 samples/sec#011loss=1.297652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[235] avg_epoch_loss=1.594669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=1.2275192975997924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [235]#011Speed: 1349.43 samples/sec#011loss=1.227519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[240] avg_epoch_loss=1.589211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=1.3315688371658325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [240]#011Speed: 780.71 samples/sec#011loss=1.331569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[245] avg_epoch_loss=1.581908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=1.229916524887085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [245]#011Speed: 1349.13 samples/sec#011loss=1.229917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[250] avg_epoch_loss=1.576474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=1.3091049194335938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [250]#011Speed: 630.60 samples/sec#011loss=1.309105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch[255] avg_epoch_loss=1.570753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=1.2835645437240601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:37 INFO 140281140962944] Epoch[2] Batch [255]#011Speed: 1366.34 samples/sec#011loss=1.283565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[260] avg_epoch_loss=1.595149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=2.844254994392395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [260]#011Speed: 831.76 samples/sec#011loss=2.844255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[265] avg_epoch_loss=1.604765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=2.1067097663879393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [265]#011Speed: 1354.15 samples/sec#011loss=2.106710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[270] avg_epoch_loss=1.603882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=270 train loss <loss>=1.5569177627563477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [270]#011Speed: 770.66 samples/sec#011loss=1.556918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[275] avg_epoch_loss=1.604486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=275 train loss <loss>=1.6371942043304444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [275]#011Speed: 1297.27 samples/sec#011loss=1.637194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[280] avg_epoch_loss=1.603492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=280 train loss <loss>=1.548640751838684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [280]#011Speed: 867.28 samples/sec#011loss=1.548641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[285] avg_epoch_loss=1.602930\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=285 train loss <loss>=1.5713683843612671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [285]#011Speed: 1331.47 samples/sec#011loss=1.571368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch[290] avg_epoch_loss=1.601855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=290 train loss <loss>=1.5403417825698853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:38 INFO 140281140962944] Epoch[2] Batch [290]#011Speed: 803.22 samples/sec#011loss=1.540342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[295] avg_epoch_loss=1.605443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=295 train loss <loss>=1.8142453670501708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [295]#011Speed: 1349.09 samples/sec#011loss=1.814245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[300] avg_epoch_loss=1.604054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=300 train loss <loss>=1.5218369245529175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [300]#011Speed: 774.52 samples/sec#011loss=1.521837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[305] avg_epoch_loss=1.605904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=305 train loss <loss>=1.7173028230667113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [305]#011Speed: 1295.98 samples/sec#011loss=1.717303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[310] avg_epoch_loss=1.603755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=310 train loss <loss>=1.4722387313842773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [310]#011Speed: 793.37 samples/sec#011loss=1.472239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[315] avg_epoch_loss=1.600152\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=315 train loss <loss>=1.376037049293518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [315]#011Speed: 1351.68 samples/sec#011loss=1.376037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch[320] avg_epoch_loss=1.596461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=320 train loss <loss>=1.3631415128707887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:39 INFO 140281140962944] Epoch[2] Batch [320]#011Speed: 831.42 samples/sec#011loss=1.363142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[325] avg_epoch_loss=1.591478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=325 train loss <loss>=1.2716187477111816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [325]#011Speed: 1286.35 samples/sec#011loss=1.271619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[330] avg_epoch_loss=1.586882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=330 train loss <loss>=1.2871933460235596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [330]#011Speed: 793.21 samples/sec#011loss=1.287193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[335] avg_epoch_loss=1.581532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=335 train loss <loss>=1.2273800373077393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [335]#011Speed: 1356.94 samples/sec#011loss=1.227380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[340] avg_epoch_loss=1.575381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=340 train loss <loss>=1.1620283603668213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [340]#011Speed: 824.61 samples/sec#011loss=1.162028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[345] avg_epoch_loss=1.569782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=345 train loss <loss>=1.1879348278045654\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [345]#011Speed: 1362.82 samples/sec#011loss=1.187935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch[350] avg_epoch_loss=1.565509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=350 train loss <loss>=1.269839334487915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:40 INFO 140281140962944] Epoch[2] Batch [350]#011Speed: 859.00 samples/sec#011loss=1.269839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[355] avg_epoch_loss=1.563498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=355 train loss <loss>=1.4222895145416259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [355]#011Speed: 1313.14 samples/sec#011loss=1.422290\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[360] avg_epoch_loss=1.559264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=360 train loss <loss>=1.257828450202942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [360]#011Speed: 857.00 samples/sec#011loss=1.257828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[365] avg_epoch_loss=1.554875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=365 train loss <loss>=1.2379504442214966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [365]#011Speed: 1271.09 samples/sec#011loss=1.237950\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[370] avg_epoch_loss=1.550876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=370 train loss <loss>=1.258167290687561\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [370]#011Speed: 843.04 samples/sec#011loss=1.258167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[375] avg_epoch_loss=1.547294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=375 train loss <loss>=1.2814867973327637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [375]#011Speed: 1346.08 samples/sec#011loss=1.281487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[380] avg_epoch_loss=1.544575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=380 train loss <loss>=1.3401232004165649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [380]#011Speed: 858.35 samples/sec#011loss=1.340123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch[385] avg_epoch_loss=1.541025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=385 train loss <loss>=1.2705149173736572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:41 INFO 140281140962944] Epoch[2] Batch [385]#011Speed: 1169.40 samples/sec#011loss=1.270515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[390] avg_epoch_loss=1.539009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=390 train loss <loss>=1.3833505868911744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [390]#011Speed: 512.57 samples/sec#011loss=1.383351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[395] avg_epoch_loss=1.536529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=395 train loss <loss>=1.3426605463027954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [395]#011Speed: 838.15 samples/sec#011loss=1.342661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[400] avg_epoch_loss=1.535774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=400 train loss <loss>=1.4759130001068115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [400]#011Speed: 607.90 samples/sec#011loss=1.475913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch[405] avg_epoch_loss=1.532938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=405 train loss <loss>=1.3054978370666503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:42 INFO 140281140962944] Epoch[2] Batch [405]#011Speed: 1026.86 samples/sec#011loss=1.305498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[410] avg_epoch_loss=1.533819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=410 train loss <loss>=1.6053376913070678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [410]#011Speed: 847.43 samples/sec#011loss=1.605338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[415] avg_epoch_loss=1.530127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=415 train loss <loss>=1.2266712427139281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [415]#011Speed: 1347.46 samples/sec#011loss=1.226671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[420] avg_epoch_loss=1.527686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=420 train loss <loss>=1.32463800907135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [420]#011Speed: 779.31 samples/sec#011loss=1.324638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[425] avg_epoch_loss=1.525772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=425 train loss <loss>=1.3646044254302978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [425]#011Speed: 1359.28 samples/sec#011loss=1.364604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[430] avg_epoch_loss=1.523520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=430 train loss <loss>=1.331591749191284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [430]#011Speed: 870.04 samples/sec#011loss=1.331592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[435] avg_epoch_loss=1.523813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=435 train loss <loss>=1.5490822792053223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch [435]#011Speed: 1331.74 samples/sec#011loss=1.549082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:43 INFO 140281140962944] Epoch[2] Batch[440] avg_epoch_loss=1.520161\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=440 train loss <loss>=1.201698398590088\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [440]#011Speed: 838.22 samples/sec#011loss=1.201698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[445] avg_epoch_loss=1.516341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=445 train loss <loss>=1.1794648885726928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [445]#011Speed: 1334.63 samples/sec#011loss=1.179465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[450] avg_epoch_loss=1.515253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=450 train loss <loss>=1.418145513534546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [450]#011Speed: 823.26 samples/sec#011loss=1.418146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[455] avg_epoch_loss=1.513436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=455 train loss <loss>=1.3495707750320434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [455]#011Speed: 1355.27 samples/sec#011loss=1.349571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[460] avg_epoch_loss=1.512128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=460 train loss <loss>=1.3928860902786255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [460]#011Speed: 702.03 samples/sec#011loss=1.392886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[465] avg_epoch_loss=1.517532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=465 train loss <loss>=2.015733790397644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [465]#011Speed: 1334.60 samples/sec#011loss=2.015734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch[470] avg_epoch_loss=1.514740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=470 train loss <loss>=1.2545839309692384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:44 INFO 140281140962944] Epoch[2] Batch [470]#011Speed: 843.01 samples/sec#011loss=1.254584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[475] avg_epoch_loss=1.512300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=475 train loss <loss>=1.282410168647766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [475]#011Speed: 1303.33 samples/sec#011loss=1.282410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[480] avg_epoch_loss=1.510003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=480 train loss <loss>=1.2912798881530763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [480]#011Speed: 737.54 samples/sec#011loss=1.291280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[485] avg_epoch_loss=1.507459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=485 train loss <loss>=1.2628020524978638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [485]#011Speed: 1304.22 samples/sec#011loss=1.262802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[490] avg_epoch_loss=1.503791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=490 train loss <loss>=1.1472304344177247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [490]#011Speed: 820.93 samples/sec#011loss=1.147230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[495] avg_epoch_loss=1.501488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=495 train loss <loss>=1.2753582715988159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [495]#011Speed: 1319.59 samples/sec#011loss=1.275358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch[500] avg_epoch_loss=1.498469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=500 train loss <loss>=1.1989265441894532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:45 INFO 140281140962944] Epoch[2] Batch [500]#011Speed: 862.83 samples/sec#011loss=1.198927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[505] avg_epoch_loss=1.499060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=505 train loss <loss>=1.558327865600586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [505]#011Speed: 1279.27 samples/sec#011loss=1.558328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[510] avg_epoch_loss=1.497684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=510 train loss <loss>=1.358445644378662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [510]#011Speed: 792.90 samples/sec#011loss=1.358446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[515] avg_epoch_loss=1.494996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=515 train loss <loss>=1.2202059984207154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [515]#011Speed: 1121.64 samples/sec#011loss=1.220206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[520] avg_epoch_loss=1.492254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=520 train loss <loss>=1.2093385219573975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [520]#011Speed: 837.29 samples/sec#011loss=1.209339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[525] avg_epoch_loss=1.488608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=525 train loss <loss>=1.108695125579834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [525]#011Speed: 1320.40 samples/sec#011loss=1.108695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch[530] avg_epoch_loss=1.488003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=530 train loss <loss>=1.4243282556533814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:46 INFO 140281140962944] Epoch[2] Batch [530]#011Speed: 819.34 samples/sec#011loss=1.424328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch[535] avg_epoch_loss=1.486387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=535 train loss <loss>=1.3147730112075806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch [535]#011Speed: 1351.90 samples/sec#011loss=1.314773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch[540] avg_epoch_loss=1.485291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=540 train loss <loss>=1.3678291082382201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch [540]#011Speed: 941.44 samples/sec#011loss=1.367829\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch[545] avg_epoch_loss=1.483052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, batch=545 train loss <loss>=1.2407281875610352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[2] Batch [545]#011Speed: 1297.14 samples/sec#011loss=1.240728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] processed a total of 17496 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717269.5797493, \"EndTime\": 1620717287.36247, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17782.611846923828, \"count\": 1, \"min\": 17782.611846923828, \"max\": 17782.611846923828}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=983.8718209640307 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.4823990312747153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_23fdd8a1-3754-49e6-81ab-0bc5fefc5b66-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717287.3625517, \"EndTime\": 1620717287.3730128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.72747802734375, \"count\": 1, \"min\": 9.72747802734375, \"max\": 9.72747802734375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[0] avg_epoch_loss=1.275267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=1.2752673625946045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[5] avg_epoch_loss=1.204551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=1.204550564289093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch [5]#011Speed: 1342.83 samples/sec#011loss=1.204551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[10] avg_epoch_loss=1.175234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=1.1400543451309204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch [10]#011Speed: 833.43 samples/sec#011loss=1.140054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch[15] avg_epoch_loss=1.158225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=1.1208057880401612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:47 INFO 140281140962944] Epoch[3] Batch [15]#011Speed: 991.21 samples/sec#011loss=1.120806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[20] avg_epoch_loss=1.140857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=1.0852767944335937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [20]#011Speed: 842.41 samples/sec#011loss=1.085277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[25] avg_epoch_loss=1.232954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=1.6197627544403077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [25]#011Speed: 1310.67 samples/sec#011loss=1.619763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[30] avg_epoch_loss=1.277770\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=1.5108116626739503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [30]#011Speed: 738.97 samples/sec#011loss=1.510812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[35] avg_epoch_loss=1.286101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=1.3377578258514404\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [35]#011Speed: 1331.30 samples/sec#011loss=1.337758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[40] avg_epoch_loss=1.300279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=1.4023576736450196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [40]#011Speed: 852.80 samples/sec#011loss=1.402358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch[45] avg_epoch_loss=1.287127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=1.179284405708313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:48 INFO 140281140962944] Epoch[3] Batch [45]#011Speed: 1320.87 samples/sec#011loss=1.179284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[50] avg_epoch_loss=1.298853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=1.4067265033721923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [50]#011Speed: 842.66 samples/sec#011loss=1.406727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[55] avg_epoch_loss=1.291573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=1.217314863204956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [55]#011Speed: 1323.15 samples/sec#011loss=1.217315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[60] avg_epoch_loss=1.291735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=1.2935492992401123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [60]#011Speed: 791.96 samples/sec#011loss=1.293549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[65] avg_epoch_loss=1.296957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=1.36067533493042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [65]#011Speed: 1295.42 samples/sec#011loss=1.360675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[70] avg_epoch_loss=1.289821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=1.1956242561340331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [70]#011Speed: 809.18 samples/sec#011loss=1.195624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch[75] avg_epoch_loss=1.302060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=1.4758437871932983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:49 INFO 140281140962944] Epoch[3] Batch [75]#011Speed: 1345.07 samples/sec#011loss=1.475844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[80] avg_epoch_loss=1.298612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=1.24620840549469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [80]#011Speed: 840.57 samples/sec#011loss=1.246208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[85] avg_epoch_loss=1.298541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=1.2973976135253906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [85]#011Speed: 1315.21 samples/sec#011loss=1.297398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[90] avg_epoch_loss=1.298078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=1.2901065587997436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [90]#011Speed: 841.28 samples/sec#011loss=1.290107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[95] avg_epoch_loss=1.294339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=1.2262929439544679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [95]#011Speed: 1123.91 samples/sec#011loss=1.226293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[100] avg_epoch_loss=1.292692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=1.2610651016235352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [100]#011Speed: 841.05 samples/sec#011loss=1.261065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[105] avg_epoch_loss=1.283112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=1.089599895477295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [105]#011Speed: 1340.76 samples/sec#011loss=1.089600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch[110] avg_epoch_loss=1.275815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=1.1211170434951783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:50 INFO 140281140962944] Epoch[3] Batch [110]#011Speed: 843.00 samples/sec#011loss=1.121117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[115] avg_epoch_loss=1.276049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=1.2812532186508179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [115]#011Speed: 1278.41 samples/sec#011loss=1.281253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[120] avg_epoch_loss=1.313714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=2.1875388860702514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [120]#011Speed: 847.04 samples/sec#011loss=2.187539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[125] avg_epoch_loss=1.315204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=1.351255679130554\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [125]#011Speed: 1201.71 samples/sec#011loss=1.351256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[130] avg_epoch_loss=1.313575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=1.2725213766098022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [130]#011Speed: 847.23 samples/sec#011loss=1.272521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[135] avg_epoch_loss=1.309758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=1.2097529888153076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [135]#011Speed: 1303.12 samples/sec#011loss=1.209753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch[140] avg_epoch_loss=1.305815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=1.1985737323760985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:51 INFO 140281140962944] Epoch[3] Batch [140]#011Speed: 833.20 samples/sec#011loss=1.198574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[145] avg_epoch_loss=1.308533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=1.3851855754852296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [145]#011Speed: 1319.74 samples/sec#011loss=1.385186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[150] avg_epoch_loss=1.336219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=2.144645643234253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [150]#011Speed: 847.43 samples/sec#011loss=2.144646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[155] avg_epoch_loss=1.335035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=1.2992839574813844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [155]#011Speed: 1359.32 samples/sec#011loss=1.299284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[160] avg_epoch_loss=1.333971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=1.3007646322250366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [160]#011Speed: 797.72 samples/sec#011loss=1.300765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[165] avg_epoch_loss=1.333292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=1.311422848701477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [165]#011Speed: 1315.41 samples/sec#011loss=1.311423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch[170] avg_epoch_loss=1.336272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=1.4352198839187622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:52 INFO 140281140962944] Epoch[3] Batch [170]#011Speed: 818.03 samples/sec#011loss=1.435220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[175] avg_epoch_loss=1.333539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=1.2400554180145265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [175]#011Speed: 943.77 samples/sec#011loss=1.240055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[180] avg_epoch_loss=1.328608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=1.1550403118133545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [180]#011Speed: 766.30 samples/sec#011loss=1.155040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[185] avg_epoch_loss=1.331436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=1.4338241815567017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [185]#011Speed: 1275.43 samples/sec#011loss=1.433824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[190] avg_epoch_loss=1.345155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=1.8554766654968262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [190]#011Speed: 761.10 samples/sec#011loss=1.855477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[195] avg_epoch_loss=1.358331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=1.86167254447937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [195]#011Speed: 1280.75 samples/sec#011loss=1.861673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch[200] avg_epoch_loss=1.362471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=1.5247608184814454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:53 INFO 140281140962944] Epoch[3] Batch [200]#011Speed: 847.35 samples/sec#011loss=1.524761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[205] avg_epoch_loss=1.368250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=1.600553321838379\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [205]#011Speed: 1333.05 samples/sec#011loss=1.600553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[210] avg_epoch_loss=1.372575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=1.5507522344589233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [210]#011Speed: 808.96 samples/sec#011loss=1.550752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[215] avg_epoch_loss=1.374514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=1.4563389539718627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [215]#011Speed: 1314.71 samples/sec#011loss=1.456339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[220] avg_epoch_loss=1.373733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=1.3400254249572754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [220]#011Speed: 751.15 samples/sec#011loss=1.340025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[225] avg_epoch_loss=1.371974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=1.2942049741744994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [225]#011Speed: 1299.02 samples/sec#011loss=1.294205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch[230] avg_epoch_loss=1.367840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=1.1810125589370728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:54 INFO 140281140962944] Epoch[3] Batch [230]#011Speed: 821.19 samples/sec#011loss=1.181013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[235] avg_epoch_loss=1.365039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=1.2356156826019287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [235]#011Speed: 1330.20 samples/sec#011loss=1.235616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[240] avg_epoch_loss=1.395523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=2.834377384185791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [240]#011Speed: 832.63 samples/sec#011loss=2.834377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[245] avg_epoch_loss=1.391571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=1.20106840133667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [245]#011Speed: 1366.38 samples/sec#011loss=1.201068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[250] avg_epoch_loss=1.389520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=1.2886189222335815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [250]#011Speed: 785.14 samples/sec#011loss=1.288619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[255] avg_epoch_loss=1.388455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=1.3350092411041259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [255]#011Speed: 1329.48 samples/sec#011loss=1.335009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[260] avg_epoch_loss=1.387695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=1.3487560749053955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [260]#011Speed: 851.08 samples/sec#011loss=1.348756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch[265] avg_epoch_loss=1.389315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=1.4738706350326538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:55 INFO 140281140962944] Epoch[3] Batch [265]#011Speed: 1359.49 samples/sec#011loss=1.473871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[270] avg_epoch_loss=1.392758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=270 train loss <loss>=1.5759284973144532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [270]#011Speed: 847.09 samples/sec#011loss=1.575928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[275] avg_epoch_loss=1.389857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=275 train loss <loss>=1.2326127767562867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [275]#011Speed: 1358.52 samples/sec#011loss=1.232613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[280] avg_epoch_loss=1.387419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=280 train loss <loss>=1.2528837203979493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [280]#011Speed: 849.34 samples/sec#011loss=1.252884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[285] avg_epoch_loss=1.384622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=285 train loss <loss>=1.2273965358734131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [285]#011Speed: 1161.83 samples/sec#011loss=1.227397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[290] avg_epoch_loss=1.379741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=290 train loss <loss>=1.100575566291809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [290]#011Speed: 844.67 samples/sec#011loss=1.100576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch[295] avg_epoch_loss=1.379592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=295 train loss <loss>=1.3708930492401123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:56 INFO 140281140962944] Epoch[3] Batch [295]#011Speed: 1339.72 samples/sec#011loss=1.370893\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[300] avg_epoch_loss=1.377237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=300 train loss <loss>=1.2378345727920532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [300]#011Speed: 856.35 samples/sec#011loss=1.237835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[305] avg_epoch_loss=1.375769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=305 train loss <loss>=1.2874160051345824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [305]#011Speed: 1367.79 samples/sec#011loss=1.287416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[310] avg_epoch_loss=1.373620\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=310 train loss <loss>=1.242080807685852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [310]#011Speed: 847.14 samples/sec#011loss=1.242081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[315] avg_epoch_loss=1.370313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=315 train loss <loss>=1.164588212966919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [315]#011Speed: 1353.21 samples/sec#011loss=1.164588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[320] avg_epoch_loss=1.383752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=320 train loss <loss>=2.2331547260284426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [320]#011Speed: 801.99 samples/sec#011loss=2.233155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch[325] avg_epoch_loss=1.385424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=325 train loss <loss>=1.4927331447601317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:57 INFO 140281140962944] Epoch[3] Batch [325]#011Speed: 1312.06 samples/sec#011loss=1.492733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[330] avg_epoch_loss=1.384349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=330 train loss <loss>=1.3142274618148804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [330]#011Speed: 854.23 samples/sec#011loss=1.314227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[335] avg_epoch_loss=1.385024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=335 train loss <loss>=1.4297393560409546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [335]#011Speed: 1198.78 samples/sec#011loss=1.429739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[340] avg_epoch_loss=1.382022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=340 train loss <loss>=1.1803080320358277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [340]#011Speed: 730.40 samples/sec#011loss=1.180308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[345] avg_epoch_loss=1.379609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=345 train loss <loss>=1.2150445938110352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [345]#011Speed: 1341.30 samples/sec#011loss=1.215045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[350] avg_epoch_loss=1.379876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=350 train loss <loss>=1.3983357429504395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [350]#011Speed: 822.34 samples/sec#011loss=1.398336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[355] avg_epoch_loss=1.376407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=355 train loss <loss>=1.1328683376312256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [355]#011Speed: 1358.44 samples/sec#011loss=1.132868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch[360] avg_epoch_loss=1.372502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=360 train loss <loss>=1.0944893956184387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:58 INFO 140281140962944] Epoch[3] Batch [360]#011Speed: 858.11 samples/sec#011loss=1.094489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[365] avg_epoch_loss=1.369531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=365 train loss <loss>=1.1550247311592101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [365]#011Speed: 1320.52 samples/sec#011loss=1.155025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[370] avg_epoch_loss=1.367355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=370 train loss <loss>=1.2080315589904784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [370]#011Speed: 854.16 samples/sec#011loss=1.208032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[375] avg_epoch_loss=1.364114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=375 train loss <loss>=1.123622965812683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [375]#011Speed: 1350.47 samples/sec#011loss=1.123623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[380] avg_epoch_loss=1.363014\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=380 train loss <loss>=1.280337119102478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [380]#011Speed: 759.77 samples/sec#011loss=1.280337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[385] avg_epoch_loss=1.362619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=385 train loss <loss>=1.3325037002563476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [385]#011Speed: 1347.94 samples/sec#011loss=1.332504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch[390] avg_epoch_loss=1.369812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=390 train loss <loss>=1.925124502182007\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:14:59 INFO 140281140962944] Epoch[3] Batch [390]#011Speed: 850.67 samples/sec#011loss=1.925125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[395] avg_epoch_loss=1.374585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=395 train loss <loss>=1.7478572607040406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [395]#011Speed: 1279.51 samples/sec#011loss=1.747857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[400] avg_epoch_loss=1.376570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=400 train loss <loss>=1.5337567806243897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [400]#011Speed: 793.65 samples/sec#011loss=1.533757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[405] avg_epoch_loss=1.376783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=405 train loss <loss>=1.3939044237136842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [405]#011Speed: 1381.04 samples/sec#011loss=1.393904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[410] avg_epoch_loss=1.378430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=410 train loss <loss>=1.5121066093444824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [410]#011Speed: 729.94 samples/sec#011loss=1.512107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[415] avg_epoch_loss=1.381252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=415 train loss <loss>=1.6132477521896362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [415]#011Speed: 1350.79 samples/sec#011loss=1.613248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch[420] avg_epoch_loss=1.382932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=420 train loss <loss>=1.5226881980895997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:00 INFO 140281140962944] Epoch[3] Batch [420]#011Speed: 807.07 samples/sec#011loss=1.522688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[425] avg_epoch_loss=1.383332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=425 train loss <loss>=1.4170480966567993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [425]#011Speed: 1356.26 samples/sec#011loss=1.417048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[430] avg_epoch_loss=1.382091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=430 train loss <loss>=1.276338815689087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [430]#011Speed: 823.52 samples/sec#011loss=1.276339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[435] avg_epoch_loss=1.381897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=435 train loss <loss>=1.365193247795105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [435]#011Speed: 1357.16 samples/sec#011loss=1.365193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[440] avg_epoch_loss=1.380937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=440 train loss <loss>=1.2971624374389648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [440]#011Speed: 835.90 samples/sec#011loss=1.297162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[445] avg_epoch_loss=1.379245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=445 train loss <loss>=1.230006456375122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [445]#011Speed: 1188.96 samples/sec#011loss=1.230006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch[450] avg_epoch_loss=1.377016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=450 train loss <loss>=1.1781985759735107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:01 INFO 140281140962944] Epoch[3] Batch [450]#011Speed: 847.56 samples/sec#011loss=1.178199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[455] avg_epoch_loss=1.375640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=455 train loss <loss>=1.2515417337417603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [455]#011Speed: 911.35 samples/sec#011loss=1.251542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[460] avg_epoch_loss=1.374868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=460 train loss <loss>=1.304506540298462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [460]#011Speed: 399.66 samples/sec#011loss=1.304507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[465] avg_epoch_loss=1.372489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=465 train loss <loss>=1.1531190872192383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [465]#011Speed: 768.10 samples/sec#011loss=1.153119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[470] avg_epoch_loss=1.370276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=470 train loss <loss>=1.16400089263916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [470]#011Speed: 831.98 samples/sec#011loss=1.164001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch[475] avg_epoch_loss=1.369855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=475 train loss <loss>=1.3301915287971497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:02 INFO 140281140962944] Epoch[3] Batch [475]#011Speed: 1291.87 samples/sec#011loss=1.330192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[480] avg_epoch_loss=1.368010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=480 train loss <loss>=1.192430329322815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [480]#011Speed: 849.64 samples/sec#011loss=1.192430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[485] avg_epoch_loss=1.366065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=485 train loss <loss>=1.178966236114502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [485]#011Speed: 1279.51 samples/sec#011loss=1.178966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[490] avg_epoch_loss=1.366013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=490 train loss <loss>=1.3609161376953125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [490]#011Speed: 645.63 samples/sec#011loss=1.360916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[495] avg_epoch_loss=1.363382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=495 train loss <loss>=1.1049922227859497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [495]#011Speed: 1239.01 samples/sec#011loss=1.104992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[500] avg_epoch_loss=1.362125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=500 train loss <loss>=1.2374598026275634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [500]#011Speed: 843.44 samples/sec#011loss=1.237460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch[505] avg_epoch_loss=1.359402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=505 train loss <loss>=1.086556077003479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:03 INFO 140281140962944] Epoch[3] Batch [505]#011Speed: 1362.95 samples/sec#011loss=1.086556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[510] avg_epoch_loss=1.359057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=510 train loss <loss>=1.3241506814956665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [510]#011Speed: 841.02 samples/sec#011loss=1.324151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[515] avg_epoch_loss=1.358533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=515 train loss <loss>=1.304983389377594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [515]#011Speed: 887.97 samples/sec#011loss=1.304983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[520] avg_epoch_loss=1.359968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=520 train loss <loss>=1.5080660104751586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [520]#011Speed: 449.20 samples/sec#011loss=1.508066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch[525] avg_epoch_loss=1.359716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=525 train loss <loss>=1.3334328413009644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:04 INFO 140281140962944] Epoch[3] Batch [525]#011Speed: 863.64 samples/sec#011loss=1.333433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[530] avg_epoch_loss=1.358512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=530 train loss <loss>=1.2318774938583374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [530]#011Speed: 523.64 samples/sec#011loss=1.231877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[535] avg_epoch_loss=1.357914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=535 train loss <loss>=1.2943687677383422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [535]#011Speed: 1288.48 samples/sec#011loss=1.294369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[540] avg_epoch_loss=1.357493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=540 train loss <loss>=1.3123962879180908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [540]#011Speed: 846.43 samples/sec#011loss=1.312396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[545] avg_epoch_loss=1.356734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=545 train loss <loss>=1.2746009349822998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [545]#011Speed: 1302.52 samples/sec#011loss=1.274601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch[550] avg_epoch_loss=1.356105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=550 train loss <loss>=1.2874167680740356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:05 INFO 140281140962944] Epoch[3] Batch [550]#011Speed: 536.30 samples/sec#011loss=1.287417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[3] Batch[555] avg_epoch_loss=1.354951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, batch=555 train loss <loss>=1.227741575241089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[3] Batch [555]#011Speed: 835.09 samples/sec#011loss=1.227742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] processed a total of 17805 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717287.3730938, \"EndTime\": 1620717306.1465006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18773.342609405518, \"count\": 1, \"min\": 18773.342609405518, \"max\": 18773.342609405518}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=948.4136267276848 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=3, train loss <loss>=1.3547960230863287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_c8b0e41b-7769-4564-a22b-faba45ed9be7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717306.1465774, \"EndTime\": 1620717306.1603403, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 13.219356536865234, \"count\": 1, \"min\": 13.219356536865234, \"max\": 13.219356536865234}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch[0] avg_epoch_loss=1.110884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.1108835935592651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch[5] avg_epoch_loss=1.069283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=1.0692826708157857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch [5]#011Speed: 769.96 samples/sec#011loss=1.069283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch[10] avg_epoch_loss=1.137943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.2203347206115722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:06 INFO 140281140962944] Epoch[4] Batch [10]#011Speed: 447.00 samples/sec#011loss=1.220335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[15] avg_epoch_loss=1.173831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=1.252785897254944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [15]#011Speed: 768.40 samples/sec#011loss=1.252786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[20] avg_epoch_loss=1.155495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=1.0968208074569703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [20]#011Speed: 491.02 samples/sec#011loss=1.096821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[25] avg_epoch_loss=1.190692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=1.3385156393051147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [25]#011Speed: 831.23 samples/sec#011loss=1.338516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch[30] avg_epoch_loss=1.257587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=1.6054431676864624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:07 INFO 140281140962944] Epoch[4] Batch [30]#011Speed: 498.23 samples/sec#011loss=1.605443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[35] avg_epoch_loss=1.253675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=1.2294181346893311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [35]#011Speed: 1229.44 samples/sec#011loss=1.229418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[40] avg_epoch_loss=1.245955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=1.1903698682785033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [40]#011Speed: 833.15 samples/sec#011loss=1.190370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[45] avg_epoch_loss=1.236507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=1.1590386867523192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [45]#011Speed: 1145.93 samples/sec#011loss=1.159039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[50] avg_epoch_loss=1.230613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=1.176387333869934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [50]#011Speed: 617.20 samples/sec#011loss=1.176387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[55] avg_epoch_loss=1.228258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=1.2042400121688843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [55]#011Speed: 1243.41 samples/sec#011loss=1.204240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch[60] avg_epoch_loss=1.229000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=1.237301802635193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:08 INFO 140281140962944] Epoch[4] Batch [60]#011Speed: 843.58 samples/sec#011loss=1.237302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[65] avg_epoch_loss=1.293600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=2.0817206382751463\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [65]#011Speed: 1341.85 samples/sec#011loss=2.081721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[70] avg_epoch_loss=1.291661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=1.2660664081573487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [70]#011Speed: 854.54 samples/sec#011loss=1.266066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[75] avg_epoch_loss=1.285220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=1.1937644243240357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [75]#011Speed: 1363.92 samples/sec#011loss=1.193764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[80] avg_epoch_loss=1.284209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=1.2688390254974364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [80]#011Speed: 831.17 samples/sec#011loss=1.268839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[85] avg_epoch_loss=1.277200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=1.1636584043502807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [85]#011Speed: 1073.67 samples/sec#011loss=1.163658\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch[90] avg_epoch_loss=1.278511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=1.3010511159896851\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:09 INFO 140281140962944] Epoch[4] Batch [90]#011Speed: 827.27 samples/sec#011loss=1.301051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[95] avg_epoch_loss=1.269357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=1.1027660846710206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [95]#011Speed: 1312.29 samples/sec#011loss=1.102766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[100] avg_epoch_loss=1.265321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=1.1878133773803712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [100]#011Speed: 826.82 samples/sec#011loss=1.187813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[105] avg_epoch_loss=1.323432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=2.49727885723114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [105]#011Speed: 1352.14 samples/sec#011loss=2.497279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[110] avg_epoch_loss=1.321313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=1.276384997367859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [110]#011Speed: 831.94 samples/sec#011loss=1.276385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[115] avg_epoch_loss=1.320669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=1.3063873767852783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [115]#011Speed: 1318.05 samples/sec#011loss=1.306387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch[120] avg_epoch_loss=1.320545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=1.317668581008911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:10 INFO 140281140962944] Epoch[4] Batch [120]#011Speed: 777.77 samples/sec#011loss=1.317669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[125] avg_epoch_loss=1.316886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=1.2283326625823974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [125]#011Speed: 1343.34 samples/sec#011loss=1.228333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[130] avg_epoch_loss=1.315408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=1.2781748056411744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [130]#011Speed: 835.49 samples/sec#011loss=1.278175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[135] avg_epoch_loss=1.311602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=1.2118679761886597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [135]#011Speed: 1333.18 samples/sec#011loss=1.211868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[140] avg_epoch_loss=1.311916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=1.3204712629318238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [140]#011Speed: 838.99 samples/sec#011loss=1.320471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[145] avg_epoch_loss=1.309432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=1.2393754720687866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [145]#011Speed: 1329.30 samples/sec#011loss=1.239375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[150] avg_epoch_loss=1.304632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=1.1644804239273072\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [150]#011Speed: 728.82 samples/sec#011loss=1.164480\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch[155] avg_epoch_loss=1.297146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=1.0710575342178346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:11 INFO 140281140962944] Epoch[4] Batch [155]#011Speed: 1337.08 samples/sec#011loss=1.071058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[160] avg_epoch_loss=1.292151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=1.1363183975219726\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [160]#011Speed: 857.57 samples/sec#011loss=1.136318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[165] avg_epoch_loss=1.289694\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=1.210567021369934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [165]#011Speed: 1364.15 samples/sec#011loss=1.210567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[170] avg_epoch_loss=1.287442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=1.2126842141151428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [170]#011Speed: 852.39 samples/sec#011loss=1.212684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[175] avg_epoch_loss=1.282116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=1.0999637603759767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [175]#011Speed: 1365.12 samples/sec#011loss=1.099964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch[180] avg_epoch_loss=1.281927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=1.2752636194229126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:12 INFO 140281140962944] Epoch[4] Batch [180]#011Speed: 582.17 samples/sec#011loss=1.275264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[185] avg_epoch_loss=1.280376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=1.2242436170578004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [185]#011Speed: 842.11 samples/sec#011loss=1.224244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[190] avg_epoch_loss=1.279200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=1.2354314804077149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [190]#011Speed: 551.21 samples/sec#011loss=1.235431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[195] avg_epoch_loss=1.296413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=1.9539644956588744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [195]#011Speed: 1353.43 samples/sec#011loss=1.953964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[200] avg_epoch_loss=1.295563\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=1.2622586131095885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [200]#011Speed: 592.29 samples/sec#011loss=1.262259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch[205] avg_epoch_loss=1.306986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=1.7661929607391358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:13 INFO 140281140962944] Epoch[4] Batch [205]#011Speed: 1225.16 samples/sec#011loss=1.766193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[210] avg_epoch_loss=1.306852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=1.3013062477111816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [210]#011Speed: 845.87 samples/sec#011loss=1.301306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[215] avg_epoch_loss=1.309248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=1.410385823249817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [215]#011Speed: 1342.64 samples/sec#011loss=1.410386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[220] avg_epoch_loss=1.308419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=1.2726061582565307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [220]#011Speed: 853.85 samples/sec#011loss=1.272606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[225] avg_epoch_loss=1.306793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=1.2349009037017822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [225]#011Speed: 1334.73 samples/sec#011loss=1.234901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[230] avg_epoch_loss=1.303602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=1.1593819856643677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [230]#011Speed: 784.35 samples/sec#011loss=1.159382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch[235] avg_epoch_loss=1.300869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=1.1745711326599122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:14 INFO 140281140962944] Epoch[4] Batch [235]#011Speed: 1279.87 samples/sec#011loss=1.174571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[240] avg_epoch_loss=1.297296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=1.1286497831344604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [240]#011Speed: 769.31 samples/sec#011loss=1.128650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[245] avg_epoch_loss=1.296396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=1.2530407190322876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [245]#011Speed: 1296.43 samples/sec#011loss=1.253041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[250] avg_epoch_loss=1.301296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=1.5423672676086426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [250]#011Speed: 836.59 samples/sec#011loss=1.542367\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[255] avg_epoch_loss=1.322008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=2.3617627382278443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [255]#011Speed: 1346.92 samples/sec#011loss=2.361763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[260] avg_epoch_loss=1.323696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=1.410132384300232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [260]#011Speed: 825.52 samples/sec#011loss=1.410132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[265] avg_epoch_loss=1.322661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=1.2686219453811645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [265]#011Speed: 1326.26 samples/sec#011loss=1.268622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch[270] avg_epoch_loss=1.322447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=270 train loss <loss>=1.3110353708267213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:15 INFO 140281140962944] Epoch[4] Batch [270]#011Speed: 798.96 samples/sec#011loss=1.311035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[275] avg_epoch_loss=1.322723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=275 train loss <loss>=1.3376965284347535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [275]#011Speed: 1327.63 samples/sec#011loss=1.337697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[280] avg_epoch_loss=1.320267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=280 train loss <loss>=1.1847007751464844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [280]#011Speed: 850.31 samples/sec#011loss=1.184701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[285] avg_epoch_loss=1.316363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=285 train loss <loss>=1.09693284034729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [285]#011Speed: 1338.76 samples/sec#011loss=1.096933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[290] avg_epoch_loss=1.315759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=290 train loss <loss>=1.2812633752822875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [290]#011Speed: 856.73 samples/sec#011loss=1.281263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[295] avg_epoch_loss=1.315718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=295 train loss <loss>=1.3133319854736327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [295]#011Speed: 1297.11 samples/sec#011loss=1.313332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch[300] avg_epoch_loss=1.316185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=300 train loss <loss>=1.3438318014144897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:16 INFO 140281140962944] Epoch[4] Batch [300]#011Speed: 783.37 samples/sec#011loss=1.343832\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[305] avg_epoch_loss=1.314652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=305 train loss <loss>=1.2223575353622436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [305]#011Speed: 1301.64 samples/sec#011loss=1.222358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[310] avg_epoch_loss=1.312026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=310 train loss <loss>=1.1512678861618042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [310]#011Speed: 845.72 samples/sec#011loss=1.151268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[315] avg_epoch_loss=1.311777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=315 train loss <loss>=1.2962991714477539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [315]#011Speed: 1313.55 samples/sec#011loss=1.296299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[320] avg_epoch_loss=1.308611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=320 train loss <loss>=1.1085336923599243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [320]#011Speed: 825.77 samples/sec#011loss=1.108534\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[325] avg_epoch_loss=1.305422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=325 train loss <loss>=1.1007039546966553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [325]#011Speed: 1362.20 samples/sec#011loss=1.100704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[330] avg_epoch_loss=1.308054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=330 train loss <loss>=1.479644513130188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [330]#011Speed: 823.80 samples/sec#011loss=1.479645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch[335] avg_epoch_loss=1.304430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=335 train loss <loss>=1.0644938468933105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:17 INFO 140281140962944] Epoch[4] Batch [335]#011Speed: 1219.35 samples/sec#011loss=1.064494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[340] avg_epoch_loss=1.300603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=340 train loss <loss>=1.0434354186058044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [340]#011Speed: 836.78 samples/sec#011loss=1.043435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[345] avg_epoch_loss=1.298383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=345 train loss <loss>=1.1470215320587158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [345]#011Speed: 1295.05 samples/sec#011loss=1.147022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[350] avg_epoch_loss=1.296126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=350 train loss <loss>=1.1399107336997987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [350]#011Speed: 812.33 samples/sec#011loss=1.139911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[355] avg_epoch_loss=1.294358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=355 train loss <loss>=1.1702375411987305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [355]#011Speed: 1328.29 samples/sec#011loss=1.170238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[360] avg_epoch_loss=1.293106\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=360 train loss <loss>=1.204015564918518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [360]#011Speed: 642.61 samples/sec#011loss=1.204016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch[365] avg_epoch_loss=1.289976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=365 train loss <loss>=1.0639646768569946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:18 INFO 140281140962944] Epoch[4] Batch [365]#011Speed: 1237.60 samples/sec#011loss=1.063965\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[370] avg_epoch_loss=1.288751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=370 train loss <loss>=1.1990738749504088\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [370]#011Speed: 836.96 samples/sec#011loss=1.199074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[375] avg_epoch_loss=1.287384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=375 train loss <loss>=1.1859597444534302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [375]#011Speed: 1299.95 samples/sec#011loss=1.185960\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[380] avg_epoch_loss=1.296355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=380 train loss <loss>=1.9709426522254945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [380]#011Speed: 824.65 samples/sec#011loss=1.970943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[385] avg_epoch_loss=1.297521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=385 train loss <loss>=1.3863911390304566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [385]#011Speed: 1255.00 samples/sec#011loss=1.386391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[390] avg_epoch_loss=1.297804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=390 train loss <loss>=1.3196645736694337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [390]#011Speed: 717.94 samples/sec#011loss=1.319665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch[395] avg_epoch_loss=1.296901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=395 train loss <loss>=1.2262833833694458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:19 INFO 140281140962944] Epoch[4] Batch [395]#011Speed: 1175.33 samples/sec#011loss=1.226283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[400] avg_epoch_loss=1.295432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=400 train loss <loss>=1.1790844678878785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [400]#011Speed: 820.47 samples/sec#011loss=1.179084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[405] avg_epoch_loss=1.295124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=405 train loss <loss>=1.2704567432403564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [405]#011Speed: 1312.48 samples/sec#011loss=1.270457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[410] avg_epoch_loss=1.294397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=410 train loss <loss>=1.2352961301803589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [410]#011Speed: 827.78 samples/sec#011loss=1.235296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[415] avg_epoch_loss=1.292958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=415 train loss <loss>=1.174687647819519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [415]#011Speed: 1284.96 samples/sec#011loss=1.174688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[420] avg_epoch_loss=1.293647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=420 train loss <loss>=1.3509535551071168\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [420]#011Speed: 845.93 samples/sec#011loss=1.350954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch[425] avg_epoch_loss=1.294844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=425 train loss <loss>=1.395706868171692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:20 INFO 140281140962944] Epoch[4] Batch [425]#011Speed: 1300.74 samples/sec#011loss=1.395707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[430] avg_epoch_loss=1.295439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=430 train loss <loss>=1.3461154222488403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [430]#011Speed: 772.41 samples/sec#011loss=1.346115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[435] avg_epoch_loss=1.293447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=435 train loss <loss>=1.1216846704483032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [435]#011Speed: 1350.51 samples/sec#011loss=1.121685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[440] avg_epoch_loss=1.293415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=440 train loss <loss>=1.2906865239143372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [440]#011Speed: 842.28 samples/sec#011loss=1.290687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[445] avg_epoch_loss=1.292321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=445 train loss <loss>=1.1957633733749389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [445]#011Speed: 1338.69 samples/sec#011loss=1.195763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[450] avg_epoch_loss=1.292094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=450 train loss <loss>=1.271849775314331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [450]#011Speed: 841.51 samples/sec#011loss=1.271850\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch[455] avg_epoch_loss=1.292866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=455 train loss <loss>=1.3624943971633912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:21 INFO 140281140962944] Epoch[4] Batch [455]#011Speed: 1334.03 samples/sec#011loss=1.362494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[460] avg_epoch_loss=1.302073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=460 train loss <loss>=2.1417988538742065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [460]#011Speed: 804.88 samples/sec#011loss=2.141799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[465] avg_epoch_loss=1.307835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=465 train loss <loss>=1.8391164541244507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [465]#011Speed: 1361.21 samples/sec#011loss=1.839116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[470] avg_epoch_loss=1.309943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=470 train loss <loss>=1.5064109086990356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [470]#011Speed: 867.48 samples/sec#011loss=1.506411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[475] avg_epoch_loss=1.312495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=475 train loss <loss>=1.5528582811355591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [475]#011Speed: 1327.46 samples/sec#011loss=1.552858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[480] avg_epoch_loss=1.313028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=480 train loss <loss>=1.3637592792510986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [480]#011Speed: 849.84 samples/sec#011loss=1.363759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch[485] avg_epoch_loss=1.312517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=485 train loss <loss>=1.2633854627609253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:22 INFO 140281140962944] Epoch[4] Batch [485]#011Speed: 1320.80 samples/sec#011loss=1.263385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[490] avg_epoch_loss=1.312414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=490 train loss <loss>=1.3024261236190795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [490]#011Speed: 793.95 samples/sec#011loss=1.302426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[495] avg_epoch_loss=1.311852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=495 train loss <loss>=1.2565770387649535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [495]#011Speed: 1335.75 samples/sec#011loss=1.256577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[500] avg_epoch_loss=1.310643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=500 train loss <loss>=1.1907914876937866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [500]#011Speed: 874.46 samples/sec#011loss=1.190791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[505] avg_epoch_loss=1.309253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=505 train loss <loss>=1.1699443101882934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [505]#011Speed: 1326.05 samples/sec#011loss=1.169944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[510] avg_epoch_loss=1.306954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=510 train loss <loss>=1.0743158340454102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [510]#011Speed: 715.25 samples/sec#011loss=1.074316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch[515] avg_epoch_loss=1.304304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=515 train loss <loss>=1.0334643363952636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:23 INFO 140281140962944] Epoch[4] Batch [515]#011Speed: 1356.90 samples/sec#011loss=1.033464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[520] avg_epoch_loss=1.302459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=520 train loss <loss>=1.112037682533264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [520]#011Speed: 574.30 samples/sec#011loss=1.112038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[525] avg_epoch_loss=1.299516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=525 train loss <loss>=0.9928559064865112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [525]#011Speed: 1362.91 samples/sec#011loss=0.992856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[530] avg_epoch_loss=1.297167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=530 train loss <loss>=1.050092887878418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [530]#011Speed: 855.64 samples/sec#011loss=1.050093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[535] avg_epoch_loss=1.303051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=535 train loss <loss>=1.9279313564300538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [535]#011Speed: 1352.51 samples/sec#011loss=1.927931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[540] avg_epoch_loss=1.304135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=540 train loss <loss>=1.4203054666519166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [540]#011Speed: 900.00 samples/sec#011loss=1.420305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch[545] avg_epoch_loss=1.302107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, batch=545 train loss <loss>=1.0826474666595458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[4] Batch [545]#011Speed: 1304.39 samples/sec#011loss=1.082647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] processed a total of 17570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717306.1604047, \"EndTime\": 1620717324.890717, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18730.2463054657, \"count\": 1, \"min\": 18730.2463054657, \"max\": 18730.2463054657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=938.0491687778757 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.3008225758509202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_a17fba37-3144-4a15-b572-43888481273b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717324.8907967, \"EndTime\": 1620717324.9012141, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.664058685302734, \"count\": 1, \"min\": 9.664058685302734, \"max\": 9.664058685302734}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] Epoch[5] Batch[0] avg_epoch_loss=1.114033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=1.1140326261520386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[5] avg_epoch_loss=1.118777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=1.1187767386436462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [5]#011Speed: 1206.17 samples/sec#011loss=1.118777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[10] avg_epoch_loss=1.163884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=1.2180119037628174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [10]#011Speed: 860.99 samples/sec#011loss=1.218012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[15] avg_epoch_loss=1.151614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=1.1246196031570435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [15]#011Speed: 1304.32 samples/sec#011loss=1.124620\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[20] avg_epoch_loss=1.135665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=1.084629273414612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [20]#011Speed: 856.25 samples/sec#011loss=1.084629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[25] avg_epoch_loss=1.163795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=1.2819432973861695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [25]#011Speed: 1231.72 samples/sec#011loss=1.281943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch[30] avg_epoch_loss=1.154551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=1.106479024887085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:25 INFO 140281140962944] Epoch[5] Batch [30]#011Speed: 823.71 samples/sec#011loss=1.106479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[35] avg_epoch_loss=1.172783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=1.2858253359794616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [35]#011Speed: 1249.33 samples/sec#011loss=1.285825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[40] avg_epoch_loss=1.185020\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=1.2731242418289184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [40]#011Speed: 852.67 samples/sec#011loss=1.273124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[45] avg_epoch_loss=1.186528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=1.198888397216797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [45]#011Speed: 1338.37 samples/sec#011loss=1.198888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[50] avg_epoch_loss=1.194986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=1.272801923751831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [50]#011Speed: 834.08 samples/sec#011loss=1.272802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[55] avg_epoch_loss=1.187325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=1.1091891288757325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [55]#011Speed: 1365.68 samples/sec#011loss=1.109189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch[60] avg_epoch_loss=1.192412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=1.2493770480155946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:26 INFO 140281140962944] Epoch[5] Batch [60]#011Speed: 844.85 samples/sec#011loss=1.249377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[65] avg_epoch_loss=1.203158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=1.3342580556869508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [65]#011Speed: 1334.12 samples/sec#011loss=1.334258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[70] avg_epoch_loss=1.208913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=1.2848875045776367\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [70]#011Speed: 795.94 samples/sec#011loss=1.284888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[75] avg_epoch_loss=1.210911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=1.239276075363159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [75]#011Speed: 1373.55 samples/sec#011loss=1.239276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[80] avg_epoch_loss=1.201060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=1.051333522796631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [80]#011Speed: 860.08 samples/sec#011loss=1.051334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[85] avg_epoch_loss=1.192804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=1.0590500116348267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [85]#011Speed: 1329.40 samples/sec#011loss=1.059050\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[90] avg_epoch_loss=1.191618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=1.1712254762649537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [90]#011Speed: 848.54 samples/sec#011loss=1.171225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch[95] avg_epoch_loss=1.314968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=3.5599280834197997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:27 INFO 140281140962944] Epoch[5] Batch [95]#011Speed: 1359.53 samples/sec#011loss=3.559928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[100] avg_epoch_loss=1.307693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=1.1680170059204102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [100]#011Speed: 794.81 samples/sec#011loss=1.168017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[105] avg_epoch_loss=1.322869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=1.6294226408004762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [105]#011Speed: 1361.06 samples/sec#011loss=1.629423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[110] avg_epoch_loss=1.325704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=1.3858046531677246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [110]#011Speed: 840.70 samples/sec#011loss=1.385805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[115] avg_epoch_loss=1.339185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=1.6384785175323486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [115]#011Speed: 1302.98 samples/sec#011loss=1.638479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[120] avg_epoch_loss=1.342501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=1.4194201946258544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [120]#011Speed: 869.30 samples/sec#011loss=1.419420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch[125] avg_epoch_loss=1.346195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=1.435596776008606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:28 INFO 140281140962944] Epoch[5] Batch [125]#011Speed: 1353.40 samples/sec#011loss=1.435597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[130] avg_epoch_loss=1.345821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=1.336397409439087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [130]#011Speed: 681.04 samples/sec#011loss=1.336397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[135] avg_epoch_loss=1.344684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=1.3148881912231445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [135]#011Speed: 1230.87 samples/sec#011loss=1.314888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[140] avg_epoch_loss=1.368915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=2.0279873609542847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [140]#011Speed: 837.34 samples/sec#011loss=2.027987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[145] avg_epoch_loss=1.364522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=1.2406358003616333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [145]#011Speed: 1360.83 samples/sec#011loss=1.240636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[150] avg_epoch_loss=1.359912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=1.2253163576126098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [150]#011Speed: 841.22 samples/sec#011loss=1.225316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch[155] avg_epoch_loss=1.356607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=1.2567824363708495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:29 INFO 140281140962944] Epoch[5] Batch [155]#011Speed: 1278.72 samples/sec#011loss=1.256782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[160] avg_epoch_loss=1.351903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=1.2051606893539428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [160]#011Speed: 850.04 samples/sec#011loss=1.205161\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[165] avg_epoch_loss=1.346679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=1.178462266921997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [165]#011Speed: 1206.22 samples/sec#011loss=1.178462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[170] avg_epoch_loss=1.339702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=1.1080570459365844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [170]#011Speed: 859.41 samples/sec#011loss=1.108057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[175] avg_epoch_loss=1.335854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=1.2042388200759888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [175]#011Speed: 1334.08 samples/sec#011loss=1.204239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[180] avg_epoch_loss=1.330640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=1.1471360564231872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [180]#011Speed: 837.32 samples/sec#011loss=1.147136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[185] avg_epoch_loss=1.324523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=1.1030730128288269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [185]#011Speed: 1335.02 samples/sec#011loss=1.103073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch[190] avg_epoch_loss=1.326145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=1.386484479904175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:30 INFO 140281140962944] Epoch[5] Batch [190]#011Speed: 842.93 samples/sec#011loss=1.386484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[195] avg_epoch_loss=1.337630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=1.776344108581543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [195]#011Speed: 1298.09 samples/sec#011loss=1.776344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[200] avg_epoch_loss=1.346901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=1.7103343248367309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [200]#011Speed: 821.10 samples/sec#011loss=1.710334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[205] avg_epoch_loss=1.346079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=1.313044810295105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [205]#011Speed: 1335.48 samples/sec#011loss=1.313045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[210] avg_epoch_loss=1.356200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=1.7731921672821045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [210]#011Speed: 857.44 samples/sec#011loss=1.773192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[215] avg_epoch_loss=1.354742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=1.2931842803955078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [215]#011Speed: 1360.26 samples/sec#011loss=1.293184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch[220] avg_epoch_loss=1.356083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=1.4140177965164185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:31 INFO 140281140962944] Epoch[5] Batch [220]#011Speed: 835.72 samples/sec#011loss=1.414018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[225] avg_epoch_loss=1.356013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=1.352942132949829\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [225]#011Speed: 1340.41 samples/sec#011loss=1.352942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[230] avg_epoch_loss=1.353112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=1.2219601631164552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [230]#011Speed: 804.32 samples/sec#011loss=1.221960\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[235] avg_epoch_loss=1.349729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=1.1934433460235596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [235]#011Speed: 1362.00 samples/sec#011loss=1.193443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[240] avg_epoch_loss=1.345412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=1.1416734457015991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [240]#011Speed: 854.82 samples/sec#011loss=1.141673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[245] avg_epoch_loss=1.339490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=1.0540381908416747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [245]#011Speed: 1347.66 samples/sec#011loss=1.054038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[250] avg_epoch_loss=1.333716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=1.0496256589889525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [250]#011Speed: 855.56 samples/sec#011loss=1.049626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch[255] avg_epoch_loss=1.339512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=1.6304791688919067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:32 INFO 140281140962944] Epoch[5] Batch [255]#011Speed: 1321.34 samples/sec#011loss=1.630479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[260] avg_epoch_loss=1.337863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=1.2534091472625732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [260]#011Speed: 855.79 samples/sec#011loss=1.253409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[265] avg_epoch_loss=1.334113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=1.138370966911316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [265]#011Speed: 1238.57 samples/sec#011loss=1.138371\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[270] avg_epoch_loss=1.331135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=270 train loss <loss>=1.1727189540863037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [270]#011Speed: 844.56 samples/sec#011loss=1.172719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[275] avg_epoch_loss=1.328291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=275 train loss <loss>=1.174133849143982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [275]#011Speed: 1309.17 samples/sec#011loss=1.174134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[280] avg_epoch_loss=1.325070\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=280 train loss <loss>=1.147283673286438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [280]#011Speed: 852.22 samples/sec#011loss=1.147284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch[285] avg_epoch_loss=1.327238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=285 train loss <loss>=1.449065136909485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:33 INFO 140281140962944] Epoch[5] Batch [285]#011Speed: 1317.16 samples/sec#011loss=1.449065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[290] avg_epoch_loss=1.324632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=290 train loss <loss>=1.1756065964698792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [290]#011Speed: 800.19 samples/sec#011loss=1.175607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[295] avg_epoch_loss=1.325420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=295 train loss <loss>=1.3712471723556519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [295]#011Speed: 821.21 samples/sec#011loss=1.371247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[300] avg_epoch_loss=1.329290\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=300 train loss <loss>=1.558429765701294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [300]#011Speed: 835.78 samples/sec#011loss=1.558430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[305] avg_epoch_loss=1.325640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=305 train loss <loss>=1.1058832168579102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [305]#011Speed: 1362.98 samples/sec#011loss=1.105883\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[310] avg_epoch_loss=1.322164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=310 train loss <loss>=1.1094334363937377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [310]#011Speed: 696.27 samples/sec#011loss=1.109433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch[315] avg_epoch_loss=1.319224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=315 train loss <loss>=1.136364722251892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:34 INFO 140281140962944] Epoch[5] Batch [315]#011Speed: 1197.24 samples/sec#011loss=1.136365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[320] avg_epoch_loss=1.326060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=320 train loss <loss>=1.7581013202667237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [320]#011Speed: 802.44 samples/sec#011loss=1.758101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[325] avg_epoch_loss=1.324500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=325 train loss <loss>=1.2243331670761108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [325]#011Speed: 1188.09 samples/sec#011loss=1.224333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[330] avg_epoch_loss=1.322337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=330 train loss <loss>=1.1813038825988769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [330]#011Speed: 843.80 samples/sec#011loss=1.181304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[335] avg_epoch_loss=1.318755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=335 train loss <loss>=1.0816039562225341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [335]#011Speed: 1349.39 samples/sec#011loss=1.081604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[340] avg_epoch_loss=1.314737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=340 train loss <loss>=1.0447791814804077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [340]#011Speed: 816.04 samples/sec#011loss=1.044779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch[345] avg_epoch_loss=1.310678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=345 train loss <loss>=1.0338446021080017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:35 INFO 140281140962944] Epoch[5] Batch [345]#011Speed: 1363.29 samples/sec#011loss=1.033845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[350] avg_epoch_loss=1.307598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=350 train loss <loss>=1.0944652795791625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [350]#011Speed: 823.69 samples/sec#011loss=1.094465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[355] avg_epoch_loss=1.307099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=355 train loss <loss>=1.272042202949524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [355]#011Speed: 1345.33 samples/sec#011loss=1.272042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[360] avg_epoch_loss=1.307357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=360 train loss <loss>=1.325771701335907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [360]#011Speed: 757.63 samples/sec#011loss=1.325772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[365] avg_epoch_loss=1.306616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=365 train loss <loss>=1.2530804753303528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [365]#011Speed: 1313.78 samples/sec#011loss=1.253080\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[370] avg_epoch_loss=1.307865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=370 train loss <loss>=1.3992856740951538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [370]#011Speed: 829.96 samples/sec#011loss=1.399286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch[375] avg_epoch_loss=1.307761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=375 train loss <loss>=1.3000755548477172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:36 INFO 140281140962944] Epoch[5] Batch [375]#011Speed: 1316.63 samples/sec#011loss=1.300076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[380] avg_epoch_loss=1.306260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=380 train loss <loss>=1.1933395624160767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [380]#011Speed: 852.10 samples/sec#011loss=1.193340\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[385] avg_epoch_loss=1.304348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=385 train loss <loss>=1.1586845636367797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [385]#011Speed: 1362.92 samples/sec#011loss=1.158685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[390] avg_epoch_loss=1.302864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=390 train loss <loss>=1.188312029838562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [390]#011Speed: 821.97 samples/sec#011loss=1.188312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[395] avg_epoch_loss=1.300292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=395 train loss <loss>=1.0991544365882873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [395]#011Speed: 1365.06 samples/sec#011loss=1.099154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[400] avg_epoch_loss=1.296672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=400 train loss <loss>=1.0099689483642578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [400]#011Speed: 837.31 samples/sec#011loss=1.009969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch[405] avg_epoch_loss=1.295147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=405 train loss <loss>=1.1728020548820495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:37 INFO 140281140962944] Epoch[5] Batch [405]#011Speed: 1358.49 samples/sec#011loss=1.172802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[410] avg_epoch_loss=1.292214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=410 train loss <loss>=1.0540921807289123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [410]#011Speed: 855.36 samples/sec#011loss=1.054092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[415] avg_epoch_loss=1.293025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=415 train loss <loss>=1.3596691846847535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [415]#011Speed: 1337.85 samples/sec#011loss=1.359669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[420] avg_epoch_loss=1.291044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=420 train loss <loss>=1.1262288093566895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [420]#011Speed: 792.46 samples/sec#011loss=1.126229\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[425] avg_epoch_loss=1.292329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=425 train loss <loss>=1.400535225868225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [425]#011Speed: 1329.98 samples/sec#011loss=1.400535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[430] avg_epoch_loss=1.293605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=430 train loss <loss>=1.402346634864807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [430]#011Speed: 836.46 samples/sec#011loss=1.402347\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[435] avg_epoch_loss=1.294141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=435 train loss <loss>=1.3402997732162476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [435]#011Speed: 1333.86 samples/sec#011loss=1.340300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch[440] avg_epoch_loss=1.292330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=440 train loss <loss>=1.134454083442688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:38 INFO 140281140962944] Epoch[5] Batch [440]#011Speed: 817.92 samples/sec#011loss=1.134454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[445] avg_epoch_loss=1.290943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=445 train loss <loss>=1.1685545206069947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [445]#011Speed: 1293.87 samples/sec#011loss=1.168555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[450] avg_epoch_loss=1.288761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=450 train loss <loss>=1.0941850781440734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [450]#011Speed: 853.99 samples/sec#011loss=1.094185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[455] avg_epoch_loss=1.289981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=455 train loss <loss>=1.3999862670898438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [455]#011Speed: 666.78 samples/sec#011loss=1.399986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[460] avg_epoch_loss=1.288828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=460 train loss <loss>=1.1837114334106444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [460]#011Speed: 723.50 samples/sec#011loss=1.183711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch[465] avg_epoch_loss=1.286724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=465 train loss <loss>=1.0926649212837218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:39 INFO 140281140962944] Epoch[5] Batch [465]#011Speed: 1297.17 samples/sec#011loss=1.092665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[470] avg_epoch_loss=1.284892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=470 train loss <loss>=1.1141623258590698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [470]#011Speed: 833.48 samples/sec#011loss=1.114162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[475] avg_epoch_loss=1.283898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=475 train loss <loss>=1.1903043508529663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [475]#011Speed: 1333.50 samples/sec#011loss=1.190304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[480] avg_epoch_loss=1.283969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=480 train loss <loss>=1.2906914710998536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [480]#011Speed: 794.28 samples/sec#011loss=1.290691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[485] avg_epoch_loss=1.282910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=485 train loss <loss>=1.1810594558715821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [485]#011Speed: 1318.73 samples/sec#011loss=1.181059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[490] avg_epoch_loss=1.279906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=490 train loss <loss>=0.9879572272300721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [490]#011Speed: 870.74 samples/sec#011loss=0.987957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[495] avg_epoch_loss=1.276812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=495 train loss <loss>=0.9729038715362549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [495]#011Speed: 1273.91 samples/sec#011loss=0.972904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch[500] avg_epoch_loss=1.274178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=500 train loss <loss>=1.0129318118095398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:40 INFO 140281140962944] Epoch[5] Batch [500]#011Speed: 854.30 samples/sec#011loss=1.012932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[505] avg_epoch_loss=1.271442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=505 train loss <loss>=0.9972755432128906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [505]#011Speed: 1318.78 samples/sec#011loss=0.997276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[510] avg_epoch_loss=1.268317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=510 train loss <loss>=0.9520822525024414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [510]#011Speed: 841.93 samples/sec#011loss=0.952082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[515] avg_epoch_loss=1.264884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=515 train loss <loss>=0.9139766454696655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [515]#011Speed: 1176.13 samples/sec#011loss=0.913977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[520] avg_epoch_loss=1.265533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=520 train loss <loss>=1.3325002670288086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [520]#011Speed: 852.80 samples/sec#011loss=1.332500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[525] avg_epoch_loss=1.265203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=525 train loss <loss>=1.2309121131896972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [525]#011Speed: 1374.53 samples/sec#011loss=1.230912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch[530] avg_epoch_loss=1.263924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=530 train loss <loss>=1.12933851480484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:41 INFO 140281140962944] Epoch[5] Batch [530]#011Speed: 832.64 samples/sec#011loss=1.129339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[535] avg_epoch_loss=1.263414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=535 train loss <loss>=1.209227168560028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [535]#011Speed: 1356.44 samples/sec#011loss=1.209227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[540] avg_epoch_loss=1.262670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=540 train loss <loss>=1.1828863382339478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [540]#011Speed: 850.86 samples/sec#011loss=1.182886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[545] avg_epoch_loss=1.260822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=545 train loss <loss>=1.0609622716903686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [545]#011Speed: 1365.70 samples/sec#011loss=1.060962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch[550] avg_epoch_loss=1.259798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, batch=550 train loss <loss>=1.1479232549667358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[5] Batch [550]#011Speed: 1122.21 samples/sec#011loss=1.147923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] processed a total of 17658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717324.90128, \"EndTime\": 1620717342.524269, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17622.914791107178, \"count\": 1, \"min\": 17622.914791107178, \"max\": 17622.914791107178}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=1001.9798378111614 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.2600485670609751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_6f71a84d-24a2-4dbf-9567-8b5c633193d7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717342.524426, \"EndTime\": 1620717342.5346668, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.489774703979492, \"count\": 1, \"min\": 9.489774703979492, \"max\": 9.489774703979492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch[0] avg_epoch_loss=1.102250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=1.1022497415542603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch[5] avg_epoch_loss=1.285740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=1.2857404748598735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch [5]#011Speed: 1341.05 samples/sec#011loss=1.285740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch[10] avg_epoch_loss=1.210768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=1.1208012104034424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:42 INFO 140281140962944] Epoch[6] Batch [10]#011Speed: 854.50 samples/sec#011loss=1.120801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[15] avg_epoch_loss=1.154471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=1.03061603307724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [15]#011Speed: 1359.09 samples/sec#011loss=1.030616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[20] avg_epoch_loss=1.122149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=1.0187183022499084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [20]#011Speed: 872.43 samples/sec#011loss=1.018718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[25] avg_epoch_loss=1.102561\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=1.0202925562858582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [25]#011Speed: 1197.22 samples/sec#011loss=1.020293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[30] avg_epoch_loss=1.141125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=1.3416593313217162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [30]#011Speed: 504.42 samples/sec#011loss=1.341659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch[35] avg_epoch_loss=1.166529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=1.324034285545349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:43 INFO 140281140962944] Epoch[6] Batch [35]#011Speed: 847.82 samples/sec#011loss=1.324034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[40] avg_epoch_loss=1.208673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=1.5121105432510376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [40]#011Speed: 633.67 samples/sec#011loss=1.512111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[45] avg_epoch_loss=1.218190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=1.2962233066558837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [45]#011Speed: 1354.48 samples/sec#011loss=1.296223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[50] avg_epoch_loss=1.222676\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=1.2639504194259643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [50]#011Speed: 875.42 samples/sec#011loss=1.263950\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[55] avg_epoch_loss=1.213466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=1.1195289850234986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [55]#011Speed: 1259.63 samples/sec#011loss=1.119529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[60] avg_epoch_loss=1.206938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=1.1338140726089478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [60]#011Speed: 617.13 samples/sec#011loss=1.133814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch[65] avg_epoch_loss=1.212473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=1.2800008296966552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:44 INFO 140281140962944] Epoch[6] Batch [65]#011Speed: 1099.24 samples/sec#011loss=1.280001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[70] avg_epoch_loss=1.212157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=1.2079939365386962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [70]#011Speed: 855.25 samples/sec#011loss=1.207994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[75] avg_epoch_loss=1.205535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=1.1114991784095765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [75]#011Speed: 1356.19 samples/sec#011loss=1.111499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[80] avg_epoch_loss=1.206291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=1.217785406112671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [80]#011Speed: 808.96 samples/sec#011loss=1.217785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[85] avg_epoch_loss=1.208470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=1.2437751293182373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [85]#011Speed: 1264.62 samples/sec#011loss=1.243775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[90] avg_epoch_loss=1.268742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=2.305406963825226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [90]#011Speed: 811.42 samples/sec#011loss=2.305407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch[95] avg_epoch_loss=1.267089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=1.237001657485962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:45 INFO 140281140962944] Epoch[6] Batch [95]#011Speed: 1352.43 samples/sec#011loss=1.237002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[100] avg_epoch_loss=1.264325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=1.2112600803375244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [100]#011Speed: 767.22 samples/sec#011loss=1.211260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[105] avg_epoch_loss=1.266202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=1.3041212797164916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [105]#011Speed: 1315.17 samples/sec#011loss=1.304121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[110] avg_epoch_loss=1.273715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=1.432996964454651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [110]#011Speed: 880.16 samples/sec#011loss=1.432997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[115] avg_epoch_loss=1.267852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=1.1376930475234985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [115]#011Speed: 1215.87 samples/sec#011loss=1.137693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[120] avg_epoch_loss=1.263256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=1.1566114544868469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [120]#011Speed: 831.09 samples/sec#011loss=1.156611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch[125] avg_epoch_loss=1.262673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=1.248574423789978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:46 INFO 140281140962944] Epoch[6] Batch [125]#011Speed: 1371.04 samples/sec#011loss=1.248574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[130] avg_epoch_loss=1.254026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=1.0361281752586364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [130]#011Speed: 844.05 samples/sec#011loss=1.036128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[135] avg_epoch_loss=1.249857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=1.1406158685684205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [135]#011Speed: 1358.99 samples/sec#011loss=1.140616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[140] avg_epoch_loss=1.246910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=1.16674702167511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [140]#011Speed: 860.15 samples/sec#011loss=1.166747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[145] avg_epoch_loss=1.250531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=1.3526482820510863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [145]#011Speed: 1358.65 samples/sec#011loss=1.352648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[150] avg_epoch_loss=1.242800\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=1.0170606136322022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [150]#011Speed: 788.90 samples/sec#011loss=1.017061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[155] avg_epoch_loss=1.235052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=1.0010712146759033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [155]#011Speed: 1324.18 samples/sec#011loss=1.001071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch[160] avg_epoch_loss=1.232997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=1.1688789129257202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:47 INFO 140281140962944] Epoch[6] Batch [160]#011Speed: 854.86 samples/sec#011loss=1.168879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[165] avg_epoch_loss=1.229415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=1.1140759706497192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [165]#011Speed: 1289.92 samples/sec#011loss=1.114076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[170] avg_epoch_loss=1.226431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=1.1273509740829468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [170]#011Speed: 835.74 samples/sec#011loss=1.127351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[175] avg_epoch_loss=1.227321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=1.2577655553817748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [175]#011Speed: 1362.31 samples/sec#011loss=1.257766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[180] avg_epoch_loss=1.223382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=1.0847232222557068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [180]#011Speed: 766.56 samples/sec#011loss=1.084723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[185] avg_epoch_loss=1.223820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=1.2396875619888306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [185]#011Speed: 1327.84 samples/sec#011loss=1.239688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch[190] avg_epoch_loss=1.227052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=1.347277283668518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:48 INFO 140281140962944] Epoch[6] Batch [190]#011Speed: 795.34 samples/sec#011loss=1.347277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[195] avg_epoch_loss=1.228495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=1.2836182594299317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [195]#011Speed: 1326.23 samples/sec#011loss=1.283618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[200] avg_epoch_loss=1.235060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=1.4924192428588867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [200]#011Speed: 840.90 samples/sec#011loss=1.492419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[205] avg_epoch_loss=1.253526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=1.995837426185608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [205]#011Speed: 1334.40 samples/sec#011loss=1.995837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[210] avg_epoch_loss=1.263908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=1.691664457321167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [210]#011Speed: 813.25 samples/sec#011loss=1.691664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[215] avg_epoch_loss=1.268737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=1.4725284099578857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [215]#011Speed: 1299.53 samples/sec#011loss=1.472528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch[220] avg_epoch_loss=1.270370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=1.3408852577209474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:49 INFO 140281140962944] Epoch[6] Batch [220]#011Speed: 545.55 samples/sec#011loss=1.340885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[225] avg_epoch_loss=1.271705\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=1.330724334716797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [225]#011Speed: 1314.02 samples/sec#011loss=1.330724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[230] avg_epoch_loss=1.270977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=1.2380711317062378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [230]#011Speed: 848.05 samples/sec#011loss=1.238071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[235] avg_epoch_loss=1.286380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=1.9980099678039551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [235]#011Speed: 1322.41 samples/sec#011loss=1.998010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[240] avg_epoch_loss=1.284182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=1.1804015159606933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [240]#011Speed: 793.85 samples/sec#011loss=1.180402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[245] avg_epoch_loss=1.281413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=1.1479856252670289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [245]#011Speed: 1316.25 samples/sec#011loss=1.147986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch[250] avg_epoch_loss=1.278681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=1.1442556619644164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:50 INFO 140281140962944] Epoch[6] Batch [250]#011Speed: 836.73 samples/sec#011loss=1.144256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[255] avg_epoch_loss=1.276411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=1.162478518486023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [255]#011Speed: 1317.01 samples/sec#011loss=1.162479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[260] avg_epoch_loss=1.275503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=1.2290128231048585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [260]#011Speed: 820.45 samples/sec#011loss=1.229013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[265] avg_epoch_loss=1.283748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=1.7141282558441162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [265]#011Speed: 1371.26 samples/sec#011loss=1.714128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[270] avg_epoch_loss=1.294548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=270 train loss <loss>=1.8691116571426392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [270]#011Speed: 858.23 samples/sec#011loss=1.869112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[275] avg_epoch_loss=1.291254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=275 train loss <loss>=1.1127177953720093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [275]#011Speed: 1257.04 samples/sec#011loss=1.112718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch[280] avg_epoch_loss=1.288310\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=280 train loss <loss>=1.1257898092269898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:51 INFO 140281140962944] Epoch[6] Batch [280]#011Speed: 848.39 samples/sec#011loss=1.125790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[285] avg_epoch_loss=1.285314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=285 train loss <loss>=1.1169332027435304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [285]#011Speed: 1314.41 samples/sec#011loss=1.116933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[290] avg_epoch_loss=1.282175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=290 train loss <loss>=1.1026313304901123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [290]#011Speed: 837.83 samples/sec#011loss=1.102631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[295] avg_epoch_loss=1.278798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=295 train loss <loss>=1.0822400093078612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [295]#011Speed: 1356.14 samples/sec#011loss=1.082240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[300] avg_epoch_loss=1.274426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=300 train loss <loss>=1.0156419396400451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [300]#011Speed: 872.78 samples/sec#011loss=1.015642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[305] avg_epoch_loss=1.274023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=305 train loss <loss>=1.2497605562210083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [305]#011Speed: 1246.03 samples/sec#011loss=1.249761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[310] avg_epoch_loss=1.271611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=310 train loss <loss>=1.1239505767822267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [310]#011Speed: 854.57 samples/sec#011loss=1.123951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch[315] avg_epoch_loss=1.279636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=315 train loss <loss>=1.778791880607605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:52 INFO 140281140962944] Epoch[6] Batch [315]#011Speed: 1363.63 samples/sec#011loss=1.778792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[320] avg_epoch_loss=1.277358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=320 train loss <loss>=1.1334031820297241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [320]#011Speed: 856.54 samples/sec#011loss=1.133403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[325] avg_epoch_loss=1.276293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=325 train loss <loss>=1.2079347133636475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [325]#011Speed: 1301.25 samples/sec#011loss=1.207935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[330] avg_epoch_loss=1.275240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=330 train loss <loss>=1.2065797328948975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [330]#011Speed: 866.31 samples/sec#011loss=1.206580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[335] avg_epoch_loss=1.273246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=335 train loss <loss>=1.1412063837051392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [335]#011Speed: 1370.73 samples/sec#011loss=1.141206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[340] avg_epoch_loss=1.270413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=340 train loss <loss>=1.0800971269607544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [340]#011Speed: 826.90 samples/sec#011loss=1.080097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch[345] avg_epoch_loss=1.267943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=345 train loss <loss>=1.0994686365127564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:53 INFO 140281140962944] Epoch[6] Batch [345]#011Speed: 1364.49 samples/sec#011loss=1.099469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[350] avg_epoch_loss=1.266132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=350 train loss <loss>=1.1408063888549804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [350]#011Speed: 852.26 samples/sec#011loss=1.140806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[355] avg_epoch_loss=1.262468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=355 train loss <loss>=1.005265200138092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [355]#011Speed: 1313.49 samples/sec#011loss=1.005265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[360] avg_epoch_loss=1.259970\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=360 train loss <loss>=1.0820652365684509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [360]#011Speed: 862.47 samples/sec#011loss=1.082065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[365] avg_epoch_loss=1.259456\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=365 train loss <loss>=1.2224032282829285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [365]#011Speed: 1378.71 samples/sec#011loss=1.222403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[370] avg_epoch_loss=1.255671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=370 train loss <loss>=0.978585171699524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [370]#011Speed: 814.78 samples/sec#011loss=0.978585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[375] avg_epoch_loss=1.253774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=375 train loss <loss>=1.1130251169204712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [375]#011Speed: 1371.84 samples/sec#011loss=1.113025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch[380] avg_epoch_loss=1.256279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=380 train loss <loss>=1.444653058052063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:54 INFO 140281140962944] Epoch[6] Batch [380]#011Speed: 752.42 samples/sec#011loss=1.444653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[385] avg_epoch_loss=1.252441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=385 train loss <loss>=0.9599414825439453\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [385]#011Speed: 826.87 samples/sec#011loss=0.959941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[390] avg_epoch_loss=1.249884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=390 train loss <loss>=1.0524823188781738\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [390]#011Speed: 824.95 samples/sec#011loss=1.052482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[395] avg_epoch_loss=1.246579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=395 train loss <loss>=0.9881485819816589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [395]#011Speed: 1345.75 samples/sec#011loss=0.988149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[400] avg_epoch_loss=1.242664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=400 train loss <loss>=0.9326163172721863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [400]#011Speed: 768.18 samples/sec#011loss=0.932616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch[405] avg_epoch_loss=1.240759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=405 train loss <loss>=1.08799649477005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:55 INFO 140281140962944] Epoch[6] Batch [405]#011Speed: 1269.89 samples/sec#011loss=1.087996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[410] avg_epoch_loss=1.237221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=410 train loss <loss>=0.9499072670936585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [410]#011Speed: 808.86 samples/sec#011loss=0.949907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[415] avg_epoch_loss=1.235596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=415 train loss <loss>=1.1020413517951966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [415]#011Speed: 1352.16 samples/sec#011loss=1.102041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[420] avg_epoch_loss=1.235659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=420 train loss <loss>=1.240854549407959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [420]#011Speed: 847.45 samples/sec#011loss=1.240855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[425] avg_epoch_loss=1.232247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=425 train loss <loss>=0.9449854254722595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [425]#011Speed: 1340.61 samples/sec#011loss=0.944985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[430] avg_epoch_loss=1.231999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=430 train loss <loss>=1.2109062433242799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [430]#011Speed: 862.65 samples/sec#011loss=1.210906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[435] avg_epoch_loss=1.231377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=435 train loss <loss>=1.177693510055542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [435]#011Speed: 1216.92 samples/sec#011loss=1.177694\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch[440] avg_epoch_loss=1.230956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=440 train loss <loss>=1.1942971110343934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:56 INFO 140281140962944] Epoch[6] Batch [440]#011Speed: 831.29 samples/sec#011loss=1.194297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[445] avg_epoch_loss=1.229728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=445 train loss <loss>=1.1213773250579835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [445]#011Speed: 1316.14 samples/sec#011loss=1.121377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[450] avg_epoch_loss=1.226854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=450 train loss <loss>=0.9705368161201477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [450]#011Speed: 855.39 samples/sec#011loss=0.970537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[455] avg_epoch_loss=1.225488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=455 train loss <loss>=1.1022768020629883\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [455]#011Speed: 1347.74 samples/sec#011loss=1.102277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[460] avg_epoch_loss=1.224376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=460 train loss <loss>=1.1229016184806824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [460]#011Speed: 876.79 samples/sec#011loss=1.122902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[465] avg_epoch_loss=1.221784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=465 train loss <loss>=0.9828758478164673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [465]#011Speed: 1171.10 samples/sec#011loss=0.982876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch[470] avg_epoch_loss=1.221768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=470 train loss <loss>=1.2202656745910645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:57 INFO 140281140962944] Epoch[6] Batch [470]#011Speed: 860.65 samples/sec#011loss=1.220266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[475] avg_epoch_loss=1.233801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=475 train loss <loss>=2.3672322630882263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [475]#011Speed: 1368.11 samples/sec#011loss=2.367232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[480] avg_epoch_loss=1.233954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=480 train loss <loss>=1.2485323429107666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [480]#011Speed: 816.51 samples/sec#011loss=1.248532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[485] avg_epoch_loss=1.233530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=485 train loss <loss>=1.1927481651306153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [485]#011Speed: 1373.62 samples/sec#011loss=1.192748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[490] avg_epoch_loss=1.234192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=490 train loss <loss>=1.2985690355300903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [490]#011Speed: 865.55 samples/sec#011loss=1.298569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[495] avg_epoch_loss=1.233274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=495 train loss <loss>=1.1430814027786256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [495]#011Speed: 1363.83 samples/sec#011loss=1.143081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[500] avg_epoch_loss=1.231818\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=500 train loss <loss>=1.0874413013458253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [500]#011Speed: 803.50 samples/sec#011loss=1.087441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch[505] avg_epoch_loss=1.231312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=505 train loss <loss>=1.180580723285675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:58 INFO 140281140962944] Epoch[6] Batch [505]#011Speed: 1338.83 samples/sec#011loss=1.180581\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[510] avg_epoch_loss=1.229057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=510 train loss <loss>=1.0008270263671875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [510]#011Speed: 860.15 samples/sec#011loss=1.000827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[515] avg_epoch_loss=1.226877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=515 train loss <loss>=1.0041272282600402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [515]#011Speed: 1311.94 samples/sec#011loss=1.004127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[520] avg_epoch_loss=1.225533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=520 train loss <loss>=1.0868736863136292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [520]#011Speed: 850.31 samples/sec#011loss=1.086874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[525] avg_epoch_loss=1.223255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=525 train loss <loss>=0.9858634829521179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [525]#011Speed: 1382.27 samples/sec#011loss=0.985863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[530] avg_epoch_loss=1.221725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=530 train loss <loss>=1.0607390403747559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [530]#011Speed: 783.88 samples/sec#011loss=1.060739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch[535] avg_epoch_loss=1.220651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=535 train loss <loss>=1.1066262483596803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:15:59 INFO 140281140962944] Epoch[6] Batch [535]#011Speed: 1370.25 samples/sec#011loss=1.106626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch[540] avg_epoch_loss=1.219340\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=540 train loss <loss>=1.0788007140159608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch [540]#011Speed: 610.54 samples/sec#011loss=1.078801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch[545] avg_epoch_loss=1.219634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=545 train loss <loss>=1.2514257788658143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch [545]#011Speed: 775.97 samples/sec#011loss=1.251426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch[550] avg_epoch_loss=1.220864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, batch=550 train loss <loss>=1.3551444292068482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[6] Batch [550]#011Speed: 805.14 samples/sec#011loss=1.355144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] processed a total of 17669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717342.5347297, \"EndTime\": 1620717360.5969174, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18062.083959579468, \"count\": 1, \"min\": 18062.083959579468, \"max\": 18062.083959579468}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=978.2314221695659 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.2209775296947625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_fdaa35cc-cfad-42fc-b79d-5bf824b9c7a4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717360.5969875, \"EndTime\": 1620717360.6069279, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.435415267944336, \"count\": 1, \"min\": 9.435415267944336, \"max\": 9.435415267944336}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[7] Batch[0] avg_epoch_loss=1.102039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.1020385026931763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[7] Batch[5] avg_epoch_loss=1.052074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=1.05207355817159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:00 INFO 140281140962944] Epoch[7] Batch [5]#011Speed: 1105.82 samples/sec#011loss=1.052074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[10] avg_epoch_loss=1.118799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=1.1988701343536377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [10]#011Speed: 827.27 samples/sec#011loss=1.198870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[15] avg_epoch_loss=1.103774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=1.0707199335098267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [15]#011Speed: 1290.36 samples/sec#011loss=1.070720\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[20] avg_epoch_loss=1.080394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=1.0055774569511413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [20]#011Speed: 839.51 samples/sec#011loss=1.005577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[25] avg_epoch_loss=1.089356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=1.1269929885864258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [25]#011Speed: 1335.84 samples/sec#011loss=1.126993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[30] avg_epoch_loss=1.096863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=1.1359016299247742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [30]#011Speed: 846.94 samples/sec#011loss=1.135902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[35] avg_epoch_loss=1.105255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=1.157288408279419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [35]#011Speed: 1243.59 samples/sec#011loss=1.157288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch[40] avg_epoch_loss=1.096693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=1.035046935081482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:01 INFO 140281140962944] Epoch[7] Batch [40]#011Speed: 833.19 samples/sec#011loss=1.035047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[45] avg_epoch_loss=1.091015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=1.0444485187530517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [45]#011Speed: 505.07 samples/sec#011loss=1.044449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[50] avg_epoch_loss=1.109043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=1.274900460243225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [50]#011Speed: 548.52 samples/sec#011loss=1.274900\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[55] avg_epoch_loss=1.104923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=1.0629021883010865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [55]#011Speed: 1203.30 samples/sec#011loss=1.062902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch[60] avg_epoch_loss=1.104824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=1.103713321685791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:02 INFO 140281140962944] Epoch[7] Batch [60]#011Speed: 806.78 samples/sec#011loss=1.103713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[65] avg_epoch_loss=1.105091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=1.1083482265472413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [65]#011Speed: 1345.95 samples/sec#011loss=1.108348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[70] avg_epoch_loss=1.104089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=1.0908694505691527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [70]#011Speed: 839.54 samples/sec#011loss=1.090869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[75] avg_epoch_loss=1.101820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=1.069601547718048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [75]#011Speed: 1329.63 samples/sec#011loss=1.069602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[80] avg_epoch_loss=1.103316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=1.1260426998138429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [80]#011Speed: 842.50 samples/sec#011loss=1.126043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[85] avg_epoch_loss=1.093499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=0.9344653964042664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [85]#011Speed: 1361.36 samples/sec#011loss=0.934465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[90] avg_epoch_loss=1.208093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=3.179115915298462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [90]#011Speed: 782.44 samples/sec#011loss=3.179116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch[95] avg_epoch_loss=1.232363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=1.6740705490112304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:03 INFO 140281140962944] Epoch[7] Batch [95]#011Speed: 1310.69 samples/sec#011loss=1.674071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[100] avg_epoch_loss=1.243816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=1.4637139081954955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [100]#011Speed: 849.09 samples/sec#011loss=1.463714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[105] avg_epoch_loss=1.255677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=1.4952784538269044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [105]#011Speed: 1095.58 samples/sec#011loss=1.495278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[110] avg_epoch_loss=1.264797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=1.458134126663208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [110]#011Speed: 490.58 samples/sec#011loss=1.458134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch[115] avg_epoch_loss=1.273417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=1.464790439605713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:04 INFO 140281140962944] Epoch[7] Batch [115]#011Speed: 737.93 samples/sec#011loss=1.464790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[120] avg_epoch_loss=1.278269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=1.3908278942108154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [120]#011Speed: 513.00 samples/sec#011loss=1.390828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[125] avg_epoch_loss=1.279078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=1.298645305633545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [125]#011Speed: 1361.65 samples/sec#011loss=1.298645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[130] avg_epoch_loss=1.276370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=1.2081377267837525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [130]#011Speed: 829.88 samples/sec#011loss=1.208138\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch[135] avg_epoch_loss=1.272575\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=1.1731439352035522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:05 INFO 140281140962944] Epoch[7] Batch [135]#011Speed: 785.43 samples/sec#011loss=1.173144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[140] avg_epoch_loss=1.265988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=1.0868150234222411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [140]#011Speed: 422.18 samples/sec#011loss=1.086815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[145] avg_epoch_loss=1.270797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=1.4064194440841675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [145]#011Speed: 760.66 samples/sec#011loss=1.406419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[150] avg_epoch_loss=1.264147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=1.0699841260910035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [150]#011Speed: 494.85 samples/sec#011loss=1.069984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch[155] avg_epoch_loss=1.259594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=1.1220916986465455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:06 INFO 140281140962944] Epoch[7] Batch [155]#011Speed: 756.08 samples/sec#011loss=1.122092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[160] avg_epoch_loss=1.263504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=1.385477614402771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [160]#011Speed: 494.42 samples/sec#011loss=1.385478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[165] avg_epoch_loss=1.255401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=0.9944855690002441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [165]#011Speed: 857.47 samples/sec#011loss=0.994486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[170] avg_epoch_loss=1.250163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=1.0762680053710938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [170]#011Speed: 497.20 samples/sec#011loss=1.076268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch[175] avg_epoch_loss=1.241661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=0.9509009957313538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:07 INFO 140281140962944] Epoch[7] Batch [175]#011Speed: 772.15 samples/sec#011loss=0.950901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[180] avg_epoch_loss=1.235155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=1.0061460971832275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [180]#011Speed: 529.41 samples/sec#011loss=1.006146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[185] avg_epoch_loss=1.237646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=1.3278074860572815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [185]#011Speed: 1376.25 samples/sec#011loss=1.327807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[190] avg_epoch_loss=1.248303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=1.644739818572998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [190]#011Speed: 872.40 samples/sec#011loss=1.644740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[195] avg_epoch_loss=1.276791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=2.365052914619446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [195]#011Speed: 1190.98 samples/sec#011loss=2.365053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[200] avg_epoch_loss=1.276830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=1.2783298254013062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [200]#011Speed: 855.59 samples/sec#011loss=1.278330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch[205] avg_epoch_loss=1.278940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=1.363762378692627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:08 INFO 140281140962944] Epoch[7] Batch [205]#011Speed: 1312.10 samples/sec#011loss=1.363762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[210] avg_epoch_loss=1.280366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=1.3391271352767944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [210]#011Speed: 796.46 samples/sec#011loss=1.339127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[215] avg_epoch_loss=1.280856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=1.3015296936035157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [215]#011Speed: 1348.34 samples/sec#011loss=1.301530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[220] avg_epoch_loss=1.280240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=1.2536452770233155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [220]#011Speed: 862.20 samples/sec#011loss=1.253645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[225] avg_epoch_loss=1.278220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=1.1889219760894776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [225]#011Speed: 1354.60 samples/sec#011loss=1.188922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[230] avg_epoch_loss=1.275838\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=1.1681614875793458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [230]#011Speed: 854.50 samples/sec#011loss=1.168161\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch[235] avg_epoch_loss=1.272709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=1.1281487226486206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:09 INFO 140281140962944] Epoch[7] Batch [235]#011Speed: 1361.06 samples/sec#011loss=1.128149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[240] avg_epoch_loss=1.267172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=1.0058167338371278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [240]#011Speed: 767.85 samples/sec#011loss=1.005817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[245] avg_epoch_loss=1.261999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=1.0127063751220704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [245]#011Speed: 1359.60 samples/sec#011loss=1.012706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[250] avg_epoch_loss=1.257621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=1.0421804785728455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [250]#011Speed: 834.99 samples/sec#011loss=1.042180\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[255] avg_epoch_loss=1.256443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=1.1973092198371886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [255]#011Speed: 1365.37 samples/sec#011loss=1.197309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[260] avg_epoch_loss=1.259922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=1.4380678415298462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [260]#011Speed: 849.39 samples/sec#011loss=1.438068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch[265] avg_epoch_loss=1.254779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=0.98628830909729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:10 INFO 140281140962944] Epoch[7] Batch [265]#011Speed: 1356.35 samples/sec#011loss=0.986288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[270] avg_epoch_loss=1.251420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=270 train loss <loss>=1.0727446913719176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [270]#011Speed: 652.11 samples/sec#011loss=1.072745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[275] avg_epoch_loss=1.268268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=275 train loss <loss>=2.1814017057418824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [275]#011Speed: 1048.33 samples/sec#011loss=2.181402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[280] avg_epoch_loss=1.266158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=280 train loss <loss>=1.1497368335723877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [280]#011Speed: 752.47 samples/sec#011loss=1.149737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[285] avg_epoch_loss=1.266051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=285 train loss <loss>=1.2600306510925292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [285]#011Speed: 1348.35 samples/sec#011loss=1.260031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[290] avg_epoch_loss=1.264284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=290 train loss <loss>=1.1632087469100951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [290]#011Speed: 820.44 samples/sec#011loss=1.163209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch[295] avg_epoch_loss=1.264460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=295 train loss <loss>=1.2747018814086915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:11 INFO 140281140962944] Epoch[7] Batch [295]#011Speed: 1319.31 samples/sec#011loss=1.274702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[300] avg_epoch_loss=1.262466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=300 train loss <loss>=1.1444212675094605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [300]#011Speed: 796.70 samples/sec#011loss=1.144421\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[305] avg_epoch_loss=1.261254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=305 train loss <loss>=1.1882685422897339\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [305]#011Speed: 1282.87 samples/sec#011loss=1.188269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[310] avg_epoch_loss=1.259959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=310 train loss <loss>=1.1807273626327515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [310]#011Speed: 867.39 samples/sec#011loss=1.180727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[315] avg_epoch_loss=1.256805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=315 train loss <loss>=1.0606006503105163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [315]#011Speed: 1367.46 samples/sec#011loss=1.060601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[320] avg_epoch_loss=1.255262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=320 train loss <loss>=1.1577602863311767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [320]#011Speed: 850.08 samples/sec#011loss=1.157760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[325] avg_epoch_loss=1.253954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=325 train loss <loss>=1.1699575901031494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [325]#011Speed: 1346.86 samples/sec#011loss=1.169958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch[330] avg_epoch_loss=1.252213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=330 train loss <loss>=1.1387073278427124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:12 INFO 140281140962944] Epoch[7] Batch [330]#011Speed: 862.24 samples/sec#011loss=1.138707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[335] avg_epoch_loss=1.249007\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=335 train loss <loss>=1.0367954611778258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [335]#011Speed: 1243.17 samples/sec#011loss=1.036795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[340] avg_epoch_loss=1.246113\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=340 train loss <loss>=1.0516493201255799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [340]#011Speed: 851.79 samples/sec#011loss=1.051649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[345] avg_epoch_loss=1.244382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=345 train loss <loss>=1.12629314661026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [345]#011Speed: 1372.70 samples/sec#011loss=1.126293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[350] avg_epoch_loss=1.240405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=350 train loss <loss>=0.9652140498161316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [350]#011Speed: 850.73 samples/sec#011loss=0.965214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[355] avg_epoch_loss=1.240952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=355 train loss <loss>=1.2793522357940674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [355]#011Speed: 1319.62 samples/sec#011loss=1.279352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch[360] avg_epoch_loss=1.239314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=360 train loss <loss>=1.1226968169212341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:13 INFO 140281140962944] Epoch[7] Batch [360]#011Speed: 841.72 samples/sec#011loss=1.122697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[365] avg_epoch_loss=1.237571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=365 train loss <loss>=1.1117440223693849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [365]#011Speed: 1257.25 samples/sec#011loss=1.111744\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[370] avg_epoch_loss=1.239482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=370 train loss <loss>=1.3793116927146911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [370]#011Speed: 544.05 samples/sec#011loss=1.379312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[375] avg_epoch_loss=1.239617\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=375 train loss <loss>=1.2496373414993287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [375]#011Speed: 848.19 samples/sec#011loss=1.249637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[380] avg_epoch_loss=1.238611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=380 train loss <loss>=1.16294686794281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [380]#011Speed: 617.59 samples/sec#011loss=1.162947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch[385] avg_epoch_loss=1.236451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=385 train loss <loss>=1.0718721747398376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:14 INFO 140281140962944] Epoch[7] Batch [385]#011Speed: 1356.19 samples/sec#011loss=1.071872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[390] avg_epoch_loss=1.233274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=390 train loss <loss>=0.9880045533180237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [390]#011Speed: 767.73 samples/sec#011loss=0.988005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[395] avg_epoch_loss=1.235459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=395 train loss <loss>=1.4063725471496582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [395]#011Speed: 1295.07 samples/sec#011loss=1.406373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[400] avg_epoch_loss=1.234299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=400 train loss <loss>=1.1423911094665526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [400]#011Speed: 830.46 samples/sec#011loss=1.142391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[405] avg_epoch_loss=1.231923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=405 train loss <loss>=1.0413501262664795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [405]#011Speed: 1335.89 samples/sec#011loss=1.041350\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[410] avg_epoch_loss=1.229786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=410 train loss <loss>=1.0562950372695923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [410]#011Speed: 864.75 samples/sec#011loss=1.056295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[415] avg_epoch_loss=1.227289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=415 train loss <loss>=1.0220707297325133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [415]#011Speed: 1366.66 samples/sec#011loss=1.022071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch[420] avg_epoch_loss=1.226482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=420 train loss <loss>=1.159303879737854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:15 INFO 140281140962944] Epoch[7] Batch [420]#011Speed: 835.43 samples/sec#011loss=1.159304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[425] avg_epoch_loss=1.224346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=425 train loss <loss>=1.0445268988609313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [425]#011Speed: 1020.71 samples/sec#011loss=1.044527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[430] avg_epoch_loss=1.222743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=430 train loss <loss>=1.0861154556274415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [430]#011Speed: 701.29 samples/sec#011loss=1.086115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[435] avg_epoch_loss=1.224255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=435 train loss <loss>=1.3545716762542725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [435]#011Speed: 1179.25 samples/sec#011loss=1.354572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[440] avg_epoch_loss=1.222446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=440 train loss <loss>=1.064713752269745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [440]#011Speed: 848.61 samples/sec#011loss=1.064714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch[445] avg_epoch_loss=1.220869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=445 train loss <loss>=1.0818342804908752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:16 INFO 140281140962944] Epoch[7] Batch [445]#011Speed: 1348.19 samples/sec#011loss=1.081834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[450] avg_epoch_loss=1.219567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=450 train loss <loss>=1.1033507704734802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [450]#011Speed: 839.34 samples/sec#011loss=1.103351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[455] avg_epoch_loss=1.221033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=455 train loss <loss>=1.3532626628875732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [455]#011Speed: 1236.99 samples/sec#011loss=1.353263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[460] avg_epoch_loss=1.220442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=460 train loss <loss>=1.1665980100631714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [460]#011Speed: 824.80 samples/sec#011loss=1.166598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[465] avg_epoch_loss=1.218961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=465 train loss <loss>=1.0823760509490967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [465]#011Speed: 1361.44 samples/sec#011loss=1.082376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[470] avg_epoch_loss=1.216426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=470 train loss <loss>=0.9801885962486268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [470]#011Speed: 843.87 samples/sec#011loss=0.980189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[475] avg_epoch_loss=1.214724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=475 train loss <loss>=1.0544370889663697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [475]#011Speed: 1287.71 samples/sec#011loss=1.054437\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch[480] avg_epoch_loss=1.212236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=480 train loss <loss>=0.9753236293792724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:17 INFO 140281140962944] Epoch[7] Batch [480]#011Speed: 849.00 samples/sec#011loss=0.975324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[485] avg_epoch_loss=1.214439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=485 train loss <loss>=1.4263409972190857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [485]#011Speed: 1221.34 samples/sec#011loss=1.426341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[490] avg_epoch_loss=1.215697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=490 train loss <loss>=1.3379872560501098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [490]#011Speed: 830.51 samples/sec#011loss=1.337987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[495] avg_epoch_loss=1.214190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=495 train loss <loss>=1.066230881214142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [495]#011Speed: 1359.35 samples/sec#011loss=1.066231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[500] avg_epoch_loss=1.212137\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=500 train loss <loss>=1.0084755063056945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [500]#011Speed: 847.13 samples/sec#011loss=1.008476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[505] avg_epoch_loss=1.210431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=505 train loss <loss>=1.0394826173782348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [505]#011Speed: 1315.83 samples/sec#011loss=1.039483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch[510] avg_epoch_loss=1.208891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=510 train loss <loss>=1.0530263662338257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:18 INFO 140281140962944] Epoch[7] Batch [510]#011Speed: 833.96 samples/sec#011loss=1.053026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[515] avg_epoch_loss=1.208217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=515 train loss <loss>=1.139312195777893\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [515]#011Speed: 1353.73 samples/sec#011loss=1.139312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[520] avg_epoch_loss=1.206230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=520 train loss <loss>=1.001208519935608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [520]#011Speed: 803.24 samples/sec#011loss=1.001209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[525] avg_epoch_loss=1.204983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=525 train loss <loss>=1.0750566720962524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [525]#011Speed: 1320.45 samples/sec#011loss=1.075057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[530] avg_epoch_loss=1.202676\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=530 train loss <loss>=0.9599546432495117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [530]#011Speed: 860.49 samples/sec#011loss=0.959955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[535] avg_epoch_loss=1.204289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=535 train loss <loss>=1.3756592869758606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [535]#011Speed: 1371.23 samples/sec#011loss=1.375659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[540] avg_epoch_loss=1.203262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=540 train loss <loss>=1.093112325668335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [540]#011Speed: 919.89 samples/sec#011loss=1.093112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch[545] avg_epoch_loss=1.200940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, batch=545 train loss <loss>=0.9497390747070312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:19 INFO 140281140962944] Epoch[7] Batch [545]#011Speed: 1362.17 samples/sec#011loss=0.949739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] processed a total of 17548 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717360.6069915, \"EndTime\": 1620717380.0171654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 19410.11095046997, \"count\": 1, \"min\": 19410.11095046997, \"max\": 19410.11095046997}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=904.0568371748502 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=7, train loss <loss>=1.1999961616563015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_3b4e50f4-9087-41f9-a50e-d5c79f61b6ba-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717380.0173016, \"EndTime\": 1620717380.0284007, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.373353958129883, \"count\": 1, \"min\": 10.373353958129883, \"max\": 10.373353958129883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[0] avg_epoch_loss=1.039583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=1.03958261013031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[5] avg_epoch_loss=1.036236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=1.0362363457679749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [5]#011Speed: 1333.83 samples/sec#011loss=1.036236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[10] avg_epoch_loss=0.993206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=0.941569697856903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [10]#011Speed: 802.98 samples/sec#011loss=0.941570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[15] avg_epoch_loss=1.050928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=1.1779156804084778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [15]#011Speed: 1360.38 samples/sec#011loss=1.177916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[20] avg_epoch_loss=1.067241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=1.1194446325302123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [20]#011Speed: 853.77 samples/sec#011loss=1.119445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch[25] avg_epoch_loss=1.077845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=1.1223817706108092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:20 INFO 140281140962944] Epoch[8] Batch [25]#011Speed: 1313.25 samples/sec#011loss=1.122382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[30] avg_epoch_loss=1.086982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=1.1344940662384033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [30]#011Speed: 826.53 samples/sec#011loss=1.134494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[35] avg_epoch_loss=1.095834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=1.150717067718506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [35]#011Speed: 1164.72 samples/sec#011loss=1.150717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[40] avg_epoch_loss=1.094512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=1.0849953651428224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [40]#011Speed: 629.38 samples/sec#011loss=1.084995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[45] avg_epoch_loss=1.093012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=1.0807113528251648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [45]#011Speed: 1342.90 samples/sec#011loss=1.080711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[50] avg_epoch_loss=1.095417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=1.1175428748130798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [50]#011Speed: 837.96 samples/sec#011loss=1.117543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch[55] avg_epoch_loss=1.100869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=1.156474781036377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:21 INFO 140281140962944] Epoch[8] Batch [55]#011Speed: 1340.06 samples/sec#011loss=1.156475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[60] avg_epoch_loss=1.101201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=1.1049270749092102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [60]#011Speed: 829.36 samples/sec#011loss=1.104927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[65] avg_epoch_loss=1.110835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=1.2283591985702516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [65]#011Speed: 1201.78 samples/sec#011loss=1.228359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[70] avg_epoch_loss=1.105247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=1.0314926266670228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [70]#011Speed: 842.74 samples/sec#011loss=1.031493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[75] avg_epoch_loss=1.106250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=1.1204850316047668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [75]#011Speed: 1334.08 samples/sec#011loss=1.120485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[80] avg_epoch_loss=1.104010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=1.0699642300605774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [80]#011Speed: 846.03 samples/sec#011loss=1.069964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch[85] avg_epoch_loss=1.107942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=1.1716498017311097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:22 INFO 140281140962944] Epoch[8] Batch [85]#011Speed: 1355.93 samples/sec#011loss=1.171650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[90] avg_epoch_loss=1.109479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=1.1359044551849364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [90]#011Speed: 857.94 samples/sec#011loss=1.135904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[95] avg_epoch_loss=1.118060\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=1.27423437833786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [95]#011Speed: 1347.40 samples/sec#011loss=1.274234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[100] avg_epoch_loss=1.113119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=1.018255066871643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [100]#011Speed: 794.29 samples/sec#011loss=1.018255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[105] avg_epoch_loss=1.175767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=2.4412645578384398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [105]#011Speed: 1370.29 samples/sec#011loss=2.441265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[110] avg_epoch_loss=1.174845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=1.1552971601486206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [110]#011Speed: 874.00 samples/sec#011loss=1.155297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[115] avg_epoch_loss=1.178482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=1.2592284440994264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [115]#011Speed: 1301.38 samples/sec#011loss=1.259228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch[120] avg_epoch_loss=1.178597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=1.1812655687332154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:23 INFO 140281140962944] Epoch[8] Batch [120]#011Speed: 844.78 samples/sec#011loss=1.181266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[125] avg_epoch_loss=1.177577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=1.1528944969177246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [125]#011Speed: 1358.42 samples/sec#011loss=1.152894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[130] avg_epoch_loss=1.173874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=1.0805550575256349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [130]#011Speed: 808.24 samples/sec#011loss=1.080555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[135] avg_epoch_loss=1.172729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=1.1427334785461425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [135]#011Speed: 1362.90 samples/sec#011loss=1.142733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[140] avg_epoch_loss=1.174576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=1.2247879266738892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [140]#011Speed: 820.08 samples/sec#011loss=1.224788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[145] avg_epoch_loss=1.168689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=1.0027024865150451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [145]#011Speed: 1360.97 samples/sec#011loss=1.002702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch[150] avg_epoch_loss=1.165213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=1.0637009501457215\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:24 INFO 140281140962944] Epoch[8] Batch [150]#011Speed: 854.68 samples/sec#011loss=1.063701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[155] avg_epoch_loss=1.164166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=1.1325406074523925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [155]#011Speed: 1355.99 samples/sec#011loss=1.132541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[160] avg_epoch_loss=1.160384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=1.0423766493797302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [160]#011Speed: 575.01 samples/sec#011loss=1.042377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[165] avg_epoch_loss=1.159731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=1.1387144804000855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [165]#011Speed: 1087.55 samples/sec#011loss=1.138714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[170] avg_epoch_loss=1.159641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=1.156655728816986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [170]#011Speed: 839.63 samples/sec#011loss=1.156656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[175] avg_epoch_loss=1.154098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=0.9645320177078247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [175]#011Speed: 1321.45 samples/sec#011loss=0.964532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch[180] avg_epoch_loss=1.158389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=1.3094240069389342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:25 INFO 140281140962944] Epoch[8] Batch [180]#011Speed: 840.61 samples/sec#011loss=1.309424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[185] avg_epoch_loss=1.153568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=0.9790367603302002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [185]#011Speed: 1205.12 samples/sec#011loss=0.979037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[190] avg_epoch_loss=1.149523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=0.9990558862686157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [190]#011Speed: 655.06 samples/sec#011loss=0.999056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[195] avg_epoch_loss=1.163445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=1.695276129245758\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [195]#011Speed: 777.32 samples/sec#011loss=1.695276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[200] avg_epoch_loss=1.167297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=1.318299150466919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [200]#011Speed: 760.11 samples/sec#011loss=1.318299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch[205] avg_epoch_loss=1.167691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=1.1835355520248414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:26 INFO 140281140962944] Epoch[8] Batch [205]#011Speed: 1349.53 samples/sec#011loss=1.183536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[210] avg_epoch_loss=1.173287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=1.4038155555725098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [210]#011Speed: 853.50 samples/sec#011loss=1.403816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[215] avg_epoch_loss=1.172136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=1.1235957622528077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [215]#011Speed: 1224.50 samples/sec#011loss=1.123596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[220] avg_epoch_loss=1.169420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=1.052073347568512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [220]#011Speed: 800.83 samples/sec#011loss=1.052073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[225] avg_epoch_loss=1.166678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=1.0454883217811584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [225]#011Speed: 1363.02 samples/sec#011loss=1.045488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[230] avg_epoch_loss=1.164911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=1.0850545406341552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [230]#011Speed: 864.69 samples/sec#011loss=1.085055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[235] avg_epoch_loss=1.184599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=2.0941876649856566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [235]#011Speed: 1297.75 samples/sec#011loss=2.094188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch[240] avg_epoch_loss=1.182987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=1.1069018125534058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:27 INFO 140281140962944] Epoch[8] Batch [240]#011Speed: 813.16 samples/sec#011loss=1.106902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[245] avg_epoch_loss=1.182796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=1.1735527753829955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [245]#011Speed: 1353.54 samples/sec#011loss=1.173553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[250] avg_epoch_loss=1.181780\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=1.1318134307861327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [250]#011Speed: 812.03 samples/sec#011loss=1.131813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[255] avg_epoch_loss=1.180839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=1.133593702316284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [255]#011Speed: 1334.49 samples/sec#011loss=1.133594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[260] avg_epoch_loss=1.179677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=1.1201954126358031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [260]#011Speed: 825.32 samples/sec#011loss=1.120195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[265] avg_epoch_loss=1.194164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=265 train loss <loss>=1.9503593444824219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [265]#011Speed: 1298.01 samples/sec#011loss=1.950359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch[270] avg_epoch_loss=1.193355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=270 train loss <loss>=1.150333857536316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:28 INFO 140281140962944] Epoch[8] Batch [270]#011Speed: 838.38 samples/sec#011loss=1.150334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[275] avg_epoch_loss=1.190968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=275 train loss <loss>=1.0615883827209474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [275]#011Speed: 1350.69 samples/sec#011loss=1.061588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[280] avg_epoch_loss=1.187825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=280 train loss <loss>=1.014358150959015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [280]#011Speed: 848.84 samples/sec#011loss=1.014358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[285] avg_epoch_loss=1.184578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=285 train loss <loss>=1.0020635008811951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [285]#011Speed: 1250.23 samples/sec#011loss=1.002064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[290] avg_epoch_loss=1.180741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=290 train loss <loss>=0.9612534165382385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [290]#011Speed: 826.66 samples/sec#011loss=0.961253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[295] avg_epoch_loss=1.179775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=295 train loss <loss>=1.1235867977142333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [295]#011Speed: 1373.34 samples/sec#011loss=1.123587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[300] avg_epoch_loss=1.178777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=300 train loss <loss>=1.1196950793266296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [300]#011Speed: 879.09 samples/sec#011loss=1.119695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch[305] avg_epoch_loss=1.177824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=305 train loss <loss>=1.1204546689987183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:29 INFO 140281140962944] Epoch[8] Batch [305]#011Speed: 1352.30 samples/sec#011loss=1.120455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[310] avg_epoch_loss=1.176205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=310 train loss <loss>=1.0771085500717164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [310]#011Speed: 802.64 samples/sec#011loss=1.077109\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[315] avg_epoch_loss=1.186459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=315 train loss <loss>=1.8242642879486084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [315]#011Speed: 1265.93 samples/sec#011loss=1.824264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[320] avg_epoch_loss=1.185022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=320 train loss <loss>=1.0942039966583252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [320]#011Speed: 843.54 samples/sec#011loss=1.094204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[325] avg_epoch_loss=1.183896\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=325 train loss <loss>=1.111574125289917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [325]#011Speed: 1365.68 samples/sec#011loss=1.111574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[330] avg_epoch_loss=1.183568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=330 train loss <loss>=1.1622186541557311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [330]#011Speed: 843.93 samples/sec#011loss=1.162219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch[335] avg_epoch_loss=1.181077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=335 train loss <loss>=1.0161906003952026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:30 INFO 140281140962944] Epoch[8] Batch [335]#011Speed: 1337.67 samples/sec#011loss=1.016191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[340] avg_epoch_loss=1.178906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=340 train loss <loss>=1.0329797744750977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [340]#011Speed: 820.77 samples/sec#011loss=1.032980\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[345] avg_epoch_loss=1.175507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=345 train loss <loss>=0.9437127113342285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [345]#011Speed: 1246.63 samples/sec#011loss=0.943713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[350] avg_epoch_loss=1.172754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=350 train loss <loss>=0.9822677969932556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [350]#011Speed: 765.67 samples/sec#011loss=0.982268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[355] avg_epoch_loss=1.173860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=355 train loss <loss>=1.2514979481697082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [355]#011Speed: 1275.82 samples/sec#011loss=1.251498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[360] avg_epoch_loss=1.171797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=360 train loss <loss>=1.0249037384986877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [360]#011Speed: 601.54 samples/sec#011loss=1.024904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch[365] avg_epoch_loss=1.173997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=365 train loss <loss>=1.3328400611877442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:31 INFO 140281140962944] Epoch[8] Batch [365]#011Speed: 1343.18 samples/sec#011loss=1.332840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[370] avg_epoch_loss=1.174040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=370 train loss <loss>=1.1771909713745117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [370]#011Speed: 851.88 samples/sec#011loss=1.177191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[375] avg_epoch_loss=1.182360\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=375 train loss <loss>=1.7996625185012818\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [375]#011Speed: 1307.17 samples/sec#011loss=1.799663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[380] avg_epoch_loss=1.183514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=380 train loss <loss>=1.2702970266342164\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [380]#011Speed: 789.77 samples/sec#011loss=1.270297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[385] avg_epoch_loss=1.184212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=385 train loss <loss>=1.2373996019363402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [385]#011Speed: 1362.36 samples/sec#011loss=1.237400\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[390] avg_epoch_loss=1.184653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=390 train loss <loss>=1.2187434673309325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [390]#011Speed: 833.94 samples/sec#011loss=1.218743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch[395] avg_epoch_loss=1.184431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=395 train loss <loss>=1.1670199394226075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:32 INFO 140281140962944] Epoch[8] Batch [395]#011Speed: 1343.82 samples/sec#011loss=1.167020\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[400] avg_epoch_loss=1.183260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=400 train loss <loss>=1.0905145406723022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [400]#011Speed: 825.25 samples/sec#011loss=1.090515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[405] avg_epoch_loss=1.181557\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=405 train loss <loss>=1.0449682831764222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [405]#011Speed: 1355.78 samples/sec#011loss=1.044968\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[410] avg_epoch_loss=1.181558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=410 train loss <loss>=1.1816956520080566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [410]#011Speed: 817.37 samples/sec#011loss=1.181696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[415] avg_epoch_loss=1.179891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=415 train loss <loss>=1.0428395509719848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [415]#011Speed: 1358.27 samples/sec#011loss=1.042840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[420] avg_epoch_loss=1.179943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=420 train loss <loss>=1.1842761635780334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [420]#011Speed: 808.50 samples/sec#011loss=1.184276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch[425] avg_epoch_loss=1.179422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=425 train loss <loss>=1.1355121850967407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:33 INFO 140281140962944] Epoch[8] Batch [425]#011Speed: 1290.60 samples/sec#011loss=1.135512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[430] avg_epoch_loss=1.177009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=430 train loss <loss>=0.9714294791221618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [430]#011Speed: 826.00 samples/sec#011loss=0.971429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[435] avg_epoch_loss=1.176406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=435 train loss <loss>=1.1244733572006225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [435]#011Speed: 1364.32 samples/sec#011loss=1.124473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[440] avg_epoch_loss=1.174990\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=440 train loss <loss>=1.051451075077057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [440]#011Speed: 849.31 samples/sec#011loss=1.051451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[445] avg_epoch_loss=1.175248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=445 train loss <loss>=1.1980541586875915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [445]#011Speed: 1124.70 samples/sec#011loss=1.198054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[450] avg_epoch_loss=1.172920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=450 train loss <loss>=0.9652335524559021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [450]#011Speed: 859.93 samples/sec#011loss=0.965234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[455] avg_epoch_loss=1.171384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=455 train loss <loss>=1.032840943336487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [455]#011Speed: 1365.56 samples/sec#011loss=1.032841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch[460] avg_epoch_loss=1.169369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=460 train loss <loss>=0.9856133699417114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:34 INFO 140281140962944] Epoch[8] Batch [460]#011Speed: 851.56 samples/sec#011loss=0.985613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[465] avg_epoch_loss=1.186265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=465 train loss <loss>=2.744038224220276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [465]#011Speed: 1268.11 samples/sec#011loss=2.744038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[470] avg_epoch_loss=1.184756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=470 train loss <loss>=1.044120717048645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [470]#011Speed: 852.44 samples/sec#011loss=1.044121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[475] avg_epoch_loss=1.183436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=475 train loss <loss>=1.0590895533561706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [475]#011Speed: 1246.49 samples/sec#011loss=1.059090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[480] avg_epoch_loss=1.182283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=480 train loss <loss>=1.0725120067596436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [480]#011Speed: 822.79 samples/sec#011loss=1.072512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[485] avg_epoch_loss=1.181298\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=485 train loss <loss>=1.0865420818328857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [485]#011Speed: 1354.20 samples/sec#011loss=1.086542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch[490] avg_epoch_loss=1.179870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=490 train loss <loss>=1.0410784244537354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:35 INFO 140281140962944] Epoch[8] Batch [490]#011Speed: 853.01 samples/sec#011loss=1.041078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[495] avg_epoch_loss=1.177757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=495 train loss <loss>=0.9703274130821228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [495]#011Speed: 1274.93 samples/sec#011loss=0.970327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[500] avg_epoch_loss=1.176823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=500 train loss <loss>=1.084175205230713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [500]#011Speed: 828.01 samples/sec#011loss=1.084175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[505] avg_epoch_loss=1.177158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=505 train loss <loss>=1.2106772303581237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [505]#011Speed: 1354.05 samples/sec#011loss=1.210677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[510] avg_epoch_loss=1.178730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=510 train loss <loss>=1.3377936840057374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [510]#011Speed: 741.65 samples/sec#011loss=1.337794\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[515] avg_epoch_loss=1.176986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=515 train loss <loss>=0.9987629652023315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [515]#011Speed: 1333.44 samples/sec#011loss=0.998763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch[520] avg_epoch_loss=1.175400\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=520 train loss <loss>=1.0117834091186524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:36 INFO 140281140962944] Epoch[8] Batch [520]#011Speed: 613.93 samples/sec#011loss=1.011783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[525] avg_epoch_loss=1.174248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=525 train loss <loss>=1.0541726708412171\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [525]#011Speed: 1371.89 samples/sec#011loss=1.054173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[530] avg_epoch_loss=1.172351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=530 train loss <loss>=0.9727334141731262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [530]#011Speed: 851.36 samples/sec#011loss=0.972733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[535] avg_epoch_loss=1.170915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=535 train loss <loss>=1.0184155702590942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [535]#011Speed: 1306.11 samples/sec#011loss=1.018416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[540] avg_epoch_loss=1.171069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=540 train loss <loss>=1.187644362449646\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [540]#011Speed: 960.45 samples/sec#011loss=1.187644\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch[545] avg_epoch_loss=1.169806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, batch=545 train loss <loss>=1.033171570301056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[8] Batch [545]#011Speed: 1367.66 samples/sec#011loss=1.033172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] processed a total of 17447 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717380.02851, \"EndTime\": 1620717397.683204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17654.630184173584, \"count\": 1, \"min\": 17654.630184173584, \"max\": 17654.630184173584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=988.2294863239279 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=8, train loss <loss>=1.1698064283355252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_99d7595c-ac85-43b8-8562-d82a9c6c8da7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717397.6832824, \"EndTime\": 1620717397.693364, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.396791458129883, \"count\": 1, \"min\": 9.396791458129883, \"max\": 9.396791458129883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[9] Batch[0] avg_epoch_loss=1.170805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=1.170804500579834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[9] Batch[5] avg_epoch_loss=0.998538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=0.9985377689202627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:37 INFO 140281140962944] Epoch[9] Batch [5]#011Speed: 1264.80 samples/sec#011loss=0.998538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[10] avg_epoch_loss=0.977236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=0.951674473285675\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [10]#011Speed: 829.74 samples/sec#011loss=0.951674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[15] avg_epoch_loss=0.949100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=0.8871992945671081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [15]#011Speed: 1329.50 samples/sec#011loss=0.887199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[20] avg_epoch_loss=0.966333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=1.021478283405304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [20]#011Speed: 796.85 samples/sec#011loss=1.021478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[25] avg_epoch_loss=0.977013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=1.0218705415725708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [25]#011Speed: 1227.91 samples/sec#011loss=1.021871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[30] avg_epoch_loss=0.974455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=0.9611510276794434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [30]#011Speed: 841.81 samples/sec#011loss=0.961151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch[35] avg_epoch_loss=0.998055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=1.1443796515464784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:38 INFO 140281140962944] Epoch[9] Batch [35]#011Speed: 1302.31 samples/sec#011loss=1.144380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[40] avg_epoch_loss=1.014682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=1.1343950271606444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [40]#011Speed: 831.68 samples/sec#011loss=1.134395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[45] avg_epoch_loss=1.027111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=1.1290271878242493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [45]#011Speed: 1342.69 samples/sec#011loss=1.129027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[50] avg_epoch_loss=1.042093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=1.179923450946808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [50]#011Speed: 857.22 samples/sec#011loss=1.179923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[55] avg_epoch_loss=1.064588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=1.2940365552902222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [55]#011Speed: 1287.64 samples/sec#011loss=1.294037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[60] avg_epoch_loss=1.065663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=1.077702236175537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [60]#011Speed: 821.25 samples/sec#011loss=1.077702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[65] avg_epoch_loss=1.063885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=1.042197823524475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [65]#011Speed: 1349.34 samples/sec#011loss=1.042198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch[70] avg_epoch_loss=1.080386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=1.298195767402649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:39 INFO 140281140962944] Epoch[9] Batch [70]#011Speed: 852.47 samples/sec#011loss=1.298196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[75] avg_epoch_loss=1.077878\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=1.0422627329826355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [75]#011Speed: 1306.13 samples/sec#011loss=1.042263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[80] avg_epoch_loss=1.068079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=0.9191354990005494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [80]#011Speed: 659.17 samples/sec#011loss=0.919135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[85] avg_epoch_loss=1.058999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=0.9119025826454162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [85]#011Speed: 1311.00 samples/sec#011loss=0.911903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[90] avg_epoch_loss=1.051209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=0.9172237396240235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [90]#011Speed: 796.58 samples/sec#011loss=0.917224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[95] avg_epoch_loss=1.041976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=0.8739474296569825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [95]#011Speed: 1349.36 samples/sec#011loss=0.873947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch[100] avg_epoch_loss=1.039996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=1.001961851119995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:40 INFO 140281140962944] Epoch[9] Batch [100]#011Speed: 836.62 samples/sec#011loss=1.001962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[105] avg_epoch_loss=1.039631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=1.0322750210762024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [105]#011Speed: 1322.32 samples/sec#011loss=1.032275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[110] avg_epoch_loss=1.033955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=0.9136135101318359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [110]#011Speed: 815.93 samples/sec#011loss=0.913614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[115] avg_epoch_loss=1.033342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=1.0197318911552429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [115]#011Speed: 1359.93 samples/sec#011loss=1.019732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[120] avg_epoch_loss=1.045311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=1.3230019450187682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [120]#011Speed: 772.87 samples/sec#011loss=1.323002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[125] avg_epoch_loss=1.043450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=0.9984181642532348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [125]#011Speed: 1352.11 samples/sec#011loss=0.998418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch[130] avg_epoch_loss=1.049383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=1.1988890767097473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:41 INFO 140281140962944] Epoch[9] Batch [130]#011Speed: 753.23 samples/sec#011loss=1.198889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[135] avg_epoch_loss=1.049042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=1.0400914549827576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [135]#011Speed: 1155.18 samples/sec#011loss=1.040091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[140] avg_epoch_loss=1.090880\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=2.228872013092041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [140]#011Speed: 845.96 samples/sec#011loss=2.228872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[145] avg_epoch_loss=1.088192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=1.012415838241577\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [145]#011Speed: 1341.99 samples/sec#011loss=1.012416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[150] avg_epoch_loss=1.092701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=1.2243375778198242\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [150]#011Speed: 801.04 samples/sec#011loss=1.224338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[155] avg_epoch_loss=1.094540\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=1.1500962495803833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [155]#011Speed: 1346.75 samples/sec#011loss=1.150096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch[160] avg_epoch_loss=1.094603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=1.0965699553489685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:42 INFO 140281140962944] Epoch[9] Batch [160]#011Speed: 858.62 samples/sec#011loss=1.096570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[165] avg_epoch_loss=1.092596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=1.0279621720314025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [165]#011Speed: 1356.58 samples/sec#011loss=1.027962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[170] avg_epoch_loss=1.091770\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=1.064346432685852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [170]#011Speed: 835.65 samples/sec#011loss=1.064346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[175] avg_epoch_loss=1.088841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=0.9886544346809387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [175]#011Speed: 1349.49 samples/sec#011loss=0.988654\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[180] avg_epoch_loss=1.088157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=1.0640934109687805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [180]#011Speed: 847.88 samples/sec#011loss=1.064093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[185] avg_epoch_loss=1.089617\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=1.142455017566681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [185]#011Speed: 1153.01 samples/sec#011loss=1.142455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[190] avg_epoch_loss=1.107051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=1.7556000113487245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [190]#011Speed: 838.38 samples/sec#011loss=1.755600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch[195] avg_epoch_loss=1.119119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=1.5801382899284362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:43 INFO 140281140962944] Epoch[9] Batch [195]#011Speed: 1278.56 samples/sec#011loss=1.580138\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[200] avg_epoch_loss=1.125784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=1.3870440006256104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [200]#011Speed: 858.38 samples/sec#011loss=1.387044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[205] avg_epoch_loss=1.128574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=1.2407277822494507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [205]#011Speed: 1366.52 samples/sec#011loss=1.240728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[210] avg_epoch_loss=1.130691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=1.2179224014282226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [210]#011Speed: 861.09 samples/sec#011loss=1.217922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[215] avg_epoch_loss=1.133214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=1.2396804809570312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [215]#011Speed: 1209.78 samples/sec#011loss=1.239680\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch[220] avg_epoch_loss=1.131938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=1.0768072843551635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:44 INFO 140281140962944] Epoch[9] Batch [220]#011Speed: 649.40 samples/sec#011loss=1.076807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[225] avg_epoch_loss=1.147166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=1.8202452421188355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [225]#011Speed: 855.36 samples/sec#011loss=1.820245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[230] avg_epoch_loss=1.150285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=1.2912736177444457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [230]#011Speed: 528.02 samples/sec#011loss=1.291274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[235] avg_epoch_loss=1.149770\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=1.1259599208831788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [235]#011Speed: 1360.30 samples/sec#011loss=1.125960\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[240] avg_epoch_loss=1.149055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=1.1153255343437194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [240]#011Speed: 786.22 samples/sec#011loss=1.115326\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[245] avg_epoch_loss=1.145104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=0.9546670317649841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [245]#011Speed: 1339.28 samples/sec#011loss=0.954667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch[250] avg_epoch_loss=1.141948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=0.9866676449775695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:45 INFO 140281140962944] Epoch[9] Batch [250]#011Speed: 835.70 samples/sec#011loss=0.986668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[255] avg_epoch_loss=1.141039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=1.0954177856445313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [255]#011Speed: 1293.22 samples/sec#011loss=1.095418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[260] avg_epoch_loss=1.140099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=1.0919639110565185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [260]#011Speed: 821.14 samples/sec#011loss=1.091964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[265] avg_epoch_loss=1.139385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=1.1021329522132874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [265]#011Speed: 1374.12 samples/sec#011loss=1.102133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[270] avg_epoch_loss=1.137605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=1.042897593975067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [270]#011Speed: 801.74 samples/sec#011loss=1.042898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[275] avg_epoch_loss=1.134482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=275 train loss <loss>=0.9652164816856384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [275]#011Speed: 1297.04 samples/sec#011loss=0.965216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch[280] avg_epoch_loss=1.129508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=280 train loss <loss>=0.8549170613288879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:46 INFO 140281140962944] Epoch[9] Batch [280]#011Speed: 806.48 samples/sec#011loss=0.854917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[285] avg_epoch_loss=1.126786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=285 train loss <loss>=0.9738237261772156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [285]#011Speed: 1217.72 samples/sec#011loss=0.973824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[290] avg_epoch_loss=1.124336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=290 train loss <loss>=0.9842075109481812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [290]#011Speed: 678.59 samples/sec#011loss=0.984208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[295] avg_epoch_loss=1.123759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=295 train loss <loss>=1.0901471853256226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [295]#011Speed: 1338.54 samples/sec#011loss=1.090147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[300] avg_epoch_loss=1.125967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=300 train loss <loss>=1.256700611114502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [300]#011Speed: 839.55 samples/sec#011loss=1.256701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[305] avg_epoch_loss=1.126287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=305 train loss <loss>=1.1455289483070374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [305]#011Speed: 1258.12 samples/sec#011loss=1.145529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch[310] avg_epoch_loss=1.125655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=310 train loss <loss>=1.086968731880188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:47 INFO 140281140962944] Epoch[9] Batch [310]#011Speed: 836.62 samples/sec#011loss=1.086969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[315] avg_epoch_loss=1.135235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=315 train loss <loss>=1.7311509370803833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [315]#011Speed: 1355.33 samples/sec#011loss=1.731151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[320] avg_epoch_loss=1.135179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=320 train loss <loss>=1.1316413164138794\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [320]#011Speed: 833.78 samples/sec#011loss=1.131641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[325] avg_epoch_loss=1.135518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=325 train loss <loss>=1.1572545528411866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [325]#011Speed: 1295.30 samples/sec#011loss=1.157255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[330] avg_epoch_loss=1.134684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=330 train loss <loss>=1.0803051710128784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [330]#011Speed: 837.10 samples/sec#011loss=1.080305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[335] avg_epoch_loss=1.133198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=335 train loss <loss>=1.0348082423210143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [335]#011Speed: 1128.61 samples/sec#011loss=1.034808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch[340] avg_epoch_loss=1.130233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=340 train loss <loss>=0.9309995412826538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:48 INFO 140281140962944] Epoch[9] Batch [340]#011Speed: 815.96 samples/sec#011loss=0.931000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[345] avg_epoch_loss=1.127597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=345 train loss <loss>=0.9478047728538513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [345]#011Speed: 1287.54 samples/sec#011loss=0.947805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[350] avg_epoch_loss=1.125701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=350 train loss <loss>=0.9945625543594361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [350]#011Speed: 851.10 samples/sec#011loss=0.994563\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[355] avg_epoch_loss=1.124441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=355 train loss <loss>=1.0359818816184998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [355]#011Speed: 1349.48 samples/sec#011loss=1.035982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[360] avg_epoch_loss=1.126128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=360 train loss <loss>=1.2462327837944032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [360]#011Speed: 855.34 samples/sec#011loss=1.246233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[365] avg_epoch_loss=1.126141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=365 train loss <loss>=1.1270769715309144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [365]#011Speed: 1340.57 samples/sec#011loss=1.127077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[370] avg_epoch_loss=1.124105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=370 train loss <loss>=0.9750559806823731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [370]#011Speed: 810.91 samples/sec#011loss=0.975056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch[375] avg_epoch_loss=1.122355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=375 train loss <loss>=0.992490816116333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:49 INFO 140281140962944] Epoch[9] Batch [375]#011Speed: 1355.08 samples/sec#011loss=0.992491\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[380] avg_epoch_loss=1.129461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=380 train loss <loss>=1.6638588547706603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [380]#011Speed: 842.49 samples/sec#011loss=1.663859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[385] avg_epoch_loss=1.130062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=385 train loss <loss>=1.17584331035614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [385]#011Speed: 1345.42 samples/sec#011loss=1.175843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[390] avg_epoch_loss=1.129956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=390 train loss <loss>=1.1217361450195313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [390]#011Speed: 775.98 samples/sec#011loss=1.121736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[395] avg_epoch_loss=1.129187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=395 train loss <loss>=1.0691075205802918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [395]#011Speed: 1346.33 samples/sec#011loss=1.069108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[400] avg_epoch_loss=1.127584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=400 train loss <loss>=1.0005703926086427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [400]#011Speed: 792.72 samples/sec#011loss=1.000570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch[405] avg_epoch_loss=1.129991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=405 train loss <loss>=1.323049247264862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:50 INFO 140281140962944] Epoch[9] Batch [405]#011Speed: 1337.88 samples/sec#011loss=1.323049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[410] avg_epoch_loss=1.129405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=410 train loss <loss>=1.0818235039711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [410]#011Speed: 843.92 samples/sec#011loss=1.081824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[415] avg_epoch_loss=1.127938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=415 train loss <loss>=1.0073879480361938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [415]#011Speed: 1212.34 samples/sec#011loss=1.007388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[420] avg_epoch_loss=1.137183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=420 train loss <loss>=1.906321144104004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [420]#011Speed: 857.54 samples/sec#011loss=1.906321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[425] avg_epoch_loss=1.137333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=425 train loss <loss>=1.1499728918075562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [425]#011Speed: 1345.39 samples/sec#011loss=1.149973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[430] avg_epoch_loss=1.137935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=430 train loss <loss>=1.1892539262771606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [430]#011Speed: 775.09 samples/sec#011loss=1.189254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch[435] avg_epoch_loss=1.137338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=435 train loss <loss>=1.0858741521835327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:51 INFO 140281140962944] Epoch[9] Batch [435]#011Speed: 1321.99 samples/sec#011loss=1.085874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[440] avg_epoch_loss=1.136819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=440 train loss <loss>=1.0915757775306703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [440]#011Speed: 837.86 samples/sec#011loss=1.091576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[445] avg_epoch_loss=1.135747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=445 train loss <loss>=1.0411500215530396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [445]#011Speed: 1302.53 samples/sec#011loss=1.041150\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[450] avg_epoch_loss=1.135083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=450 train loss <loss>=1.0759158372879027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [450]#011Speed: 643.06 samples/sec#011loss=1.075916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[455] avg_epoch_loss=1.134909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=455 train loss <loss>=1.1191540241241456\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [455]#011Speed: 1318.07 samples/sec#011loss=1.119154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[460] avg_epoch_loss=1.133691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=460 train loss <loss>=1.0226598024368285\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [460]#011Speed: 796.69 samples/sec#011loss=1.022660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch[465] avg_epoch_loss=1.132533\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=465 train loss <loss>=1.0257149815559388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:52 INFO 140281140962944] Epoch[9] Batch [465]#011Speed: 1299.03 samples/sec#011loss=1.025715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[470] avg_epoch_loss=1.130677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=470 train loss <loss>=0.9577334880828857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [470]#011Speed: 854.09 samples/sec#011loss=0.957733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[475] avg_epoch_loss=1.145936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=475 train loss <loss>=2.5832873582839966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [475]#011Speed: 1335.79 samples/sec#011loss=2.583287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[480] avg_epoch_loss=1.144271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=480 train loss <loss>=0.9858061671257019\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [480]#011Speed: 842.89 samples/sec#011loss=0.985806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[485] avg_epoch_loss=1.143348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=485 train loss <loss>=1.0545894026756286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [485]#011Speed: 1357.84 samples/sec#011loss=1.054589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[490] avg_epoch_loss=1.142260\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=490 train loss <loss>=1.036446213722229\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [490]#011Speed: 866.81 samples/sec#011loss=1.036446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[495] avg_epoch_loss=1.140766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=495 train loss <loss>=0.9940580129623413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [495]#011Speed: 1230.50 samples/sec#011loss=0.994058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch[500] avg_epoch_loss=1.139645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=500 train loss <loss>=1.0284518957138062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:53 INFO 140281140962944] Epoch[9] Batch [500]#011Speed: 858.81 samples/sec#011loss=1.028452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[505] avg_epoch_loss=1.138165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=505 train loss <loss>=0.9898720383644104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [505]#011Speed: 1319.44 samples/sec#011loss=0.989872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[510] avg_epoch_loss=1.137734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=510 train loss <loss>=1.0940964341163635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [510]#011Speed: 875.86 samples/sec#011loss=1.094096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[515] avg_epoch_loss=1.136892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=515 train loss <loss>=1.0508328914642333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [515]#011Speed: 1380.69 samples/sec#011loss=1.050833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[520] avg_epoch_loss=1.134652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=520 train loss <loss>=0.9034939646720886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [520]#011Speed: 857.50 samples/sec#011loss=0.903494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[525] avg_epoch_loss=1.132250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=525 train loss <loss>=0.8819656729698181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [525]#011Speed: 1369.02 samples/sec#011loss=0.881966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch[530] avg_epoch_loss=1.129858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=530 train loss <loss>=0.8782430529594422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:54 INFO 140281140962944] Epoch[9] Batch [530]#011Speed: 812.14 samples/sec#011loss=0.878243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[535] avg_epoch_loss=1.128059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=535 train loss <loss>=0.9369762659072876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [535]#011Speed: 1359.59 samples/sec#011loss=0.936976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[540] avg_epoch_loss=1.127997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=540 train loss <loss>=1.1213817596435547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [540]#011Speed: 843.46 samples/sec#011loss=1.121382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[545] avg_epoch_loss=1.128207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=545 train loss <loss>=1.1509323358535766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [545]#011Speed: 1344.92 samples/sec#011loss=1.150932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch[550] avg_epoch_loss=1.126735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, batch=550 train loss <loss>=0.9660319209098815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[9] Batch [550]#011Speed: 1187.16 samples/sec#011loss=0.966032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] processed a total of 17661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717397.6934876, \"EndTime\": 1620717415.5047896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17811.151266098022, \"count\": 1, \"min\": 17811.151266098022, \"max\": 17811.151266098022}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=991.5574332965368 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=9, train loss <loss>=1.1265391756011092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_c45c8404-cc09-4c11-a2a2-f8e82ff04c1c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717415.5049553, \"EndTime\": 1620717415.5155296, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.671449661254883, \"count\": 1, \"min\": 9.671449661254883, \"max\": 9.671449661254883}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch[0] avg_epoch_loss=0.901921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.9019213914871216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch[5] avg_epoch_loss=0.865864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.8658635715643564\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch [5]#011Speed: 1306.44 samples/sec#011loss=0.865864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch[10] avg_epoch_loss=0.905471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=0.9530003786087036\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:55 INFO 140281140962944] Epoch[10] Batch [10]#011Speed: 786.79 samples/sec#011loss=0.953000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[15] avg_epoch_loss=0.916144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=0.9396244645118713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [15]#011Speed: 1355.17 samples/sec#011loss=0.939624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[20] avg_epoch_loss=0.921419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=0.9382966041564942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [20]#011Speed: 820.03 samples/sec#011loss=0.938297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[25] avg_epoch_loss=1.017010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=1.4184955716133119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [25]#011Speed: 1359.13 samples/sec#011loss=1.418496\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[30] avg_epoch_loss=1.026711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=1.077155065536499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [30]#011Speed: 856.57 samples/sec#011loss=1.077155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[35] avg_epoch_loss=1.026688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=1.0265453577041626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [35]#011Speed: 1331.01 samples/sec#011loss=1.026545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch[40] avg_epoch_loss=1.025293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=1.0152513265609742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:56 INFO 140281140962944] Epoch[10] Batch [40]#011Speed: 777.60 samples/sec#011loss=1.015251\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[45] avg_epoch_loss=1.015874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=0.9386318325996399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [45]#011Speed: 1296.21 samples/sec#011loss=0.938632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[50] avg_epoch_loss=1.019230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=1.0501071572303773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [50]#011Speed: 820.45 samples/sec#011loss=1.050107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[55] avg_epoch_loss=1.018116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=1.0067520260810852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [55]#011Speed: 1372.07 samples/sec#011loss=1.006752\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[60] avg_epoch_loss=1.020701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=1.049657368659973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [60]#011Speed: 634.93 samples/sec#011loss=1.049657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[65] avg_epoch_loss=1.052008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=1.4339460611343384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [65]#011Speed: 1355.85 samples/sec#011loss=1.433946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch[70] avg_epoch_loss=1.077327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=1.411542534828186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:57 INFO 140281140962944] Epoch[10] Batch [70]#011Speed: 790.11 samples/sec#011loss=1.411543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[75] avg_epoch_loss=1.087614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=1.2336942434310914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [75]#011Speed: 1365.72 samples/sec#011loss=1.233694\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[80] avg_epoch_loss=1.088208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=1.0972393989562987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [80]#011Speed: 839.44 samples/sec#011loss=1.097239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[85] avg_epoch_loss=1.112771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=1.5106884360313415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [85]#011Speed: 1339.11 samples/sec#011loss=1.510688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[90] avg_epoch_loss=1.109488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=1.0530166983604432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [90]#011Speed: 844.98 samples/sec#011loss=1.053017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[95] avg_epoch_loss=1.103182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=0.9884101152420044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [95]#011Speed: 1319.06 samples/sec#011loss=0.988410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[100] avg_epoch_loss=1.129471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=1.6342183828353882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [100]#011Speed: 790.53 samples/sec#011loss=1.634218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch[105] avg_epoch_loss=1.133008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=1.2044533014297485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:58 INFO 140281140962944] Epoch[10] Batch [105]#011Speed: 1240.96 samples/sec#011loss=1.204453\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[110] avg_epoch_loss=1.133683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=1.1480037212371825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [110]#011Speed: 825.11 samples/sec#011loss=1.148004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[115] avg_epoch_loss=1.170018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=1.9766409635543822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [115]#011Speed: 1332.93 samples/sec#011loss=1.976641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[120] avg_epoch_loss=1.168344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=1.1295196533203125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [120]#011Speed: 872.07 samples/sec#011loss=1.129520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[125] avg_epoch_loss=1.170372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=1.219445037841797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [125]#011Speed: 1360.17 samples/sec#011loss=1.219445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[130] avg_epoch_loss=1.168949\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=1.1331037759780884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [130]#011Speed: 848.25 samples/sec#011loss=1.133104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch[135] avg_epoch_loss=1.170198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=1.2029208302497865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:16:59 INFO 140281140962944] Epoch[10] Batch [135]#011Speed: 1207.74 samples/sec#011loss=1.202921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[140] avg_epoch_loss=1.163743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=0.9881434082984925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [140]#011Speed: 791.16 samples/sec#011loss=0.988143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[145] avg_epoch_loss=1.158546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=1.011996293067932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [145]#011Speed: 1312.16 samples/sec#011loss=1.011996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[150] avg_epoch_loss=1.189816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=2.1029135942459107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [150]#011Speed: 837.21 samples/sec#011loss=2.102914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[155] avg_epoch_loss=1.186464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=1.0852142572402954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [155]#011Speed: 1285.71 samples/sec#011loss=1.085214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[160] avg_epoch_loss=1.181313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=1.0206290483474731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [160]#011Speed: 824.72 samples/sec#011loss=1.020629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch[165] avg_epoch_loss=1.177034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=1.039237105846405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:00 INFO 140281140962944] Epoch[10] Batch [165]#011Speed: 1312.92 samples/sec#011loss=1.039237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[170] avg_epoch_loss=1.171162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=0.9761968493461609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [170]#011Speed: 799.95 samples/sec#011loss=0.976197\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[175] avg_epoch_loss=1.172135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=1.2054284811019897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [175]#011Speed: 709.01 samples/sec#011loss=1.205428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[180] avg_epoch_loss=1.167806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=1.015419864654541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [180]#011Speed: 443.16 samples/sec#011loss=1.015420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch[185] avg_epoch_loss=1.174273\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=1.408388602733612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:01 INFO 140281140962944] Epoch[10] Batch [185]#011Speed: 904.16 samples/sec#011loss=1.408389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[190] avg_epoch_loss=1.172569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=1.109165906906128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [190]#011Speed: 496.19 samples/sec#011loss=1.109166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[195] avg_epoch_loss=1.171674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=1.1375005006790162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [195]#011Speed: 800.41 samples/sec#011loss=1.137501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[200] avg_epoch_loss=1.169947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=1.1022197008132935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [200]#011Speed: 397.02 samples/sec#011loss=1.102220\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch[205] avg_epoch_loss=1.170520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=1.1935594201087951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:02 INFO 140281140962944] Epoch[10] Batch [205]#011Speed: 1069.12 samples/sec#011loss=1.193559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[210] avg_epoch_loss=1.169514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=1.1280729651451111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [210]#011Speed: 811.32 samples/sec#011loss=1.128073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[215] avg_epoch_loss=1.165420\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=0.9926401376724243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [215]#011Speed: 1370.59 samples/sec#011loss=0.992640\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[220] avg_epoch_loss=1.161428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=0.9889744997024537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [220]#011Speed: 671.82 samples/sec#011loss=0.988974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[225] avg_epoch_loss=1.163292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=1.2456790447235107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [225]#011Speed: 723.32 samples/sec#011loss=1.245679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch[230] avg_epoch_loss=1.158536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=0.9436006546020508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:03 INFO 140281140962944] Epoch[10] Batch [230]#011Speed: 489.23 samples/sec#011loss=0.943601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch[235] avg_epoch_loss=1.152427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=0.8701731920242309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch [235]#011Speed: 732.17 samples/sec#011loss=0.870173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch[240] avg_epoch_loss=1.147585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=0.919051992893219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch [240]#011Speed: 514.83 samples/sec#011loss=0.919052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch[245] avg_epoch_loss=1.145734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=1.056499457359314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:04 INFO 140281140962944] Epoch[10] Batch [245]#011Speed: 744.09 samples/sec#011loss=1.056499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[250] avg_epoch_loss=1.139626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=0.8391138076782226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [250]#011Speed: 472.53 samples/sec#011loss=0.839114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[255] avg_epoch_loss=1.170655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=2.728311836719513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [255]#011Speed: 692.67 samples/sec#011loss=2.728312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[260] avg_epoch_loss=1.172414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=1.2624988794326781\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [260]#011Speed: 538.69 samples/sec#011loss=1.262499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[265] avg_epoch_loss=1.171203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=1.1079831838607788\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [265]#011Speed: 1236.10 samples/sec#011loss=1.107983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch[270] avg_epoch_loss=1.170503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=1.133233332633972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:05 INFO 140281140962944] Epoch[10] Batch [270]#011Speed: 837.28 samples/sec#011loss=1.133233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[275] avg_epoch_loss=1.170149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=275 train loss <loss>=1.150990629196167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [275]#011Speed: 1126.67 samples/sec#011loss=1.150991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[280] avg_epoch_loss=1.167893\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=280 train loss <loss>=1.0433367848396302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [280]#011Speed: 828.95 samples/sec#011loss=1.043337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[285] avg_epoch_loss=1.164402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=285 train loss <loss>=0.9682324051856994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [285]#011Speed: 1295.60 samples/sec#011loss=0.968232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[290] avg_epoch_loss=1.162494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=290 train loss <loss>=1.0533332228660583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [290]#011Speed: 831.54 samples/sec#011loss=1.053333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[295] avg_epoch_loss=1.159145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=295 train loss <loss>=0.9642372846603393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [295]#011Speed: 1358.84 samples/sec#011loss=0.964237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch[300] avg_epoch_loss=1.156140\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=300 train loss <loss>=0.9782819747924805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:06 INFO 140281140962944] Epoch[10] Batch [300]#011Speed: 818.60 samples/sec#011loss=0.978282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[305] avg_epoch_loss=1.154332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=305 train loss <loss>=1.0454866528511046\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [305]#011Speed: 1278.00 samples/sec#011loss=1.045487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[310] avg_epoch_loss=1.150338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=310 train loss <loss>=0.9059083700180054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [310]#011Speed: 822.18 samples/sec#011loss=0.905908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[315] avg_epoch_loss=1.146455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=315 train loss <loss>=0.9049252510070801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [315]#011Speed: 1345.16 samples/sec#011loss=0.904925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[320] avg_epoch_loss=1.144069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=320 train loss <loss>=0.9932819724082946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [320]#011Speed: 836.04 samples/sec#011loss=0.993282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[325] avg_epoch_loss=1.141126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=325 train loss <loss>=0.9521263360977172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [325]#011Speed: 1363.73 samples/sec#011loss=0.952126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch[330] avg_epoch_loss=1.142712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=330 train loss <loss>=1.2461786270141602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:07 INFO 140281140962944] Epoch[10] Batch [330]#011Speed: 657.89 samples/sec#011loss=1.246179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[335] avg_epoch_loss=1.139433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=335 train loss <loss>=0.9223327994346618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [335]#011Speed: 1361.97 samples/sec#011loss=0.922333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[340] avg_epoch_loss=1.137122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=340 train loss <loss>=0.981857442855835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [340]#011Speed: 779.85 samples/sec#011loss=0.981857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[345] avg_epoch_loss=1.134505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=345 train loss <loss>=0.9560099720954895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [345]#011Speed: 1338.13 samples/sec#011loss=0.956010\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[350] avg_epoch_loss=1.131819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=350 train loss <loss>=0.9459453463554383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [350]#011Speed: 819.05 samples/sec#011loss=0.945945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[355] avg_epoch_loss=1.129121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=355 train loss <loss>=0.9397364020347595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [355]#011Speed: 1353.47 samples/sec#011loss=0.939736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[360] avg_epoch_loss=1.126256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=360 train loss <loss>=0.9222521781921387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [360]#011Speed: 849.06 samples/sec#011loss=0.922252\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch[365] avg_epoch_loss=1.126317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=365 train loss <loss>=1.1307335257530213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:08 INFO 140281140962944] Epoch[10] Batch [365]#011Speed: 1330.09 samples/sec#011loss=1.130734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[370] avg_epoch_loss=1.127071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=370 train loss <loss>=1.1822471737861633\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [370]#011Speed: 767.16 samples/sec#011loss=1.182247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[375] avg_epoch_loss=1.125050\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=375 train loss <loss>=0.9750554323196411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [375]#011Speed: 1353.69 samples/sec#011loss=0.975055\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[380] avg_epoch_loss=1.122535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=380 train loss <loss>=0.933463704586029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [380]#011Speed: 838.35 samples/sec#011loss=0.933464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[385] avg_epoch_loss=1.120277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=385 train loss <loss>=0.9481836676597595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [385]#011Speed: 1346.46 samples/sec#011loss=0.948184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[390] avg_epoch_loss=1.118712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=390 train loss <loss>=0.9979102134704589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [390]#011Speed: 863.15 samples/sec#011loss=0.997910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch[395] avg_epoch_loss=1.119412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=395 train loss <loss>=1.1741124749183656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:09 INFO 140281140962944] Epoch[10] Batch [395]#011Speed: 1356.74 samples/sec#011loss=1.174112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[400] avg_epoch_loss=1.119729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=400 train loss <loss>=1.1448586940765382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [400]#011Speed: 803.03 samples/sec#011loss=1.144859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[405] avg_epoch_loss=1.120239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=405 train loss <loss>=1.1611648440361022\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [405]#011Speed: 1364.27 samples/sec#011loss=1.161165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[410] avg_epoch_loss=1.118380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=410 train loss <loss>=0.9674111723899841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [410]#011Speed: 846.15 samples/sec#011loss=0.967411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[415] avg_epoch_loss=1.126792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=415 train loss <loss>=1.8182317972183228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [415]#011Speed: 1296.48 samples/sec#011loss=1.818232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[420] avg_epoch_loss=1.126518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=420 train loss <loss>=1.1037386417388917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [420]#011Speed: 873.73 samples/sec#011loss=1.103739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch[425] avg_epoch_loss=1.126003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=425 train loss <loss>=1.0826421976089478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:10 INFO 140281140962944] Epoch[10] Batch [425]#011Speed: 1324.41 samples/sec#011loss=1.082642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[430] avg_epoch_loss=1.125877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=430 train loss <loss>=1.1151516437530518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [430]#011Speed: 838.94 samples/sec#011loss=1.115152\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[435] avg_epoch_loss=1.124687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=435 train loss <loss>=1.022090232372284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [435]#011Speed: 1182.98 samples/sec#011loss=1.022090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[440] avg_epoch_loss=1.123119\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=440 train loss <loss>=0.9864005208015442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [440]#011Speed: 843.84 samples/sec#011loss=0.986401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[445] avg_epoch_loss=1.121687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=445 train loss <loss>=0.995348858833313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [445]#011Speed: 1292.62 samples/sec#011loss=0.995349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[450] avg_epoch_loss=1.121660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=450 train loss <loss>=1.119274413585663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [450]#011Speed: 853.40 samples/sec#011loss=1.119274\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[455] avg_epoch_loss=1.120939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=455 train loss <loss>=1.0559378862380981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [455]#011Speed: 1347.53 samples/sec#011loss=1.055938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch[460] avg_epoch_loss=1.121222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=460 train loss <loss>=1.146996808052063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:11 INFO 140281140962944] Epoch[10] Batch [460]#011Speed: 844.16 samples/sec#011loss=1.146997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[465] avg_epoch_loss=1.134877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=465 train loss <loss>=2.393892157077789\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [465]#011Speed: 1352.55 samples/sec#011loss=2.393892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[470] avg_epoch_loss=1.134690\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=470 train loss <loss>=1.1172589540481568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [470]#011Speed: 817.18 samples/sec#011loss=1.117259\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[475] avg_epoch_loss=1.134422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=475 train loss <loss>=1.1091310024261474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [475]#011Speed: 1367.76 samples/sec#011loss=1.109131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[480] avg_epoch_loss=1.133820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=480 train loss <loss>=1.0765249252319335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [480]#011Speed: 861.23 samples/sec#011loss=1.076525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[485] avg_epoch_loss=1.132913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=485 train loss <loss>=1.0457171678543091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [485]#011Speed: 1346.04 samples/sec#011loss=1.045717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch[490] avg_epoch_loss=1.131450\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=490 train loss <loss>=0.9892154574394226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:12 INFO 140281140962944] Epoch[10] Batch [490]#011Speed: 649.86 samples/sec#011loss=0.989215\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[495] avg_epoch_loss=1.129470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=495 train loss <loss>=0.9350264310836792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [495]#011Speed: 1367.41 samples/sec#011loss=0.935026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[500] avg_epoch_loss=1.128699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=500 train loss <loss>=1.0522448301315308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [500]#011Speed: 818.18 samples/sec#011loss=1.052245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[505] avg_epoch_loss=1.126411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=505 train loss <loss>=0.8971303462982178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [505]#011Speed: 1342.86 samples/sec#011loss=0.897130\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[510] avg_epoch_loss=1.124156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=510 train loss <loss>=0.8959341645240784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [510]#011Speed: 860.66 samples/sec#011loss=0.895934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[515] avg_epoch_loss=1.122549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=515 train loss <loss>=0.9583521604537963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [515]#011Speed: 1348.86 samples/sec#011loss=0.958352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[520] avg_epoch_loss=1.122885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=520 train loss <loss>=1.1575168251991272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [520]#011Speed: 852.09 samples/sec#011loss=1.157517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch[525] avg_epoch_loss=1.122692\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=525 train loss <loss>=1.102633500099182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:13 INFO 140281140962944] Epoch[10] Batch [525]#011Speed: 1335.80 samples/sec#011loss=1.102634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch[530] avg_epoch_loss=1.122075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=530 train loss <loss>=1.0571882724761963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch [530]#011Speed: 809.52 samples/sec#011loss=1.057188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch[535] avg_epoch_loss=1.120604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=535 train loss <loss>=0.964364230632782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch [535]#011Speed: 1369.71 samples/sec#011loss=0.964364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch[540] avg_epoch_loss=1.120615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, batch=540 train loss <loss>=1.1217184662818909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[10] Batch [540]#011Speed: 1121.44 samples/sec#011loss=1.121718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] processed a total of 17410 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717415.5156744, \"EndTime\": 1620717434.5469275, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 19031.18658065796, \"count\": 1, \"min\": 19031.18658065796, \"max\": 19031.18658065796}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=914.8090227338512 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=10, train loss <loss>=1.1188817831354403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_6b703284-f5c4-4df7-bb0f-bf8e06c6ba11-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717434.5470006, \"EndTime\": 1620717434.5570211, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.188413619995117, \"count\": 1, \"min\": 9.188413619995117, \"max\": 9.188413619995117}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch[0] avg_epoch_loss=0.841986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=0.841985821723938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch[5] avg_epoch_loss=0.916721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=0.916721115509669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch [5]#011Speed: 1357.56 samples/sec#011loss=0.916721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch[10] avg_epoch_loss=0.903590\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=0.8878321886062622\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:14 INFO 140281140962944] Epoch[11] Batch [10]#011Speed: 819.20 samples/sec#011loss=0.887832\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[15] avg_epoch_loss=0.900207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=0.8927656769752502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [15]#011Speed: 1358.87 samples/sec#011loss=0.892766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[20] avg_epoch_loss=0.888910\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=0.8527597069740296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [20]#011Speed: 811.11 samples/sec#011loss=0.852760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[25] avg_epoch_loss=0.899512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=0.9440372943878174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [25]#011Speed: 1088.01 samples/sec#011loss=0.944037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[30] avg_epoch_loss=0.929762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=1.0870643734931946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [30]#011Speed: 521.90 samples/sec#011loss=1.087064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch[35] avg_epoch_loss=0.948605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=1.0654295921325683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:15 INFO 140281140962944] Epoch[11] Batch [35]#011Speed: 845.73 samples/sec#011loss=1.065430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[40] avg_epoch_loss=0.950289\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=0.9624164819717407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [40]#011Speed: 576.86 samples/sec#011loss=0.962416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[45] avg_epoch_loss=0.943451\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=0.8873812794685364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [45]#011Speed: 1339.42 samples/sec#011loss=0.887381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[50] avg_epoch_loss=0.933548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=0.842434537410736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [50]#011Speed: 787.39 samples/sec#011loss=0.842435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[55] avg_epoch_loss=0.946160\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=1.074811041355133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [55]#011Speed: 1330.85 samples/sec#011loss=1.074811\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[60] avg_epoch_loss=0.956568\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=1.0731321573257446\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [60]#011Speed: 845.28 samples/sec#011loss=1.073132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch[65] avg_epoch_loss=0.973783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=1.1838008642196656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:16 INFO 140281140962944] Epoch[11] Batch [65]#011Speed: 1353.32 samples/sec#011loss=1.183801\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[70] avg_epoch_loss=0.977520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=1.026858377456665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [70]#011Speed: 849.51 samples/sec#011loss=1.026858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[75] avg_epoch_loss=0.980636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=1.0248777866363525\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [75]#011Speed: 1269.25 samples/sec#011loss=1.024878\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[80] avg_epoch_loss=0.981518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=0.9949231505393982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [80]#011Speed: 850.98 samples/sec#011loss=0.994923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[85] avg_epoch_loss=0.987975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=1.0925859928131103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [85]#011Speed: 1356.86 samples/sec#011loss=1.092586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[90] avg_epoch_loss=0.987909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=0.9867731809616089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [90]#011Speed: 843.21 samples/sec#011loss=0.986773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch[95] avg_epoch_loss=0.991003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=1.0473020434379579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:17 INFO 140281140962944] Epoch[11] Batch [95]#011Speed: 1361.76 samples/sec#011loss=1.047302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[100] avg_epoch_loss=0.991541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=1.0018707871437074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [100]#011Speed: 647.85 samples/sec#011loss=1.001871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[105] avg_epoch_loss=0.994808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=1.0608165264129639\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [105]#011Speed: 1208.88 samples/sec#011loss=1.060817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[110] avg_epoch_loss=0.999139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=1.0909483432769775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [110]#011Speed: 815.30 samples/sec#011loss=1.090948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[115] avg_epoch_loss=0.999074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=0.9976304650306702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [115]#011Speed: 1363.89 samples/sec#011loss=0.997630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[120] avg_epoch_loss=0.996057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=0.9260641813278199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [120]#011Speed: 846.07 samples/sec#011loss=0.926064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch[125] avg_epoch_loss=0.992898\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=0.9164579629898071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:18 INFO 140281140962944] Epoch[11] Batch [125]#011Speed: 1367.88 samples/sec#011loss=0.916458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[130] avg_epoch_loss=0.992578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=0.9844934940338135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [130]#011Speed: 843.84 samples/sec#011loss=0.984493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[135] avg_epoch_loss=0.989678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=0.913716721534729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [135]#011Speed: 1361.31 samples/sec#011loss=0.913717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[140] avg_epoch_loss=0.990989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=1.0266301155090332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [140]#011Speed: 808.41 samples/sec#011loss=1.026630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[145] avg_epoch_loss=0.999093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=1.2276298761367799\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [145]#011Speed: 1377.32 samples/sec#011loss=1.227630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[150] avg_epoch_loss=0.998307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=0.9753745675086976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [150]#011Speed: 856.40 samples/sec#011loss=0.975375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch[155] avg_epoch_loss=1.000486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=1.0662775993347169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:19 INFO 140281140962944] Epoch[11] Batch [155]#011Speed: 1343.87 samples/sec#011loss=1.066278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[160] avg_epoch_loss=0.998380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=0.9326583027839661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [160]#011Speed: 806.82 samples/sec#011loss=0.932658\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[165] avg_epoch_loss=0.998699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=1.008981418609619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [165]#011Speed: 1337.04 samples/sec#011loss=1.008981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[170] avg_epoch_loss=0.999168\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=1.0147318959236145\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [170]#011Speed: 805.86 samples/sec#011loss=1.014732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[175] avg_epoch_loss=0.994398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=0.8312787055969239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [175]#011Speed: 1350.32 samples/sec#011loss=0.831279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[180] avg_epoch_loss=0.990845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=0.8657931566238404\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [180]#011Speed: 823.84 samples/sec#011loss=0.865793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[185] avg_epoch_loss=0.990979\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=0.9957963109016419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [185]#011Speed: 1356.57 samples/sec#011loss=0.995796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch[190] avg_epoch_loss=0.990430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=0.9700319409370423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:20 INFO 140281140962944] Epoch[11] Batch [190]#011Speed: 852.42 samples/sec#011loss=0.970032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[195] avg_epoch_loss=0.990409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=0.9895969986915588\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [195]#011Speed: 1311.65 samples/sec#011loss=0.989597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[200] avg_epoch_loss=0.990796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=1.0059666156768798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [200]#011Speed: 817.45 samples/sec#011loss=1.005967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[205] avg_epoch_loss=1.008296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=1.7118128180503844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [205]#011Speed: 1241.05 samples/sec#011loss=1.711813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[210] avg_epoch_loss=1.009864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=1.0744449377059937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [210]#011Speed: 842.14 samples/sec#011loss=1.074445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[215] avg_epoch_loss=1.012024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=1.1031695127487182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [215]#011Speed: 1364.44 samples/sec#011loss=1.103170\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch[220] avg_epoch_loss=1.016753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=1.221053147315979\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:21 INFO 140281140962944] Epoch[11] Batch [220]#011Speed: 836.79 samples/sec#011loss=1.221053\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[225] avg_epoch_loss=1.016475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=1.00419442653656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [225]#011Speed: 1337.52 samples/sec#011loss=1.004194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[230] avg_epoch_loss=1.016412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=1.0135593175888062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [230]#011Speed: 853.90 samples/sec#011loss=1.013559\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[235] avg_epoch_loss=1.016604\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=1.0254730224609374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [235]#011Speed: 1245.65 samples/sec#011loss=1.025473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[240] avg_epoch_loss=1.028385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=1.5844708323478698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [240]#011Speed: 861.89 samples/sec#011loss=1.584471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[245] avg_epoch_loss=1.026781\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=0.9494678735733032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [245]#011Speed: 1361.99 samples/sec#011loss=0.949468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[250] avg_epoch_loss=1.025354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=0.9551161646842956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [250]#011Speed: 861.20 samples/sec#011loss=0.955116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch[255] avg_epoch_loss=1.025600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=1.0379401922225953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:22 INFO 140281140962944] Epoch[11] Batch [255]#011Speed: 1375.89 samples/sec#011loss=1.037940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[260] avg_epoch_loss=1.025720\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=1.0318696618080139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [260]#011Speed: 798.49 samples/sec#011loss=1.031870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[265] avg_epoch_loss=1.028509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=1.1741149425506592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [265]#011Speed: 972.15 samples/sec#011loss=1.174115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[270] avg_epoch_loss=1.027548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=270 train loss <loss>=0.9763995051383972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [270]#011Speed: 782.40 samples/sec#011loss=0.976400\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[275] avg_epoch_loss=1.027711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=275 train loss <loss>=1.036565113067627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [275]#011Speed: 1377.35 samples/sec#011loss=1.036565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[280] avg_epoch_loss=1.028951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=280 train loss <loss>=1.0973763942718506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [280]#011Speed: 841.34 samples/sec#011loss=1.097376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch[285] avg_epoch_loss=1.028390\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=285 train loss <loss>=0.9969009518623352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:23 INFO 140281140962944] Epoch[11] Batch [285]#011Speed: 1366.33 samples/sec#011loss=0.996901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[290] avg_epoch_loss=1.026760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=290 train loss <loss>=0.9335174798965454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [290]#011Speed: 812.24 samples/sec#011loss=0.933517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[295] avg_epoch_loss=1.028558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=295 train loss <loss>=1.1331730246543885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [295]#011Speed: 1368.37 samples/sec#011loss=1.133173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[300] avg_epoch_loss=1.028487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=300 train loss <loss>=1.0243115663528441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [300]#011Speed: 811.15 samples/sec#011loss=1.024312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[305] avg_epoch_loss=1.027148\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=305 train loss <loss>=0.9465125560760498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [305]#011Speed: 1337.80 samples/sec#011loss=0.946513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[310] avg_epoch_loss=1.024865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=310 train loss <loss>=0.8851732850074768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [310]#011Speed: 844.46 samples/sec#011loss=0.885173\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch[315] avg_epoch_loss=1.025124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=315 train loss <loss>=1.0412174224853517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:24 INFO 140281140962944] Epoch[11] Batch [315]#011Speed: 1364.68 samples/sec#011loss=1.041217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[320] avg_epoch_loss=1.037059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=320 train loss <loss>=1.791335129737854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [320]#011Speed: 833.42 samples/sec#011loss=1.791335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[325] avg_epoch_loss=1.039740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=325 train loss <loss>=1.2118859767913819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [325]#011Speed: 1345.77 samples/sec#011loss=1.211886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[330] avg_epoch_loss=1.040131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=330 train loss <loss>=1.0656129837036132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [330]#011Speed: 818.31 samples/sec#011loss=1.065613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[335] avg_epoch_loss=1.041125\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=335 train loss <loss>=1.106930673122406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [335]#011Speed: 1342.06 samples/sec#011loss=1.106931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[340] avg_epoch_loss=1.040211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=340 train loss <loss>=0.9787827491760254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [340]#011Speed: 853.55 samples/sec#011loss=0.978783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[345] avg_epoch_loss=1.038217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=345 train loss <loss>=0.9022478818893432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [345]#011Speed: 1317.99 samples/sec#011loss=0.902248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch[350] avg_epoch_loss=1.036047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=350 train loss <loss>=0.8859050512313843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:25 INFO 140281140962944] Epoch[11] Batch [350]#011Speed: 851.30 samples/sec#011loss=0.885905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[355] avg_epoch_loss=1.034596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=355 train loss <loss>=0.9327014565467835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [355]#011Speed: 1243.20 samples/sec#011loss=0.932701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[360] avg_epoch_loss=1.034541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=360 train loss <loss>=1.0306230306625366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [360]#011Speed: 836.51 samples/sec#011loss=1.030623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[365] avg_epoch_loss=1.033354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=365 train loss <loss>=0.947683322429657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [365]#011Speed: 1187.65 samples/sec#011loss=0.947683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[370] avg_epoch_loss=1.033785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=370 train loss <loss>=1.0652779936790466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [370]#011Speed: 853.83 samples/sec#011loss=1.065278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[375] avg_epoch_loss=1.032035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=375 train loss <loss>=0.9022295594215393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [375]#011Speed: 1368.13 samples/sec#011loss=0.902230\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch[380] avg_epoch_loss=1.031554\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=380 train loss <loss>=0.9953986406326294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:26 INFO 140281140962944] Epoch[11] Batch [380]#011Speed: 860.19 samples/sec#011loss=0.995399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[385] avg_epoch_loss=1.033556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=385 train loss <loss>=1.1860504865646362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [385]#011Speed: 1312.16 samples/sec#011loss=1.186050\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[390] avg_epoch_loss=1.035569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=390 train loss <loss>=1.190977156162262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [390]#011Speed: 858.80 samples/sec#011loss=1.190977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[395] avg_epoch_loss=1.036485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=395 train loss <loss>=1.1081688046455382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [395]#011Speed: 1341.95 samples/sec#011loss=1.108169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[400] avg_epoch_loss=1.038063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=400 train loss <loss>=1.1630087733268737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [400]#011Speed: 742.86 samples/sec#011loss=1.163009\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[405] avg_epoch_loss=1.043505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=405 train loss <loss>=1.4799325823783875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [405]#011Speed: 1362.09 samples/sec#011loss=1.479933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[410] avg_epoch_loss=1.044065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=410 train loss <loss>=1.0895856022834778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [410]#011Speed: 852.72 samples/sec#011loss=1.089586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch[415] avg_epoch_loss=1.046916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=415 train loss <loss>=1.281278419494629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:27 INFO 140281140962944] Epoch[11] Batch [415]#011Speed: 1364.04 samples/sec#011loss=1.281278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[420] avg_epoch_loss=1.047039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=420 train loss <loss>=1.0572776079177857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [420]#011Speed: 870.87 samples/sec#011loss=1.057278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[425] avg_epoch_loss=1.047407\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=425 train loss <loss>=1.078364634513855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [425]#011Speed: 1044.08 samples/sec#011loss=1.078365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[430] avg_epoch_loss=1.047684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=430 train loss <loss>=1.0712584972381591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [430]#011Speed: 655.90 samples/sec#011loss=1.071258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[435] avg_epoch_loss=1.047477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=435 train loss <loss>=1.0296518564224244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [435]#011Speed: 1379.10 samples/sec#011loss=1.029652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch[440] avg_epoch_loss=1.045800\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=440 train loss <loss>=0.8995957255363465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:28 INFO 140281140962944] Epoch[11] Batch [440]#011Speed: 843.96 samples/sec#011loss=0.899596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[445] avg_epoch_loss=1.044447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=445 train loss <loss>=0.9250762462615967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [445]#011Speed: 1344.03 samples/sec#011loss=0.925076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[450] avg_epoch_loss=1.042725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=450 train loss <loss>=0.8891488790512085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [450]#011Speed: 835.98 samples/sec#011loss=0.889149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[455] avg_epoch_loss=1.042023\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=455 train loss <loss>=0.9786870002746582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [455]#011Speed: 1351.84 samples/sec#011loss=0.978687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[460] avg_epoch_loss=1.040976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=460 train loss <loss>=0.9454440593719482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [460]#011Speed: 801.22 samples/sec#011loss=0.945444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[465] avg_epoch_loss=1.039322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=465 train loss <loss>=0.8868314504623414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [465]#011Speed: 1347.44 samples/sec#011loss=0.886831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[470] avg_epoch_loss=1.037953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=470 train loss <loss>=0.9103983044624329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [470]#011Speed: 814.04 samples/sec#011loss=0.910398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch[475] avg_epoch_loss=1.036629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=475 train loss <loss>=0.91194007396698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:29 INFO 140281140962944] Epoch[11] Batch [475]#011Speed: 1360.75 samples/sec#011loss=0.911940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[480] avg_epoch_loss=1.050460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=480 train loss <loss>=2.3670993208885194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [480]#011Speed: 832.42 samples/sec#011loss=2.367099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[485] avg_epoch_loss=1.051098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=485 train loss <loss>=1.1125486373901368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [485]#011Speed: 1350.56 samples/sec#011loss=1.112549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[490] avg_epoch_loss=1.051264\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=490 train loss <loss>=1.0673804521560668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [490]#011Speed: 855.03 samples/sec#011loss=1.067380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[495] avg_epoch_loss=1.050641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=495 train loss <loss>=0.9894744515419006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [495]#011Speed: 1231.87 samples/sec#011loss=0.989474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[500] avg_epoch_loss=1.049627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=500 train loss <loss>=0.949037742614746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [500]#011Speed: 854.17 samples/sec#011loss=0.949038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch[505] avg_epoch_loss=1.048765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=505 train loss <loss>=0.9623983979225159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:30 INFO 140281140962944] Epoch[11] Batch [505]#011Speed: 1354.32 samples/sec#011loss=0.962398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[510] avg_epoch_loss=1.048355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=510 train loss <loss>=1.0067753314971923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [510]#011Speed: 804.46 samples/sec#011loss=1.006775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[515] avg_epoch_loss=1.047246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=515 train loss <loss>=0.9339086174964905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [515]#011Speed: 1299.48 samples/sec#011loss=0.933909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[520] avg_epoch_loss=1.045606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=520 train loss <loss>=0.8763816356658936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [520]#011Speed: 851.89 samples/sec#011loss=0.876382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[525] avg_epoch_loss=1.044296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=525 train loss <loss>=0.9078600525856018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [525]#011Speed: 1171.06 samples/sec#011loss=0.907860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[530] avg_epoch_loss=1.042878\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=530 train loss <loss>=0.8936717271804809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [530]#011Speed: 862.47 samples/sec#011loss=0.893672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch[535] avg_epoch_loss=1.044102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=535 train loss <loss>=1.1740981698036195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:31 INFO 140281140962944] Epoch[11] Batch [535]#011Speed: 1349.93 samples/sec#011loss=1.174098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch[540] avg_epoch_loss=1.046336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=540 train loss <loss>=1.285830056667328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch [540]#011Speed: 838.91 samples/sec#011loss=1.285830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch[545] avg_epoch_loss=1.046536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=545 train loss <loss>=1.0681750655174256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch [545]#011Speed: 1340.16 samples/sec#011loss=1.068175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch[550] avg_epoch_loss=1.047107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, batch=550 train loss <loss>=1.109464693069458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[11] Batch [550]#011Speed: 1310.16 samples/sec#011loss=1.109465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] processed a total of 17620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717434.5570836, \"EndTime\": 1620717452.26737, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17710.209131240845, \"count\": 1, \"min\": 17710.209131240845, \"max\": 17710.209131240845}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=994.895514725533 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=11, train loss <loss>=1.047107315431273\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_aa78f14e-11e8-4f88-a784-19dafd2f2e61-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717452.2674437, \"EndTime\": 1620717452.2773604, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.24062728881836, \"count\": 1, \"min\": 9.24062728881836, \"max\": 9.24062728881836}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[0] avg_epoch_loss=1.940828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=1.9408282041549683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[5] avg_epoch_loss=1.127660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=1.127659837404887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch [5]#011Speed: 1364.27 samples/sec#011loss=1.127660\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[10] avg_epoch_loss=1.097202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=1.0606522917747498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch [10]#011Speed: 770.37 samples/sec#011loss=1.060652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch[15] avg_epoch_loss=1.045263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=0.9309965372085571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:32 INFO 140281140962944] Epoch[12] Batch [15]#011Speed: 1236.44 samples/sec#011loss=0.930997\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[20] avg_epoch_loss=1.007045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=0.8847486019134522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [20]#011Speed: 845.94 samples/sec#011loss=0.884749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[25] avg_epoch_loss=1.003979\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=0.9911038517951966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [25]#011Speed: 1363.53 samples/sec#011loss=0.991104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[30] avg_epoch_loss=0.992409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=0.9322413325309753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [30]#011Speed: 847.90 samples/sec#011loss=0.932241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[35] avg_epoch_loss=1.002711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=1.066586709022522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [35]#011Speed: 1376.42 samples/sec#011loss=1.066587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[40] avg_epoch_loss=0.997708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=0.9616826295852661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [40]#011Speed: 636.80 samples/sec#011loss=0.961683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[45] avg_epoch_loss=0.978865\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=0.8243542432785034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch [45]#011Speed: 1361.52 samples/sec#011loss=0.824354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:33 INFO 140281140962944] Epoch[12] Batch[50] avg_epoch_loss=0.964700\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=0.8343805074691772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [50]#011Speed: 835.74 samples/sec#011loss=0.834381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[55] avg_epoch_loss=0.979386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=1.1291826367378235\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [55]#011Speed: 1342.19 samples/sec#011loss=1.129183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[60] avg_epoch_loss=0.984918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=1.0468755841255188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [60]#011Speed: 817.20 samples/sec#011loss=1.046876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[65] avg_epoch_loss=0.981406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=0.9385603308677674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [65]#011Speed: 1333.45 samples/sec#011loss=0.938560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[70] avg_epoch_loss=0.974284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=0.8802759766578674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [70]#011Speed: 798.85 samples/sec#011loss=0.880276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[75] avg_epoch_loss=0.970643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=0.9189385294914245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [75]#011Speed: 1294.26 samples/sec#011loss=0.918939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch[80] avg_epoch_loss=0.966460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=0.9028793573379517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:34 INFO 140281140962944] Epoch[12] Batch [80]#011Speed: 863.00 samples/sec#011loss=0.902879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[85] avg_epoch_loss=0.969334\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=1.0158952474594116\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [85]#011Speed: 1235.75 samples/sec#011loss=1.015895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[90] avg_epoch_loss=1.001203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=1.5493499398231507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [90]#011Speed: 850.47 samples/sec#011loss=1.549350\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[95] avg_epoch_loss=0.997187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=0.9240965723991394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [95]#011Speed: 1320.97 samples/sec#011loss=0.924097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[100] avg_epoch_loss=0.994149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=0.9358165860176086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [100]#011Speed: 803.49 samples/sec#011loss=0.935817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[105] avg_epoch_loss=1.034467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=1.8488814949989318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [105]#011Speed: 1362.97 samples/sec#011loss=1.848881\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch[110] avg_epoch_loss=1.050972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=1.4008773565292358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:35 INFO 140281140962944] Epoch[12] Batch [110]#011Speed: 843.06 samples/sec#011loss=1.400877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[115] avg_epoch_loss=1.059647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=1.2522510290145874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [115]#011Speed: 1352.89 samples/sec#011loss=1.252251\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[120] avg_epoch_loss=1.065384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=1.1984666585922241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [120]#011Speed: 823.80 samples/sec#011loss=1.198467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[125] avg_epoch_loss=1.065763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=1.0749297857284545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [125]#011Speed: 1347.06 samples/sec#011loss=1.074930\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[130] avg_epoch_loss=1.061990\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=0.9669141888618469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [130]#011Speed: 821.87 samples/sec#011loss=0.966914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[135] avg_epoch_loss=1.057740\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=0.9464106678962707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [135]#011Speed: 1232.61 samples/sec#011loss=0.946411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[140] avg_epoch_loss=1.061004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=1.149767768383026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [140]#011Speed: 850.68 samples/sec#011loss=1.149768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch[145] avg_epoch_loss=1.058328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=0.9828704595565796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:36 INFO 140281140962944] Epoch[12] Batch [145]#011Speed: 1280.87 samples/sec#011loss=0.982870\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[150] avg_epoch_loss=1.057455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=1.0319611787796021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [150]#011Speed: 844.90 samples/sec#011loss=1.031961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[155] avg_epoch_loss=1.053932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=0.947530210018158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [155]#011Speed: 1372.12 samples/sec#011loss=0.947530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[160] avg_epoch_loss=1.049121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=0.8990199089050293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [160]#011Speed: 859.66 samples/sec#011loss=0.899020\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[165] avg_epoch_loss=1.044708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=0.9026183962821961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [165]#011Speed: 1353.17 samples/sec#011loss=0.902618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[170] avg_epoch_loss=1.043551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=1.005126452445984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [170]#011Speed: 795.10 samples/sec#011loss=1.005126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch[175] avg_epoch_loss=1.043859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=1.0543957352638245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:37 INFO 140281140962944] Epoch[12] Batch [175]#011Speed: 1371.87 samples/sec#011loss=1.054396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[180] avg_epoch_loss=1.038152\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=0.8372607350349426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [180]#011Speed: 841.91 samples/sec#011loss=0.837261\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[185] avg_epoch_loss=1.032996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=0.8463647842407227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [185]#011Speed: 1361.88 samples/sec#011loss=0.846365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[190] avg_epoch_loss=1.030159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=0.9246082186698914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [190]#011Speed: 855.14 samples/sec#011loss=0.924608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[195] avg_epoch_loss=1.030529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=1.044680082798004\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [195]#011Speed: 1266.08 samples/sec#011loss=1.044680\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[200] avg_epoch_loss=1.072206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=2.705950379371643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [200]#011Speed: 705.51 samples/sec#011loss=2.705950\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch[205] avg_epoch_loss=1.075698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=1.216076421737671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:38 INFO 140281140962944] Epoch[12] Batch [205]#011Speed: 1138.16 samples/sec#011loss=1.216076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[210] avg_epoch_loss=1.077043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=1.132433867454529\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [210]#011Speed: 841.82 samples/sec#011loss=1.132434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[215] avg_epoch_loss=1.076390\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=1.0488269090652467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [215]#011Speed: 1315.08 samples/sec#011loss=1.048827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[220] avg_epoch_loss=1.074802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=1.0061957597732545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [220]#011Speed: 842.27 samples/sec#011loss=1.006196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[225] avg_epoch_loss=1.090877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=1.80140620470047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [225]#011Speed: 1366.46 samples/sec#011loss=1.801406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[230] avg_epoch_loss=1.092185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=1.1512921094894408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [230]#011Speed: 785.11 samples/sec#011loss=1.151292\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch[235] avg_epoch_loss=1.093346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=1.1469916105270386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:39 INFO 140281140962944] Epoch[12] Batch [235]#011Speed: 1306.75 samples/sec#011loss=1.146992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[240] avg_epoch_loss=1.091432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=1.0010809659957887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [240]#011Speed: 832.09 samples/sec#011loss=1.001081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[245] avg_epoch_loss=1.089322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=0.9876608490943909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [245]#011Speed: 1322.54 samples/sec#011loss=0.987661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[250] avg_epoch_loss=1.089132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=1.0797825932502747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [250]#011Speed: 862.39 samples/sec#011loss=1.079783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[255] avg_epoch_loss=1.088028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=1.0326073527336121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [255]#011Speed: 1373.74 samples/sec#011loss=1.032607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[260] avg_epoch_loss=1.087730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=1.0724576234817504\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [260]#011Speed: 854.68 samples/sec#011loss=1.072458\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[265] avg_epoch_loss=1.105448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=2.030309188365936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [265]#011Speed: 1213.44 samples/sec#011loss=2.030309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch[270] avg_epoch_loss=1.103973\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=270 train loss <loss>=1.0255407810211181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:40 INFO 140281140962944] Epoch[12] Batch [270]#011Speed: 844.92 samples/sec#011loss=1.025541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[275] avg_epoch_loss=1.103924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=275 train loss <loss>=1.1012628078460693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [275]#011Speed: 1359.54 samples/sec#011loss=1.101263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[280] avg_epoch_loss=1.126805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=280 train loss <loss>=2.3898300886154176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [280]#011Speed: 779.15 samples/sec#011loss=2.389830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[285] avg_epoch_loss=1.128276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=285 train loss <loss>=1.2109201431274415\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [285]#011Speed: 1363.54 samples/sec#011loss=1.210920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[290] avg_epoch_loss=1.130002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=290 train loss <loss>=1.2287692308425904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [290]#011Speed: 847.25 samples/sec#011loss=1.228769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[295] avg_epoch_loss=1.132195\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=295 train loss <loss>=1.2598253965377808\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [295]#011Speed: 1259.82 samples/sec#011loss=1.259825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch[300] avg_epoch_loss=1.133462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=300 train loss <loss>=1.2084704399108888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:41 INFO 140281140962944] Epoch[12] Batch [300]#011Speed: 863.19 samples/sec#011loss=1.208470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[305] avg_epoch_loss=1.132743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=305 train loss <loss>=1.0894489526748656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [305]#011Speed: 1297.82 samples/sec#011loss=1.089449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[310] avg_epoch_loss=1.129924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=310 train loss <loss>=0.9573842525482178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [310]#011Speed: 849.67 samples/sec#011loss=0.957384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[315] avg_epoch_loss=1.126065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=315 train loss <loss>=0.8860162854194641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [315]#011Speed: 1362.53 samples/sec#011loss=0.886016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[320] avg_epoch_loss=1.127123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=320 train loss <loss>=1.194000792503357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [320]#011Speed: 861.07 samples/sec#011loss=1.194001\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[325] avg_epoch_loss=1.125835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=325 train loss <loss>=1.0431339383125304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [325]#011Speed: 1323.66 samples/sec#011loss=1.043134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[330] avg_epoch_loss=1.125084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=330 train loss <loss>=1.0761579394340515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [330]#011Speed: 788.94 samples/sec#011loss=1.076158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch[335] avg_epoch_loss=1.123530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=335 train loss <loss>=1.02062908411026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:42 INFO 140281140962944] Epoch[12] Batch [335]#011Speed: 1369.21 samples/sec#011loss=1.020629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[340] avg_epoch_loss=1.120778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=340 train loss <loss>=0.9358540296554565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [340]#011Speed: 846.71 samples/sec#011loss=0.935854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[345] avg_epoch_loss=1.117346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=345 train loss <loss>=0.8832711696624755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [345]#011Speed: 1372.13 samples/sec#011loss=0.883271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[350] avg_epoch_loss=1.114385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=350 train loss <loss>=0.9094886660575867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [350]#011Speed: 864.41 samples/sec#011loss=0.909489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[355] avg_epoch_loss=1.116183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=355 train loss <loss>=1.242435336112976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [355]#011Speed: 1362.79 samples/sec#011loss=1.242435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[360] avg_epoch_loss=1.118402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=360 train loss <loss>=1.2763617992401124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [360]#011Speed: 831.83 samples/sec#011loss=1.276362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch[365] avg_epoch_loss=1.116823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=365 train loss <loss>=1.002821946144104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:43 INFO 140281140962944] Epoch[12] Batch [365]#011Speed: 1022.46 samples/sec#011loss=1.002822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[370] avg_epoch_loss=1.115089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=370 train loss <loss>=0.9881432771682739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [370]#011Speed: 802.53 samples/sec#011loss=0.988143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[375] avg_epoch_loss=1.112817\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=375 train loss <loss>=0.9442385673522949\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [375]#011Speed: 1343.33 samples/sec#011loss=0.944239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[380] avg_epoch_loss=1.110163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=380 train loss <loss>=0.9105796694755555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [380]#011Speed: 850.93 samples/sec#011loss=0.910580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[385] avg_epoch_loss=1.107542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=385 train loss <loss>=0.9078360080718995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [385]#011Speed: 1373.45 samples/sec#011loss=0.907836\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[390] avg_epoch_loss=1.105874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=390 train loss <loss>=0.9770989894866944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [390]#011Speed: 842.13 samples/sec#011loss=0.977099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch[395] avg_epoch_loss=1.104423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=395 train loss <loss>=0.9909334659576416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:44 INFO 140281140962944] Epoch[12] Batch [395]#011Speed: 1230.25 samples/sec#011loss=0.990933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[400] avg_epoch_loss=1.103679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=400 train loss <loss>=1.0447901129722594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [400]#011Speed: 824.79 samples/sec#011loss=1.044790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[405] avg_epoch_loss=1.106107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=405 train loss <loss>=1.3008405566215515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [405]#011Speed: 1304.31 samples/sec#011loss=1.300841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[410] avg_epoch_loss=1.105746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=410 train loss <loss>=1.0764254808425904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [410]#011Speed: 849.01 samples/sec#011loss=1.076425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[415] avg_epoch_loss=1.104927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=415 train loss <loss>=1.037586236000061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [415]#011Speed: 1324.36 samples/sec#011loss=1.037586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[420] avg_epoch_loss=1.105048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=420 train loss <loss>=1.1150985717773438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [420]#011Speed: 831.39 samples/sec#011loss=1.115099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[425] avg_epoch_loss=1.102626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=425 train loss <loss>=0.8987053513526917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [425]#011Speed: 1190.58 samples/sec#011loss=0.898705\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch[430] avg_epoch_loss=1.100698\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=430 train loss <loss>=0.936486291885376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:45 INFO 140281140962944] Epoch[12] Batch [430]#011Speed: 848.91 samples/sec#011loss=0.936486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[435] avg_epoch_loss=1.098669\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=435 train loss <loss>=0.9236957669258118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [435]#011Speed: 1043.44 samples/sec#011loss=0.923696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[440] avg_epoch_loss=1.097952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=440 train loss <loss>=1.0354903221130372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [440]#011Speed: 539.08 samples/sec#011loss=1.035490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[445] avg_epoch_loss=1.096209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=445 train loss <loss>=0.942463731765747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [445]#011Speed: 842.74 samples/sec#011loss=0.942464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[450] avg_epoch_loss=1.094779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=450 train loss <loss>=0.9672344207763672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [450]#011Speed: 654.89 samples/sec#011loss=0.967234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch[455] avg_epoch_loss=1.093858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=455 train loss <loss>=1.0107565760612487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:46 INFO 140281140962944] Epoch[12] Batch [455]#011Speed: 1330.11 samples/sec#011loss=1.010757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[460] avg_epoch_loss=1.092218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=460 train loss <loss>=0.942681360244751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [460]#011Speed: 803.74 samples/sec#011loss=0.942681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[465] avg_epoch_loss=1.090517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=465 train loss <loss>=0.9337014079093933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [465]#011Speed: 1347.87 samples/sec#011loss=0.933701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[470] avg_epoch_loss=1.091118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=470 train loss <loss>=1.1471198081970215\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [470]#011Speed: 848.80 samples/sec#011loss=1.147120\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[475] avg_epoch_loss=1.088593\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=475 train loss <loss>=0.8507280111312866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [475]#011Speed: 1342.02 samples/sec#011loss=0.850728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[480] avg_epoch_loss=1.086673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=480 train loss <loss>=0.9038397073745728\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [480]#011Speed: 779.28 samples/sec#011loss=0.903840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch[485] avg_epoch_loss=1.084996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=485 train loss <loss>=0.9237056612968445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:47 INFO 140281140962944] Epoch[12] Batch [485]#011Speed: 1310.39 samples/sec#011loss=0.923706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[490] avg_epoch_loss=1.082506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=490 train loss <loss>=0.840455150604248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [490]#011Speed: 843.91 samples/sec#011loss=0.840455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[495] avg_epoch_loss=1.080196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=495 train loss <loss>=0.8533513426780701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [495]#011Speed: 1338.00 samples/sec#011loss=0.853351\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[500] avg_epoch_loss=1.077212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=500 train loss <loss>=0.7811806559562683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [500]#011Speed: 808.02 samples/sec#011loss=0.781181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[505] avg_epoch_loss=1.075426\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=505 train loss <loss>=0.8965357780456543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [505]#011Speed: 1335.31 samples/sec#011loss=0.896536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[510] avg_epoch_loss=1.073057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=510 train loss <loss>=0.8332450032234192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [510]#011Speed: 847.00 samples/sec#011loss=0.833245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch[515] avg_epoch_loss=1.072047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=515 train loss <loss>=0.9688687205314637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:48 INFO 140281140962944] Epoch[12] Batch [515]#011Speed: 1150.95 samples/sec#011loss=0.968869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[520] avg_epoch_loss=1.070253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=520 train loss <loss>=0.8850950360298157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [520]#011Speed: 839.32 samples/sec#011loss=0.885095\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[525] avg_epoch_loss=1.068952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=525 train loss <loss>=0.9333539009094238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [525]#011Speed: 1343.18 samples/sec#011loss=0.933354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[530] avg_epoch_loss=1.067465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=530 train loss <loss>=0.9110610008239746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [530]#011Speed: 855.16 samples/sec#011loss=0.911061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[535] avg_epoch_loss=1.066755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=535 train loss <loss>=0.991332221031189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [535]#011Speed: 1375.22 samples/sec#011loss=0.991332\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[540] avg_epoch_loss=1.065228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=540 train loss <loss>=0.9015920400619507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [540]#011Speed: 807.14 samples/sec#011loss=0.901592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch[545] avg_epoch_loss=1.064047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, batch=545 train loss <loss>=0.9362486481666565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] Epoch[12] Batch [545]#011Speed: 1228.20 samples/sec#011loss=0.936249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] processed a total of 17588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717452.2774825, \"EndTime\": 1620717469.9457338, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17668.187379837036, \"count\": 1, \"min\": 17668.187379837036, \"max\": 17668.187379837036}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=995.448627172823 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=12, train loss <loss>=1.0629779676957565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:49 INFO 140281140962944] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[0] avg_epoch_loss=1.001016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=1.0010156631469727\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[5] avg_epoch_loss=0.923061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=0.9230611622333527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [5]#011Speed: 1338.82 samples/sec#011loss=0.923061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[10] avg_epoch_loss=0.897366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=0.8665308237075806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [10]#011Speed: 844.69 samples/sec#011loss=0.866531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[15] avg_epoch_loss=0.883530\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=0.8530908942222595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [15]#011Speed: 1360.37 samples/sec#011loss=0.853091\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[20] avg_epoch_loss=0.847150\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=0.7307328104972839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [20]#011Speed: 834.84 samples/sec#011loss=0.730733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[25] avg_epoch_loss=0.836255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=0.7904989719390869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [25]#011Speed: 1346.90 samples/sec#011loss=0.790499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch[30] avg_epoch_loss=0.824202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=0.7615258812904357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:50 INFO 140281140962944] Epoch[13] Batch [30]#011Speed: 791.60 samples/sec#011loss=0.761526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[35] avg_epoch_loss=0.824889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=0.8291467189788818\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [35]#011Speed: 1365.68 samples/sec#011loss=0.829147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[40] avg_epoch_loss=0.818653\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=0.7737532973289489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [40]#011Speed: 832.72 samples/sec#011loss=0.773753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[45] avg_epoch_loss=0.813659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=0.7727131247520447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [45]#011Speed: 1353.24 samples/sec#011loss=0.772713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[50] avg_epoch_loss=0.832309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=1.0038838505744934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [50]#011Speed: 867.76 samples/sec#011loss=1.003884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[55] avg_epoch_loss=0.841713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=0.9376350164413452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [55]#011Speed: 1277.19 samples/sec#011loss=0.937635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch[60] avg_epoch_loss=0.850225\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=0.945555853843689\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:51 INFO 140281140962944] Epoch[13] Batch [60]#011Speed: 796.96 samples/sec#011loss=0.945556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[65] avg_epoch_loss=0.871542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=1.1316189527511598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [65]#011Speed: 1341.07 samples/sec#011loss=1.131619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[70] avg_epoch_loss=0.880208\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=0.9945907592773438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [70]#011Speed: 844.52 samples/sec#011loss=0.994591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[75] avg_epoch_loss=0.884621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=0.9472959280014038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [75]#011Speed: 1377.77 samples/sec#011loss=0.947296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[80] avg_epoch_loss=0.888637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=0.94966721534729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [80]#011Speed: 849.57 samples/sec#011loss=0.949667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[85] avg_epoch_loss=0.888101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=0.8794243454933166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [85]#011Speed: 1368.01 samples/sec#011loss=0.879424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[90] avg_epoch_loss=0.884487\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=0.8223208069801331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [90]#011Speed: 845.44 samples/sec#011loss=0.822321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch[95] avg_epoch_loss=0.884421\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=0.8832156777381897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:52 INFO 140281140962944] Epoch[13] Batch [95]#011Speed: 1221.02 samples/sec#011loss=0.883216\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[100] avg_epoch_loss=0.885395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=0.9040991783142089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [100]#011Speed: 859.29 samples/sec#011loss=0.904099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[105] avg_epoch_loss=0.888144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=0.9436778664588928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [105]#011Speed: 1344.27 samples/sec#011loss=0.943678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[110] avg_epoch_loss=0.889348\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=0.914876914024353\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [110]#011Speed: 852.62 samples/sec#011loss=0.914877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[115] avg_epoch_loss=1.090637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=5.559247088432312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [115]#011Speed: 1356.88 samples/sec#011loss=5.559247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[120] avg_epoch_loss=1.091382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=1.1086569547653198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [120]#011Speed: 782.76 samples/sec#011loss=1.108657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch[125] avg_epoch_loss=1.100623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=1.3242722034454346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:53 INFO 140281140962944] Epoch[13] Batch [125]#011Speed: 1240.07 samples/sec#011loss=1.324272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[130] avg_epoch_loss=1.113473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=1.4372793197631837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [130]#011Speed: 850.84 samples/sec#011loss=1.437279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[135] avg_epoch_loss=1.123635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=1.3898767709732056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [135]#011Speed: 1346.06 samples/sec#011loss=1.389877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[140] avg_epoch_loss=1.131931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=1.3576061964035033\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [140]#011Speed: 857.84 samples/sec#011loss=1.357606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[145] avg_epoch_loss=1.136580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=1.2676658630371094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [145]#011Speed: 1370.80 samples/sec#011loss=1.267666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[150] avg_epoch_loss=1.141600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=1.2881765127182008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [150]#011Speed: 859.50 samples/sec#011loss=1.288177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch[155] avg_epoch_loss=1.142648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=1.174310040473938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:54 INFO 140281140962944] Epoch[13] Batch [155]#011Speed: 1281.08 samples/sec#011loss=1.174310\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[160] avg_epoch_loss=1.142759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=1.1462087154388427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [160]#011Speed: 788.17 samples/sec#011loss=1.146209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[165] avg_epoch_loss=1.139300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=1.0279370546340942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [165]#011Speed: 1345.30 samples/sec#011loss=1.027937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[170] avg_epoch_loss=1.134921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=0.9895232439041137\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [170]#011Speed: 832.22 samples/sec#011loss=0.989523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[175] avg_epoch_loss=1.129918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=0.958821713924408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [175]#011Speed: 1355.85 samples/sec#011loss=0.958822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[180] avg_epoch_loss=1.126890\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=1.0202957153320313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [180]#011Speed: 859.03 samples/sec#011loss=1.020296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[185] avg_epoch_loss=1.131602\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=1.3021973729133607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [185]#011Speed: 1349.14 samples/sec#011loss=1.302197\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch[190] avg_epoch_loss=1.131847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=1.1409447908401489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:55 INFO 140281140962944] Epoch[13] Batch [190]#011Speed: 799.18 samples/sec#011loss=1.140945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[195] avg_epoch_loss=1.127083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=0.9451011061668396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [195]#011Speed: 1304.34 samples/sec#011loss=0.945101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[200] avg_epoch_loss=1.137267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=1.5364840030670166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [200]#011Speed: 868.29 samples/sec#011loss=1.536484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[205] avg_epoch_loss=1.135630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=1.0698263764381408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [205]#011Speed: 1340.43 samples/sec#011loss=1.069826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[210] avg_epoch_loss=1.136877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=1.1882697701454163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [210]#011Speed: 858.58 samples/sec#011loss=1.188270\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[215] avg_epoch_loss=1.134048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=1.0146520376205443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [215]#011Speed: 1362.36 samples/sec#011loss=1.014652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch[220] avg_epoch_loss=1.131709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=1.030637788772583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:56 INFO 140281140962944] Epoch[13] Batch [220]#011Speed: 806.90 samples/sec#011loss=1.030638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[225] avg_epoch_loss=1.129598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=1.0363142371177674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [225]#011Speed: 1233.11 samples/sec#011loss=1.036314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[230] avg_epoch_loss=1.135304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=1.3932123064994812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [230]#011Speed: 842.46 samples/sec#011loss=1.393212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[235] avg_epoch_loss=1.131566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=0.9588570356369018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [235]#011Speed: 1339.02 samples/sec#011loss=0.958857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[240] avg_epoch_loss=1.126826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=0.9031334638595581\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [240]#011Speed: 839.96 samples/sec#011loss=0.903133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[245] avg_epoch_loss=1.122572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=0.9175213694572448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [245]#011Speed: 1362.76 samples/sec#011loss=0.917521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[250] avg_epoch_loss=1.120467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=1.0168920636177063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [250]#011Speed: 846.48 samples/sec#011loss=1.016892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch[255] avg_epoch_loss=1.118913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=1.04090496301651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:57 INFO 140281140962944] Epoch[13] Batch [255]#011Speed: 1367.53 samples/sec#011loss=1.040905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[260] avg_epoch_loss=1.116959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=1.0169222712516786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [260]#011Speed: 793.43 samples/sec#011loss=1.016922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[265] avg_epoch_loss=1.112368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=0.8727015018463135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [265]#011Speed: 1372.59 samples/sec#011loss=0.872702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[270] avg_epoch_loss=1.109737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=270 train loss <loss>=0.9697447896003724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [270]#011Speed: 857.00 samples/sec#011loss=0.969745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[275] avg_epoch_loss=1.104488\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=275 train loss <loss>=0.8199942946434021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [275]#011Speed: 1359.82 samples/sec#011loss=0.819994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[280] avg_epoch_loss=1.101096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=280 train loss <loss>=0.913867962360382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [280]#011Speed: 853.83 samples/sec#011loss=0.913868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch[285] avg_epoch_loss=1.100076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=285 train loss <loss>=1.042753314971924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:58 INFO 140281140962944] Epoch[13] Batch [285]#011Speed: 1370.79 samples/sec#011loss=1.042753\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[290] avg_epoch_loss=1.096966\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=290 train loss <loss>=0.9190941572189331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [290]#011Speed: 803.33 samples/sec#011loss=0.919094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[295] avg_epoch_loss=1.097853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=295 train loss <loss>=1.1494487285614015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [295]#011Speed: 1361.88 samples/sec#011loss=1.149449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[300] avg_epoch_loss=1.100081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=300 train loss <loss>=1.2320188522338866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [300]#011Speed: 853.09 samples/sec#011loss=1.232019\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[305] avg_epoch_loss=1.098668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=305 train loss <loss>=1.0135825157165528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [305]#011Speed: 1369.91 samples/sec#011loss=1.013583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[310] avg_epoch_loss=1.095964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=310 train loss <loss>=0.9304932475090026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [310]#011Speed: 863.16 samples/sec#011loss=0.930493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch[315] avg_epoch_loss=1.094193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=315 train loss <loss>=0.9840402126312255\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:17:59 INFO 140281140962944] Epoch[13] Batch [315]#011Speed: 1306.13 samples/sec#011loss=0.984040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[320] avg_epoch_loss=1.090283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=320 train loss <loss>=0.8431262969970703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [320]#011Speed: 813.14 samples/sec#011loss=0.843126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[325] avg_epoch_loss=1.087291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=325 train loss <loss>=0.8952221870422363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [325]#011Speed: 1240.56 samples/sec#011loss=0.895222\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[330] avg_epoch_loss=1.083503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=330 train loss <loss>=0.8365143775939942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [330]#011Speed: 795.47 samples/sec#011loss=0.836514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[335] avg_epoch_loss=1.080470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=335 train loss <loss>=0.8797355532646179\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [335]#011Speed: 1333.58 samples/sec#011loss=0.879736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[340] avg_epoch_loss=1.076929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=340 train loss <loss>=0.838943338394165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [340]#011Speed: 873.52 samples/sec#011loss=0.838943\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[345] avg_epoch_loss=1.073169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=345 train loss <loss>=0.8167161226272583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [345]#011Speed: 1332.14 samples/sec#011loss=0.816716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch[350] avg_epoch_loss=1.073511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=350 train loss <loss>=1.0972103357315064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:00 INFO 140281140962944] Epoch[13] Batch [350]#011Speed: 847.75 samples/sec#011loss=1.097210\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[355] avg_epoch_loss=1.072084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=355 train loss <loss>=0.9719178795814514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [355]#011Speed: 1211.89 samples/sec#011loss=0.971918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[360] avg_epoch_loss=1.068328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=360 train loss <loss>=0.8008889317512512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [360]#011Speed: 813.52 samples/sec#011loss=0.800889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[365] avg_epoch_loss=1.065294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=365 train loss <loss>=0.8462058544158936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [365]#011Speed: 1295.75 samples/sec#011loss=0.846206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[370] avg_epoch_loss=1.062691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=370 train loss <loss>=0.8721559405326843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [370]#011Speed: 598.21 samples/sec#011loss=0.872156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch[375] avg_epoch_loss=1.060470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=375 train loss <loss>=0.895660674571991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:01 INFO 140281140962944] Epoch[13] Batch [375]#011Speed: 678.39 samples/sec#011loss=0.895661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[380] avg_epoch_loss=1.057763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=380 train loss <loss>=0.8541923046112061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [380]#011Speed: 518.08 samples/sec#011loss=0.854192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[385] avg_epoch_loss=1.055067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=385 train loss <loss>=0.8496695280075073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [385]#011Speed: 1106.50 samples/sec#011loss=0.849670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[390] avg_epoch_loss=1.052624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=390 train loss <loss>=0.8639907240867615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [390]#011Speed: 847.62 samples/sec#011loss=0.863991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[395] avg_epoch_loss=1.051322\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=395 train loss <loss>=0.949543571472168\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [395]#011Speed: 1338.39 samples/sec#011loss=0.949544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[400] avg_epoch_loss=1.048975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=400 train loss <loss>=0.8630842447280884\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [400]#011Speed: 820.45 samples/sec#011loss=0.863084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch[405] avg_epoch_loss=1.047937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=405 train loss <loss>=0.9646506786346436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:02 INFO 140281140962944] Epoch[13] Batch [405]#011Speed: 1324.96 samples/sec#011loss=0.964651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[410] avg_epoch_loss=1.051443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=410 train loss <loss>=1.336204731464386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [410]#011Speed: 814.57 samples/sec#011loss=1.336205\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[415] avg_epoch_loss=1.050919\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=415 train loss <loss>=1.0078187465667725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [415]#011Speed: 1352.95 samples/sec#011loss=1.007819\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[420] avg_epoch_loss=1.050796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=420 train loss <loss>=1.0405870437622071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [420]#011Speed: 854.91 samples/sec#011loss=1.040587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[425] avg_epoch_loss=1.050209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=425 train loss <loss>=1.0007539629936217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [425]#011Speed: 1358.29 samples/sec#011loss=1.000754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[430] avg_epoch_loss=1.049162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=430 train loss <loss>=0.959974753856659\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [430]#011Speed: 859.85 samples/sec#011loss=0.959975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch[435] avg_epoch_loss=1.047171\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=435 train loss <loss>=0.8754945993423462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:03 INFO 140281140962944] Epoch[13] Batch [435]#011Speed: 1366.21 samples/sec#011loss=0.875495\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[440] avg_epoch_loss=1.044804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=440 train loss <loss>=0.8384280800819397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [440]#011Speed: 795.21 samples/sec#011loss=0.838428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[445] avg_epoch_loss=1.042410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=445 train loss <loss>=0.8312833309173584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [445]#011Speed: 1315.82 samples/sec#011loss=0.831283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[450] avg_epoch_loss=1.043782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=450 train loss <loss>=1.1661691308021545\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [450]#011Speed: 815.14 samples/sec#011loss=1.166169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[455] avg_epoch_loss=1.042626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=455 train loss <loss>=0.9383279800415039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [455]#011Speed: 846.20 samples/sec#011loss=0.938328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch[460] avg_epoch_loss=1.040537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=460 train loss <loss>=0.8500176548957825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:04 INFO 140281140962944] Epoch[13] Batch [460]#011Speed: 501.93 samples/sec#011loss=0.850018\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[465] avg_epoch_loss=1.038810\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=465 train loss <loss>=0.879630172252655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [465]#011Speed: 758.24 samples/sec#011loss=0.879630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[470] avg_epoch_loss=1.040627\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=470 train loss <loss>=1.2099042057991027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [470]#011Speed: 599.01 samples/sec#011loss=1.209904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[475] avg_epoch_loss=1.038790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=475 train loss <loss>=0.8657559514045715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [475]#011Speed: 1334.33 samples/sec#011loss=0.865756\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[480] avg_epoch_loss=1.048370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=480 train loss <loss>=1.9603663444519044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [480]#011Speed: 857.32 samples/sec#011loss=1.960366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch[485] avg_epoch_loss=1.047075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=485 train loss <loss>=0.9224978685379028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:05 INFO 140281140962944] Epoch[13] Batch [485]#011Speed: 1189.00 samples/sec#011loss=0.922498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch[490] avg_epoch_loss=1.045583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=490 train loss <loss>=0.900615394115448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch [490]#011Speed: 412.13 samples/sec#011loss=0.900615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch[495] avg_epoch_loss=1.044280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=495 train loss <loss>=0.9162666201591492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch [495]#011Speed: 745.17 samples/sec#011loss=0.916267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch[500] avg_epoch_loss=1.042887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=500 train loss <loss>=0.9047030568122864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:06 INFO 140281140962944] Epoch[13] Batch [500]#011Speed: 468.01 samples/sec#011loss=0.904703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[505] avg_epoch_loss=1.041071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=505 train loss <loss>=0.859181571006775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [505]#011Speed: 797.10 samples/sec#011loss=0.859182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[510] avg_epoch_loss=1.040261\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=510 train loss <loss>=0.9582895755767822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [510]#011Speed: 460.57 samples/sec#011loss=0.958290\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[515] avg_epoch_loss=1.037978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=515 train loss <loss>=0.8046345353126526\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [515]#011Speed: 765.17 samples/sec#011loss=0.804635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch[520] avg_epoch_loss=1.036907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=520 train loss <loss>=0.92631094455719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:07 INFO 140281140962944] Epoch[13] Batch [520]#011Speed: 472.46 samples/sec#011loss=0.926311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[525] avg_epoch_loss=1.034373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=525 train loss <loss>=0.7704080939292908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [525]#011Speed: 801.68 samples/sec#011loss=0.770408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[530] avg_epoch_loss=1.032706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=530 train loss <loss>=0.8573274374008178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [530]#011Speed: 763.41 samples/sec#011loss=0.857327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[535] avg_epoch_loss=1.034926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=535 train loss <loss>=1.270651137828827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [535]#011Speed: 1336.08 samples/sec#011loss=1.270651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[540] avg_epoch_loss=1.036645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=540 train loss <loss>=1.2209034085273742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [540]#011Speed: 857.21 samples/sec#011loss=1.220903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[545] avg_epoch_loss=1.035167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=545 train loss <loss>=0.8752912402153015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [545]#011Speed: 1349.45 samples/sec#011loss=0.875291\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch[550] avg_epoch_loss=1.034494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, batch=550 train loss <loss>=0.9610400915145874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Epoch[13] Batch [550]#011Speed: 1145.78 samples/sec#011loss=0.961040\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] processed a total of 17679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717469.9459233, \"EndTime\": 1620717488.9358704, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 18989.048719406128, \"count\": 1, \"min\": 18989.048719406128, \"max\": 18989.048719406128}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=931.0043413538345 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=13, train loss <loss>=1.0342042567932583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:08 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_f1400874-11d7-4c91-8b84-77d93b4560ae-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717488.9359572, \"EndTime\": 1620717488.9458601, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.401321411132812, \"count\": 1, \"min\": 9.401321411132812, \"max\": 9.401321411132812}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[0] avg_epoch_loss=1.029626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.0296260118484497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[5] avg_epoch_loss=1.015668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.015668163696925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [5]#011Speed: 1332.01 samples/sec#011loss=1.015668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[10] avg_epoch_loss=0.974316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=0.9246933937072754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [10]#011Speed: 799.30 samples/sec#011loss=0.924693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[15] avg_epoch_loss=0.969964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=0.9603905558586121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [15]#011Speed: 1337.19 samples/sec#011loss=0.960391\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[20] avg_epoch_loss=0.968442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=0.9635694622993469\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [20]#011Speed: 856.25 samples/sec#011loss=0.963569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[25] avg_epoch_loss=0.999990\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=1.1324929475784302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [25]#011Speed: 1342.59 samples/sec#011loss=1.132493\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch[30] avg_epoch_loss=0.994159\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=0.9638367056846618\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:09 INFO 140281140962944] Epoch[14] Batch [30]#011Speed: 851.10 samples/sec#011loss=0.963837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[35] avg_epoch_loss=0.984207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=0.922507905960083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [35]#011Speed: 1258.35 samples/sec#011loss=0.922508\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[40] avg_epoch_loss=0.979131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=0.9425854563713074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [40]#011Speed: 819.70 samples/sec#011loss=0.942585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[45] avg_epoch_loss=0.972233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=0.9156698703765869\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [45]#011Speed: 1299.67 samples/sec#011loss=0.915670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[50] avg_epoch_loss=0.974254\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=0.9928405046463012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [50]#011Speed: 869.86 samples/sec#011loss=0.992841\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[55] avg_epoch_loss=0.981631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=1.0568731665611266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [55]#011Speed: 1357.41 samples/sec#011loss=1.056873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch[60] avg_epoch_loss=0.973774\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=0.8857756376266479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:10 INFO 140281140962944] Epoch[14] Batch [60]#011Speed: 862.59 samples/sec#011loss=0.885776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[65] avg_epoch_loss=0.969207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=0.9134996652603149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [65]#011Speed: 1349.32 samples/sec#011loss=0.913500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[70] avg_epoch_loss=0.964954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=0.9088094353675842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [70]#011Speed: 851.64 samples/sec#011loss=0.908809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[75] avg_epoch_loss=0.956123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=0.8307221889495849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [75]#011Speed: 1166.76 samples/sec#011loss=0.830722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[80] avg_epoch_loss=0.950124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=0.8589408278465271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [80]#011Speed: 828.88 samples/sec#011loss=0.858941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[85] avg_epoch_loss=0.980078\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=1.4653268933296204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [85]#011Speed: 1362.53 samples/sec#011loss=1.465327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[90] avg_epoch_loss=0.975103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=0.8895469903945923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [90]#011Speed: 838.68 samples/sec#011loss=0.889547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch[95] avg_epoch_loss=0.966822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=0.8160999178886413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:11 INFO 140281140962944] Epoch[14] Batch [95]#011Speed: 1306.69 samples/sec#011loss=0.816100\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[100] avg_epoch_loss=0.963474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=0.8991846203804016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [100]#011Speed: 856.10 samples/sec#011loss=0.899185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[105] avg_epoch_loss=0.973600\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=1.1781619548797608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [105]#011Speed: 1241.83 samples/sec#011loss=1.178162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[110] avg_epoch_loss=0.986427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=1.2583440303802491\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [110]#011Speed: 854.00 samples/sec#011loss=1.258344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[115] avg_epoch_loss=0.984686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=0.9460382103919983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [115]#011Speed: 1374.11 samples/sec#011loss=0.946038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[120] avg_epoch_loss=0.981490\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=0.9073546171188355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [120]#011Speed: 840.12 samples/sec#011loss=0.907355\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch[125] avg_epoch_loss=0.978881\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=0.9157302021980286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:12 INFO 140281140962944] Epoch[14] Batch [125]#011Speed: 1360.15 samples/sec#011loss=0.915730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[130] avg_epoch_loss=0.972071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=0.8004549026489258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [130]#011Speed: 866.75 samples/sec#011loss=0.800455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[135] avg_epoch_loss=0.970337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=0.9249029994010926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [135]#011Speed: 1375.63 samples/sec#011loss=0.924903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[140] avg_epoch_loss=0.968648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=0.9227182626724243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [140]#011Speed: 809.28 samples/sec#011loss=0.922718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[145] avg_epoch_loss=0.966796\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=0.9145565748214721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [145]#011Speed: 1347.64 samples/sec#011loss=0.914557\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[150] avg_epoch_loss=0.966853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=0.9685435891151428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [150]#011Speed: 851.04 samples/sec#011loss=0.968544\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch[155] avg_epoch_loss=0.968369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=1.01412672996521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:13 INFO 140281140962944] Epoch[14] Batch [155]#011Speed: 1353.04 samples/sec#011loss=1.014127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[160] avg_epoch_loss=0.970468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=1.0359673142433166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [160]#011Speed: 859.39 samples/sec#011loss=1.035967\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[165] avg_epoch_loss=0.967506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=0.8721229434013367\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [165]#011Speed: 1371.26 samples/sec#011loss=0.872123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[170] avg_epoch_loss=0.963650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=0.8356417417526245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [170]#011Speed: 805.80 samples/sec#011loss=0.835642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[175] avg_epoch_loss=0.966857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=1.0765204310417176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [175]#011Speed: 1368.27 samples/sec#011loss=1.076520\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[180] avg_epoch_loss=0.967107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=0.9759037971496582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [180]#011Speed: 871.32 samples/sec#011loss=0.975904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[185] avg_epoch_loss=0.976789\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=1.3272990226745605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [185]#011Speed: 1370.86 samples/sec#011loss=1.327299\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch[190] avg_epoch_loss=0.984302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=1.2637633800506591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:14 INFO 140281140962944] Epoch[14] Batch [190]#011Speed: 848.98 samples/sec#011loss=1.263763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[195] avg_epoch_loss=0.984959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=1.0100737929344177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [195]#011Speed: 1344.40 samples/sec#011loss=1.010074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[200] avg_epoch_loss=0.989187\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=1.154928708076477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [200]#011Speed: 848.18 samples/sec#011loss=1.154929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[205] avg_epoch_loss=0.991670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=1.0915013551712036\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [205]#011Speed: 1244.60 samples/sec#011loss=1.091501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[210] avg_epoch_loss=0.997778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=1.2494143486022948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [210]#011Speed: 855.28 samples/sec#011loss=1.249414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[215] avg_epoch_loss=0.996742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=0.9530029654502868\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [215]#011Speed: 1362.59 samples/sec#011loss=0.953003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[220] avg_epoch_loss=0.995522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=0.9428343415260315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [220]#011Speed: 848.54 samples/sec#011loss=0.942834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch[225] avg_epoch_loss=0.995219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=0.981829571723938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:15 INFO 140281140962944] Epoch[14] Batch [225]#011Speed: 1325.97 samples/sec#011loss=0.981830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[230] avg_epoch_loss=0.993089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=0.8967931628227234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [230]#011Speed: 839.68 samples/sec#011loss=0.896793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[235] avg_epoch_loss=0.992112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=0.9469961047172546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [235]#011Speed: 1358.32 samples/sec#011loss=0.946996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[240] avg_epoch_loss=0.990295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=0.9045047044754029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [240]#011Speed: 761.26 samples/sec#011loss=0.904505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[245] avg_epoch_loss=0.986448\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=0.8010394096374511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [245]#011Speed: 1326.60 samples/sec#011loss=0.801039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch[250] avg_epoch_loss=0.985029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=0.9152035593986512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:16 INFO 140281140962944] Epoch[14] Batch [250]#011Speed: 637.79 samples/sec#011loss=0.915204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[255] avg_epoch_loss=0.983381\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=0.9006844997406006\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [255]#011Speed: 872.43 samples/sec#011loss=0.900684\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[260] avg_epoch_loss=0.982427\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=0.9335410714149475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [260]#011Speed: 523.63 samples/sec#011loss=0.933541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[265] avg_epoch_loss=0.981411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=0.9284160971641541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [265]#011Speed: 1333.54 samples/sec#011loss=0.928416\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[270] avg_epoch_loss=0.982430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=270 train loss <loss>=1.036610472202301\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [270]#011Speed: 853.85 samples/sec#011loss=1.036610\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[275] avg_epoch_loss=1.026444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=275 train loss <loss>=3.412000334262848\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [275]#011Speed: 1346.95 samples/sec#011loss=3.412000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch[280] avg_epoch_loss=1.030974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=280 train loss <loss>=1.2810240983963013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:17 INFO 140281140962944] Epoch[14] Batch [280]#011Speed: 831.44 samples/sec#011loss=1.281024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[285] avg_epoch_loss=1.037695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=285 train loss <loss>=1.4154288053512574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [285]#011Speed: 1344.05 samples/sec#011loss=1.415429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[290] avg_epoch_loss=1.043673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=290 train loss <loss>=1.3855952501296998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [290]#011Speed: 863.44 samples/sec#011loss=1.385595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[295] avg_epoch_loss=1.048580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=295 train loss <loss>=1.3342136144638062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [295]#011Speed: 1193.46 samples/sec#011loss=1.334214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[300] avg_epoch_loss=1.052223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=300 train loss <loss>=1.2678656339645387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [300]#011Speed: 848.07 samples/sec#011loss=1.267866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[305] avg_epoch_loss=1.056092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=305 train loss <loss>=1.2890153169631957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [305]#011Speed: 1351.67 samples/sec#011loss=1.289015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch[310] avg_epoch_loss=1.057185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=310 train loss <loss>=1.1240978717803956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:18 INFO 140281140962944] Epoch[14] Batch [310]#011Speed: 862.79 samples/sec#011loss=1.124098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[315] avg_epoch_loss=1.056933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=315 train loss <loss>=1.0412127733230592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [315]#011Speed: 1338.42 samples/sec#011loss=1.041213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[320] avg_epoch_loss=1.056283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=320 train loss <loss>=1.015247917175293\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [320]#011Speed: 862.59 samples/sec#011loss=1.015248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[325] avg_epoch_loss=1.054054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=325 train loss <loss>=0.9109395623207093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [325]#011Speed: 1361.64 samples/sec#011loss=0.910940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[330] avg_epoch_loss=1.051754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=330 train loss <loss>=0.901747751235962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [330]#011Speed: 824.58 samples/sec#011loss=0.901748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[335] avg_epoch_loss=1.048191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=335 train loss <loss>=0.8123515129089356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [335]#011Speed: 1374.56 samples/sec#011loss=0.812352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[340] avg_epoch_loss=1.045930\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=340 train loss <loss>=0.893976354598999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [340]#011Speed: 859.91 samples/sec#011loss=0.893976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch[345] avg_epoch_loss=1.042631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=345 train loss <loss>=0.8176425814628601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:19 INFO 140281140962944] Epoch[14] Batch [345]#011Speed: 1358.57 samples/sec#011loss=0.817643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[350] avg_epoch_loss=1.039245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=350 train loss <loss>=0.8049621224403382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [350]#011Speed: 859.01 samples/sec#011loss=0.804962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[355] avg_epoch_loss=1.038149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=355 train loss <loss>=0.9611884117126465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [355]#011Speed: 1361.94 samples/sec#011loss=0.961188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[360] avg_epoch_loss=1.035702\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=360 train loss <loss>=0.8614672660827637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [360]#011Speed: 781.70 samples/sec#011loss=0.861467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[365] avg_epoch_loss=1.038759\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=365 train loss <loss>=1.2595121622085572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [365]#011Speed: 1337.24 samples/sec#011loss=1.259512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[370] avg_epoch_loss=1.038607\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=370 train loss <loss>=1.0274221897125244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [370]#011Speed: 853.10 samples/sec#011loss=1.027422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch[375] avg_epoch_loss=1.041390\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=375 train loss <loss>=1.247960591316223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:20 INFO 140281140962944] Epoch[14] Batch [375]#011Speed: 1337.38 samples/sec#011loss=1.247961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[380] avg_epoch_loss=1.040246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=380 train loss <loss>=0.9541840553283691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [380]#011Speed: 855.89 samples/sec#011loss=0.954184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[385] avg_epoch_loss=1.038404\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=385 train loss <loss>=0.8980303525924682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [385]#011Speed: 1358.36 samples/sec#011loss=0.898030\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[390] avg_epoch_loss=1.037306\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=390 train loss <loss>=0.9525281906127929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [390]#011Speed: 845.38 samples/sec#011loss=0.952528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[395] avg_epoch_loss=1.035323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=395 train loss <loss>=0.8803114175796509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [395]#011Speed: 1176.84 samples/sec#011loss=0.880311\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[400] avg_epoch_loss=1.032996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=400 train loss <loss>=0.8486620664596558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [400]#011Speed: 854.10 samples/sec#011loss=0.848662\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch[405] avg_epoch_loss=1.033345\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=405 train loss <loss>=1.0613425850868226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:21 INFO 140281140962944] Epoch[14] Batch [405]#011Speed: 1314.16 samples/sec#011loss=1.061343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[410] avg_epoch_loss=1.031679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=410 train loss <loss>=0.8963787913322449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [410]#011Speed: 850.81 samples/sec#011loss=0.896379\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[415] avg_epoch_loss=1.031406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=415 train loss <loss>=1.008939754962921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [415]#011Speed: 1340.06 samples/sec#011loss=1.008940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[420] avg_epoch_loss=1.031611\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=420 train loss <loss>=1.048715054988861\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [420]#011Speed: 836.34 samples/sec#011loss=1.048715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[425] avg_epoch_loss=1.030244\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=425 train loss <loss>=0.9151348233222961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [425]#011Speed: 1228.46 samples/sec#011loss=0.915135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[430] avg_epoch_loss=1.039903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=430 train loss <loss>=1.8628472208976745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [430]#011Speed: 850.69 samples/sec#011loss=1.862847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[435] avg_epoch_loss=1.041229\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=435 train loss <loss>=1.1555120944976807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [435]#011Speed: 1301.17 samples/sec#011loss=1.155512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch[440] avg_epoch_loss=1.040779\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=440 train loss <loss>=1.0015953421592712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:22 INFO 140281140962944] Epoch[14] Batch [440]#011Speed: 845.91 samples/sec#011loss=1.001595\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[445] avg_epoch_loss=1.039630\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=445 train loss <loss>=0.9382312297821045\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [445]#011Speed: 1325.76 samples/sec#011loss=0.938231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[450] avg_epoch_loss=1.038813\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=450 train loss <loss>=0.9659932374954223\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [450]#011Speed: 842.72 samples/sec#011loss=0.965993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[455] avg_epoch_loss=1.039151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=455 train loss <loss>=1.069635546207428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [455]#011Speed: 1357.24 samples/sec#011loss=1.069636\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[460] avg_epoch_loss=1.037571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=460 train loss <loss>=0.8934804320335388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [460]#011Speed: 778.00 samples/sec#011loss=0.893480\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[465] avg_epoch_loss=1.037674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=465 train loss <loss>=1.0471571445465089\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [465]#011Speed: 1321.58 samples/sec#011loss=1.047157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch[470] avg_epoch_loss=1.036843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=470 train loss <loss>=0.9593422889709473\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:23 INFO 140281140962944] Epoch[14] Batch [470]#011Speed: 849.51 samples/sec#011loss=0.959342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[475] avg_epoch_loss=1.034741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=475 train loss <loss>=0.836784815788269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [475]#011Speed: 1298.07 samples/sec#011loss=0.836785\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[480] avg_epoch_loss=1.034433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=480 train loss <loss>=1.0051083207130431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [480]#011Speed: 858.98 samples/sec#011loss=1.005108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[485] avg_epoch_loss=1.035143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=485 train loss <loss>=1.1034452080726624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [485]#011Speed: 1339.96 samples/sec#011loss=1.103445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[490] avg_epoch_loss=1.033803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=490 train loss <loss>=0.9035564541816712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [490]#011Speed: 751.78 samples/sec#011loss=0.903556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[495] avg_epoch_loss=1.032026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=495 train loss <loss>=0.8574761986732483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [495]#011Speed: 1350.48 samples/sec#011loss=0.857476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[500] avg_epoch_loss=1.029377\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=500 train loss <loss>=0.7665803790092468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [500]#011Speed: 847.12 samples/sec#011loss=0.766580\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch[505] avg_epoch_loss=1.026916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=505 train loss <loss>=0.7803159356117249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:24 INFO 140281140962944] Epoch[14] Batch [505]#011Speed: 1322.64 samples/sec#011loss=0.780316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[510] avg_epoch_loss=1.025472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=510 train loss <loss>=0.8793384075164795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [510]#011Speed: 829.57 samples/sec#011loss=0.879338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[515] avg_epoch_loss=1.024308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=515 train loss <loss>=0.905380392074585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [515]#011Speed: 1312.49 samples/sec#011loss=0.905380\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[520] avg_epoch_loss=1.022369\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=520 train loss <loss>=0.8222496151924134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [520]#011Speed: 801.26 samples/sec#011loss=0.822250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[525] avg_epoch_loss=1.020747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=525 train loss <loss>=0.8518021941184998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [525]#011Speed: 1241.33 samples/sec#011loss=0.851802\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[530] avg_epoch_loss=1.018769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=530 train loss <loss>=0.8106126189231873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [530]#011Speed: 843.76 samples/sec#011loss=0.810613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch[535] avg_epoch_loss=1.017507\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=535 train loss <loss>=0.8834601163864135\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:25 INFO 140281140962944] Epoch[14] Batch [535]#011Speed: 1339.23 samples/sec#011loss=0.883460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[540] avg_epoch_loss=1.016157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=540 train loss <loss>=0.8714744687080384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [540]#011Speed: 849.08 samples/sec#011loss=0.871474\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[545] avg_epoch_loss=1.018605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=545 train loss <loss>=1.2834646582603455\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [545]#011Speed: 1334.85 samples/sec#011loss=1.283465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[550] avg_epoch_loss=1.016733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=550 train loss <loss>=0.8123136639595032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [550]#011Speed: 924.86 samples/sec#011loss=0.812314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch[555] avg_epoch_loss=1.015206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, batch=555 train loss <loss>=0.8469874858856201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[14] Batch [555]#011Speed: 1341.60 samples/sec#011loss=0.846987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] processed a total of 17844 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717488.9459221, \"EndTime\": 1620717506.6009102, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17654.924869537354, \"count\": 1, \"min\": 17654.924869537354, \"max\": 17654.924869537354}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=1010.6982916706178 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.0146141645087992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_efa04013-0390-4159-9158-7fd4867ee79b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717506.6009912, \"EndTime\": 1620717506.6114419, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.536981582641602, \"count\": 1, \"min\": 9.536981582641602, \"max\": 9.536981582641602}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[15] Batch[0] avg_epoch_loss=0.720649\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=0.7206494808197021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[15] Batch[5] avg_epoch_loss=0.807433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=0.8074333667755127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:26 INFO 140281140962944] Epoch[15] Batch [5]#011Speed: 1349.20 samples/sec#011loss=0.807433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[10] avg_epoch_loss=0.779746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=0.7465214490890503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [10]#011Speed: 847.97 samples/sec#011loss=0.746521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[15] avg_epoch_loss=0.784284\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=0.7942657709121704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [15]#011Speed: 1333.55 samples/sec#011loss=0.794266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[20] avg_epoch_loss=0.779344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=0.7635370254516601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [20]#011Speed: 868.13 samples/sec#011loss=0.763537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[25] avg_epoch_loss=0.783614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=0.8015475869178772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [25]#011Speed: 1269.58 samples/sec#011loss=0.801548\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[30] avg_epoch_loss=0.795628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=0.8581024765968323\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [30]#011Speed: 808.01 samples/sec#011loss=0.858102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[35] avg_epoch_loss=0.809234\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=0.8935905337333679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [35]#011Speed: 1265.03 samples/sec#011loss=0.893591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch[40] avg_epoch_loss=0.809518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=0.811559545993805\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:27 INFO 140281140962944] Epoch[15] Batch [40]#011Speed: 823.18 samples/sec#011loss=0.811560\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[45] avg_epoch_loss=0.825362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=0.955282986164093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [45]#011Speed: 1307.52 samples/sec#011loss=0.955283\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[50] avg_epoch_loss=0.833527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=0.9086520195007324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [50]#011Speed: 861.40 samples/sec#011loss=0.908652\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[55] avg_epoch_loss=0.858478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=1.1129776000976563\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [55]#011Speed: 1332.29 samples/sec#011loss=1.112978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[60] avg_epoch_loss=0.869781\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=0.9963725447654724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [60]#011Speed: 850.41 samples/sec#011loss=0.996373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[65] avg_epoch_loss=0.873888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=0.9239985466003418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [65]#011Speed: 1223.95 samples/sec#011loss=0.923999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch[70] avg_epoch_loss=0.885316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=1.0361570239067077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:28 INFO 140281140962944] Epoch[15] Batch [70]#011Speed: 850.30 samples/sec#011loss=1.036157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[75] avg_epoch_loss=0.886375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=0.9014223337173461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [75]#011Speed: 1313.47 samples/sec#011loss=0.901422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[80] avg_epoch_loss=0.887341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=0.9020158290863037\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [80]#011Speed: 855.33 samples/sec#011loss=0.902016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[85] avg_epoch_loss=0.890918\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=0.9488727807998657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [85]#011Speed: 1323.53 samples/sec#011loss=0.948873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[90] avg_epoch_loss=0.911734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=1.2697597861289978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [90]#011Speed: 844.65 samples/sec#011loss=1.269760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[95] avg_epoch_loss=1.018357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=2.958890986442566\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [95]#011Speed: 1199.59 samples/sec#011loss=2.958891\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[100] avg_epoch_loss=1.018411\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=1.0194604754447938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [100]#011Speed: 845.71 samples/sec#011loss=1.019460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch[105] avg_epoch_loss=1.028742\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=1.2374220371246338\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:29 INFO 140281140962944] Epoch[15] Batch [105]#011Speed: 1339.42 samples/sec#011loss=1.237422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[110] avg_epoch_loss=1.032579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=1.113917350769043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [110]#011Speed: 855.37 samples/sec#011loss=1.113917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[115] avg_epoch_loss=1.037499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=1.1467220544815064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [115]#011Speed: 1333.73 samples/sec#011loss=1.146722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[120] avg_epoch_loss=1.037459\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=1.036534583568573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [120]#011Speed: 826.13 samples/sec#011loss=1.036535\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[125] avg_epoch_loss=1.034007\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=0.9504850149154663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [125]#011Speed: 1291.34 samples/sec#011loss=0.950485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[130] avg_epoch_loss=1.028296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=0.8843762874603271\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [130]#011Speed: 795.02 samples/sec#011loss=0.884376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch[135] avg_epoch_loss=1.021737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=0.8498705625534058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:30 INFO 140281140962944] Epoch[15] Batch [135]#011Speed: 1336.97 samples/sec#011loss=0.849871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[140] avg_epoch_loss=1.017866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=0.9125963091850281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [140]#011Speed: 830.83 samples/sec#011loss=0.912596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[145] avg_epoch_loss=1.013539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=0.891512930393219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [145]#011Speed: 1309.10 samples/sec#011loss=0.891513\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[150] avg_epoch_loss=1.010732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=0.9287662982940674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [150]#011Speed: 844.83 samples/sec#011loss=0.928766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[155] avg_epoch_loss=1.004962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=0.8306949019432068\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [155]#011Speed: 1258.75 samples/sec#011loss=0.830695\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[160] avg_epoch_loss=0.999428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=0.8267774105072021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [160]#011Speed: 788.43 samples/sec#011loss=0.826777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch[165] avg_epoch_loss=0.994081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=0.8218993425369263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:31 INFO 140281140962944] Epoch[15] Batch [165]#011Speed: 1328.56 samples/sec#011loss=0.821899\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[170] avg_epoch_loss=0.991038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=0.8900110006332398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [170]#011Speed: 825.55 samples/sec#011loss=0.890011\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[175] avg_epoch_loss=0.990392\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=0.9683093190193176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [175]#011Speed: 1351.92 samples/sec#011loss=0.968309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[180] avg_epoch_loss=0.985132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=0.7999931335449219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [180]#011Speed: 844.89 samples/sec#011loss=0.799993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[185] avg_epoch_loss=0.981928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=0.8659086942672729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [185]#011Speed: 1208.77 samples/sec#011loss=0.865909\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[190] avg_epoch_loss=0.990711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=1.3174444317817688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [190]#011Speed: 788.14 samples/sec#011loss=1.317444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch[195] avg_epoch_loss=1.002556\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=1.4550279021263122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:32 INFO 140281140962944] Epoch[15] Batch [195]#011Speed: 1244.68 samples/sec#011loss=1.455028\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[200] avg_epoch_loss=1.007422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=1.1981943488121032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [200]#011Speed: 818.43 samples/sec#011loss=1.198194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[205] avg_epoch_loss=1.016067\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=1.363605296611786\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [205]#011Speed: 1323.01 samples/sec#011loss=1.363605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[210] avg_epoch_loss=1.015749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=1.0026421308517457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [210]#011Speed: 844.85 samples/sec#011loss=1.002642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[215] avg_epoch_loss=1.016202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=1.0353041410446167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [215]#011Speed: 1344.16 samples/sec#011loss=1.035304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[220] avg_epoch_loss=1.015321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=0.9772464752197265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [220]#011Speed: 843.85 samples/sec#011loss=0.977246\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[225] avg_epoch_loss=1.014464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=0.9765893697738648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [225]#011Speed: 1231.37 samples/sec#011loss=0.976589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch[230] avg_epoch_loss=1.012328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=0.9158032774925232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:33 INFO 140281140962944] Epoch[15] Batch [230]#011Speed: 838.54 samples/sec#011loss=0.915803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[235] avg_epoch_loss=1.013857\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=1.084465205669403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [235]#011Speed: 1298.09 samples/sec#011loss=1.084465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[240] avg_epoch_loss=1.009717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=0.814341378211975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [240]#011Speed: 835.26 samples/sec#011loss=0.814341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[245] avg_epoch_loss=1.007170\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=0.8844188570976257\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [245]#011Speed: 1324.78 samples/sec#011loss=0.884419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[250] avg_epoch_loss=1.003429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=0.819340980052948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [250]#011Speed: 811.35 samples/sec#011loss=0.819341\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[255] avg_epoch_loss=0.999127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=0.7831808686256408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [255]#011Speed: 1241.88 samples/sec#011loss=0.783181\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch[260] avg_epoch_loss=0.997240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=0.900625205039978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:34 INFO 140281140962944] Epoch[15] Batch [260]#011Speed: 828.91 samples/sec#011loss=0.900625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[265] avg_epoch_loss=1.043102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=3.4371030569076537\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [265]#011Speed: 1206.09 samples/sec#011loss=3.437103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[270] avg_epoch_loss=1.045855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=270 train loss <loss>=1.1923001766204835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [270]#011Speed: 845.43 samples/sec#011loss=1.192300\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[275] avg_epoch_loss=1.046858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=275 train loss <loss>=1.1012169599533081\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [275]#011Speed: 1322.00 samples/sec#011loss=1.101217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[280] avg_epoch_loss=1.048057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=280 train loss <loss>=1.1142258167266845\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [280]#011Speed: 825.82 samples/sec#011loss=1.114226\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[285] avg_epoch_loss=1.049106\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=285 train loss <loss>=1.1081042170524598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [285]#011Speed: 1333.35 samples/sec#011loss=1.108104\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch[290] avg_epoch_loss=1.049906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=290 train loss <loss>=1.0956426858901978\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:35 INFO 140281140962944] Epoch[15] Batch [290]#011Speed: 795.18 samples/sec#011loss=1.095643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[295] avg_epoch_loss=1.051016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=295 train loss <loss>=1.1156229019165038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [295]#011Speed: 1326.44 samples/sec#011loss=1.115623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[300] avg_epoch_loss=1.049784\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=300 train loss <loss>=0.9768514752388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [300]#011Speed: 846.16 samples/sec#011loss=0.976851\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[305] avg_epoch_loss=1.048720\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=305 train loss <loss>=0.9846695542335511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [305]#011Speed: 1306.41 samples/sec#011loss=0.984670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[310] avg_epoch_loss=1.045515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=310 train loss <loss>=0.8493778944015503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [310]#011Speed: 839.62 samples/sec#011loss=0.849378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[315] avg_epoch_loss=1.043172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=315 train loss <loss>=0.8974056720733643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [315]#011Speed: 1290.10 samples/sec#011loss=0.897406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[320] avg_epoch_loss=1.041935\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=320 train loss <loss>=0.9637462377548218\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [320]#011Speed: 784.04 samples/sec#011loss=0.963746\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch[325] avg_epoch_loss=1.042760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=325 train loss <loss>=1.0957828640937806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:36 INFO 140281140962944] Epoch[15] Batch [325]#011Speed: 1307.58 samples/sec#011loss=1.095783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[330] avg_epoch_loss=1.041310\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=330 train loss <loss>=0.9467233419418335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [330]#011Speed: 821.10 samples/sec#011loss=0.946723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[335] avg_epoch_loss=1.037486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=335 train loss <loss>=0.7843524217605591\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [335]#011Speed: 1325.69 samples/sec#011loss=0.784352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[340] avg_epoch_loss=1.035000\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=340 train loss <loss>=0.8679542899131775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [340]#011Speed: 830.97 samples/sec#011loss=0.867954\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[345] avg_epoch_loss=1.031917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=345 train loss <loss>=0.8216722846031189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [345]#011Speed: 1290.07 samples/sec#011loss=0.821672\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[350] avg_epoch_loss=1.028855\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=350 train loss <loss>=0.8169057726860046\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [350]#011Speed: 764.67 samples/sec#011loss=0.816906\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch[355] avg_epoch_loss=1.025231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=355 train loss <loss>=0.7708424091339111\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:37 INFO 140281140962944] Epoch[15] Batch [355]#011Speed: 1328.69 samples/sec#011loss=0.770842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[360] avg_epoch_loss=1.024476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=360 train loss <loss>=0.9707503914833069\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [360]#011Speed: 837.75 samples/sec#011loss=0.970750\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[365] avg_epoch_loss=1.026163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=365 train loss <loss>=1.1479207277297974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [365]#011Speed: 1330.39 samples/sec#011loss=1.147921\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[370] avg_epoch_loss=1.026976\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=370 train loss <loss>=1.0864944577217102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [370]#011Speed: 866.17 samples/sec#011loss=1.086494\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[375] avg_epoch_loss=1.028103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=375 train loss <loss>=1.1117249965667724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [375]#011Speed: 1280.69 samples/sec#011loss=1.111725\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[380] avg_epoch_loss=1.024975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=380 train loss <loss>=0.7897954821586609\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [380]#011Speed: 850.83 samples/sec#011loss=0.789795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch[385] avg_epoch_loss=1.022435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=385 train loss <loss>=0.8288923501968384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:38 INFO 140281140962944] Epoch[15] Batch [385]#011Speed: 1211.06 samples/sec#011loss=0.828892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[390] avg_epoch_loss=1.019764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=390 train loss <loss>=0.8135006785392761\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [390]#011Speed: 837.30 samples/sec#011loss=0.813501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[395] avg_epoch_loss=1.017049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=395 train loss <loss>=0.8047762155532837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [395]#011Speed: 1350.33 samples/sec#011loss=0.804776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[400] avg_epoch_loss=1.015044\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=400 train loss <loss>=0.8562326550483703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [400]#011Speed: 860.52 samples/sec#011loss=0.856233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[405] avg_epoch_loss=1.013485\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=405 train loss <loss>=0.8884349465370178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [405]#011Speed: 1127.88 samples/sec#011loss=0.888435\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[410] avg_epoch_loss=1.023079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=410 train loss <loss>=1.8021512269973754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [410]#011Speed: 832.93 samples/sec#011loss=1.802151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch[415] avg_epoch_loss=1.031386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=415 train loss <loss>=1.714168906211853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:39 INFO 140281140962944] Epoch[15] Batch [415]#011Speed: 1230.94 samples/sec#011loss=1.714169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[420] avg_epoch_loss=1.031958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=420 train loss <loss>=1.079577875137329\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [420]#011Speed: 822.71 samples/sec#011loss=1.079578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[425] avg_epoch_loss=1.031382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=425 train loss <loss>=0.9828595757484436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [425]#011Speed: 1330.78 samples/sec#011loss=0.982860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[430] avg_epoch_loss=1.033090\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=430 train loss <loss>=1.1786563873291016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [430]#011Speed: 844.52 samples/sec#011loss=1.178656\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[435] avg_epoch_loss=1.032601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=435 train loss <loss>=0.9904015183448791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [435]#011Speed: 1343.42 samples/sec#011loss=0.990402\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[440] avg_epoch_loss=1.031674\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=440 train loss <loss>=0.9509155869483947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [440]#011Speed: 751.43 samples/sec#011loss=0.950916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[445] avg_epoch_loss=1.030177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=445 train loss <loss>=0.8980650424957275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [445]#011Speed: 1363.17 samples/sec#011loss=0.898065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch[450] avg_epoch_loss=1.030922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=450 train loss <loss>=1.0973716974258423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:40 INFO 140281140962944] Epoch[15] Batch [450]#011Speed: 780.92 samples/sec#011loss=1.097372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[455] avg_epoch_loss=1.030192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=455 train loss <loss>=0.9643647313117981\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [455]#011Speed: 1361.86 samples/sec#011loss=0.964365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[460] avg_epoch_loss=1.030160\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=460 train loss <loss>=1.0272817254066466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [460]#011Speed: 868.95 samples/sec#011loss=1.027282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[465] avg_epoch_loss=1.027512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=465 train loss <loss>=0.7833279848098755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [465]#011Speed: 1368.73 samples/sec#011loss=0.783328\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[470] avg_epoch_loss=1.024939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=470 train loss <loss>=0.7851339340209961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [470]#011Speed: 831.33 samples/sec#011loss=0.785134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[475] avg_epoch_loss=1.041562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=475 train loss <loss>=2.607511913776398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [475]#011Speed: 1356.61 samples/sec#011loss=2.607512\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch[480] avg_epoch_loss=1.041288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=480 train loss <loss>=1.0152026891708374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:41 INFO 140281140962944] Epoch[15] Batch [480]#011Speed: 798.64 samples/sec#011loss=1.015203\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[485] avg_epoch_loss=1.041204\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=485 train loss <loss>=1.033070480823517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [485]#011Speed: 1344.18 samples/sec#011loss=1.033070\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[490] avg_epoch_loss=1.041221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=490 train loss <loss>=1.0429129362106324\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [490]#011Speed: 858.91 samples/sec#011loss=1.042913\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[495] avg_epoch_loss=1.039999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=495 train loss <loss>=0.9199373960494995\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [495]#011Speed: 1360.95 samples/sec#011loss=0.919937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[500] avg_epoch_loss=1.038743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=500 train loss <loss>=0.9141768097877503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [500]#011Speed: 851.02 samples/sec#011loss=0.914177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[505] avg_epoch_loss=1.037409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=505 train loss <loss>=0.9037317156791687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [505]#011Speed: 1322.62 samples/sec#011loss=0.903732\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[510] avg_epoch_loss=1.037071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=510 train loss <loss>=1.00287606716156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [510]#011Speed: 838.38 samples/sec#011loss=1.002876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch[515] avg_epoch_loss=1.035256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=515 train loss <loss>=0.8497212052345275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:42 INFO 140281140962944] Epoch[15] Batch [515]#011Speed: 1267.93 samples/sec#011loss=0.849721\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[520] avg_epoch_loss=1.034359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=520 train loss <loss>=0.9418418526649475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [520]#011Speed: 853.12 samples/sec#011loss=0.941842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[525] avg_epoch_loss=1.032452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=525 train loss <loss>=0.8337154269218445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [525]#011Speed: 1357.95 samples/sec#011loss=0.833715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[530] avg_epoch_loss=1.031193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=530 train loss <loss>=0.8987293481826782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [530]#011Speed: 864.39 samples/sec#011loss=0.898729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[535] avg_epoch_loss=1.029541\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=535 train loss <loss>=0.8541597247123718\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [535]#011Speed: 1359.31 samples/sec#011loss=0.854160\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[540] avg_epoch_loss=1.028603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=540 train loss <loss>=0.9279718160629272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [540]#011Speed: 872.16 samples/sec#011loss=0.927972\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch[545] avg_epoch_loss=1.026008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=545 train loss <loss>=0.7452279567718506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:43 INFO 140281140962944] Epoch[15] Batch [545]#011Speed: 1314.67 samples/sec#011loss=0.745228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[15] Batch[550] avg_epoch_loss=1.024265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, batch=550 train loss <loss>=0.8339375257492065\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[15] Batch [550]#011Speed: 1172.17 samples/sec#011loss=0.833938\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] processed a total of 17639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717506.6115127, \"EndTime\": 1620717524.0361261, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17424.465894699097, \"count\": 1, \"min\": 17424.465894699097, \"max\": 17424.465894699097}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=1012.3052392909136 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.0234829178754834\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[0] avg_epoch_loss=0.797047\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=0.7970466017723083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[5] avg_epoch_loss=0.932989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=0.9329885542392731\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [5]#011Speed: 1346.51 samples/sec#011loss=0.932989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[10] avg_epoch_loss=0.899190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=0.8586321234703064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [10]#011Speed: 851.44 samples/sec#011loss=0.858632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[15] avg_epoch_loss=0.904999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=0.9177780151367188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [15]#011Speed: 1361.50 samples/sec#011loss=0.917778\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[20] avg_epoch_loss=0.949628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=1.092440402507782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [20]#011Speed: 828.82 samples/sec#011loss=1.092440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch[25] avg_epoch_loss=0.995188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=1.1865386486053466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:44 INFO 140281140962944] Epoch[16] Batch [25]#011Speed: 1364.13 samples/sec#011loss=1.186539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[30] avg_epoch_loss=0.995419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=0.9966210126876831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [30]#011Speed: 806.44 samples/sec#011loss=0.996621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[35] avg_epoch_loss=0.985824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=0.9263355493545532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [35]#011Speed: 1342.99 samples/sec#011loss=0.926336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[40] avg_epoch_loss=0.984475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=0.9747651576995849\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [40]#011Speed: 852.07 samples/sec#011loss=0.974765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[45] avg_epoch_loss=0.974666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=0.8942323684692383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [45]#011Speed: 1354.87 samples/sec#011loss=0.894232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[50] avg_epoch_loss=0.964345\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=0.8693933486938477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [50]#011Speed: 836.48 samples/sec#011loss=0.869393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch[55] avg_epoch_loss=0.960321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=0.9192746758460999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:45 INFO 140281140962944] Epoch[16] Batch [55]#011Speed: 1342.91 samples/sec#011loss=0.919275\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[60] avg_epoch_loss=0.949354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=0.8265271425247193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [60]#011Speed: 764.43 samples/sec#011loss=0.826527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[65] avg_epoch_loss=0.947710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=0.9276430010795593\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [65]#011Speed: 1364.66 samples/sec#011loss=0.927643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[70] avg_epoch_loss=0.940677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=0.8478440761566162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [70]#011Speed: 870.33 samples/sec#011loss=0.847844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[75] avg_epoch_loss=0.932963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=0.8234192252159118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [75]#011Speed: 1371.30 samples/sec#011loss=0.823419\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[80] avg_epoch_loss=0.927387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=0.8426368713378907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [80]#011Speed: 852.37 samples/sec#011loss=0.842637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[85] avg_epoch_loss=0.919454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=0.7909366250038147\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [85]#011Speed: 1316.39 samples/sec#011loss=0.790937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch[90] avg_epoch_loss=0.913809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=0.8167156100273132\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:46 INFO 140281140962944] Epoch[16] Batch [90]#011Speed: 787.58 samples/sec#011loss=0.816716\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[95] avg_epoch_loss=1.026977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=3.086634600162506\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [95]#011Speed: 1335.63 samples/sec#011loss=3.086635\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[100] avg_epoch_loss=1.021959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=0.9256123661994934\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [100]#011Speed: 858.26 samples/sec#011loss=0.925612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[105] avg_epoch_loss=1.022041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=1.0237072467803956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [105]#011Speed: 1266.17 samples/sec#011loss=1.023707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[110] avg_epoch_loss=1.019879\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=0.9740318059921265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [110]#011Speed: 569.84 samples/sec#011loss=0.974032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch[115] avg_epoch_loss=1.019570\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=1.0127216577529907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:47 INFO 140281140962944] Epoch[16] Batch [115]#011Speed: 883.05 samples/sec#011loss=1.012722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[120] avg_epoch_loss=1.014683\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=0.9012968063354492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [120]#011Speed: 550.18 samples/sec#011loss=0.901297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[125] avg_epoch_loss=1.008154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=0.850162148475647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [125]#011Speed: 1327.62 samples/sec#011loss=0.850162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[130] avg_epoch_loss=1.003551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=0.8875622391700745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [130]#011Speed: 858.93 samples/sec#011loss=0.887562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[135] avg_epoch_loss=1.007901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=1.1218505501747131\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [135]#011Speed: 1329.63 samples/sec#011loss=1.121851\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[140] avg_epoch_loss=1.003183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=0.8748589992523194\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [140]#011Speed: 857.24 samples/sec#011loss=0.874859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch[145] avg_epoch_loss=0.998109\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=0.8550351738929749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:48 INFO 140281140962944] Epoch[16] Batch [145]#011Speed: 1342.57 samples/sec#011loss=0.855035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[150] avg_epoch_loss=0.995596\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=0.9222073316574096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [150]#011Speed: 757.98 samples/sec#011loss=0.922207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[155] avg_epoch_loss=0.990062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=0.8229416489601136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [155]#011Speed: 1344.03 samples/sec#011loss=0.822942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[160] avg_epoch_loss=0.983308\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=0.7725776553153991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [160]#011Speed: 598.30 samples/sec#011loss=0.772578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[165] avg_epoch_loss=1.002399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=1.617134404182434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [165]#011Speed: 1223.64 samples/sec#011loss=1.617134\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[170] avg_epoch_loss=0.999576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=0.905839717388153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [170]#011Speed: 849.21 samples/sec#011loss=0.905840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch[175] avg_epoch_loss=0.997685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=0.9330172777175904\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:49 INFO 140281140962944] Epoch[16] Batch [175]#011Speed: 1354.31 samples/sec#011loss=0.933017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[180] avg_epoch_loss=0.995650\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=0.9240345120429992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [180]#011Speed: 762.80 samples/sec#011loss=0.924035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[185] avg_epoch_loss=0.994436\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=0.9504722952842712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [185]#011Speed: 1369.74 samples/sec#011loss=0.950472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[190] avg_epoch_loss=0.992382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=0.9159832119941711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [190]#011Speed: 862.08 samples/sec#011loss=0.915983\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[195] avg_epoch_loss=0.991518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=0.9585051774978638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [195]#011Speed: 1355.83 samples/sec#011loss=0.958505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[200] avg_epoch_loss=1.000027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=1.3335822701454163\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [200]#011Speed: 813.02 samples/sec#011loss=1.333582\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch[205] avg_epoch_loss=1.004447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=1.1821102738380431\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:50 INFO 140281140962944] Epoch[16] Batch [205]#011Speed: 1301.72 samples/sec#011loss=1.182110\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[210] avg_epoch_loss=1.005729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=1.0585617065429687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [210]#011Speed: 765.35 samples/sec#011loss=1.058562\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[215] avg_epoch_loss=1.004286\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=0.9434008598327637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [215]#011Speed: 1247.64 samples/sec#011loss=0.943401\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[220] avg_epoch_loss=1.002815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=0.9392503142356873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [220]#011Speed: 838.19 samples/sec#011loss=0.939250\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[225] avg_epoch_loss=1.000601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=0.9027633190155029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [225]#011Speed: 1325.88 samples/sec#011loss=0.902763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[230] avg_epoch_loss=0.996587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=0.8151556968688964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [230]#011Speed: 862.41 samples/sec#011loss=0.815156\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[235] avg_epoch_loss=0.993569\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=0.8541390538215637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [235]#011Speed: 1309.01 samples/sec#011loss=0.854139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch[240] avg_epoch_loss=0.988551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=0.7516795754432678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:51 INFO 140281140962944] Epoch[16] Batch [240]#011Speed: 847.08 samples/sec#011loss=0.751680\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[245] avg_epoch_loss=0.984492\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=0.7888745188713073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [245]#011Speed: 1249.83 samples/sec#011loss=0.788875\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[250] avg_epoch_loss=0.983498\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=0.9345612049102783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [250]#011Speed: 845.87 samples/sec#011loss=0.934561\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[255] avg_epoch_loss=0.985207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=1.071018648147583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [255]#011Speed: 1375.13 samples/sec#011loss=1.071019\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[260] avg_epoch_loss=0.988558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=1.1601007580757141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [260]#011Speed: 864.38 samples/sec#011loss=1.160101\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[265] avg_epoch_loss=0.989707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=1.0497101068496704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [265]#011Speed: 1359.51 samples/sec#011loss=1.049710\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch[270] avg_epoch_loss=0.991941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=270 train loss <loss>=1.1108073234558105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:52 INFO 140281140962944] Epoch[16] Batch [270]#011Speed: 844.02 samples/sec#011loss=1.110807\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[275] avg_epoch_loss=0.993282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=275 train loss <loss>=1.0659358859062196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [275]#011Speed: 1258.56 samples/sec#011loss=1.065936\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[280] avg_epoch_loss=0.991039\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=280 train loss <loss>=0.8672096014022828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [280]#011Speed: 801.64 samples/sec#011loss=0.867210\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[285] avg_epoch_loss=0.988874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=285 train loss <loss>=0.8672012209892273\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [285]#011Speed: 1380.24 samples/sec#011loss=0.867201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[290] avg_epoch_loss=0.986615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=290 train loss <loss>=0.8574398398399353\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [290]#011Speed: 869.50 samples/sec#011loss=0.857440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[295] avg_epoch_loss=0.983982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=295 train loss <loss>=0.8307448863983155\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [295]#011Speed: 1284.14 samples/sec#011loss=0.830745\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[300] avg_epoch_loss=0.983121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=300 train loss <loss>=0.9321542501449585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [300]#011Speed: 839.87 samples/sec#011loss=0.932154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch[305] avg_epoch_loss=0.979280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=305 train loss <loss>=0.7480172872543335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:53 INFO 140281140962944] Epoch[16] Batch [305]#011Speed: 1290.01 samples/sec#011loss=0.748017\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[310] avg_epoch_loss=0.976961\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=310 train loss <loss>=0.8350268483161927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [310]#011Speed: 772.30 samples/sec#011loss=0.835027\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[315] avg_epoch_loss=0.974528\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=315 train loss <loss>=0.8232123851776123\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [315]#011Speed: 1330.13 samples/sec#011loss=0.823212\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[320] avg_epoch_loss=0.974117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=320 train loss <loss>=0.9481567978858948\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [320]#011Speed: 849.05 samples/sec#011loss=0.948157\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[325] avg_epoch_loss=0.970991\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=325 train loss <loss>=0.7703197240829468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [325]#011Speed: 842.44 samples/sec#011loss=0.770320\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[330] avg_epoch_loss=0.967387\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=330 train loss <loss>=0.7323462247848511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [330]#011Speed: 859.50 samples/sec#011loss=0.732346\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch[335] avg_epoch_loss=0.963803\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=335 train loss <loss>=0.7265791058540344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:54 INFO 140281140962944] Epoch[16] Batch [335]#011Speed: 1364.28 samples/sec#011loss=0.726579\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[340] avg_epoch_loss=0.961096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=340 train loss <loss>=0.7791828870773315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [340]#011Speed: 803.46 samples/sec#011loss=0.779183\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[345] avg_epoch_loss=0.957572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=345 train loss <loss>=0.7172426342964172\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [345]#011Speed: 1336.58 samples/sec#011loss=0.717243\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[350] avg_epoch_loss=0.956066\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=350 train loss <loss>=0.8518641710281372\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [350]#011Speed: 857.62 samples/sec#011loss=0.851864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[355] avg_epoch_loss=0.956153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=355 train loss <loss>=0.9622112035751342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [355]#011Speed: 1362.88 samples/sec#011loss=0.962211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[360] avg_epoch_loss=0.955191\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=360 train loss <loss>=0.8867545008659363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [360]#011Speed: 821.40 samples/sec#011loss=0.886755\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch[365] avg_epoch_loss=0.954989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=365 train loss <loss>=0.9403950929641723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:55 INFO 140281140962944] Epoch[16] Batch [365]#011Speed: 1325.34 samples/sec#011loss=0.940395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[370] avg_epoch_loss=0.951827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=370 train loss <loss>=0.7203702211380005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [370]#011Speed: 793.58 samples/sec#011loss=0.720370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[375] avg_epoch_loss=0.949265\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=375 train loss <loss>=0.7591666102409362\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [375]#011Speed: 1272.66 samples/sec#011loss=0.759167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[380] avg_epoch_loss=0.952240\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=380 train loss <loss>=1.1759530663490296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [380]#011Speed: 848.60 samples/sec#011loss=1.175953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[385] avg_epoch_loss=0.949452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=385 train loss <loss>=0.7370130062103272\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [385]#011Speed: 1353.65 samples/sec#011loss=0.737013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[390] avg_epoch_loss=0.947169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=390 train loss <loss>=0.770880663394928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [390]#011Speed: 864.55 samples/sec#011loss=0.770881\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch[395] avg_epoch_loss=0.946573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=395 train loss <loss>=0.8999713659286499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:56 INFO 140281140962944] Epoch[16] Batch [395]#011Speed: 1343.40 samples/sec#011loss=0.899971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[400] avg_epoch_loss=0.951201\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=400 train loss <loss>=1.317782747745514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [400]#011Speed: 855.60 samples/sec#011loss=1.317783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[405] avg_epoch_loss=0.950277\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=405 train loss <loss>=0.8761539340019227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [405]#011Speed: 1274.71 samples/sec#011loss=0.876154\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[410] avg_epoch_loss=0.948186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=410 train loss <loss>=0.7783427596092224\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [410]#011Speed: 850.99 samples/sec#011loss=0.778343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[415] avg_epoch_loss=0.947083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=415 train loss <loss>=0.8564838290214538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [415]#011Speed: 1375.14 samples/sec#011loss=0.856484\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[420] avg_epoch_loss=0.945877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=420 train loss <loss>=0.8455272197723389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [420]#011Speed: 859.43 samples/sec#011loss=0.845527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[425] avg_epoch_loss=0.944214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=425 train loss <loss>=0.8041784882545471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [425]#011Speed: 1366.12 samples/sec#011loss=0.804178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch[430] avg_epoch_loss=0.943059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=430 train loss <loss>=0.8446871638298035\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:57 INFO 140281140962944] Epoch[16] Batch [430]#011Speed: 871.23 samples/sec#011loss=0.844687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[435] avg_epoch_loss=0.941393\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=435 train loss <loss>=0.79771728515625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [435]#011Speed: 1281.99 samples/sec#011loss=0.797717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[440] avg_epoch_loss=0.941150\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=440 train loss <loss>=0.9199630737304687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [440]#011Speed: 758.79 samples/sec#011loss=0.919963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[445] avg_epoch_loss=0.941872\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=445 train loss <loss>=1.0055415630340576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [445]#011Speed: 1344.59 samples/sec#011loss=1.005542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[450] avg_epoch_loss=0.940699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=450 train loss <loss>=0.8360968232154846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [450]#011Speed: 860.81 samples/sec#011loss=0.836097\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[455] avg_epoch_loss=0.938836\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=455 train loss <loss>=0.7708266496658325\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [455]#011Speed: 1370.34 samples/sec#011loss=0.770827\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch[460] avg_epoch_loss=0.938237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=460 train loss <loss>=0.8836078643798828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:58 INFO 140281140962944] Epoch[16] Batch [460]#011Speed: 850.11 samples/sec#011loss=0.883608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[465] avg_epoch_loss=0.937771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=465 train loss <loss>=0.8948216915130616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [465]#011Speed: 1309.97 samples/sec#011loss=0.894822\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[470] avg_epoch_loss=0.953714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=470 train loss <loss>=2.4396013975143434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [470]#011Speed: 792.99 samples/sec#011loss=2.439601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[475] avg_epoch_loss=0.953772\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=475 train loss <loss>=0.9591955423355103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [475]#011Speed: 1339.21 samples/sec#011loss=0.959196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[480] avg_epoch_loss=0.953169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=480 train loss <loss>=0.8957954287528992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [480]#011Speed: 841.47 samples/sec#011loss=0.895795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[485] avg_epoch_loss=0.952434\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=485 train loss <loss>=0.8817296147346496\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [485]#011Speed: 878.60 samples/sec#011loss=0.881730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch[490] avg_epoch_loss=0.951629\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=490 train loss <loss>=0.8733074307441712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:18:59 INFO 140281140962944] Epoch[16] Batch [490]#011Speed: 774.97 samples/sec#011loss=0.873307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[495] avg_epoch_loss=0.950267\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=495 train loss <loss>=0.8165379405021668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [495]#011Speed: 1219.17 samples/sec#011loss=0.816538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[500] avg_epoch_loss=0.948944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=500 train loss <loss>=0.8177068829536438\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [500]#011Speed: 756.69 samples/sec#011loss=0.817707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[505] avg_epoch_loss=0.947478\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=505 train loss <loss>=0.8006160378456115\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [505]#011Speed: 1347.95 samples/sec#011loss=0.800616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[510] avg_epoch_loss=0.946821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=510 train loss <loss>=0.8803268671035767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [510]#011Speed: 859.99 samples/sec#011loss=0.880327\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[515] avg_epoch_loss=0.945394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=515 train loss <loss>=0.7995520234107971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [515]#011Speed: 1374.20 samples/sec#011loss=0.799552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch[520] avg_epoch_loss=0.944171\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=520 train loss <loss>=0.8179462909698486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:00 INFO 140281140962944] Epoch[16] Batch [520]#011Speed: 806.65 samples/sec#011loss=0.817946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[525] avg_epoch_loss=0.942941\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=525 train loss <loss>=0.814819598197937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [525]#011Speed: 1340.36 samples/sec#011loss=0.814820\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[530] avg_epoch_loss=0.942461\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=530 train loss <loss>=0.8919070601463318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [530]#011Speed: 495.93 samples/sec#011loss=0.891907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[535] avg_epoch_loss=0.941749\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=535 train loss <loss>=0.8661078214645386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [535]#011Speed: 772.59 samples/sec#011loss=0.866108\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[540] avg_epoch_loss=0.940192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=540 train loss <loss>=0.7732685565948486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [540]#011Speed: 620.65 samples/sec#011loss=0.773269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch[545] avg_epoch_loss=0.938964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, batch=545 train loss <loss>=0.8061271905899048\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Epoch[16] Batch [545]#011Speed: 1293.34 samples/sec#011loss=0.806127\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] processed a total of 17478 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717524.036199, \"EndTime\": 1620717541.970716, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17933.697938919067, \"count\": 1, \"min\": 17933.697938919067, \"max\": 17933.697938919067}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=974.579485683503 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] #quality_metric: host=algo-1, epoch=16, train loss <loss>=0.9385971584965149\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:01 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_0483872e-8207-4f5b-ac38-cd437d0f4609-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717541.9708645, \"EndTime\": 1620717541.9839125, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 12.181282043457031, \"count\": 1, \"min\": 12.181282043457031, \"max\": 12.181282043457031}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[0] avg_epoch_loss=0.698174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=0.6981738805770874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[5] avg_epoch_loss=0.716599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=0.7165986796220144\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch [5]#011Speed: 701.71 samples/sec#011loss=0.716599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[10] avg_epoch_loss=0.741193\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=0.7707068085670471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch [10]#011Speed: 484.41 samples/sec#011loss=0.770707\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch[15] avg_epoch_loss=0.815750\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=0.9797732114791871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:02 INFO 140281140962944] Epoch[17] Batch [15]#011Speed: 867.95 samples/sec#011loss=0.979773\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[20] avg_epoch_loss=0.835685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=0.8994791269302368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [20]#011Speed: 835.60 samples/sec#011loss=0.899479\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[25] avg_epoch_loss=0.849589\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=0.907983660697937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [25]#011Speed: 1300.06 samples/sec#011loss=0.907984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[30] avg_epoch_loss=0.849295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=0.8477661848068238\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [30]#011Speed: 663.07 samples/sec#011loss=0.847766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[35] avg_epoch_loss=0.846302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=0.8277504324913025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [35]#011Speed: 859.54 samples/sec#011loss=0.827750\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch[40] avg_epoch_loss=0.837106\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=0.7708899140357971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:03 INFO 140281140962944] Epoch[17] Batch [40]#011Speed: 476.51 samples/sec#011loss=0.770890\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch[45] avg_epoch_loss=0.832717\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=0.7967288970947266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch [45]#011Speed: 761.14 samples/sec#011loss=0.796729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch[50] avg_epoch_loss=0.836481\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=0.8711070656776428\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch [50]#011Speed: 463.77 samples/sec#011loss=0.871107\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch[55] avg_epoch_loss=0.839312\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=0.8681851863861084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:04 INFO 140281140962944] Epoch[17] Batch [55]#011Speed: 774.70 samples/sec#011loss=0.868185\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[60] avg_epoch_loss=0.845567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=0.9156229972839356\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [60]#011Speed: 367.19 samples/sec#011loss=0.915623\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[65] avg_epoch_loss=0.864724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=1.0984451413154601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [65]#011Speed: 733.30 samples/sec#011loss=1.098445\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[70] avg_epoch_loss=0.861989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=0.8258883714675903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [70]#011Speed: 499.93 samples/sec#011loss=0.825888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch[75] avg_epoch_loss=0.858248\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=0.8051182508468628\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:05 INFO 140281140962944] Epoch[17] Batch [75]#011Speed: 1306.48 samples/sec#011loss=0.805118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[80] avg_epoch_loss=0.859303\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=0.8753488063812256\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [80]#011Speed: 799.19 samples/sec#011loss=0.875349\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[85] avg_epoch_loss=0.861358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=0.8946413040161133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [85]#011Speed: 1361.35 samples/sec#011loss=0.894641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[90] avg_epoch_loss=0.889326\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=1.3703880667686463\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [90]#011Speed: 806.34 samples/sec#011loss=1.370388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[95] avg_epoch_loss=0.897481\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=1.0458871841430664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [95]#011Speed: 1332.99 samples/sec#011loss=1.045887\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[100] avg_epoch_loss=0.904449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=1.0382413148880005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [100]#011Speed: 836.79 samples/sec#011loss=1.038241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[105] avg_epoch_loss=0.908477\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=0.9898460984230042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [105]#011Speed: 1322.30 samples/sec#011loss=0.989846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch[110] avg_epoch_loss=0.912517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=0.9981670618057251\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:06 INFO 140281140962944] Epoch[17] Batch [110]#011Speed: 830.88 samples/sec#011loss=0.998167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[115] avg_epoch_loss=0.910432\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=0.8641325950622558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [115]#011Speed: 1292.18 samples/sec#011loss=0.864133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[120] avg_epoch_loss=0.911688\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=0.9408371448516846\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [120]#011Speed: 843.77 samples/sec#011loss=0.940837\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[125] avg_epoch_loss=0.913359\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=0.9537972211837769\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [125]#011Speed: 1177.32 samples/sec#011loss=0.953797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[130] avg_epoch_loss=0.909625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=0.8155153632164002\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [130]#011Speed: 860.31 samples/sec#011loss=0.815515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[135] avg_epoch_loss=0.905049\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=0.7851668357849121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [135]#011Speed: 1363.32 samples/sec#011loss=0.785167\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch[140] avg_epoch_loss=0.902842\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=0.8428227066993713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:07 INFO 140281140962944] Epoch[17] Batch [140]#011Speed: 834.78 samples/sec#011loss=0.842823\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[145] avg_epoch_loss=0.902034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=0.8792268991470337\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [145]#011Speed: 1328.47 samples/sec#011loss=0.879227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[150] avg_epoch_loss=0.909021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=1.1130638718605042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [150]#011Speed: 797.91 samples/sec#011loss=1.113064\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[155] avg_epoch_loss=0.907016\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=0.8464402556419373\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [155]#011Speed: 1242.07 samples/sec#011loss=0.846440\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[160] avg_epoch_loss=0.908709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=0.9615324258804321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [160]#011Speed: 860.61 samples/sec#011loss=0.961532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[165] avg_epoch_loss=0.912124\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=1.0220843195915221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [165]#011Speed: 1355.12 samples/sec#011loss=1.022084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[170] avg_epoch_loss=0.911538\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=0.8920980453491211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [170]#011Speed: 850.84 samples/sec#011loss=0.892098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch[175] avg_epoch_loss=0.910162\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=0.8631047368049621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:08 INFO 140281140962944] Epoch[17] Batch [175]#011Speed: 1333.42 samples/sec#011loss=0.863105\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[180] avg_epoch_loss=0.911121\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=0.9448919892311096\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [180]#011Speed: 831.72 samples/sec#011loss=0.944892\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[185] avg_epoch_loss=0.914318\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=1.0300137162208558\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [185]#011Speed: 1316.56 samples/sec#011loss=1.030014\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[190] avg_epoch_loss=0.918196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=1.0624712228775024\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [190]#011Speed: 768.93 samples/sec#011loss=1.062471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[195] avg_epoch_loss=0.920637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=1.0138863563537597\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [195]#011Speed: 1349.98 samples/sec#011loss=1.013886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[200] avg_epoch_loss=0.921309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=0.9476434111595153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [200]#011Speed: 854.71 samples/sec#011loss=0.947643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch[205] avg_epoch_loss=0.927908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=1.1931878209114075\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:09 INFO 140281140962944] Epoch[17] Batch [205]#011Speed: 1361.73 samples/sec#011loss=1.193188\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[210] avg_epoch_loss=0.935585\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=1.2518767237663269\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [210]#011Speed: 622.86 samples/sec#011loss=1.251877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[215] avg_epoch_loss=0.936638\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=0.9810796499252319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [215]#011Speed: 1108.01 samples/sec#011loss=0.981080\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[220] avg_epoch_loss=0.936719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=0.9402111649513245\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [220]#011Speed: 792.14 samples/sec#011loss=0.940211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[225] avg_epoch_loss=0.936177\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=0.9122191786766052\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [225]#011Speed: 1372.23 samples/sec#011loss=0.912219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[230] avg_epoch_loss=0.935425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=0.9014635562896729\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [230]#011Speed: 843.75 samples/sec#011loss=0.901464\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch[235] avg_epoch_loss=0.933042\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=0.8229203701019288\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:10 INFO 140281140962944] Epoch[17] Batch [235]#011Speed: 1241.87 samples/sec#011loss=0.822920\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[240] avg_epoch_loss=0.930576\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=0.8141737461090088\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [240]#011Speed: 760.29 samples/sec#011loss=0.814174\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[245] avg_epoch_loss=0.929076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=0.8567833542823792\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [245]#011Speed: 1316.88 samples/sec#011loss=0.856783\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[250] avg_epoch_loss=0.927859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=0.8679955124855041\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [250]#011Speed: 797.44 samples/sec#011loss=0.867996\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[255] avg_epoch_loss=0.925241\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=0.7937901616096497\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [255]#011Speed: 1355.17 samples/sec#011loss=0.793790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[260] avg_epoch_loss=0.924571\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=0.890316641330719\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [260]#011Speed: 860.39 samples/sec#011loss=0.890317\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch[265] avg_epoch_loss=0.924765\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=0.9348661780357361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:11 INFO 140281140962944] Epoch[17] Batch [265]#011Speed: 1335.74 samples/sec#011loss=0.934866\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[270] avg_epoch_loss=0.934026\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=270 train loss <loss>=1.4267136454582214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [270]#011Speed: 844.77 samples/sec#011loss=1.426714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[275] avg_epoch_loss=0.932816\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=275 train loss <loss>=0.8672582745552063\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [275]#011Speed: 1341.44 samples/sec#011loss=0.867258\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[280] avg_epoch_loss=0.932142\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=280 train loss <loss>=0.8949015021324158\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [280]#011Speed: 815.32 samples/sec#011loss=0.894902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[285] avg_epoch_loss=0.931894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=285 train loss <loss>=0.9179856181144714\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [285]#011Speed: 1356.71 samples/sec#011loss=0.917986\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[290] avg_epoch_loss=0.931754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=290 train loss <loss>=0.9237013697624207\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [290]#011Speed: 843.02 samples/sec#011loss=0.923701\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch[295] avg_epoch_loss=0.930830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=295 train loss <loss>=0.877058470249176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:12 INFO 140281140962944] Epoch[17] Batch [295]#011Speed: 1358.79 samples/sec#011loss=0.877058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[300] avg_epoch_loss=0.928874\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=300 train loss <loss>=0.8131285309791565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [300]#011Speed: 859.36 samples/sec#011loss=0.813129\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[305] avg_epoch_loss=0.928858\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=305 train loss <loss>=0.9278526544570923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [305]#011Speed: 1327.19 samples/sec#011loss=0.927853\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[310] avg_epoch_loss=0.930741\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=310 train loss <loss>=1.0459880590438844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [310]#011Speed: 845.92 samples/sec#011loss=1.045988\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[315] avg_epoch_loss=0.931071\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=315 train loss <loss>=0.9516249775886536\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [315]#011Speed: 1252.29 samples/sec#011loss=0.951625\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[320] avg_epoch_loss=0.930074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=320 train loss <loss>=0.8670581936836242\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [320]#011Speed: 860.07 samples/sec#011loss=0.867058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[325] avg_epoch_loss=0.929708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=325 train loss <loss>=0.9061886429786682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [325]#011Speed: 1381.29 samples/sec#011loss=0.906189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch[330] avg_epoch_loss=0.928518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=330 train loss <loss>=0.8509313464164734\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:13 INFO 140281140962944] Epoch[17] Batch [330]#011Speed: 868.60 samples/sec#011loss=0.850931\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[335] avg_epoch_loss=0.926200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=335 train loss <loss>=0.7727714896202087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [335]#011Speed: 1321.39 samples/sec#011loss=0.772771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[340] avg_epoch_loss=0.924754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=340 train loss <loss>=0.8275933504104614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [340]#011Speed: 866.31 samples/sec#011loss=0.827593\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[345] avg_epoch_loss=0.921877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=345 train loss <loss>=0.7256419658660889\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [345]#011Speed: 1330.50 samples/sec#011loss=0.725642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[350] avg_epoch_loss=0.920268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=350 train loss <loss>=0.8088877916336059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [350]#011Speed: 791.73 samples/sec#011loss=0.808888\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[355] avg_epoch_loss=0.920748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=355 train loss <loss>=0.954459810256958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [355]#011Speed: 1170.72 samples/sec#011loss=0.954460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch[360] avg_epoch_loss=0.918886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=360 train loss <loss>=0.7863306164741516\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:14 INFO 140281140962944] Epoch[17] Batch [360]#011Speed: 834.09 samples/sec#011loss=0.786331\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[365] avg_epoch_loss=0.918412\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=365 train loss <loss>=0.8841532468795776\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [365]#011Speed: 1344.88 samples/sec#011loss=0.884153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[370] avg_epoch_loss=0.917519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=370 train loss <loss>=0.8522112488746643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [370]#011Speed: 848.35 samples/sec#011loss=0.852211\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[375] avg_epoch_loss=0.916766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=375 train loss <loss>=0.8608296632766723\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [375]#011Speed: 842.16 samples/sec#011loss=0.860830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[380] avg_epoch_loss=0.915885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=380 train loss <loss>=0.8496668815612793\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [380]#011Speed: 764.68 samples/sec#011loss=0.849667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[385] avg_epoch_loss=0.916280\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=385 train loss <loss>=0.9463539600372315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [385]#011Speed: 1365.53 samples/sec#011loss=0.946354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch[390] avg_epoch_loss=0.916586\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=390 train loss <loss>=0.940267825126648\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:15 INFO 140281140962944] Epoch[17] Batch [390]#011Speed: 809.24 samples/sec#011loss=0.940268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[395] avg_epoch_loss=0.916551\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=395 train loss <loss>=0.913791048526764\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [395]#011Speed: 1283.78 samples/sec#011loss=0.913791\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[400] avg_epoch_loss=0.915970\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=400 train loss <loss>=0.869981563091278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [400]#011Speed: 851.49 samples/sec#011loss=0.869982\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[405] avg_epoch_loss=0.915398\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=405 train loss <loss>=0.8694701194763184\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [405]#011Speed: 1354.24 samples/sec#011loss=0.869470\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[410] avg_epoch_loss=0.913985\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=410 train loss <loss>=0.7992368340492249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [410]#011Speed: 792.17 samples/sec#011loss=0.799237\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[415] avg_epoch_loss=0.913370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=415 train loss <loss>=0.8628151535987854\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [415]#011Speed: 1352.07 samples/sec#011loss=0.862815\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch[420] avg_epoch_loss=0.913704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=420 train loss <loss>=0.9415425658226013\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:16 INFO 140281140962944] Epoch[17] Batch [420]#011Speed: 841.20 samples/sec#011loss=0.941543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[425] avg_epoch_loss=0.915859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=425 train loss <loss>=1.0972620010375977\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [425]#011Speed: 1315.03 samples/sec#011loss=1.097262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[430] avg_epoch_loss=0.917005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=430 train loss <loss>=1.014686918258667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [430]#011Speed: 837.19 samples/sec#011loss=1.014687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[435] avg_epoch_loss=0.917613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=435 train loss <loss>=0.9700511693954468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [435]#011Speed: 1374.49 samples/sec#011loss=0.970051\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[440] avg_epoch_loss=0.917964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=440 train loss <loss>=0.9484986543655396\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [440]#011Speed: 876.59 samples/sec#011loss=0.948499\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[445] avg_epoch_loss=0.917543\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=445 train loss <loss>=0.8804224014282227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [445]#011Speed: 1222.59 samples/sec#011loss=0.880422\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[450] avg_epoch_loss=0.916547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=450 train loss <loss>=0.8277329325675964\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [450]#011Speed: 858.99 samples/sec#011loss=0.827733\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch[455] avg_epoch_loss=0.916452\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=455 train loss <loss>=0.9079173326492309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:17 INFO 140281140962944] Epoch[17] Batch [455]#011Speed: 1367.69 samples/sec#011loss=0.907917\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[460] avg_epoch_loss=0.915522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=460 train loss <loss>=0.8306192994117737\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [460]#011Speed: 783.44 samples/sec#011loss=0.830619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[465] avg_epoch_loss=0.914771\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=465 train loss <loss>=0.8455777168273926\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [465]#011Speed: 844.63 samples/sec#011loss=0.845578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[470] avg_epoch_loss=0.913634\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=470 train loss <loss>=0.8077025890350342\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [470]#011Speed: 515.14 samples/sec#011loss=0.807703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[475] avg_epoch_loss=0.912460\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=475 train loss <loss>=0.8018091559410095\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [475]#011Speed: 930.43 samples/sec#011loss=0.801809\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch[480] avg_epoch_loss=0.911651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=480 train loss <loss>=0.8346910595893859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:18 INFO 140281140962944] Epoch[17] Batch [480]#011Speed: 853.32 samples/sec#011loss=0.834691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[485] avg_epoch_loss=0.911599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=485 train loss <loss>=0.9065271139144897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [485]#011Speed: 1325.03 samples/sec#011loss=0.906527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[490] avg_epoch_loss=0.910074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=490 train loss <loss>=0.7618758678436279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [490]#011Speed: 825.54 samples/sec#011loss=0.761876\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[495] avg_epoch_loss=0.908963\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=495 train loss <loss>=0.7998523592948914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [495]#011Speed: 1349.59 samples/sec#011loss=0.799852\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[500] avg_epoch_loss=0.906726\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=500 train loss <loss>=0.6847767472267151\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [500]#011Speed: 804.38 samples/sec#011loss=0.684777\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[505] avg_epoch_loss=0.907410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=505 train loss <loss>=0.9760145783424378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [505]#011Speed: 1360.55 samples/sec#011loss=0.976015\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch[510] avg_epoch_loss=0.906406\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=510 train loss <loss>=0.8047980546951294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:19 INFO 140281140962944] Epoch[17] Batch [510]#011Speed: 864.22 samples/sec#011loss=0.804798\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[515] avg_epoch_loss=0.905166\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=515 train loss <loss>=0.7784466028213501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [515]#011Speed: 1329.68 samples/sec#011loss=0.778447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[520] avg_epoch_loss=0.903666\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=520 train loss <loss>=0.7488564610481262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [520]#011Speed: 867.83 samples/sec#011loss=0.748856\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[525] avg_epoch_loss=0.902266\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=525 train loss <loss>=0.7563891410827637\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [525]#011Speed: 1344.48 samples/sec#011loss=0.756389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[530] avg_epoch_loss=0.902915\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=530 train loss <loss>=0.9712138295173645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [530]#011Speed: 581.80 samples/sec#011loss=0.971214\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[535] avg_epoch_loss=0.902873\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=535 train loss <loss>=0.8983402371406555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [535]#011Speed: 1291.58 samples/sec#011loss=0.898340\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch[540] avg_epoch_loss=0.903198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=540 train loss <loss>=0.9381088018417358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:20 INFO 140281140962944] Epoch[17] Batch [540]#011Speed: 882.31 samples/sec#011loss=0.938109\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[17] Batch[545] avg_epoch_loss=0.901647\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, batch=545 train loss <loss>=0.7337901711463928\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[17] Batch [545]#011Speed: 1280.69 samples/sec#011loss=0.733790\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] processed a total of 17560 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717541.984576, \"EndTime\": 1620717561.138896, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 19154.24942970276, \"count\": 1, \"min\": 19154.24942970276, \"max\": 19154.24942970276}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=916.7629510355682 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=17, train loss <loss>=0.9012727438860687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/state_590c5e48-fc6d-4f88-b7b3-933a991aba04-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717561.1389625, \"EndTime\": 1620717561.1497493, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.945869445800781, \"count\": 1, \"min\": 9.945869445800781, \"max\": 9.945869445800781}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[0] avg_epoch_loss=0.696413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=0.6964132189750671\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[5] avg_epoch_loss=0.733663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=0.7336626946926117\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [5]#011Speed: 1337.98 samples/sec#011loss=0.733663\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[10] avg_epoch_loss=0.783371\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=0.8430205583572388\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [10]#011Speed: 849.02 samples/sec#011loss=0.843021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[15] avg_epoch_loss=0.829410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=0.9306958079338074\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [15]#011Speed: 1237.18 samples/sec#011loss=0.930696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[20] avg_epoch_loss=0.845190\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=0.8956859707832336\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [20]#011Speed: 855.40 samples/sec#011loss=0.895686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch[25] avg_epoch_loss=0.880098\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=1.0267120838165282\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:21 INFO 140281140962944] Epoch[18] Batch [25]#011Speed: 1321.57 samples/sec#011loss=1.026712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[30] avg_epoch_loss=0.871523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=0.826933228969574\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [30]#011Speed: 856.91 samples/sec#011loss=0.826933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[35] avg_epoch_loss=0.858347\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=0.7766569256782532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [35]#011Speed: 1365.12 samples/sec#011loss=0.776657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[40] avg_epoch_loss=0.861405\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=0.8834171414375305\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [40]#011Speed: 851.52 samples/sec#011loss=0.883417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[45] avg_epoch_loss=0.872077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=0.9595921635627747\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [45]#011Speed: 1355.13 samples/sec#011loss=0.959592\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[50] avg_epoch_loss=0.876712\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=0.9193525075912475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [50]#011Speed: 812.58 samples/sec#011loss=0.919353\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch[55] avg_epoch_loss=0.871213\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=0.8151259660720825\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:22 INFO 140281140962944] Epoch[18] Batch [55]#011Speed: 1366.65 samples/sec#011loss=0.815126\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[60] avg_epoch_loss=0.867519\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=0.826140820980072\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [60]#011Speed: 844.40 samples/sec#011loss=0.826141\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[65] avg_epoch_loss=0.867343\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=0.8652024149894715\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [65]#011Speed: 1378.85 samples/sec#011loss=0.865202\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[70] avg_epoch_loss=0.863833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=0.8175013661384583\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [70]#011Speed: 867.79 samples/sec#011loss=0.817501\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[75] avg_epoch_loss=0.853686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=0.7095940828323364\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [75]#011Speed: 1300.97 samples/sec#011loss=0.709594\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[80] avg_epoch_loss=0.857763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=0.9197299480438232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [80]#011Speed: 806.35 samples/sec#011loss=0.919730\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch[85] avg_epoch_loss=0.883667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=1.3033190965652466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:23 INFO 140281140962944] Epoch[18] Batch [85]#011Speed: 1168.52 samples/sec#011loss=1.303319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[90] avg_epoch_loss=0.897693\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=1.1389365553855897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [90]#011Speed: 856.96 samples/sec#011loss=1.138937\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[95] avg_epoch_loss=0.898736\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=0.9177112221717835\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [95]#011Speed: 1343.70 samples/sec#011loss=0.917711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[100] avg_epoch_loss=0.902232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=0.9693567872047424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [100]#011Speed: 869.50 samples/sec#011loss=0.969357\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[105] avg_epoch_loss=0.901902\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=0.8952333092689514\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [105]#011Speed: 1375.11 samples/sec#011loss=0.895233\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[110] avg_epoch_loss=0.901475\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=0.8924303412437439\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [110]#011Speed: 800.32 samples/sec#011loss=0.892430\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[115] avg_epoch_loss=0.898643\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=0.8357670307159424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [115]#011Speed: 1363.32 samples/sec#011loss=0.835767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch[120] avg_epoch_loss=0.895370\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=0.819440734386444\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:24 INFO 140281140962944] Epoch[18] Batch [120]#011Speed: 848.55 samples/sec#011loss=0.819441\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[125] avg_epoch_loss=0.894219\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=0.8663575291633606\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [125]#011Speed: 1354.76 samples/sec#011loss=0.866358\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[130] avg_epoch_loss=0.954368\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=2.470133376121521\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [130]#011Speed: 835.99 samples/sec#011loss=2.470133\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[135] avg_epoch_loss=0.952651\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=0.9076781511306763\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [135]#011Speed: 1327.52 samples/sec#011loss=0.907678\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[140] avg_epoch_loss=0.952326\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=0.9434652209281922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [140]#011Speed: 856.49 samples/sec#011loss=0.943465\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[145] avg_epoch_loss=0.965232\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=1.3292003989219665\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [145]#011Speed: 846.80 samples/sec#011loss=1.329200\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch[150] avg_epoch_loss=0.965927\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=0.986209261417389\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:25 INFO 140281140962944] Epoch[18] Batch [150]#011Speed: 794.56 samples/sec#011loss=0.986209\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[155] avg_epoch_loss=0.965880\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=0.9644572257995605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [155]#011Speed: 1311.99 samples/sec#011loss=0.964457\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[160] avg_epoch_loss=0.965313\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=0.9476322293281555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [160]#011Speed: 859.78 samples/sec#011loss=0.947632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[165] avg_epoch_loss=0.961573\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=0.8411430597305298\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [165]#011Speed: 1326.70 samples/sec#011loss=0.841143\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[170] avg_epoch_loss=0.956992\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=0.8049071669578552\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [170]#011Speed: 834.64 samples/sec#011loss=0.804907\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[175] avg_epoch_loss=0.951094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=0.7493607878684998\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [175]#011Speed: 1208.99 samples/sec#011loss=0.749361\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch[180] avg_epoch_loss=0.947722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=0.8290564179420471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:26 INFO 140281140962944] Epoch[18] Batch [180]#011Speed: 827.77 samples/sec#011loss=0.829056\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[185] avg_epoch_loss=0.946314\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=0.8953157901763916\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [185]#011Speed: 1271.76 samples/sec#011loss=0.895316\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[190] avg_epoch_loss=0.954374\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=1.2542272806167603\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [190]#011Speed: 863.19 samples/sec#011loss=1.254227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[195] avg_epoch_loss=0.966227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=1.4189932584762572\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [195]#011Speed: 1370.85 samples/sec#011loss=1.418993\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[200] avg_epoch_loss=0.967642\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=1.023138952255249\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [200]#011Speed: 862.05 samples/sec#011loss=1.023139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[205] avg_epoch_loss=0.964384\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=0.8334083914756775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [205]#011Speed: 1305.75 samples/sec#011loss=0.833408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[210] avg_epoch_loss=0.972077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=1.2889991879463196\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [210]#011Speed: 808.02 samples/sec#011loss=1.288999\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch[215] avg_epoch_loss=0.976085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=1.1452465891838073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:27 INFO 140281140962944] Epoch[18] Batch [215]#011Speed: 1360.53 samples/sec#011loss=1.145247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[220] avg_epoch_loss=0.974962\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=0.9264420628547668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [220]#011Speed: 863.75 samples/sec#011loss=0.926442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[225] avg_epoch_loss=0.972503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=0.8637954235076905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [225]#011Speed: 1366.01 samples/sec#011loss=0.863795\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[230] avg_epoch_loss=0.970739\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=0.8910120606422425\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [230]#011Speed: 851.71 samples/sec#011loss=0.891012\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[235] avg_epoch_loss=0.977821\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=1.3050029635429383\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [235]#011Speed: 1369.16 samples/sec#011loss=1.305003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[240] avg_epoch_loss=0.975679\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=0.8745837092399598\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [240]#011Speed: 818.72 samples/sec#011loss=0.874584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch[245] avg_epoch_loss=0.971524\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=0.7712680459022522\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:28 INFO 140281140962944] Epoch[18] Batch [245]#011Speed: 1209.58 samples/sec#011loss=0.771268\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch[250] avg_epoch_loss=0.966806\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=0.7346675038337708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch [250]#011Speed: 851.39 samples/sec#011loss=0.734668\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch[255] avg_epoch_loss=0.963974\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=0.8218137621879578\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:29 INFO 140281140962944] Epoch[18] Batch [255]#011Speed: 1357.97 samples/sec#011loss=0.821814\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[20] avg_epoch_loss=0.857079\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=0.8667746901512146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [20]#011Speed: 857.42 samples/sec#011loss=0.866775\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[25] avg_epoch_loss=0.851830\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=0.8297819256782532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [25]#011Speed: 1364.89 samples/sec#011loss=0.829782\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[30] avg_epoch_loss=0.832414\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=0.7314531326293945\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [30]#011Speed: 853.09 samples/sec#011loss=0.731453\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch[35] avg_epoch_loss=0.824527\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=0.7756261587142944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:39 INFO 140281140962944] Epoch[19] Batch [35]#011Speed: 1351.19 samples/sec#011loss=0.775626\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[40] avg_epoch_loss=0.812882\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=0.7290380358695984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [40]#011Speed: 783.39 samples/sec#011loss=0.729038\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[45] avg_epoch_loss=0.821061\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=0.8881293058395385\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [45]#011Speed: 1313.43 samples/sec#011loss=0.888129\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[50] avg_epoch_loss=0.819584\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=0.8059944152832031\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [50]#011Speed: 852.24 samples/sec#011loss=0.805994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[55] avg_epoch_loss=0.815517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=0.7740318298339843\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [55]#011Speed: 1274.65 samples/sec#011loss=0.774032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[60] avg_epoch_loss=0.816021\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=0.8216732621192933\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [60]#011Speed: 819.75 samples/sec#011loss=0.821673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[65] avg_epoch_loss=0.816899\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=0.8276053309440613\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [65]#011Speed: 1325.43 samples/sec#011loss=0.827605\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch[70] avg_epoch_loss=0.814511\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=0.7829940557479859\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:40 INFO 140281140962944] Epoch[19] Batch [70]#011Speed: 790.80 samples/sec#011loss=0.782994\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[75] avg_epoch_loss=0.810077\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=0.7471100926399231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [75]#011Speed: 1138.92 samples/sec#011loss=0.747110\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[80] avg_epoch_loss=0.809942\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=0.8078848958015442\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [80]#011Speed: 654.50 samples/sec#011loss=0.807885\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[85] avg_epoch_loss=0.807760\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=0.7724166512489319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [85]#011Speed: 1340.47 samples/sec#011loss=0.772417\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[90] avg_epoch_loss=0.802751\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=0.7165985465049743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [90]#011Speed: 858.61 samples/sec#011loss=0.716599\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[95] avg_epoch_loss=0.796363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=0.6801022291183472\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [95]#011Speed: 1372.10 samples/sec#011loss=0.680102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch[100] avg_epoch_loss=0.793112\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=0.7306856513023376\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:41 INFO 140281140962944] Epoch[19] Batch [100]#011Speed: 801.39 samples/sec#011loss=0.730686\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[105] avg_epoch_loss=0.804146\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=1.0270318031311034\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [105]#011Speed: 1325.02 samples/sec#011loss=1.027032\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[110] avg_epoch_loss=0.974631\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=4.588922107219696\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [110]#011Speed: 842.03 samples/sec#011loss=4.588922\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[115] avg_epoch_loss=0.971713\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=0.9069395780563354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [115]#011Speed: 1353.47 samples/sec#011loss=0.906940\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[120] avg_epoch_loss=0.974667\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=1.0431975364685058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [120]#011Speed: 846.16 samples/sec#011loss=1.043198\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[125] avg_epoch_loss=0.980661\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=1.1256993770599366\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [125]#011Speed: 1349.22 samples/sec#011loss=1.125699\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch[130] avg_epoch_loss=0.985614\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=1.1104493379592895\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:42 INFO 140281140962944] Epoch[19] Batch [130]#011Speed: 852.02 samples/sec#011loss=1.110449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[135] avg_epoch_loss=0.991657\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=1.1499707221984863\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [135]#011Speed: 1256.92 samples/sec#011loss=1.149971\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[140] avg_epoch_loss=0.993757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=1.0508772373199462\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [140]#011Speed: 859.03 samples/sec#011loss=1.050877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[145] avg_epoch_loss=0.995748\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=1.051908254623413\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [145]#011Speed: 1373.11 samples/sec#011loss=1.051908\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[150] avg_epoch_loss=0.995471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=0.9873626708984375\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [150]#011Speed: 867.14 samples/sec#011loss=0.987363\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[155] avg_epoch_loss=0.993094\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=0.9213024020195008\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [155]#011Speed: 1355.25 samples/sec#011loss=0.921302\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[160] avg_epoch_loss=0.987505\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=0.8131529808044433\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [160]#011Speed: 862.49 samples/sec#011loss=0.813153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch[165] avg_epoch_loss=0.982722\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=0.8287063956260681\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:43 INFO 140281140962944] Epoch[19] Batch [165]#011Speed: 1252.71 samples/sec#011loss=0.828706\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[170] avg_epoch_loss=0.978743\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=0.8466454148292542\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [170]#011Speed: 810.54 samples/sec#011loss=0.846645\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[175] avg_epoch_loss=0.973624\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=0.7985457062721253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [175]#011Speed: 1331.91 samples/sec#011loss=0.798546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[180] avg_epoch_loss=0.968886\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=0.8021023988723754\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [180]#011Speed: 868.96 samples/sec#011loss=0.802102\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[185] avg_epoch_loss=0.965697\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=0.8502631545066833\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [185]#011Speed: 1350.89 samples/sec#011loss=0.850263\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[190] avg_epoch_loss=0.966386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=0.9920286655426025\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [190]#011Speed: 857.43 samples/sec#011loss=0.992029\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch[195] avg_epoch_loss=0.968379\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=1.0445026874542236\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:44 INFO 140281140962944] Epoch[19] Batch [195]#011Speed: 1323.77 samples/sec#011loss=1.044503\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[200] avg_epoch_loss=0.965221\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=0.841429340839386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [200]#011Speed: 788.81 samples/sec#011loss=0.841429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[205] avg_epoch_loss=0.961395\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=0.8075654745101929\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [205]#011Speed: 1307.04 samples/sec#011loss=0.807565\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[210] avg_epoch_loss=0.957003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=0.7760762929916382\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [210]#011Speed: 833.32 samples/sec#011loss=0.776076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[215] avg_epoch_loss=0.950958\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=0.6958403587341309\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [215]#011Speed: 1349.53 samples/sec#011loss=0.695840\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[220] avg_epoch_loss=0.946489\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=0.7534227252006531\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [220]#011Speed: 823.06 samples/sec#011loss=0.753423\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch[225] avg_epoch_loss=0.941408\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=0.7168308973312378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:45 INFO 140281140962944] Epoch[19] Batch [225]#011Speed: 1318.97 samples/sec#011loss=0.716831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[230] avg_epoch_loss=0.936953\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=0.7356151580810547\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [230]#011Speed: 801.05 samples/sec#011loss=0.735615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[235] avg_epoch_loss=0.932253\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=0.7150833010673523\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [235]#011Speed: 1363.13 samples/sec#011loss=0.715083\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[240] avg_epoch_loss=0.928176\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=0.7357670545578003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [240]#011Speed: 591.98 samples/sec#011loss=0.735767\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[245] avg_epoch_loss=0.925914\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=0.81686030626297\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [245]#011Speed: 1343.78 samples/sec#011loss=0.816860\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[250] avg_epoch_loss=0.923691\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=0.8143435955047608\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [250]#011Speed: 836.43 samples/sec#011loss=0.814344\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch[255] avg_epoch_loss=0.923330\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=0.9051887631416321\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:46 INFO 140281140962944] Epoch[19] Batch [255]#011Speed: 1345.56 samples/sec#011loss=0.905189\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[260] avg_epoch_loss=0.919957\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=0.7472473502159118\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [260]#011Speed: 800.24 samples/sec#011loss=0.747247\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[265] avg_epoch_loss=0.956947\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=2.887860691547394\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [265]#011Speed: 1332.10 samples/sec#011loss=2.887861\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[270] avg_epoch_loss=0.955989\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=0.9049871087074279\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [270]#011Speed: 836.34 samples/sec#011loss=0.904987\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[275] avg_epoch_loss=0.957070\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=275 train loss <loss>=1.0156849384307862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [275]#011Speed: 1367.14 samples/sec#011loss=1.015685\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[280] avg_epoch_loss=0.957103\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=280 train loss <loss>=0.9589444041252136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [280]#011Speed: 858.07 samples/sec#011loss=0.958944\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[285] avg_epoch_loss=0.957128\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=285 train loss <loss>=0.9585152983665466\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [285]#011Speed: 1328.03 samples/sec#011loss=0.958515\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch[290] avg_epoch_loss=0.956180\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=290 train loss <loss>=0.9019253253936768\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:47 INFO 140281140962944] Epoch[19] Batch [290]#011Speed: 866.48 samples/sec#011loss=0.901925\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[295] avg_epoch_loss=0.954894\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=295 train loss <loss>=0.8800986886024476\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [295]#011Speed: 1223.44 samples/sec#011loss=0.880099\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[300] avg_epoch_loss=0.953315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=300 train loss <loss>=0.8598279833793641\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [300]#011Speed: 864.12 samples/sec#011loss=0.859828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[305] avg_epoch_loss=0.952136\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=305 train loss <loss>=0.8811689972877502\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [305]#011Speed: 1342.06 samples/sec#011loss=0.881169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[310] avg_epoch_loss=0.949711\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=310 train loss <loss>=0.8012611627578735\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [310]#011Speed: 852.91 samples/sec#011loss=0.801261\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[315] avg_epoch_loss=0.947276\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=315 train loss <loss>=0.7958235740661621\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [315]#011Speed: 1330.19 samples/sec#011loss=0.795824\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch[320] avg_epoch_loss=0.945804\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=320 train loss <loss>=0.8527618646621704\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:48 INFO 140281140962944] Epoch[19] Batch [320]#011Speed: 603.44 samples/sec#011loss=0.852762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[325] avg_epoch_loss=0.942903\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=325 train loss <loss>=0.7567030191421509\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [325]#011Speed: 791.33 samples/sec#011loss=0.756703\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[330] avg_epoch_loss=0.941951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=330 train loss <loss>=0.879830801486969\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [330]#011Speed: 520.91 samples/sec#011loss=0.879831\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[335] avg_epoch_loss=0.938632\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=335 train loss <loss>=0.7189457654953003\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [335]#011Speed: 1252.66 samples/sec#011loss=0.718946\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[340] avg_epoch_loss=0.935294\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=340 train loss <loss>=0.7109753012657165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [340]#011Speed: 852.60 samples/sec#011loss=0.710975\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch[345] avg_epoch_loss=0.934058\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=345 train loss <loss>=0.8497937440872192\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:49 INFO 140281140962944] Epoch[19] Batch [345]#011Speed: 1352.29 samples/sec#011loss=0.849794\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[350] avg_epoch_loss=0.931952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=350 train loss <loss>=0.78618243932724\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [350]#011Speed: 796.00 samples/sec#011loss=0.786182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[355] avg_epoch_loss=0.929335\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=355 train loss <loss>=0.7456162929534912\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [355]#011Speed: 1356.94 samples/sec#011loss=0.745616\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[360] avg_epoch_loss=0.929612\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=360 train loss <loss>=0.9493066191673278\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [360]#011Speed: 862.82 samples/sec#011loss=0.949307\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[365] avg_epoch_loss=0.929500\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=365 train loss <loss>=0.9214834094047546\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [365]#011Speed: 1342.67 samples/sec#011loss=0.921483\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[370] avg_epoch_loss=0.927911\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=370 train loss <loss>=0.8115490436553955\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [370]#011Speed: 786.68 samples/sec#011loss=0.811549\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch[375] avg_epoch_loss=0.925677\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=375 train loss <loss>=0.7599242448806762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:50 INFO 140281140962944] Epoch[19] Batch [375]#011Speed: 1340.69 samples/sec#011loss=0.759924\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[380] avg_epoch_loss=0.923186\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=380 train loss <loss>=0.7358621835708619\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [380]#011Speed: 859.42 samples/sec#011loss=0.735862\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[385] avg_epoch_loss=0.921087\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=385 train loss <loss>=0.7611217975616456\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [385]#011Speed: 1216.43 samples/sec#011loss=0.761122\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[390] avg_epoch_loss=0.919304\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=390 train loss <loss>=0.781670331954956\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [390]#011Speed: 720.59 samples/sec#011loss=0.781670\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[395] avg_epoch_loss=0.918409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=395 train loss <loss>=0.8484103322029114\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [395]#011Speed: 785.36 samples/sec#011loss=0.848410\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[400] avg_epoch_loss=0.918871\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=400 train loss <loss>=0.9554536581039429\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [400]#011Speed: 825.64 samples/sec#011loss=0.955454\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch[405] avg_epoch_loss=0.917939\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=405 train loss <loss>=0.8432280898094178\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:51 INFO 140281140962944] Epoch[19] Batch [405]#011Speed: 1349.74 samples/sec#011loss=0.843228\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[410] avg_epoch_loss=0.915897\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=410 train loss <loss>=0.750092351436615\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [410]#011Speed: 870.14 samples/sec#011loss=0.750092\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[415] avg_epoch_loss=0.915175\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=415 train loss <loss>=0.855825936794281\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [415]#011Speed: 1244.49 samples/sec#011loss=0.855826\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[420] avg_epoch_loss=0.919587\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=420 train loss <loss>=1.28666433095932\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [420]#011Speed: 719.82 samples/sec#011loss=1.286664\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[425] avg_epoch_loss=0.918443\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=425 train loss <loss>=0.8220848321914673\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [425]#011Speed: 939.28 samples/sec#011loss=0.822085\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch[430] avg_epoch_loss=0.916839\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=430 train loss <loss>=0.7802309989929199\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:52 INFO 140281140962944] Epoch[19] Batch [430]#011Speed: 625.67 samples/sec#011loss=0.780231\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[435] avg_epoch_loss=0.914867\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=435 train loss <loss>=0.7448638439178467\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [435]#011Speed: 1335.75 samples/sec#011loss=0.744864\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[440] avg_epoch_loss=0.913262\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=440 train loss <loss>=0.7732873678207397\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [440]#011Speed: 811.51 samples/sec#011loss=0.773287\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[445] avg_epoch_loss=0.912532\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=445 train loss <loss>=0.8481820464134217\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [445]#011Speed: 1367.40 samples/sec#011loss=0.848182\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[450] avg_epoch_loss=0.911409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=450 train loss <loss>=0.8112055778503418\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [450]#011Speed: 854.09 samples/sec#011loss=0.811206\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[455] avg_epoch_loss=0.911076\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=455 train loss <loss>=0.8810053706169129\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [455]#011Speed: 1376.21 samples/sec#011loss=0.881005\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[460] avg_epoch_loss=0.911093\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=460 train loss <loss>=0.9126548647880555\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [460]#011Speed: 851.13 samples/sec#011loss=0.912655\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch[465] avg_epoch_loss=0.923333\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=465 train loss <loss>=2.051843762397766\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:53 INFO 140281140962944] Epoch[19] Batch [465]#011Speed: 1330.67 samples/sec#011loss=2.051844\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[470] avg_epoch_loss=0.928517\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=470 train loss <loss>=1.4117080211639403\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [470]#011Speed: 856.67 samples/sec#011loss=1.411708\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[475] avg_epoch_loss=0.928354\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=475 train loss <loss>=0.913043475151062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [475]#011Speed: 1212.97 samples/sec#011loss=0.913043\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[480] avg_epoch_loss=0.928952\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=480 train loss <loss>=0.9858282089233399\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [480]#011Speed: 863.01 samples/sec#011loss=0.985828\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[485] avg_epoch_loss=0.928847\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=485 train loss <loss>=0.9187973618507386\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [485]#011Speed: 1298.84 samples/sec#011loss=0.918797\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[490] avg_epoch_loss=0.929057\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=490 train loss <loss>=0.9494709372520447\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [490]#011Speed: 869.92 samples/sec#011loss=0.949471\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch[495] avg_epoch_loss=0.928295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=495 train loss <loss>=0.8533778309822082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:54 INFO 140281140962944] Epoch[19] Batch [495]#011Speed: 1350.86 samples/sec#011loss=0.853378\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[500] avg_epoch_loss=0.926550\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=500 train loss <loss>=0.7535178303718567\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [500]#011Speed: 853.67 samples/sec#011loss=0.753518\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[505] avg_epoch_loss=0.926959\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=505 train loss <loss>=0.9679010272026062\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [505]#011Speed: 1341.95 samples/sec#011loss=0.967901\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[510] avg_epoch_loss=0.926905\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=510 train loss <loss>=0.9214678525924682\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [510]#011Speed: 819.00 samples/sec#011loss=0.921468\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[515] avg_epoch_loss=0.924923\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=515 train loss <loss>=0.7223652362823486\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [515]#011Speed: 1341.47 samples/sec#011loss=0.722365\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[520] avg_epoch_loss=0.924296\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=520 train loss <loss>=0.8595388650894165\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [520]#011Speed: 854.11 samples/sec#011loss=0.859539\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[525] avg_epoch_loss=0.922812\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=525 train loss <loss>=0.7682390332221984\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch [525]#011Speed: 1289.35 samples/sec#011loss=0.768239\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] Epoch[19] Batch[530] avg_epoch_loss=0.921315\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:55 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=530 train loss <loss>=0.7637622475624084\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [530]#011Speed: 859.93 samples/sec#011loss=0.763762\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch[535] avg_epoch_loss=0.920352\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=535 train loss <loss>=0.8180817246437073\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [535]#011Speed: 1344.64 samples/sec#011loss=0.818082\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch[540] avg_epoch_loss=0.921054\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=540 train loss <loss>=0.9963193297386169\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [540]#011Speed: 786.00 samples/sec#011loss=0.996319\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch[545] avg_epoch_loss=0.919757\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, batch=545 train loss <loss>=0.7794240117073059\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Epoch[19] Batch [545]#011Speed: 1329.21 samples/sec#011loss=0.779424\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] processed a total of 17583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717578.663244, \"EndTime\": 1620717596.540914, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 17876.915216445923, \"count\": 1, \"min\": 17876.915216445923, \"max\": 17876.915216445923}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #throughput_metric: host=algo-1, train throughput=983.5497964009055 records/second\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, epoch=19, train loss <loss>=0.9192445795102553\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Final loss: 0.9012727438860687 (occurred at epoch 17)\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #quality_metric: host=algo-1, train final_loss <loss>=0.9012727438860687\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 WARNING 140281140962944] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.5410306, \"EndTime\": 1620717596.5870986, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 44.99530792236328, \"count\": 1, \"min\": 44.99530792236328, \"max\": 44.99530792236328}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.587164, \"EndTime\": 1620717596.6189008, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 76.81393623352051, \"count\": 1, \"min\": 76.81393623352051, \"max\": 76.81393623352051}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.618993, \"EndTime\": 1620717596.6266437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 7.579803466796875, \"count\": 1, \"min\": 7.579803466796875, \"max\": 7.579803466796875}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] #memory_usage::<batchbuffer> = 0.2696990966796875 mb\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:56 INFO 140281140962944] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.6267598, \"EndTime\": 1620717596.6281588, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.042438507080078125, \"count\": 1, \"min\": 0.042438507080078125, \"max\": 0.042438507080078125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:19:59 INFO 140281140962944] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:02 INFO 140281140962944] Number of test batches scored: 20\u001b[0m\n",
      "\n",
      "2021-05-11 07:20:12 Uploading - Uploading generated training model\u001b[34m[05/11/2021 07:20:05 INFO 140281140962944] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.6/site-packages/numpy/ma/core.py:2788: UserWarning: Warning: converting a masked element to nan.\n",
      "  order=order, subok=True, ndmin=ndmin)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717596.6282518, \"EndTime\": 1620717609.1200118, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 12491.92190170288, \"count\": 1, \"min\": 12491.92190170288, \"max\": 12491.92190170288}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, RMSE): 5.606467203227409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, mean_absolute_QuantileLoss): 21565.82130957709\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, mean_wQuantileLoss): 0.05954234706241449\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.1]): 0.019259129169366153\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.2]): 0.03471119688808139\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.3]): 0.04786356457841295\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.4]): 0.05903509831839482\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.5]): 0.06817136183152951\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.6]): 0.07519472586363227\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.7]): 0.0794489183705086\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.8]): 0.07969780930169601\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #test_score (algo-1, wQuantileLoss[0.9]): 0.07249931924010877\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #quality_metric: host=algo-1, test RMSE <loss>=5.606467203227409\u001b[0m\n",
      "\u001b[34m[05/11/2021 07:20:09 INFO 140281140962944] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.05954234706241449\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620717609.120082, \"EndTime\": 1620717609.1274393, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 7.159948348999023, \"count\": 1, \"min\": 7.159948348999023, \"max\": 7.159948348999023}, \"totaltime\": {\"sum\": 382374.2399215698, \"count\": 1, \"min\": 382374.2399215698, \"max\": 382374.2399215698}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-11 07:20:29 Completed - Training job completed\n",
      "Training seconds: 461\n",
      "Billable seconds: 461\n"
     ]
    }
   ],
   "source": [
    "dar_estimator.fit(inputs=dar_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-battery-deepar-2021-05-11-07-10-08-643'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_job_name = dar_estimator.latest_training_job.name\n",
    "dar_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_instance_type=\"ml.m5.large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-battery-deepar-2021-05-11-07-10-08-643'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=dar_job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=infer_instance_type,\n",
    "    image_uri=dar_image_name,\n",
    "    role=role\n",
    ")\n",
    "dar_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances.append(train_tss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = {\n",
    "    \"instances\": instances,\n",
    "    \"configuration\": {\n",
    "         \"output_types\": [\"mean\", \"quantiles\"],\n",
    "         \"quantiles\": [\"0.1\",\"0.5\", \"0.9\",\"0.99\",\"0.999\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        1\n",
      "      ],\n",
      "      \"target\": [\n",
      "        76.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        74.0,\n",
      "        74.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        73.0,\n",
      "        72.0,\n",
      "        71.0,\n",
      "        71.0,\n",
      "        70.0,\n",
      "        69.0,\n",
      "        69.0,\n",
      "        68.0,\n",
      "        68.0,\n",
      "        67.0,\n",
      "        66.0,\n",
      "        66.0,\n",
      "        65.0,\n",
      "        65.0,\n",
      "        64.0,\n",
      "        64.0,\n",
      "        63.0,\n",
      "        64.0,\n",
      "        65.0,\n",
      "        69.0\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"configuration\": {\n",
      "    \"output_types\": [\n",
      "      \"mean\",\n",
      "      \"quantiles\"\n",
      "    ],\n",
      "    \"quantiles\": [\n",
      "      \"0.1\",\n",
      "      \"0.5\",\n",
      "      \"0.9\",\n",
      "      \"0.99\",\n",
      "      \"0.999\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "inference_json = json.dumps(inference, indent=2)\n",
    "print(inference_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.Predictor at 0x7ff8f89525f8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "\n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    dar_endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer())\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'mean': [71.1284637451,\n",
       "    72.3249282837,\n",
       "    73.0628433228,\n",
       "    72.9008026123],\n",
       "   'quantiles': {'0.1': [68.7886962891,\n",
       "     69.7614974976,\n",
       "     70.4834442139,\n",
       "     70.0815658569],\n",
       "    '0.5': [71.0411529541, 72.1847610474, 73.2421646118, 72.8921966553],\n",
       "    '0.9': [73.9268264771, 75.0553207397, 75.9048233032, 75.8751602173],\n",
       "    '0.99': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832],\n",
       "    '0.999': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832]}}]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mean': [71.1284637451, 72.3249282837, 73.0628433228, 72.9008026123],\n",
       "  'quantiles': {'0.1': [68.7886962891,\n",
       "    69.7614974976,\n",
       "    70.4834442139,\n",
       "    70.0815658569],\n",
       "   '0.5': [71.0411529541, 72.1847610474, 73.2421646118, 72.8921966553],\n",
       "   '0.9': [73.9268264771, 75.0553207397, 75.9048233032, 75.8751602173],\n",
       "   '0.99': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832],\n",
       "   '0.999': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832]}}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = prediction[\"predictions\"]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': [71.1284637451, 72.3249282837, 73.0628433228, 72.9008026123],\n",
       " 'quantiles': {'0.1': [68.7886962891,\n",
       "   69.7614974976,\n",
       "   70.4834442139,\n",
       "   70.0815658569],\n",
       "  '0.5': [71.0411529541, 72.1847610474, 73.2421646118, 72.8921966553],\n",
       "  '0.9': [73.9268264771, 75.0553207397, 75.9048233032, 75.8751602173],\n",
       "  '0.99': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832],\n",
       "  '0.999': [76.6286773682, 77.4080276489, 77.9496307373, 80.5334777832]}}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred0 = predictions[0]\n",
    "pred0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean = pred0[\"mean\"]\n",
    "quantiles = pred0[\"quantiles\"]\n",
    "q01 = quantiles[\"0.1\"]\n",
    "q90 = quantiles[\"0.9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76., 75., 75., 75.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = sample_test[\"battery\"][0:4].values\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff8f8175cf8>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.grid(which='major', axis='both')\n",
    "\n",
    "ax1.set_ylabel('Actual Battery', color='C0')\n",
    "ax2.set_ylabel('Predicted Battery', color='C1')\n",
    "\n",
    "\n",
    "ax1.plot(actual, color='C0')\n",
    "ax2.plot(mean, color='C1')\n",
    "ax2.plot(q01, color='C2')\n",
    "ax2.plot(q90, color='C2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now let's work on detecting [motor anomalies](mt-motor-anomaly.ipynb)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

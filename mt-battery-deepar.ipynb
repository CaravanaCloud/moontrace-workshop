{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Forecasting with DeepAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll prevent battery outages using Amazon Sagemaker and [DeepAR Forecasting](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The Amazon SageMaker DeepAR forecasting algorithm is a supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the required libraries and recovering stored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the battery time series for a single device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8e4a851ed2317a249a0903f29d894361'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_loc = 1\n",
    "sample_device_id = data.iloc[device_loc][\"device_id\"]\n",
    "sample_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data[data[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery = sample_data[\"battery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [DeepAR input format](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput) requires data to be sampled at regular time intervals. Here is a sample input:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>{\"start\": \"2009-11-01 00:00:00\", \"target\": [4.3, \"NaN\", 5.1, ...], \"cat\": [0, 1], \"dynamic_feat\": [[1.1, 1.2, 0.5, ...]]}\n",
    "{\"start\": \"2012-01-30 00:00:00\", \"target\": [1.0, -5.0, ...], \"cat\": [2, 3], \"dynamic_feat\": [[1.1, 2.05, ...]]}\n",
    "{\"start\": \"1999-01-30 00:00:00\", \"target\": [2.0, 1.0], \"cat\": [1, 4], \"dynamic_feat\": [[1.3, 0.4]]}\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, we can see that the sample timestamps are no regularly spaced, but actualy reflects the observation time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2020-02-25 20:50:37    75\n",
       "2020-02-25 21:07:07    75\n",
       "2020-02-25 21:23:15    75\n",
       "2020-02-25 21:38:36    75\n",
       "2020-02-25 22:03:11    75\n",
       "Name: battery, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "battery.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fade46d4e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "battery.tail(20).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, note that observation are taken about every 5 minutes, but changing little.\n",
    "Pandas offers a convenient resampling function to create a uniform hourly dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = data[data[\"battery\"] > 0]\n",
    "hourly = (hourly.groupby(\"device_id\")\n",
    "          .battery\n",
    "          .resample(\"H\")\n",
    "          .min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                         timestamp          \n",
       "0001495ce5f079703599a94c32dab2b0  2020-02-24 15:00:00    75.0\n",
       "                                  2020-02-24 16:00:00    75.0\n",
       "                                  2020-02-24 17:00:00    75.0\n",
       "                                  2020-02-24 18:00:00    75.0\n",
       "                                  2020-02-24 19:00:00    75.0\n",
       "                                                         ... \n",
       "fffaee1fbb9c96703850f64d3262e843  2020-02-25 17:00:00    64.0\n",
       "                                  2020-02-25 18:00:00    68.0\n",
       "                                  2020-02-25 19:00:00    75.0\n",
       "                                  2020-02-25 20:00:00    76.0\n",
       "                                  2020-02-25 21:00:00    76.0\n",
       "Name: battery, Length: 532029, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly.reset_index().set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-24 15:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 16:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 17:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 18:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532029 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-24 15:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 16:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 17:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 18:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "2020-02-24 19:00:00  0001495ce5f079703599a94c32dab2b0     75.0\n",
       "...                                               ...      ...\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843     64.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843     68.0\n",
       "2020-02-25 19:00:00  fffaee1fbb9c96703850f64d3262e843     75.0\n",
       "2020-02-25 20:00:00  fffaee1fbb9c96703850f64d3262e843     76.0\n",
       "2020-02-25 21:00:00  fffaee1fbb9c96703850f64d3262e843     76.0\n",
       "\n",
       "[532029 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again visualize a sample tame series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsample = hourly[hourly[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fade4e4ec50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.tail(12).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fadc04cd320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEeCAYAAACT504VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO29e3hcZ3Xv/1m6W7IuljTjuy3HtsZJnMQ4Drk4sUckISFtCfyghTRQAoUUeEqhvx5aWs6hAVoKJS3we4ByUmhCnwPhEqDQnlASiC8hd8dxbrZlO/H9KtuSbOs2t/X7Y+8ZS7ZkjaSZ2XvPrM/zzOOZd/blld89a6+93u+7lqgqhmEYRvAo87oDhmEYxuQwA24YhhFQzIAbhmEEFDPghmEYAcUMuGEYRkAxA24YhhFQKgp5stbWVm1rayvkKQ3DMALP888/f1xVQ+e2F9SAt7W1sWnTpkKe0jAMI/CIyN7R2i2EYhiGEVDMgBuGYQQUM+CGYRgBxQy4YRhGQBnXgItIRES2DHudEpFPuN99TES2i8irIvKP+e+uYRiGkWZcFYqqdgIrAESkHDgI/ExEOoDbgStUdUhEwnntqWEYhjGCiYZQbgReU9W9wEeAL6rqEICqHst15wzDMIyxmagBfzfwoPu+HbhBRJ4RkQ0iclVuu1a6HOkd5J5fvMpgPOl1V4xJMpRI8j//42WOnRr0uiuGD4gnU3zm569wsGcgp8fN2oCLSBXwVuDHblMF0AxcA3wS+JGIyCj73S0im0RkU1dXVw66XPw8ses4Dzy5h4077P8rqOw4cob/8/Q+frRpv9ddMXzA6119/PtTe3nwmX05Pe5EPPC3AJtV9aj7+QDwU3V4FkgBrefupKr3qeoqVV0VCp23EtQYhVgyBcB6M+CBZcB9elrfaWNoQF8sAcD6HbmNNE/EgN/B2fAJwH8AHQAi0g5UAcdz17XSJe4a8A2dXVjJu2CSDn9t3tdNb3/c494YXtM/5FwPrxw8xbHTuQurZWXARaQOuBn46bDmfwMuEpFXgB8A71OzNjkhlnAM+MGeAXYdO+Nxb4zJkDbgKYXHd5kXXuqkPXCAjTty5+dmZcBVtU9VW1S1d1hbTFXfo6rLVXWlqj6Ws16VOEOuAQdY12niniAyOHwMt5sBL3X6XQNeUSY5/U3bSkwfkg6htM+cbjHUgJL2wFcuaGLDji5SKXs4LWXOuCGU65e28viOLhLJ1Dh7ZIcZcB8SS6SoLBc6ImGe23OSM0OJ8XcyfMWQa8Dfsnw2x88MsfXwKY97ZHhJv/sbvu2y2ZwaTLBlf09OjmsG3Ic4BryMtZEQ8aTyxC6bGw4ag3HHw3rzpTMBWLfdQmGlTF/MuaG/+ZKZlJdJzp6szYD7kHgyRVVFGasWNjO9usLCKAEkLSOc2zSNy+c1miS0xOkfSlBXVU5TbRVXLpiRszi4GXAfEks6HnhVRRmrl7SwofOYyQkDxmA8SUWZUFFeRrQ9xAv7uunpj3ndLcMj+mIJaqud1FNrIyFePZQbOaEZcB8ylEhRVe4MTTQS5lDvIDuOmpwwSAzGU9RUlgOwNhImpbBxp4XCSpW+oSR1Vc71EI04Cxo35ODJ2gy4D4knleqKtAF3Bnu9yQkDxWAiSU2lM4Yr5jfRVFtpY1jC9McS1FY5HvglsxsI11fnJKxmBtyHxBJJKl0PfHbjNJbNqrc4eMAYjCczHnh5mbBmaYiNJicsWfqGkkx3QygiQjQSyomc0Ay4D4klnEnMNGsjIZ7bc5LTg7YkOygMDQuhgPMkdfxMjFcO9V5gL6NY6Y8lqK0efj2EOTWY4IUpygnNgPuQeFJHGPBoe5hESnli1wkPe2VMhIH42RAKwJr2dCjMnqRKkTNDCeqqztbPWb2k1ZUTTi2sNm5FHqPwpBfypFnVNoPp1RX8fMtBWqZXediz8xHgkjkNmfie4TAYT1JTcdbjap1ezRXzGvnVq0e4dnFLwfpRXVHG8jmNlJWdl+nZKCD9sSS1VWevh8ZplVy5cAaPbj1KNDL5Ymb2q/MhQ8kUjVWVmc/pRT3/96XD/PKVIx72bHT+8OoFfOHtl3ndDV8xGE+ed1O78eKZ/POjO/j9bz1V0L58+49WcdMlMwt6TmMkfUMJ6qpHXg83XRzmCw9vn9L1YAbch8SHyQjTfOFtl3HHVQs86tHY/O+Nr/GbbUfRty1nlHoeJctgPEVz3cgxvHvNRaxqm0EqN2kwxiWeSvH++5+j8+hpM+Aeoqr0x5LUDYuBA9x13SIum9tEMouJ7Ru+NHq7GXAfEkumqKoYaQwbayu5ful59TI853DvAJ986CW2HT7NJXMavO6Ob3BkhCN/sDWV5Vy3uLBjGK6vZs/xvoKe0xhJLJkikdLznsiqKsqmHE6zSUwfEhvFA/cra12duqW9Hcm5KhSvaGutY88JM+Be0udmIqyryv31EAwrUWKkc6EEgXB9DZfOacjJqrJi4lwVilcsaqlj9/F+r7tR0vS5mQhrq3Mf8PD+CjPOI52NMChEIyGe39dN74Dp1NOcq0LxioWttRw/M2QpiT2k381EON0MeGlw7kIev9MRCZNMKb+1XB+AM2k1fCWmlyxqqQOwOLiHpMup1VoIpTSIBSiEAk6uj4aaCsv14RJPKinFFyGUtlbXgFsc3DPSIZRzZYS5wPsrzBiBqjoGPEAhlIryMm5oD7FhR5elvcVRoAC+8MAXttQCsPeExcG9Ij2JaR54CZBIKaoEyoADRNtDHDttpcPgbD1MPxjw2qoKZjZUs9tCKJ6RLmhcl4fVysGyEiVAuqBxkEIocFZOaLk+HAkh+MOAAyxsqWOvhVA8I11OzUIoJUAs4fz4g6RCAUdOuHxug8XBOVtOzQ8xcDApodf0Z2LgFkIpetIGPGgeODhZEzfv6yl5OWEmhOIDGSE4E5nHzwxZOmKP6BtKIJKf62FcKyEiERHZMux1SkQ+Mez7vxARFRH/rfMOILGAhlDA0YObnPBsRXq/hFDabCLTU/piSWory/OSEXJcK6Gqnaq6QlVXAFcC/cDPAERkPvBmYF/Oe1aiZDzwgIVQwJETNk6rLPll9YM+C6GYlNBb+ocVNM41E73CbgReU9W97uevAH8JmHYsRwTZA68oL+OGpa1sKPHSYX5SocBZKaEt5vGG4eXUcs1ErcS7gQcBROR24KCqvpjzXpUw8YRj+ILogYNTKqqrxOWEgwl/hVDSUsI9FkLxBKegcX6uhaythIhUAW8FfiwitcDfAJ/JYr+7RWSTiGzq6jKJ2XjEko73VhlADxxgbaZ0WOmGUQZj/gqhALS11JkH7hHnllPLJRO5wt4CbFbVo8BiYBHwoojsAeYBm0Vk1rk7qep9qrpKVVeFQqFc9LmoGQpwDBwgVF/NZXMbS1oP7qeVmGnaWurMA/eI/lhyREHjXDIRK3EHbvhEVV9W1bCqtqlqG3AAWKmq/qv3FTDiSTeEElAPHBw1yuZ93fT2l6ZszW8xcDApoZeMVk4tV2RlJUSkDrgZ+GleemFkCLIKJU00EiKl8Piu0vTCMzJCH92EF7WalNAr+mPJvBRzgCwNuKr2qWqLqvaO8X2bqpa2+DdHBHkhT5oV82fQVFvJuu2lasCTVJQJFT66CS9sMSmhV5wZSpxXTi1X+OcKM4Dg5kIZTnmZcMPSUMnKCQfjKab5KHwCTgwcTEpYaMYqaJwrgmslipSzuVCCXeE92h7i+JnSlBMOxJNU+8yAT6sqZ1ZDjeVEKTBDiRTJUQoa5woz4D5jqAg8cIA1JSwnHPJJPcxzWdhSa1kJC0w+y6mBGXDfEXc98Opyf3lwEyVUX83l8xpZV4JywsGEP8qpncsiq1BfcDIFjb1eyGMUhvRS+sqKYIdQwAmjvLCvm57+mNddKSiD8ZRPPfA6jp+JmZSwgKTrYXoqIzQKRzHICNOsjYQdOWGJZSf0S0X6czEpYeHJZzk1MAPuO+LJFGWCryRok2XF/CaaaitLblXmYDzJtDz9YKdCOiuhlVcrHP3mgZcWsUQqcNV4xqK8TFizNMSGHcdKSk44GE9R7UMPfGGzY8BtIrNwpD1wP+RCMQrAUCIVeAXKcKKREMfPxHj1UOnICQd9qkIxKWHhOeuBWwilJIgnU1QXkQEvRTmhY8D954EDtLXWmhKlgJxVoeTHA8/PUccgrYk0xqaYQigArdOruWJeI7985QjL5zaO+O6SOQ3MbKjxqGf5YzDhTxUKOCsyf73tqNfdKBnOVqTPzw29oAb8SO9gIU8XSGLJ4gqhANx8yUzufWQH73/guRHtV7XN4Mcfvs6jXuUPv6pQABaHpvOD5/bTdXqIUH21190pevrdgsb5Sq1QYA88wZmhRN5WJRUD8WRxeeAAf7J2MWvbwyT17ETmQ8/v5/vP7KO7L8aMuioPe5dbVNXXIZRrF7cAsHFHF++4cp7HvSl++mJJ6qoqEMnPuo6CWgoFnthVWprgiRJLpIpCAz6cyvIyLpvXyIr5TZnXO1bOI6WwcWdxSQzjSSWl+FJGCHDpnAZC9dUlX3i6UOSznBoU2ICXiZScJniiFJsKZSwun9fEjNpKNhTZ9TDgFnPw60S0iBBtD/H4zuMk3FW/Rv44M5TMmwYcCmzAp1dXsL7zGKqlowmeKPFk8Xngo1FeJqxpL76Us0M+rMZzLtFImN6BOC8e6PG6K0VP/1AReeD1NRUc7h1kx9EzhTxtoIiViAcOjkb8RF+MVw6NWickkGSq8fjYgF+/tJXyMinZghuFpC+Wv3Jq4IEBh9LSBE+UYlShjMWapSFEKCpDcragsX/HsHFaJSsXNLF+h/0O800+y6lBgQ14ZXkZy2bV2wTKBYgnNPDFHLKlZXo1l88rLkOSKWjsUxlhmmgkzCsHT3HstEl788mZoQS1xeKBg3PhbNrTbSktx8DxwP39488l0fYQW/b3cLKvOFLOBiGEAk74Cii6SWS/0T9URB44OBdOIqU8setEoU8dCIpRRnghopEQqvB4kcgJ0yqUaVX+HsNLZjcQrq9m/Y7i+H/3K0UVAwe4cuEM6qsr2FBEj825xPHASyOEAo6csLmuqmjkpYMZGaG/PXARYW17iMd3dJmcME9kChrnKQ8KeGDAK8vLuH5pK+u2d5mccBRKzQN3Us62Fo2ccDAAMsI0HcvCnBpM8MJ+kxPmg0xB4zzlQQGPshFGIyGOnBqk8+hpL07va0pJRpgmGglzsi/GSweDLyccysTA/T+Gq5c4ckJTheWHdCZCTz1wEYmIyJZhr1Mi8gkR+bKIbBeRl0TkZyLSlO1J17aHAYrmsTmXFGMulPFY0+7ICYvBkJyVEfrfA2+cVsmVC2bY7zBPpLOverqQR1U7VXWFqq4ArgT6gZ8BjwLLVfVyYAfw19medFZjDRfPbmDd9uD/YHNJKqUkUlpyHnhzXRVXzGsqCkMSpBAKwNpIiFcPneLYKZMT5pp0QeN8Ju+bqKW4EXhNVfeq6iOqmnDbnwYmlNosGgnx/F6TEw4nXZG+1Aw4ONfDiwd6OHFmyOuuTImMjDAgY9gRcZ+GTY2SczIFjX1kwN8NPDhK+weAX07kQNF2R0742xKrWH4hMga8xEIo4MTBVeHt33ySW7+6MfN61/9+it6B4NzkB+JJKsslMEWpL55dz8yG6qIIX/mNTDk1P+jARaQKeCvw43PaPw0kgO+Nsd/dIrJJRDZ1dZ29y69cOIP6moqieGzOFbFE6Xrgl89t5K7r2lg2q54FzbUsaK4l3FDDM7tP8tj24FSQ8XMxh9HIyAktO2HOyXc5NZhYQYe3AJtVNfNrEpG7gN8FbtQxNIGqeh9wH8CqVasy21SWl3GDKx9T1bwlPA8SGQMeEO8tl5SVCfe89dIRbamUctXf/5r1nV28/Q3BKD4wGE9RHZD4d5poJMyPNh1g874e3rio2evuFA2ZivQ+kRHewbDwiYjcCvwl8FZVnVSZ62h7mCOnBtl+xOSE4ChQgJJToYxFmZtyduOOLpIB0YgP+bQi/YVIZye0MEpuOVuR3uMYuIjUATcDPx3W/HWgHnjUlRd+a6InXxtJVyy3MAqUdghlLKKREN39cV4KSO7qwYR/y6mNRUNNJVcuNDlhrskUNPZ6Jaaq9qlqi6r2Dmtboqrz0xJDVf3wRE8+s6GGS2Y3WHZClyEz4OexZmmIMoF1ATEug3H/VqS/ENFIiK2HT3HU5IQ5o88taJzP68HzKy0tJzxlcsJMCKUUY+BjMaOuiivmN7EhIDf5gVgybxXI80laTmjZCXNH31B+CxqDLwx4mGRKecLkhBZCGYOOSJiXDvYGQiMexBAKwLJZ9cxqqCmq3Oxe0x9L5HUCE3xgwFcuaDI5oUspL+S5EOmUs0GoYD8YT/k+E+FoDJcTxk1OmBP68pyJEHxgwCvKy1izNMT6HVbs2FQoo7N8TiOt06sCUXotiCqUNB3LQpweTLB5b7fXXSkK+ocSec1ECD4w4OCoUY6eGmLb4dKWE5ayDvxCZOSEO/0vJxyMBzOEAk52wooysWX1OeLMUCKvi3jAJwY82u7KCUs8/mYqlLGJRsL09Md50edywsFEMFUoAPUmJ8wp+S5oDD4x4GFXTljqF0486XiX5oGfz5qlrZQJrPd5BsugqlDSRCNhth0+xZFekxNOlXyXUwOfGHBw4m/P7+0OVOKiXGMqlLFpqq3iDQtm+PrxXlUDq0JJ07HMLXZc4k/DuaB/qAQmMdNk5IS7SldOGHOLAZgBH51oe4iXDvRy3KdywlgyhWpwcoGPRmSmKycs8afhXNAXK5FJTIA3zG+ioaaipPMxpEMoleWW2Gs0ou5ik40+9cLTucCrA3wDFhGikRC/NTnhlFBV+oYSeffA83v0CVBRXsYN7SHWdXbxixcPjfhu2ax62mfWe9SzwmE68Atz6ZwGWqdXs66zi/9npf+yEw4FrBrPWEQjYX7w3H7u2/g685trM+31NRVE20OWOTQLhhIpUprfRFbgIwMOcMuls/i/Lx3mzx58YUT7rIYanvrrNxX9hTNkMsILUlbmLDb5zfajJFNKeZm/rodMNZ6AG/DVS1qoqyrny7/qPO+7H/3JtZZyNgsyBY3zHELxlQH/vctns2JeU8YTBXhs+1G+8PB2th4+xaVzGj3sXf5xChpL0d+opkI0EuInmw+wZX8PVy6c4XV3RnC2oHGwb8D1NZVs/MsOuvvPCgqGEklu//oTPLb9mBnwLDhb0LhEJjHBib8taKllSXh65vW2N8wFSiPlbCyRMu97HG5w5YR+TG414P5ogywjTNMyvXrE7/DSOY1c1dZc0nNUE+HMUP7LqYHPDPhohOtrWD63oSQunFgiZfHvcWiqrWLlghm+TC8btIr0EyUaCbH9yGkO9w543RXfky7mkM+CxhAAAw5O5Z7N+3ro7S9ujbgTQgnEkHhKNBLi5YO9dJ32l5xwMJGOgRfnGEYt5WzWpMupTS8VGeGFiEZCJFPK47uK+8IxDzw7/ConTHvgQcxGmA3tM6czu7HGCrBkQcYDL6UY+FismN9E47TKoo+Dx5JmwLPhktmOnNBvqzKLPYTiaMTDPLHrRGbVsDE6mYLGZsBdjbhbwT7l82x0U8EmMbOjrMxZbLJxRxcJHy02GYoXdwgFnKfhM0MJnreUsxekLxMDtxAK4Dw2d50eYuvhU153JW+YB5490UiI3gF/ZScciBePCmUsVi9ppbJcSj5z6HiYB34Oa9MpZ4s4/maTmNlzwxKn2LGfwmrFHkIBmF5dwaqFzawPQHENL+mPJSjLc0FjCJABD9VXc9ncRl/9YHONhVCyp7HWf7mri2Ul5nh0LAvRefQ0h3pMTjgWhShoDAEy4OA8Nm/e1120ckJToUyMaCTMywd7OXbaH7mrBxNJKsvFd0v8c01GTuizSWQ/0V+ATIQQQAOeCkhx28kQS6qFUCZAOqy2cYc/UhAPxpPUFKmEcDhLw9OZ01jDOp8X1/CSMwXIRAhZGHARiYjIlmGvUyLyCRFpFpFHRWSn+2/eE1OsmD+jqOWEsUQy0KlIC82lcxoI1Vf7Zl5kMJ6iusjDJ+BWsI+EeWLXcZMTjkF/LJn3TISQhQFX1U5VXaGqK4ArgX7gZ8CngN+o6lLgN+7nvFLuFrctVjmhqVAmhogQbfePnHAwwBXpJ0pHJERfLMmmvSe97oov6RtKUJvnPCgw8RDKjcBrqroXuB34rtv+XeBtuezYWETbQxw/M8Srh4pPThhPqBVzmCDRSJhTgwm27PdeTjgYD3Y9zIlwXVpOWKRPw1OlUB74RM/wbuBB9/1MVT3svj8CzMxZry7AGjfu+b77nx1xh6upLOdf/2gVi1rrCtGNvGAe+MS5fmkr5WXCh/5904gfTHVFGf/ynisLWgjE8cBLw4BPr67gqrZmvvvkHh5++fCI7/5k7WLee81Cj3rmD/qGEixoqR1/wymStQEXkSrgrcBfn/udqqqIjBrTEJG7gbsBFixYMMluniVUX82nb7uYbUeGeeAKP33hIP/54iH+7MalUz6HVzgywtIwALmicVol/+t3Lualg71nGxV+/uIhfr7lIJ+8ZVnB+jIYT5VMCAXgz29u5wfP7kc5+9N/dvdJ/v3JPSVvwE8NxmmcVpn380zEA38LsFlVj7qfj4rIbFU9LCKzgVFnklT1PuA+gFWrVuUkcP2hNRed17ar6wzrO48F24AnU1RWWAhloty1etF5bQe6B1jf2VVYA55IMr0Aj81+4aq2Zq5qG1nc4V83vs7fP7yNgz0DzG2a5lHPvEVV6emP01QAAz4Rd+EOzoZPAH4BvM99/z7g57nq1GSItofYsr+Hnv6Yl92YNKpKLJGi2mSEOWFtJMSrh05x7FThNOKD8VTRZiLMlmik+FdMj0dfLEkipcyorcr7ubKyFiJSB9wM/HRY8xeBm0VkJ3CT+9kzosvCrkbcH5rgiZKuSG8x8NyQMSQFXGwyVEIqlLFYEp7O3KZpJT252d3nOJGNtT7xwFW1T1VbVLV3WNsJVb1RVZeq6k2q6qme6Ip5TcyorWR9QBcXxF0ZnC3kyQ2XzG4gXF9d0OIDAyWkQhkLJ+VsiCd2HWfIrRFaavQOOCvF/RZC8TXlZcINS4OrEU8viDAPPDekDcnjOwunES8lFcqFiEbC9MeSbNpTmilne9xUH01+CaEEhY5lIU70xXjlUO/4G/uMWNIMeK5Ja8RfKJBGvNRUKGNx3eIWqsrLSjYO3u3Ow83wSwglKKxZGkJ8lmI0W9IeuIVQckdaI16InB2qymDCPHCAuuoK3rioOZC/w1zQ44ZQfBMDDwot06u5fG5jIGv2pT1wy4WSOxpqCpdyNpZMoVr8qWSzJRoJsfPYGQ5093vdlYLT63rgTdMshDJhopEwW/b3ZGaCg0ImBm4eeE6JRkJsPXyKo3mWE6ZzgdsN2CGdcrYUvfDu/jh1VeUFCYcW3dUWjYTQAKacNRVKfoi2u7mr82xISqEaz0RYHKpj3ozSlBP29McLMoEJRWjAL0/LCQN24ZgKJT9cPLuemQ3Vea/hOFgC9TAnQloF9ORrpScn7B2IFWQZPRShAS8vE9a6KUaDJCc0A54fnJSzYR7feTzzlJMPSqWc2kTocOWEz+0uLTlhd3+cGXVmwCdNNBLmRF+Mlw8GR04YsxBK3ohGQpweTLB5b/4MydkQio1fmmtLVE7Y0x8ryAQmFKkBX9MePDlh2gO3SbDcs3ppKxVlktdl9RYDP5/aqgquvqi5oOkM/EDvQLwgEkKYeD7wQNBcV8UV85pY13mMj98UjOyEtpAnf6TlhL98+TDzZ4zM0byqbUZOcoYPJtIhFBu/4UQjYT7/X1vZf7Kf+c35z4/tNelMhIVYxANF6oGD89j84oEeTgZETmgqlPxy22Wz2XOin7/52csjXh//wZacHH8g5njgpZ6N8Fy8SCrmJWeGEiRSWrAQSlF64ODc+b/66508vrOL21fM9bo742KTmPnlj65dyG2XzSalZye2v/fMPv6/3+zkSO8gsxprpnT8tNJiWgHqIAaJi1rrmN88jQ2dx0qiyEM6D0qhQihFay0un9tIc11VYOLgtpAnv4gIofpqZjbUZF63XTYLgA05kBhaDHx00iqgJ3adKAk5YdqAFyIXOBSxAS9z5YRByU4YS+cDNwNeMCIz65nVUMO67VO/yWdkhPYEdR4dy0IMxJM8u7v4K9j3DLjL6M0DnzrRSIiTfbGR9RJ9ioVQCs/w3NVT1YibBz42117USlVFWWCehqdCJpWsLeSZOjdkshP6X4dqBtwbopEwp4cSPD9Fjbgt5BmbaVXlXL2oORC/w6mSLuloS+lzQFpOGIQ7fzyZokyclaRG4Vi9pIWKMplyBsvBRJLKcrHxG4NoJMxrXX3sP1nc2Qkzk5jmgeeGjkiYFw/0cOLMkNdduSCxZMq8bw+or6lkVduMKSe7GoglqTEJ4Zh0lEix456BwmUihBIw4OnshI/7vNhxLJGyCUyP6IiE2X7kNId7ByZ9jKFEkhqTEI7JotY6FjTXBuJpeCp098cKFj6BEjDgl81tpKWuyvd3fvPAvSOdu3oqXriVU7swZ7MTnshM+BYjvf3xgilQoAQM+HA5YdLHckLzwL2jfeZ0ZjfWTCkOPhi3EMp4dETCRS8n7BkwA55z1kZCdPfHeelAYYrbToZYwjxwr3C8Q2exSVoNNFGsIv34XHNRS9HLCS2EkgfWLA1R5vPshPFkyvKgeEg0EuLMFOSEFkIZn2lV5VxzUUvei2t4SW9/vGAacMjSgItIk4g8JCLbRWSbiFwrIitE5GkR2SIim0Tkjfnu7GSZUVfFFfObfJ1Qxzxwb1m9pJXKcpm0cRkwDzwrou0hXu/qY9+J4pMTqqpvQyhfA/5bVZcBVwDbgH8EPquqK4DPuJ99S0ckzEs+lhPaJKa3TK+u4Kq2ZtZPclm9hVCyo2OZW+y4CL3w00MJkiktWB4UyMKAi0gjsAb4DoCqxlS1B1Cgwd2sETiUr07mAr8XO44lLITiNdFIiM6jpznUM3E54VAiZQY8Cxa11rGwpTjlhL0FXsQD2aWTXQR0AfeLyBXA88DHgU8AvxKRe3FuBNflrZc5YPmcRlqnV/Gpn7zMZ/9za/o5LVkAAB1sSURBVKa9okz4pz9Ywdr2kIe9czzw6dVFm903EEQjYb7w8HbWd3bxh1cvmNC+fUMJS2SVJdH2EP/+9F5WfO6REe1vvWIOn7t9uUe9mjqZPCgF9MCzsRgVwErgY6r6jIh8DfgUjtf956r6ExH5AxwP/aZzdxaRu4G7ARYsmNiPIpeUlQl///bLeHLXyAU9/7HlED95/oD3BjyRorLWDICXLA1PZ27TNNZ3HpuQAT/Q3c+x00NEZk29sk8p8MEbLqKsTEZkCd1yoJcfbdrP39x2cWCfZLrdPCiFqsYD2RnwA8ABVX3G/fwQjgG/HscTB/gx8O3RdlbV+4D7AFatWuWpEPuWS2dxy6WzRrSdHkrw2PZjJFPqaR6LeNJ04F4jIqyNhPj5CwcnNKmcDgek47vGhZnfXMvf/t6lI9rWdR7j/fc/xzO7T3ruTE2WnoG0B+6jSUxVPQLsF5GI23QjsBUn5r3WbXsTsDMvPcwz0UiYnv44L3qsETcVij+ItofoiyXZtDf7xSbrO48xv3kaF7XW5bFnxc21F7VQXRHsCva9rgfeWKByapC9CuVjwPdE5CVgBfAF4EPAP4nIi+7nu/PTxfyyZmmrLzTiNonpD65z5YTZLqsfSiR58rUTRNvDiFgmwslSU+loxKeaVMxLuvt96IEDqOoWVV2lqper6ttUtVtVf6uqV6rqFap6tao+n+/O5oOm2iresGCG53f+WFLNA/cB06sreOOi5qyX1T+3u5v+WJKOZcF87PcTHZEQrx/vY++JPq+7Mil6+uNMr64oqCNmFgPnsfmlA70c91AjHkskqTYD7gui7WF2HD2TlZxwfecxqirKuPai1gL0rLhJJxXz+ml4svQMxAoqIQQz4MDZC2ejhys1Y8kUleX2CO4Hopnc1eNfD+s6j3H1omarRp8D2lrraGup9fxpeLL0FDgTIZgBB+DSOQ20Tq/29M4ftxCKb1gyTE54Ifaf7Oe1rr6MA2BMnWgkzFOvBzPlbE9/rKCrMMEMOHA25ezGnd6knE2mlGRKqSo3L84PDC92fKHshOncOulqM8bUiUZCDMZTPP36Ca+7MmF6BuI0mgfuDdFIiJ7+OFv2F15OmDYSlRUWQvEL0UjYkRPuGVtOuH77MRY017LI5IM545qMnDB4cfCeAmciBDPgGW5w5YQbPIi/xZJuRXqTEfqG6xa3UFVeNmYGy8G4Kx+MhEw+mENqKsu5dnELG3ycOXQ0Uim1EIqXNNVWsXLBDE9SzqY9cFOh+Ie66gquWjS2vPS5PScZiCczE55G7uiIhNl9vI89x4MjJzwTS5DSwmrAwQz4CKIRR07YdbqwcsK0B24LefxFR8SREx4cRU64bnuXyQfzRDSAFex7+gqfiRDMgI/AKzlh3PXATYXiLy5kSNbvOMY1F7WYfDAPLGypY1Frna8LsJxLz0A6kZWFUDzjktmunLDAF04mBm4G3FcsDqXlhCOvh/0n+3m9q49oQJMuBYG17SGeClAF+x4PltFDdtkIS4ayMkc+9sirR7hv42sjvrtsbhPXLm7Jy3kzKhQLofgKEaFjWYifbj444np49dApwLIP5pOOZWEeeHIP//DwNubOmJZpn15dybuumu9p5tDRSKeSNQPuMb9z+Wx+svkAX3h4+4j2xmmVPP8/b6IiD0bWPHD/cttls/n+M/vOux6Wz20w+WAeuXpRM+H6ar771N7zvpvdVEOHzxZP9Q4UvpgDmAE/j45ImG2fu3XEgp5Hth7hz3/4Ii8e6OHKhc05P2dGhWIeuO+4bnErW8+5HoDAFh0ICjWV5TzxqTeNWEgVS6S49ou/YUNnl+8MeI8H5dTAYuCjUlNZTl11Reb1pshMysuEdZMseDseZxfy2HD4kXOvh7rqCt89whcjleVlI/7PZ9RVcd3i1qwzRRaS7v5YwTMRghnwrGisrWTlgqa8VdKO20Iew8iKaCTE3hP97PaZRrzXg0RWYAY8a6KRMK8cPMWx04M5P3bMZISGkRXR9nTKWX954T0DZsB9TbpO38Ydx8fZcuLYQh7DyI4FLbVc1Frnu1wp3f0xmgpYSi2NWYwsuXROA+H66rzE32wpvWFkTzrl7EDMPxpxC6H4HBEn5ezjO7pIJMdOMToZTEZoGNkTjYSIJfyVctZCKAEgGglzajCR85SztpDHMLLnjYuamVZZ7ps4eDoToYVQfM71S1sdOWGOL5y4eeCGkTXplLPrOrtQLXwBlnM5PeRNJkIwAz4hGqdVcuWCGTmfQMmoUMwDN4ys6IiE2HfSH3LC3n5vVmGCGfAJszYS4tVDpzh2KndywrMhFFscYhjZ4KcK9pk8KAVehQlmwCdMJsVoDjMWxpJKVXmZVXYxjCyZ31zLRaE6X6zK7HHzoMyo86kBF5EmEXlIRLaLyDYRudZt/5jb9qqI/GN+u+oPLpntyAk35PDOH0ukLP5tGBMk2h7mmd0nPZcT9rgeeKOPJzG/Bvy3qi4DrgC2iUgHcDtwhapeCtybpz76inTF8o07cycnjCWTFj4xjAnSscyREz71eu4X102Es5kIfeiBi0gjsAb4DoCqxlS1B/gI8EVVHXLbvX+WKRDRSJjTgwk278uNnDCeUPPADWOCpOWE+Uoyly3dbjk1v8bAFwFdwP0i8oKIfFtE6oB24AYReUZENojIVXntqY9IywlzpUONJS2EYhgTpbqinOsWt7B+xzFP5YTd/THqqyvyUitgPLI5YwWwEvgXVX0D0Ad8ym1vBq4BPgn8SEaZhRORu0Vkk4hs6uryfsY4FzTUVHLlwtzJCWOJlC3iMYxJEF0WZv/JAV73UE54oHuAOU3Txt8wD2RjNQ4AB1T1GffzQzgG/QDwU3V4FkgB55XoVtX7VHWVqq4KhYqnhmA0EmLr4VMczYGcMJZMmQbcMCZBui7puu3eRXD3nOijrbXWk3OPazVU9QiwX0QibtONwFbgP4AOABFpB6oAb2cTCkg6rWUu1CixRMoSWRnGJJjfXMviUB0bPKpgn0wp+07009biTXm9bK3Gx4DvichLwArgC8C/AReJyCvAD4D3qR/WtRaIi2fXM7OhOidFHiyEYhiTpyMS5pnXT9IfSxT83Id7B4glU7R5VB81K6uhqlvcMMjlqvo2Ve121SjvUdXlqrpSVR/Ld2f9hIgQbQ/z+M7jmVwmkyVuk5iGMWmikTCxZIqnXit8dsI9x/sBWNji0xCKMTbRSMiRE+7tntJxTIViGJPnqkUzqK0q92RV5u4TzuTpIj974MborF7aSkWZTHlZvYVQDGPyOHLCVtZ7kJ1w7/E+airLmFlfU9DzpjGrMQVyJSc0D9wwpkY0EuJA9wCvdRVWTrjnRB8Lm+soK/NmJbVZjSkSjYTZdvgUR3onLyeMJUxGaBhTIZNkrsBhlD0n+j2TEIIZ8CnTscy5cDZMQY1iBtwwpsa8GbUsDU8vaHrZjITQo/g3mAGfMpGZ9cxqqJnShWMqFMOYOtFIiGd3n6RvqDBywkM9roTQIw04mAGfMunshL+dgpzQJjENY+oUWk6494QjITQDHnCikTCnhxI8P0k5oU1iGsbUWdU2g7oCygm9lhCCGfCcsHpJiyMnnEQYRVWJJy2drGFMleqKcq5bUjg54R5XQhiur877ucbCrEYOqK+pZFXbjEnNgMfSFemtoINhTJloJMTBngFe6zqT93PtPdFHW4t3EkJwUsIaOaAjEuYffrmdL/33diqHDejCljreceW8MffLVKQ3D9wwpky62PEXf7mdS2Y3ZNory8v4o+vaaMxh0YXdx/tYEp6es+NNBjPgOeLW5bP4+mO7+NaG1zJt6ae465a0MLtx9HzBB3sGAGiu8+4xzDCKhblN07hucQu/2X6M3wxLMasKNZXlfGjNRTk5TzKl7D85wE2XzMzJ8SaLGfAcsbCljpc/e8uIts4jp7nlqxvZ0NnFu9+4YNT90nHz65ecl0rdMIxJ8P0PXXNe25u/soH1O47lzICnJYSLPFSggMXA80r7zOnMabywRnx95zGWzapnVqM3uRQMoxToiIR5bnd3zjTie1wFykIz4MWLiLA2Eua3u45nYt3DOT0YZ9OebjqWhT3onWGUDmsjIWLJFE/mSCO+x9WAeykhBAuh5J1oJMSDz+7j+b3dXLu4ZcR3T+w6TiKlmbJQpUQ8HufAgQMMDk69JF2xUVNTw7x586isLHyV82Jl1cLmjEb85hzErdMSwpkN3s5dmQHPM6uXtFJZLqzfcew8A76+s4v66gpWLpzhUe+848CBA9TX19PW1sYotbBLFlXlxIkTHDhwgEWLFnndnaKhqqKM1Uta2eBqxKd6ze057kgIvb52LYSSZ6ZXV3BVWzPrt4+Mg6sq6zu7uH5pa0kuox8cHKSlpcXzH4DfEBFaWlrsySQPdCwLc7BngF3Hpq4R3+NqwL2m9CyHB0QjITqPnuaQKxkE2H7kNEdODdIRKd34txnv0bH/l/yQTjk71aX2aQmhl1kI05gBLwDpxQXDK2enlSlrI6UX//YLe/bsYfny5Vlv/8ADD3Do0KHM569+9av09/fno2tGHpjdOI3IzPopp5w9m4XQuzzgacyAF4Cl4bSc8Oydf33nMS6e3cDMBpMPBoVcGPBkMpnrbhkTIBoJ8dyek5yZgpwwLSE0D7xEEBGiy8L8dqcjJzw9GOf5vd10mPftOYlEgjvvvJOLL76Yd77znfT39/O5z32Oq666iuXLl3P33Xejqjz00ENs2rSJO++8kxUrVvC1r32NQ4cO0dHRQUdHBwCPPPII1157LStXruT3f//3OXPGibW2tbXxV3/1V6xcuZIvfvGLrFy5MnP+nTt3jvhs5JdoJEw8qTy56/ikj7HnuGvAfRADNxVKgYi2h/j+M/vYtPckpwbijnywhOPfw/nsf77K1kOncnrMS+Y08Le/d+m423V2dvKd73yH1atX84EPfIBvfvOb/Omf/imf+cxnAHjve9/Lf/3Xf/HOd76Tr3/969x7772sWrUKgK985SusW7eO1tZWjh8/zt/93d/x61//mrq6Or70pS/xz//8z5njtLS0sHnzZgB+/etfs2XLFlasWMH999/P+9///pz+7cbYrGqbwfTqCtZ1dvHmS2dN6hh7TvQzrbLccwkhmAdeMK5z5YQbOrtYt72L+poKVi5o8rpbJc/8+fNZvXo1AO95z3v47W9/y7p167j66qu57LLLeOyxx3j11VfHPc7TTz/N1q1bWb16NStWrOC73/0ue/fuzXz/rne9K/P+gx/8IPfffz/JZJIf/vCH/OEf/mHu/zBjVCrLy1i9pIUNnccmnXJ2z/E+FrbU+mKyOSsPXESagG8DywEFPqCqT7nf/QVwLxBS1ck/lxQ5aTnhY9uPcXowwQ1LW6koQfngaGTjKeeLc3+EIsJHP/pRNm3axPz587nnnnuykvSpKjfffDMPPvjgqN/X1Z193H7HO97BZz/7Wd70pjdx5ZVX0tLSMuo+Rn6IRsL86tWj7Dx2hvaZ9RPef/eJPtrDE98vH2RrQb4G/LeqLgOuALYBiMh84M3Avvx0r7joiITZeewMR04NWvjEJ+zbt4+nnnoKgO9///tcf/31ALS2tnLmzBkeeuihzLb19fWcPn161M/XXHMNTzzxBLt27QKgr6+PHTt2jHrOmpoabrnlFj7ykY9Y+MQDMnLC7ROXEzoSQm8LGQ9nXAMuIo3AGuA7AKoaU9Ue9+uvAH+J45Ub4xAdNmlZisvn/UgkEuEb3/gGF198Md3d3XzkIx/hQx/6EMuXL+eWW27hqquuymx711138eEPf5gVK1YwMDDA3Xffza233kpHRwehUIgHHniAO+64g8svv5xrr72W7du3j3neO++8k7KyMt785jcX4s80hjG7cRrLZtWzrvMYg/HkhF67j/cRTyqLWr2XEALIeHEgEVkB3AdsxfG+nwc+DtwEvElVPy4ie4BV44VQVq1apZs2bcpFvwOJqnL9l9bROK2Shz9+g9fd8ZRt27Zx8cUXe90Nz7j33nvp7e3l85///Kjfl/r/T7754i+3j8jdP1F+ePc1XH1R4UJfIvK8qq46tz2bGHgFsBL4mKo+IyJfA+7B8crHdR9E5G7gboAFC0bPiV0qiAjfvHOlVd8pcd7+9rfz2muv8dhjj3ndlZLlgzcsoqWuikRq4sGD6TUVrGprzkOvJk42Hvgs4GlVbXM/34BjwC8D0qsY5gGHgDeq6pGxjlXqHrhxFvMwL4z9/xjDGcsDH9cVdA3yfhGJuE03AptVNayqba5hPwCsvJDxNgzDMHJLtgt5PgZ8T0SqgNcBmzo3pkwu0noWI5PVJxulR1YGXFW3AOe578O+b8tVh4zSoKamhhMnTlhK2XNI5wOvqbEcOcb42FJ6wxPmzZvHgQMH6OqaWma4YiRdkccwxsMMuOEJlZWVVnHGMKaI6dkMwzACihlwwzCMgGIG3DAMI6CMu5AnpycTOQ10ntPcChRzFsNGoNfrTuQZG8PgU+xjCMEex4iqnpcCsdCTmJ3nriYSkU2jrTAqFkTkPlW92+t+5BMbw+BT7GMIwR5HERl1CbuFUPLPf3rdAWPK2BgWB0U3jmbA84yqFt1FU2rYGBYHxTiOhTbg92XZZgQLG8PgY2Pob0Ydn4IacFU9rxOjtfkVEfk3ETkmIq8Ma/uyiGwXkZdE5Gdu+bnR9r1VRDpFZJeIfGpY+yIRecZt/6GbbyZQ2BjaGBaSUhzDscbHQigT4wHg1nPaHgWWq+rlwA7gr8/dSUTKgW8AbwEuAe4QkUvcr78EfEVVlwDdwB/np+uGywPYGAadB7AxBHJswEe7u2V7ZxORv3a36RSRWy50TK9Q1Y3AyXPaHlHVhPvxaZzc6OfyRmCXqr6uqjHgB8Dt4mRxehOQLrz4XeBteel8ltgYBn8MobjHsVTGMBtyZsAvcHcb987mbvdu4FKcO+s3RaR8nDumH/kA8EsAEZkjIg+77XOB/cO2O+C2tQA9wy68dLsn2BgCAR9DsHGkCMYwW3LpgY96dyO7O9vtwA9UdUhVdwO73OONdUzfISKfBhLA9wBU9ZCq3uZtryaMjWHwxxBKeByLaAyzIpcGfKy726h3NhF5q4h8bpx9x2r3FSJyF/C7wJ06+tLWg8D8YZ/nuW0ngCYRqTin3StsDIM/hlCi41hkY5gVnk1iquovVPUzXp0/V4jIrcBfAm9V1f4xNnsOWOrGIKtwHlF/4V5k64B3utu9D/h5vvucK2wMgz+GUBzjWKpjmEsDPtbdLZs721j7jtXuCSLyIPAUEBGRAyLyx8DXgXrgURHZIiLfcrfNxN5cr+dPgV8B24Afqeqr7mH/Cvh/RWQXTizuOwX9o0ZiYxj8MYQiH8cSGcPsUNWcvHDyqrwOLAKqgBdxJkJ+DLzb3eZbwEdH2fdSd/tqd//XgfKxjpmrPtvLxrAYXzaOpfPK9YVzG44G8zXg027bRcCzOJMhPwaq3fa3Ap8btu+n3f06gbdc6Jj2yuMFYWNYFC8bx9J4FTSdrGEYhpE7bCWmYRhGQDEDbhiGEVCmZMBFZL6IrBORrSLyqoh83G3/vDhJZbaIyCMiMmeM/de7S3O3uK93jradu+09IvI/ptJfY3TGGsdh3/+FiKiItI6xv42jx1zgt3iPiBwcNjajLmoRkQdEZPew7f7sAue6S0S+nq+/xcieqVbkSQB/oaqbRaQeeF5EHgW+rKr/C8C9ED4DfHiMY9ypqqNWmzAKxqjjqKpbRWQ+8GZg3zjHsHH0lrF+i+Asn783i2N8UlUfGn8zwy9MyQNX1cOqutl9fxpHWzlXVU8N26wOyHqmVERCIvITEXnOfa0e9vUVIvKUiOwUkQ9Npe/GWcYaR/frr+AskJjQbLeNY2EZZwwnhYjUiZO69VkReUFEhi+dn+8+ee0Ukb+dynmMKZArOQvQhuOlNbif/x5n6e0rQGiMfdbjSJW2uK8W4PvA9e73C4Bt7vt7cLSn03AKsO4H5ngt4ym21/BxxMl18TW3fQ/QauPo/9c5Y3iPO3YvAf8GzBhjnweA3cPG8DLgC8B73O+bcCSEdcBdwGF3nKe5v/FVXv/dpfjKySSmiEwHfgJ8Ql3vW1U/rarzcZLK/OkFdr9TVVe4rxPATcDXRWQL8AugwT0+wM9VdUBVj+MsfX1jLvpvOAwfR5xH8r/BCX9lg42jDxjlt/gvwGJgBY7R/acL7P7JYWP4Mk7o7FPuGK4HanBuxgCPquoJVR0Afgpcn5c/yLggU65KLyKVOBfM91T1p6Ns8j3gYeBvReRXwExgk6p+cIxDlgHXqOrgOeeB8x/jTcSeI84dRxG5DGfV3Yvu//08YLOIvBEnk52No88Y7beoqkeHff+vwH+57+8H3gBcKFufAO9Q1c5zznM1Noa+YKoqFMHJGbBNVf95WPvSYZvdDmwHUNVb3Lv7WD96gEeAjw071orhxxKRGhFpAaI4yWmMKTLaOKrqy6oaVtU2VW3DyT63UlWP2Dj6jwv8FmcP2+ztOOEOVPX97hheKNXqr4CPucdGRN4w7LubRaRZRKbhpKV9Ikd/ijEBpuqBrwbeC7zsPmaB89j9xyISAVLAXsZWoIzGnwHfEJGX3P5tHLb/SziP3K3A51X10BT7bziMOo6q+vAF9hkPG8fCMtZv8Q735qk4sfA/mcAxPw98FXhJRMpwYuS/6373LI63Pw/4P2oKJE+wpfSGYRgBxVZiGoZhBBQz4IZhGAHFDLhhGEZAybkBv0BOhmYRedRdufWoiMxw2+8UJ2/KyyLypIhcMexYt7o5NnaJyKdy3VfDMIwgk/NJTFe2NFuH5WTAkRndBZxU1S+6xniGqv6ViFyHI33qFpG3APeo6tUiUo6z8utmHAnbc8Adqro1px02DMMIKDn3wHXsnAy34ywAwf33be42T6pqt9v+NI4sCZzVebtU9XVVjQE/cI9hGIZhkOcYuIi04az2egaYqaqH3a+O4KzkO5c/Bn7pvp+LkycjzQGmmJzHMAyjmJjyUvqxODcng7uYCwBVVRHRc7bvwDHgllPBMAwjC/LigY+RH+Voelmv+++xYdtfDnwbuN1NhARwEJg/7LDz3DbDMAyD/KhQRs3JgJOR7n3u+/cBP3e3X4CTzey9qrpj2PbPAUtFZJGIVAHvdo9hGIZhkB8VyvXA48DLOLlQwMnJ8AzwI5x0lHuBP1DVkyLybeAdbhtAQlVXuce6DScXQznwb6r69zntrGEYRoCxXCiGYRgBxVZiGoZhBBQz4IZhGAHFDLhhGEZAMQNuGIYRUMyAG4ZhBBQz4IavEZEmEfmo+36OiDyUx3OtcKWrhhEIzIAbfqcJ+CiAqh5S1Xfm8VwrADPgRmAwHbjha0QknYWyE9gJXKyqy0XkLpyMlnXAUuBeoAqnsO8QcJu7UGwx8A0gBPQDH1LV7SLy+8DfAkmgF7gJ2AVMw0nZ8A84RXy/BtQAA8D7VbVzAudeD7wIrMXJO/QBVX02P/9TRkmiqvayl29fQBvwyijv78IxuPU4xrkX+LD73VdwkqgB/AZY6r6/GnjMff8yMNd93zTsmF8fdu4GoMJ9fxPwkwmeez3wr+77Nem+28teuXrlLRuhYRSAderknD8tIr3Af7rtLwOXuxkxrwN+PCwbZrX77xPAAyLyI5xcPKPRCHxXRJYCClRme+5h2z0IoKobRaRBRJpUtWeSf69hjMAMuBFkhoa9Tw37nMK5tsuAHlVdce6OqvphEbka+B3geRG5cpTjfx7HUL/dzW2/fgLnzpzq3FNf4O8xjAlhk5iG3zmNE6qYMKp6CtjtxrsRhyvc94tV9RlV/QzQhZO6+NxzNXI2hfFdk+s+73LPdz3Qq6q9kzyOYZyHGXDD16iTH/4JEXkF+PIkDnEn8Mci8iLwKmfL8n3ZLaT9CvAkzmTjOuASEdkiIu8C/hH4BxF5gck/rQ66+38Lp2CJYeQMU6EYRp5wVSj/Q1U3ed0XozgxD9wwDCOgmAduGIYRUMwDNwzDCChmwA3DMAKKGXDDMIyAYgbcMAwjoJgBNwzDCChmwA3DMALK/w+LDxxq8gRczgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the last hours in the dataset for testing against predictions. This lets you evaluate how your model will perform on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 21:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time = hourly.tail(1).index[0]\n",
    "last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 18:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_time = last_time - pd.Timedelta('3 hour')\n",
    "cut_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 14:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 15:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 16:00:00  fffaee1fbb9c96703850f64d3262e843     62.0\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843     64.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843     68.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = hourly.loc[hourly.index <= cut_time]\n",
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 19:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 20:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 21:00:00  0001495ce5f079703599a94c32dab2b0     76.0\n",
       "2020-02-25 19:00:00  00134c004e33e830e5dbce3355a485b9     76.0\n",
       "2020-02-25 20:00:00  00134c004e33e830e5dbce3355a485b9     76.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = hourly.loc[hourly.index > cut_time]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = train_set[train_set[\"device_id\"] == sample_device_id][\"battery\"]\n",
    "sample_test = test_set[test_set[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2020-02-25 14:00:00    64.0\n",
       "2020-02-25 15:00:00    64.0\n",
       "2020-02-25 16:00:00    64.0\n",
       "2020-02-25 17:00:00    66.0\n",
       "2020-02-25 18:00:00    70.0\n",
       "Name: battery, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 22:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  battery\n",
       "timestamp                                                     \n",
       "2020-02-25 19:00:00  8e4a851ed2317a249a0903f29d894361     76.0\n",
       "2020-02-25 20:00:00  8e4a851ed2317a249a0903f29d894361     75.0\n",
       "2020-02-25 21:00:00  8e4a851ed2317a249a0903f29d894361     75.0\n",
       "2020-02-25 22:00:00  8e4a851ed2317a249a0903f29d894361     75.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fadc03b8978>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sample_train.plot()\n",
    "sample_test.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data from pandas DataFrame to the expeted JSON Lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def df_to_tss(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df[\"timeindex\"] = df.index\n",
    "    cats = {}\n",
    "    tss = {}\n",
    "    for index, row in df.iterrows():\n",
    "        target = row[\"battery\"]\n",
    "        if not(math.isnan(target)):\n",
    "            identity = row[\"device_id\"]\n",
    "            cat = cats.get(identity)\n",
    "            if not cat:\n",
    "                cat = len(cats)\n",
    "                start = str(row[\"timeindex\"])\n",
    "                ts = {\n",
    "                    \"start\": start,\n",
    "                    \"cat\": [cat],\n",
    "                    \"target\": [],\n",
    "                }\n",
    "                cats[identity] = cat\n",
    "                tss[cat] = ts\n",
    "            ts = tss.get(cat)\n",
    "            ts[\"target\"].append(target)\n",
    "    return tss\n",
    "\n",
    "def tss_to_jsonl(tss):  \n",
    "    result = \"\"\n",
    "    for key, value in tss.items():\n",
    "        jsonll = json.dumps(value)\n",
    "        result += jsonll\n",
    "        result += \"\\n\"\n",
    "    return result[:-1]\n",
    "\n",
    "def df_to_jsonl(dataframe):\n",
    "    return tss_to_jsonl(df_to_tss(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017743587493896484\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [0], \"target\": [75.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [1], \"target\": [76.0, 75.0, 75.0, 74.0, 74.0, 75.0, 75.0, 75.0, 73.0, 72.0, 71.0, 71.0, 70.0, 69.0, 69.0, 68.0, 68.0, 67.0, 66.0, 66.0, 65.0, 65.0, 64.0, 64.0, 63.0, 64.0, 65.0, 69.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [2], \"target\": [75.0, 75.0, 75.0, 74.0, 74.0, 75.0, 75.0, 75.0, 73.0, 72.0, 71.0, 71.0, 70.0, 69.0, 68.0, 68.0, 67.0, 67.0, 66.0, 66.0, 65.0, 64.0, 64.0, 63.0, 63.0, 63.0, 65.0, 68.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [3], \"target\": [76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 73.0, 72.0, 72.0, 71.0, 70.0, 70.0, 69.0, 69.0]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "jsonl = df_to_jsonl(train_set.head(100))\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)\n",
    "print(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.25048232078552\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_tss = df_to_tss(train_set)\n",
    "train_jsonl = tss_to_jsonl(train_tss)\n",
    "\n",
    "test_tss = df_to_tss(test_set)\n",
    "test_jsonl = tss_to_jsonl(test_tss)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the json lines files locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mt-battery-deepar/input/train.json', './mt-battery-deepar/input/test.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "prefix = \"mt-battery-deepar\"\n",
    "input_path = \"./{}/input\".format(prefix)\n",
    "\n",
    "train_path = \"{}/train.json\".format(input_path)\n",
    "test_path = \"{}/test.json\".format(input_path)\n",
    "(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(input_path, ignore_errors=True)\n",
    "pathlib.Path(input_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"w\") as text_file:\n",
    "    print(train_jsonl, file=text_file)\n",
    "\n",
    "with open(test_path, \"w\") as text_file:\n",
    "    print(test_jsonl, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.0M\r\n",
      "1048684 drwxrwxr-x 2 ec2-user ec2-user 4.0K May 14 08:26 .\r\n",
      "1048683 drwxrwxr-x 3 ec2-user ec2-user 4.0K May 14 08:26 ..\r\n",
      "1048686 -rw-rw-r-- 1 ec2-user ec2-user 1.3M May 14 08:26 test.json\r\n",
      "1048685 -rw-rw-r-- 1 ec2-user ec2-user 3.8M May 14 08:26 train.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls -liah \"{input_path}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload train and test sets to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: mt-battery-deepar/input/test.json to s3://mt-ml-workshop-pi1g9mn3/mt-battery-deepar/test.json\n",
      "upload: mt-battery-deepar/input/train.json to s3://mt-ml-workshop-pi1g9mn3/mt-battery-deepar/train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync \"{input_path}/\" \"s3://{bucket}/{prefix}/\" --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14 08:26:43    1325499 test.json\r\n",
      "2020-05-14 08:26:43    3906490 train.json\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls \"s3://{bucket}/{prefix}/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://mt-ml-workshop-pi1g9mn3/mt-battery-deepar/train.json',\n",
       " 'test': 's3://mt-ml-workshop-pi1g9mn3/mt-battery-deepar/test.json'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_input = {\n",
    "    \"train\": \"s3://{}/{}/train.json\".format(bucket,prefix),\n",
    "    \"test\": \"s3://{}/{}/test.json\".format(bucket,prefix)\n",
    "}\n",
    "dar_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different [ML instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/) in training lets you control how efficiently models learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You can train DeepAR on both GPU and CPU instances and in both single and multi-machine settings. We recommend starting with a single CPU instance (for example, ml.c4.2xlarge or ml.c4.4xlarge), and switching to GPU instances and multiple machines only when necessary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_instance_type='ml.c5.2xlarge' #Estimated Training Time: 10m\n",
    "train_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'224300973850.dkr.ecr.eu-west-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "dar_image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')\n",
    "dar_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "dar_estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=dar_image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=train_instance_type,\n",
    "    base_job_name=prefix,\n",
    "    output_path=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 'H'\n",
    "prediction_length = 4\n",
    "context_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dar_hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"3\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"20\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"cardinality\": \"auto\",\n",
    "    \"num_dynamic_feat\":\"ignore\"\n",
    "}\n",
    "dar_estimator.set_hyperparameters(**dar_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14 08:26:44 Starting - Starting the training job...\n",
      "2020-05-14 08:26:45 Starting - Launching requested ML instances...\n",
      "2020-05-14 08:27:44 Starting - Preparing the instances for training......\n",
      "2020-05-14 08:28:28 Downloading - Downloading input data...\n",
      "2020-05-14 08:29:11 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'ignore', u'dropout_rate': u'0.05', u'mini_batch_size': u'32', u'learning_rate': u'0.001', u'num_layers': u'3', u'prediction_length': u'4', u'epochs': u'20', u'time_freq': u'H', u'context_length': u'12', u'num_cells': u'40', u'cardinality': u'auto', u'likelihood': u'gaussian', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] Final configuration: {u'dropout_rate': u'0.05', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_layers': u'3', u'epochs': u'20', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'num_dynamic_feat': u'ignore', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'4', u'time_freq': u'H', u'context_length': u'12', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] [num_dynamic_feat=ignore] Not using any `dynamic_feat` feature that may be in the data.\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:27 INFO 140074512123712] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] [cardinality=auto] Inferred value of cardinality=[16945] from dataset.\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] Integer time series\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] number of time series: 16945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] number of observations: 480294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] mean target length: 28\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] min/mean/max target: 1.0/69.7193739668/100.0\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] mean abs(target): 69.7193739668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:28 INFO 140074512123712] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Test set statistics:\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Integer time series\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] number of time series: 16826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] number of observations: 51669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] mean target length: 3\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] min/mean/max target: 13.0/75.9952776326/100.0\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] mean abs(target): 75.9952776326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] nvidia-smi took: 0.0251288414001 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 33.69402885437012, \"sum\": 33.69402885437012, \"min\": 33.69402885437012}}, \"EndTime\": 1589444970.388557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589444970.353987}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 112.74504661560059, \"sum\": 112.74504661560059, \"min\": 112.74504661560059}}, \"EndTime\": 1589444970.466859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589444970.388632}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Epoch[0] Batch[0] avg_epoch_loss=4.726706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.72670555115\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Epoch[0] Batch[5] avg_epoch_loss=4.294582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.29458161195\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:30 INFO 140074512123712] Epoch[0] Batch [5]#011Speed: 1046.79 samples/sec#011loss=4.294582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch[10] avg_epoch_loss=4.186598\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=4.05701713562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch [10]#011Speed: 754.54 samples/sec#011loss=4.057017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch[15] avg_epoch_loss=4.027122\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=3.67627463341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch [15]#011Speed: 1054.63 samples/sec#011loss=3.676275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch[20] avg_epoch_loss=3.843330\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=3.2551949501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch [20]#011Speed: 794.70 samples/sec#011loss=3.255195\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch[25] avg_epoch_loss=3.652830\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=2.85272908211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch [25]#011Speed: 1031.92 samples/sec#011loss=2.852729\u001b[0m\n",
      "\n",
      "2020-05-14 08:29:24 Training - Training image download completed. Training in progress.\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch[30] avg_epoch_loss=3.494927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=2.67383499146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch [30]#011Speed: 762.34 samples/sec#011loss=2.673835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch[35] avg_epoch_loss=3.337543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=2.36176242828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:31 INFO 140074512123712] Epoch[0] Batch [35]#011Speed: 1069.60 samples/sec#011loss=2.361762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch[40] avg_epoch_loss=3.217920\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=2.35663552284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch [40]#011Speed: 790.41 samples/sec#011loss=2.356636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch[45] avg_epoch_loss=3.121720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=2.33287987709\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch [45]#011Speed: 1074.63 samples/sec#011loss=2.332880\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch[50] avg_epoch_loss=3.030460\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=2.19086117744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch [50]#011Speed: 752.59 samples/sec#011loss=2.190861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch[55] avg_epoch_loss=2.956564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=2.20283129215\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch [55]#011Speed: 1005.43 samples/sec#011loss=2.202831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch[60] avg_epoch_loss=2.903247\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=2.30609064102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch [60]#011Speed: 780.63 samples/sec#011loss=2.306091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch[65] avg_epoch_loss=2.841672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=2.09045698643\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:32 INFO 140074512123712] Epoch[0] Batch [65]#011Speed: 1072.52 samples/sec#011loss=2.090457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch[70] avg_epoch_loss=2.789934\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=2.10700287819\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch [70]#011Speed: 1070.73 samples/sec#011loss=2.107003\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch[75] avg_epoch_loss=2.740027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=2.03134772778\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch [75]#011Speed: 776.13 samples/sec#011loss=2.031348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch[80] avg_epoch_loss=2.688492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=1.90515847206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch [80]#011Speed: 1073.49 samples/sec#011loss=1.905158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch[85] avg_epoch_loss=2.640512\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=1.86323223114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch [85]#011Speed: 693.42 samples/sec#011loss=1.863232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch[90] avg_epoch_loss=2.595939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=1.82927958965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:33 INFO 140074512123712] Epoch[0] Batch [90]#011Speed: 858.50 samples/sec#011loss=1.829280\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch[95] avg_epoch_loss=2.560479\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=1.91511034966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch [95]#011Speed: 542.06 samples/sec#011loss=1.915110\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch[100] avg_epoch_loss=2.515486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=1.65162334442\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch [100]#011Speed: 770.23 samples/sec#011loss=1.651623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch[105] avg_epoch_loss=2.479989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=1.76293776035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch [105]#011Speed: 548.11 samples/sec#011loss=1.762938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch[110] avg_epoch_loss=2.468091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=2.21586198807\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:34 INFO 140074512123712] Epoch[0] Batch [110]#011Speed: 810.55 samples/sec#011loss=2.215862\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch[115] avg_epoch_loss=2.475060\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=2.62977135181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch [115]#011Speed: 517.28 samples/sec#011loss=2.629771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch[120] avg_epoch_loss=2.450074\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=1.87038946152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch [120]#011Speed: 579.84 samples/sec#011loss=1.870389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch[125] avg_epoch_loss=2.426024\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=1.84401965141\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch [125]#011Speed: 512.54 samples/sec#011loss=1.844020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch[130] avg_epoch_loss=2.402613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=1.81266810894\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:35 INFO 140074512123712] Epoch[0] Batch [130]#011Speed: 777.91 samples/sec#011loss=1.812668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch[135] avg_epoch_loss=2.382419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=1.85331747532\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch [135]#011Speed: 626.00 samples/sec#011loss=1.853317\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch[140] avg_epoch_loss=2.359857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=1.74618785381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch [140]#011Speed: 1077.88 samples/sec#011loss=1.746188\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch[145] avg_epoch_loss=2.337180\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=1.69768023491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch [145]#011Speed: 707.97 samples/sec#011loss=1.697680\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch[150] avg_epoch_loss=2.333507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=2.22624149323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch [150]#011Speed: 930.82 samples/sec#011loss=2.226241\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch[155] avg_epoch_loss=2.309783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=1.5933300972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:36 INFO 140074512123712] Epoch[0] Batch [155]#011Speed: 783.38 samples/sec#011loss=1.593330\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch[160] avg_epoch_loss=2.293721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=1.79257378578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch [160]#011Speed: 1063.26 samples/sec#011loss=1.792574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch[165] avg_epoch_loss=2.275232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=1.67989625931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch [165]#011Speed: 787.17 samples/sec#011loss=1.679896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch[170] avg_epoch_loss=2.265450\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=1.94070618153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch [170]#011Speed: 1058.24 samples/sec#011loss=1.940706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch[175] avg_epoch_loss=2.249717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=1.71163139343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch [175]#011Speed: 761.51 samples/sec#011loss=1.711631\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch[180] avg_epoch_loss=2.234167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=1.68682813644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:37 INFO 140074512123712] Epoch[0] Batch [180]#011Speed: 1076.90 samples/sec#011loss=1.686828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch[185] avg_epoch_loss=2.215036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=1.52246096134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch [185]#011Speed: 781.56 samples/sec#011loss=1.522461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch[190] avg_epoch_loss=2.206614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=1.89331967831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch [190]#011Speed: 1081.21 samples/sec#011loss=1.893320\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch[195] avg_epoch_loss=2.199223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=1.91689100266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch [195]#011Speed: 803.36 samples/sec#011loss=1.916891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch[200] avg_epoch_loss=2.194531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=2.01061317921\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch [200]#011Speed: 1092.37 samples/sec#011loss=2.010613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch[205] avg_epoch_loss=2.189915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=2.00435757637\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch [205]#011Speed: 773.71 samples/sec#011loss=2.004358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch[210] avg_epoch_loss=2.180538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=1.79421637058\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:38 INFO 140074512123712] Epoch[0] Batch [210]#011Speed: 1053.50 samples/sec#011loss=1.794216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch[215] avg_epoch_loss=2.170589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=1.7507365942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch [215]#011Speed: 776.67 samples/sec#011loss=1.750737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch[220] avg_epoch_loss=2.158533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=1.63767867088\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch [220]#011Speed: 1085.56 samples/sec#011loss=1.637679\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch[225] avg_epoch_loss=2.146309\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=1.60602443218\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch [225]#011Speed: 763.29 samples/sec#011loss=1.606024\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch[230] avg_epoch_loss=2.133696\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=1.56360929012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch [230]#011Speed: 1033.18 samples/sec#011loss=1.563609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch[235] avg_epoch_loss=2.119677\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=1.47199499607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch [235]#011Speed: 778.84 samples/sec#011loss=1.471995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch[240] avg_epoch_loss=2.106179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=1.46908307076\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:39 INFO 140074512123712] Epoch[0] Batch [240]#011Speed: 1076.83 samples/sec#011loss=1.469083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch[245] avg_epoch_loss=2.121737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=2.87160599232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch [245]#011Speed: 791.83 samples/sec#011loss=2.871606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch[250] avg_epoch_loss=2.114030\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=1.7348293066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch [250]#011Speed: 789.95 samples/sec#011loss=1.734829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch[255] avg_epoch_loss=2.103412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=1.57040417194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch [255]#011Speed: 1076.45 samples/sec#011loss=1.570404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch[260] avg_epoch_loss=2.094407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=1.63334357738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch [260]#011Speed: 867.93 samples/sec#011loss=1.633344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch[265] avg_epoch_loss=2.084889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=1.58806121349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:40 INFO 140074512123712] Epoch[0] Batch [265]#011Speed: 758.10 samples/sec#011loss=1.588061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch[270] avg_epoch_loss=2.075167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=1.55794446468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch [270]#011Speed: 1013.58 samples/sec#011loss=1.557944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch[275] avg_epoch_loss=2.066980\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=275 train loss <loss>=1.62326796055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch [275]#011Speed: 755.45 samples/sec#011loss=1.623268\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch[280] avg_epoch_loss=2.058826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=280 train loss <loss>=1.6086943388\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch [280]#011Speed: 1070.54 samples/sec#011loss=1.608694\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch[285] avg_epoch_loss=2.048233\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=285 train loss <loss>=1.45294947624\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch [285]#011Speed: 796.21 samples/sec#011loss=1.452949\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch[290] avg_epoch_loss=2.037886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=290 train loss <loss>=1.44603149891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:41 INFO 140074512123712] Epoch[0] Batch [290]#011Speed: 708.56 samples/sec#011loss=1.446031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch[295] avg_epoch_loss=2.028821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=295 train loss <loss>=1.50119969845\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch [295]#011Speed: 1074.76 samples/sec#011loss=1.501200\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch[300] avg_epoch_loss=2.018426\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=300 train loss <loss>=1.40305635929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch [300]#011Speed: 786.33 samples/sec#011loss=1.403056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch[305] avg_epoch_loss=2.010109\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=305 train loss <loss>=1.50945520401\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch [305]#011Speed: 1051.45 samples/sec#011loss=1.509455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch[310] avg_epoch_loss=2.000726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=310 train loss <loss>=1.42648339272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch [310]#011Speed: 812.61 samples/sec#011loss=1.426483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch[315] avg_epoch_loss=2.009560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=315 train loss <loss>=2.55901184082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch [315]#011Speed: 1077.75 samples/sec#011loss=2.559012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch[320] avg_epoch_loss=2.008539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=320 train loss <loss>=1.94402265549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:42 INFO 140074512123712] Epoch[0] Batch [320]#011Speed: 753.62 samples/sec#011loss=1.944023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch[325] avg_epoch_loss=2.002544\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=325 train loss <loss>=1.61764314175\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch [325]#011Speed: 1079.77 samples/sec#011loss=1.617643\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch[330] avg_epoch_loss=1.997065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=330 train loss <loss>=1.63987872601\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch [330]#011Speed: 770.20 samples/sec#011loss=1.639879\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch[335] avg_epoch_loss=1.993792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=335 train loss <loss>=1.77712180614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch [335]#011Speed: 1027.04 samples/sec#011loss=1.777122\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch[340] avg_epoch_loss=1.989295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=340 train loss <loss>=1.68705718517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch [340]#011Speed: 787.55 samples/sec#011loss=1.687057\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch[345] avg_epoch_loss=1.982639\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=345 train loss <loss>=1.52872567177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:43 INFO 140074512123712] Epoch[0] Batch [345]#011Speed: 980.94 samples/sec#011loss=1.528726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch[350] avg_epoch_loss=1.976768\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=350 train loss <loss>=1.57046904564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch [350]#011Speed: 780.19 samples/sec#011loss=1.570469\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch[355] avg_epoch_loss=1.972305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=355 train loss <loss>=1.65903203487\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch [355]#011Speed: 1075.69 samples/sec#011loss=1.659032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch[360] avg_epoch_loss=1.964928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=360 train loss <loss>=1.43969922066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch [360]#011Speed: 775.18 samples/sec#011loss=1.439699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch[365] avg_epoch_loss=1.958074\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=365 train loss <loss>=1.46319732666\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch [365]#011Speed: 1058.82 samples/sec#011loss=1.463197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch[370] avg_epoch_loss=1.951601\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=370 train loss <loss>=1.47778699398\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch [370]#011Speed: 1084.56 samples/sec#011loss=1.477787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch[375] avg_epoch_loss=1.949202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=375 train loss <loss>=1.77113263607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:44 INFO 140074512123712] Epoch[0] Batch [375]#011Speed: 761.34 samples/sec#011loss=1.771133\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch[380] avg_epoch_loss=1.943254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=380 train loss <loss>=1.49599494934\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch [380]#011Speed: 1066.27 samples/sec#011loss=1.495995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch[385] avg_epoch_loss=1.937403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=385 train loss <loss>=1.49159121513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch [385]#011Speed: 794.81 samples/sec#011loss=1.491591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch[390] avg_epoch_loss=1.932662\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=390 train loss <loss>=1.56662256718\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch [390]#011Speed: 1077.90 samples/sec#011loss=1.566623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch[395] avg_epoch_loss=1.925793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=395 train loss <loss>=1.38867108822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch [395]#011Speed: 798.63 samples/sec#011loss=1.388671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch[400] avg_epoch_loss=1.919543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=400 train loss <loss>=1.42455472946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch [400]#011Speed: 778.64 samples/sec#011loss=1.424555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch[405] avg_epoch_loss=1.917102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=405 train loss <loss>=1.72128064632\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:45 INFO 140074512123712] Epoch[0] Batch [405]#011Speed: 782.66 samples/sec#011loss=1.721281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch[410] avg_epoch_loss=1.914743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=410 train loss <loss>=1.7232216835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch [410]#011Speed: 880.70 samples/sec#011loss=1.723222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch[415] avg_epoch_loss=1.912673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=415 train loss <loss>=1.7425110817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch [415]#011Speed: 597.66 samples/sec#011loss=1.742511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch[420] avg_epoch_loss=1.914322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=420 train loss <loss>=2.05150940418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch [420]#011Speed: 1050.72 samples/sec#011loss=2.051509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch[425] avg_epoch_loss=1.908980\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=425 train loss <loss>=1.45920350552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch [425]#011Speed: 784.53 samples/sec#011loss=1.459204\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch[430] avg_epoch_loss=1.904688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=430 train loss <loss>=1.53897721767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:46 INFO 140074512123712] Epoch[0] Batch [430]#011Speed: 1105.91 samples/sec#011loss=1.538977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch[435] avg_epoch_loss=1.900595\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=435 train loss <loss>=1.54776468277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch [435]#011Speed: 791.52 samples/sec#011loss=1.547765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch[440] avg_epoch_loss=1.896366\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=440 train loss <loss>=1.52762966156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch [440]#011Speed: 1106.83 samples/sec#011loss=1.527630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch[445] avg_epoch_loss=1.890297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=445 train loss <loss>=1.35501639843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch [445]#011Speed: 796.39 samples/sec#011loss=1.355016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch[450] avg_epoch_loss=1.889572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=450 train loss <loss>=1.82486987114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch [450]#011Speed: 1064.67 samples/sec#011loss=1.824870\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch[455] avg_epoch_loss=1.885056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=455 train loss <loss>=1.47774507999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:47 INFO 140074512123712] Epoch[0] Batch [455]#011Speed: 766.88 samples/sec#011loss=1.477745\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch[460] avg_epoch_loss=1.880881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=460 train loss <loss>=1.50010197163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch [460]#011Speed: 1077.98 samples/sec#011loss=1.500102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch[465] avg_epoch_loss=1.876942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=465 train loss <loss>=1.51376984119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch [465]#011Speed: 776.67 samples/sec#011loss=1.513770\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch[470] avg_epoch_loss=1.875307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=470 train loss <loss>=1.72296891212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch [470]#011Speed: 1074.70 samples/sec#011loss=1.722969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch[475] avg_epoch_loss=1.878612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=475 train loss <loss>=2.18990097046\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch [475]#011Speed: 772.51 samples/sec#011loss=2.189901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch[480] avg_epoch_loss=1.880130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=480 train loss <loss>=2.02463550568\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch [480]#011Speed: 1064.11 samples/sec#011loss=2.024636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch[485] avg_epoch_loss=1.877945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=485 train loss <loss>=1.66774702072\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:48 INFO 140074512123712] Epoch[0] Batch [485]#011Speed: 753.34 samples/sec#011loss=1.667747\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch[490] avg_epoch_loss=1.874882\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=490 train loss <loss>=1.57717506886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch [490]#011Speed: 1032.78 samples/sec#011loss=1.577175\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch[495] avg_epoch_loss=1.872154\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=495 train loss <loss>=1.60423562527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch [495]#011Speed: 767.48 samples/sec#011loss=1.604236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch[500] avg_epoch_loss=1.869604\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=500 train loss <loss>=1.61663591862\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch [500]#011Speed: 1069.56 samples/sec#011loss=1.616636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch[505] avg_epoch_loss=1.866019\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=505 train loss <loss>=1.50688502789\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch [505]#011Speed: 785.71 samples/sec#011loss=1.506885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch[510] avg_epoch_loss=1.861381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=510 train loss <loss>=1.3919917345\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:49 INFO 140074512123712] Epoch[0] Batch [510]#011Speed: 1076.67 samples/sec#011loss=1.391992\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch[515] avg_epoch_loss=1.856902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=515 train loss <loss>=1.39911231995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch [515]#011Speed: 744.03 samples/sec#011loss=1.399112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch[520] avg_epoch_loss=1.853758\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=520 train loss <loss>=1.52926952839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch [520]#011Speed: 1042.71 samples/sec#011loss=1.529270\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch[525] avg_epoch_loss=1.849718\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=525 train loss <loss>=1.42882804871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch [525]#011Speed: 788.08 samples/sec#011loss=1.428828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch[530] avg_epoch_loss=1.844509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=530 train loss <loss>=1.29644842148\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch [530]#011Speed: 1077.57 samples/sec#011loss=1.296448\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch[535] avg_epoch_loss=1.845847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=535 train loss <loss>=1.98802893162\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch [535]#011Speed: 776.59 samples/sec#011loss=1.988029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch[540] avg_epoch_loss=1.840795\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=540 train loss <loss>=1.2991976738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:50 INFO 140074512123712] Epoch[0] Batch [540]#011Speed: 672.84 samples/sec#011loss=1.299198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch[545] avg_epoch_loss=1.842803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=545 train loss <loss>=2.06006810665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch [545]#011Speed: 623.81 samples/sec#011loss=2.060068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch[550] avg_epoch_loss=1.840452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=550 train loss <loss>=1.58368320465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch [550]#011Speed: 1056.35 samples/sec#011loss=1.583683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch[555] avg_epoch_loss=1.837970\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=555 train loss <loss>=1.56448309422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch [555]#011Speed: 825.73 samples/sec#011loss=1.564483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch[560] avg_epoch_loss=1.835592\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, batch=560 train loss <loss>=1.5711619854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[0] Batch [560]#011Speed: 1067.73 samples/sec#011loss=1.571162\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] processed a total of 17972 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"update.time\": {\"count\": 1, \"max\": 21280.307054519653, \"sum\": 21280.307054519653, \"min\": 21280.307054519653}}, \"EndTime\": 1589444991.747336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589444970.466931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=844.530460228 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=0, train loss <loss>=1.83495994543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_1421e933-d6b5-41b5-baf1-ec109da9e9fb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.423898696899414, \"sum\": 10.423898696899414, \"min\": 10.423898696899414}}, \"EndTime\": 1589444991.758705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589444991.747433}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] Epoch[1] Batch[0] avg_epoch_loss=1.522149\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.52214896679\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch[5] avg_epoch_loss=1.456725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.4567253987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch [5]#011Speed: 1021.53 samples/sec#011loss=1.456725\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch[10] avg_epoch_loss=1.484978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=1.51888084412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch [10]#011Speed: 785.99 samples/sec#011loss=1.518881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch[15] avg_epoch_loss=1.435044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=1.32518973351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch [15]#011Speed: 1079.42 samples/sec#011loss=1.325190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch[20] avg_epoch_loss=1.414286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=1.34786183834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch [20]#011Speed: 771.13 samples/sec#011loss=1.347862\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch[25] avg_epoch_loss=1.401296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=1.34673702717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch [25]#011Speed: 1068.20 samples/sec#011loss=1.346737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch[30] avg_epoch_loss=1.395313\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=1.36419935226\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:52 INFO 140074512123712] Epoch[1] Batch [30]#011Speed: 763.18 samples/sec#011loss=1.364199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch[35] avg_epoch_loss=1.380969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=1.29203784466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch [35]#011Speed: 1067.76 samples/sec#011loss=1.292038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch[40] avg_epoch_loss=1.358698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=1.19834916592\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch [40]#011Speed: 769.18 samples/sec#011loss=1.198349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch[45] avg_epoch_loss=1.352527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=1.30192177296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch [45]#011Speed: 1075.24 samples/sec#011loss=1.301922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch[50] avg_epoch_loss=1.398468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=1.82112083435\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch [50]#011Speed: 790.45 samples/sec#011loss=1.821121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch[55] avg_epoch_loss=1.409143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=1.51802749634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:53 INFO 140074512123712] Epoch[1] Batch [55]#011Speed: 1072.07 samples/sec#011loss=1.518027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch[60] avg_epoch_loss=1.409656\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=1.41540689468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch [60]#011Speed: 753.42 samples/sec#011loss=1.415407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch[65] avg_epoch_loss=1.413441\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=1.45961403847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch [65]#011Speed: 1060.52 samples/sec#011loss=1.459614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch[70] avg_epoch_loss=1.407152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=1.32413773537\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch [70]#011Speed: 782.87 samples/sec#011loss=1.324138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch[75] avg_epoch_loss=1.415336\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=1.53155961037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch [75]#011Speed: 1086.00 samples/sec#011loss=1.531560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch[80] avg_epoch_loss=1.405475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=1.25557603836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch [80]#011Speed: 810.17 samples/sec#011loss=1.255576\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch[85] avg_epoch_loss=1.407235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=1.43575348854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:54 INFO 140074512123712] Epoch[1] Batch [85]#011Speed: 1077.41 samples/sec#011loss=1.435753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch[90] avg_epoch_loss=1.403042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=1.33092725277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch [90]#011Speed: 757.65 samples/sec#011loss=1.330927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch[95] avg_epoch_loss=1.399012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=1.32565333843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch [95]#011Speed: 1084.41 samples/sec#011loss=1.325653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch[100] avg_epoch_loss=1.389564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=1.20817701817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch [100]#011Speed: 1093.04 samples/sec#011loss=1.208177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch[105] avg_epoch_loss=1.383333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=1.25746123791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch [105]#011Speed: 783.22 samples/sec#011loss=1.257461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch[110] avg_epoch_loss=1.387494\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=1.47570271492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch [110]#011Speed: 1074.55 samples/sec#011loss=1.475703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch[115] avg_epoch_loss=1.387187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=1.38036496639\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:55 INFO 140074512123712] Epoch[1] Batch [115]#011Speed: 781.25 samples/sec#011loss=1.380365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch[120] avg_epoch_loss=1.389190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=1.43566508293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch [120]#011Speed: 644.95 samples/sec#011loss=1.435665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch[125] avg_epoch_loss=1.396810\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=1.58121848106\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch [125]#011Speed: 899.69 samples/sec#011loss=1.581218\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch[130] avg_epoch_loss=1.393631\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=1.31351854801\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch [130]#011Speed: 713.69 samples/sec#011loss=1.313519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch[135] avg_epoch_loss=1.395227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=1.43705165386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch [135]#011Speed: 1062.88 samples/sec#011loss=1.437052\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch[140] avg_epoch_loss=1.394927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=1.38675847054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:56 INFO 140074512123712] Epoch[1] Batch [140]#011Speed: 1061.77 samples/sec#011loss=1.386758\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch[145] avg_epoch_loss=1.391642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=1.29900374413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch [145]#011Speed: 763.51 samples/sec#011loss=1.299004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch[150] avg_epoch_loss=1.392564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=1.41950001717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch [150]#011Speed: 1072.11 samples/sec#011loss=1.419500\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch[155] avg_epoch_loss=1.394682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=1.45862269402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch [155]#011Speed: 772.38 samples/sec#011loss=1.458623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch[160] avg_epoch_loss=1.393174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=1.34611830711\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch [160]#011Speed: 1059.74 samples/sec#011loss=1.346118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch[165] avg_epoch_loss=1.391486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=1.33713765144\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch [165]#011Speed: 738.67 samples/sec#011loss=1.337138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch[170] avg_epoch_loss=1.401658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=1.73939173222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:57 INFO 140074512123712] Epoch[1] Batch [170]#011Speed: 1066.74 samples/sec#011loss=1.739392\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch[175] avg_epoch_loss=1.403740\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=1.47491853237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch [175]#011Speed: 789.29 samples/sec#011loss=1.474919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch[180] avg_epoch_loss=1.405515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=1.46801476479\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch [180]#011Speed: 768.01 samples/sec#011loss=1.468015\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch[185] avg_epoch_loss=1.411342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=1.62225551605\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch [185]#011Speed: 1088.35 samples/sec#011loss=1.622256\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch[190] avg_epoch_loss=1.411434\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=1.41488518715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch [190]#011Speed: 1083.93 samples/sec#011loss=1.414885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch[195] avg_epoch_loss=1.410954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=1.39259605408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:58 INFO 140074512123712] Epoch[1] Batch [195]#011Speed: 804.40 samples/sec#011loss=1.392596\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch[200] avg_epoch_loss=1.415110\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=1.57805330753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch [200]#011Speed: 753.96 samples/sec#011loss=1.578053\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch[205] avg_epoch_loss=1.418762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=1.56557271481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch [205]#011Speed: 1061.13 samples/sec#011loss=1.565573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch[210] avg_epoch_loss=1.427213\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=1.77537226677\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch [210]#011Speed: 794.67 samples/sec#011loss=1.775372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch[215] avg_epoch_loss=1.426745\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=1.40700798035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch [215]#011Speed: 1047.65 samples/sec#011loss=1.407008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch[220] avg_epoch_loss=1.426835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=1.4307104826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:29:59 INFO 140074512123712] Epoch[1] Batch [220]#011Speed: 527.52 samples/sec#011loss=1.430710\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch[225] avg_epoch_loss=1.427084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=1.43807590008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch [225]#011Speed: 1014.92 samples/sec#011loss=1.438076\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch[230] avg_epoch_loss=1.423670\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=1.26936950684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch [230]#011Speed: 1049.28 samples/sec#011loss=1.269370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch[235] avg_epoch_loss=1.420725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=1.2846909523\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch [235]#011Speed: 768.84 samples/sec#011loss=1.284691\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch[240] avg_epoch_loss=1.419699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=1.37127327919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch [240]#011Speed: 1074.91 samples/sec#011loss=1.371273\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch[245] avg_epoch_loss=1.415408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=1.20856740475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch [245]#011Speed: 775.58 samples/sec#011loss=1.208567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch[250] avg_epoch_loss=1.413835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=1.33643109798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:00 INFO 140074512123712] Epoch[1] Batch [250]#011Speed: 1076.02 samples/sec#011loss=1.336431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch[255] avg_epoch_loss=1.415836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=1.51627874374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch [255]#011Speed: 767.54 samples/sec#011loss=1.516279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch[260] avg_epoch_loss=1.422448\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=1.76097402573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch [260]#011Speed: 648.96 samples/sec#011loss=1.760974\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch[265] avg_epoch_loss=1.436199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=2.15403461456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch [265]#011Speed: 724.26 samples/sec#011loss=2.154035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch[270] avg_epoch_loss=1.443144\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=270 train loss <loss>=1.81258349419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch [270]#011Speed: 1050.56 samples/sec#011loss=1.812583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch[275] avg_epoch_loss=1.444222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=275 train loss <loss>=1.50268449783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:01 INFO 140074512123712] Epoch[1] Batch [275]#011Speed: 779.30 samples/sec#011loss=1.502684\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch[280] avg_epoch_loss=1.444673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=280 train loss <loss>=1.46958293915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch [280]#011Speed: 1007.64 samples/sec#011loss=1.469583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch[285] avg_epoch_loss=1.444809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=285 train loss <loss>=1.45241003036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch [285]#011Speed: 771.62 samples/sec#011loss=1.452410\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch[290] avg_epoch_loss=1.443204\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=290 train loss <loss>=1.35140810013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch [290]#011Speed: 1049.01 samples/sec#011loss=1.351408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch[295] avg_epoch_loss=1.442100\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=295 train loss <loss>=1.3778583765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch [295]#011Speed: 759.76 samples/sec#011loss=1.377858\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch[300] avg_epoch_loss=1.441892\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=300 train loss <loss>=1.42955527306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:02 INFO 140074512123712] Epoch[1] Batch [300]#011Speed: 1059.55 samples/sec#011loss=1.429555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch[305] avg_epoch_loss=1.441894\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=305 train loss <loss>=1.44202580452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch [305]#011Speed: 761.81 samples/sec#011loss=1.442026\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch[310] avg_epoch_loss=1.437361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=310 train loss <loss>=1.15994288921\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch [310]#011Speed: 1064.46 samples/sec#011loss=1.159943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch[315] avg_epoch_loss=1.435644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=315 train loss <loss>=1.32882766724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch [315]#011Speed: 767.79 samples/sec#011loss=1.328828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch[320] avg_epoch_loss=1.569235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=320 train loss <loss>=10.0121860027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch [320]#011Speed: 1018.93 samples/sec#011loss=10.012186\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch[325] avg_epoch_loss=1.569205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=325 train loss <loss>=1.56731889248\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch [325]#011Speed: 786.12 samples/sec#011loss=1.567319\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch[330] avg_epoch_loss=1.570966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=330 train loss <loss>=1.68577713966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:03 INFO 140074512123712] Epoch[1] Batch [330]#011Speed: 1041.59 samples/sec#011loss=1.685777\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch[335] avg_epoch_loss=1.573653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=335 train loss <loss>=1.75151610374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch [335]#011Speed: 763.55 samples/sec#011loss=1.751516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch[340] avg_epoch_loss=1.576118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=340 train loss <loss>=1.74176800251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch [340]#011Speed: 1063.81 samples/sec#011loss=1.741768\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch[345] avg_epoch_loss=1.579312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=345 train loss <loss>=1.79717438221\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch [345]#011Speed: 788.61 samples/sec#011loss=1.797174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch[350] avg_epoch_loss=1.580928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=350 train loss <loss>=1.69272894859\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch [350]#011Speed: 1031.90 samples/sec#011loss=1.692729\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch[355] avg_epoch_loss=1.581647\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=355 train loss <loss>=1.63214054108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch [355]#011Speed: 783.78 samples/sec#011loss=1.632141\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch[360] avg_epoch_loss=1.581834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=360 train loss <loss>=1.59512937069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:04 INFO 140074512123712] Epoch[1] Batch [360]#011Speed: 1076.48 samples/sec#011loss=1.595129\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch[365] avg_epoch_loss=1.579384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=365 train loss <loss>=1.4024920702\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch [365]#011Speed: 753.38 samples/sec#011loss=1.402492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch[370] avg_epoch_loss=1.577234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=370 train loss <loss>=1.41983785629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch [370]#011Speed: 1079.88 samples/sec#011loss=1.419838\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch[375] avg_epoch_loss=1.577085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=375 train loss <loss>=1.56600925922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch [375]#011Speed: 789.09 samples/sec#011loss=1.566009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch[380] avg_epoch_loss=1.573871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=380 train loss <loss>=1.33222310543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch [380]#011Speed: 1073.01 samples/sec#011loss=1.332223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch[385] avg_epoch_loss=1.570234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=385 train loss <loss>=1.29308331013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:05 INFO 140074512123712] Epoch[1] Batch [385]#011Speed: 783.27 samples/sec#011loss=1.293083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch[390] avg_epoch_loss=1.569160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=390 train loss <loss>=1.48624007702\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch [390]#011Speed: 1004.48 samples/sec#011loss=1.486240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch[395] avg_epoch_loss=1.564721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=395 train loss <loss>=1.21762480736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch [395]#011Speed: 735.40 samples/sec#011loss=1.217625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch[400] avg_epoch_loss=1.564988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=400 train loss <loss>=1.5860793829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch [400]#011Speed: 816.55 samples/sec#011loss=1.586079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch[405] avg_epoch_loss=1.560408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=405 train loss <loss>=1.1931281805\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch [405]#011Speed: 761.64 samples/sec#011loss=1.193128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch[410] avg_epoch_loss=1.556026\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=410 train loss <loss>=1.20016262531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:06 INFO 140074512123712] Epoch[1] Batch [410]#011Speed: 1072.68 samples/sec#011loss=1.200163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch[415] avg_epoch_loss=1.553062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=415 train loss <loss>=1.30946819782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch [415]#011Speed: 780.34 samples/sec#011loss=1.309468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch[420] avg_epoch_loss=1.551347\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=420 train loss <loss>=1.40868237019\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch [420]#011Speed: 1065.37 samples/sec#011loss=1.408682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch[425] avg_epoch_loss=1.552224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=425 train loss <loss>=1.62601845264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch [425]#011Speed: 772.13 samples/sec#011loss=1.626018\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch[430] avg_epoch_loss=1.549476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=430 train loss <loss>=1.31538674831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch [430]#011Speed: 1057.86 samples/sec#011loss=1.315387\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch[435] avg_epoch_loss=1.547021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=435 train loss <loss>=1.3353717804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch [435]#011Speed: 753.23 samples/sec#011loss=1.335372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch[440] avg_epoch_loss=1.547336\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=440 train loss <loss>=1.57483842373\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:07 INFO 140074512123712] Epoch[1] Batch [440]#011Speed: 1054.77 samples/sec#011loss=1.574838\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch[445] avg_epoch_loss=1.545346\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=445 train loss <loss>=1.36976599693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch [445]#011Speed: 774.16 samples/sec#011loss=1.369766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch[450] avg_epoch_loss=1.542771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=450 train loss <loss>=1.31310806274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch [450]#011Speed: 1066.90 samples/sec#011loss=1.313108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch[455] avg_epoch_loss=1.539800\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=455 train loss <loss>=1.27181632519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch [455]#011Speed: 773.32 samples/sec#011loss=1.271816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch[460] avg_epoch_loss=1.538436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=460 train loss <loss>=1.41402504444\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch [460]#011Speed: 1069.87 samples/sec#011loss=1.414025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch[465] avg_epoch_loss=1.535815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=465 train loss <loss>=1.29417154789\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch [465]#011Speed: 775.74 samples/sec#011loss=1.294172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch[470] avg_epoch_loss=1.534450\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=470 train loss <loss>=1.40719358921\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:08 INFO 140074512123712] Epoch[1] Batch [470]#011Speed: 1073.04 samples/sec#011loss=1.407194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch[475] avg_epoch_loss=1.535760\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=475 train loss <loss>=1.65919880867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch [475]#011Speed: 753.83 samples/sec#011loss=1.659199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch[480] avg_epoch_loss=1.537982\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=480 train loss <loss>=1.74954662323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch [480]#011Speed: 1089.73 samples/sec#011loss=1.749547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch[485] avg_epoch_loss=1.544938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=485 train loss <loss>=2.21406018734\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch [485]#011Speed: 772.67 samples/sec#011loss=2.214060\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch[490] avg_epoch_loss=1.543370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=490 train loss <loss>=1.39095976353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch [490]#011Speed: 1059.91 samples/sec#011loss=1.390960\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch[495] avg_epoch_loss=1.542652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=495 train loss <loss>=1.47218093872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:09 INFO 140074512123712] Epoch[1] Batch [495]#011Speed: 785.41 samples/sec#011loss=1.472181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch[500] avg_epoch_loss=1.540626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=500 train loss <loss>=1.33961265087\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch [500]#011Speed: 1062.22 samples/sec#011loss=1.339613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch[505] avg_epoch_loss=1.538915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=505 train loss <loss>=1.36744477749\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch [505]#011Speed: 769.12 samples/sec#011loss=1.367445\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch[510] avg_epoch_loss=1.536811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=510 train loss <loss>=1.32390189171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch [510]#011Speed: 1076.49 samples/sec#011loss=1.323902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch[515] avg_epoch_loss=1.533912\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=515 train loss <loss>=1.23763623238\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch [515]#011Speed: 775.84 samples/sec#011loss=1.237636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch[520] avg_epoch_loss=1.532660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=520 train loss <loss>=1.40351991653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch [520]#011Speed: 1055.89 samples/sec#011loss=1.403520\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch[525] avg_epoch_loss=1.530371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=525 train loss <loss>=1.2918097496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:10 INFO 140074512123712] Epoch[1] Batch [525]#011Speed: 749.13 samples/sec#011loss=1.291810\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch[530] avg_epoch_loss=1.528975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=530 train loss <loss>=1.38210074902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch [530]#011Speed: 1018.19 samples/sec#011loss=1.382101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch[535] avg_epoch_loss=1.525711\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=535 train loss <loss>=1.17907896042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch [535]#011Speed: 1064.18 samples/sec#011loss=1.179079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch[540] avg_epoch_loss=1.523650\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=540 train loss <loss>=1.30269405842\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch [540]#011Speed: 689.17 samples/sec#011loss=1.302694\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch[545] avg_epoch_loss=1.525735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=545 train loss <loss>=1.7513409853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:11 INFO 140074512123712] Epoch[1] Batch [545]#011Speed: 741.62 samples/sec#011loss=1.751341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[1] Batch[550] avg_epoch_loss=1.522407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=550 train loss <loss>=1.1590400219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[1] Batch [550]#011Speed: 550.75 samples/sec#011loss=1.159040\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[1] Batch[555] avg_epoch_loss=1.520889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=555 train loss <loss>=1.35359375477\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[1] Batch [555]#011Speed: 988.88 samples/sec#011loss=1.353594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[1] Batch[560] avg_epoch_loss=1.518649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, batch=560 train loss <loss>=1.26953310966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[1] Batch [560]#011Speed: 924.17 samples/sec#011loss=1.269533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] processed a total of 17946 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20591.856956481934, \"sum\": 20591.856956481934, \"min\": 20591.856956481934}}, \"EndTime\": 1589445012.350692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589444991.758771}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=871.505948168 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.51864882608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_243779c3-83b3-46a4-a568-beae8142e791-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.234905242919922, \"sum\": 9.234905242919922, \"min\": 9.234905242919922}}, \"EndTime\": 1589445012.360837, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445012.350748}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch[0] avg_epoch_loss=1.124814\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.12481439114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch[5] avg_epoch_loss=1.117257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.11725691954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch [5]#011Speed: 972.74 samples/sec#011loss=1.117257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch[10] avg_epoch_loss=1.167831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=1.22851958275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch [10]#011Speed: 780.08 samples/sec#011loss=1.228520\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch[15] avg_epoch_loss=1.182674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=1.21532998085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:12 INFO 140074512123712] Epoch[2] Batch [15]#011Speed: 1057.04 samples/sec#011loss=1.215330\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch[20] avg_epoch_loss=1.214772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=1.31748480797\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch [20]#011Speed: 763.26 samples/sec#011loss=1.317485\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch[25] avg_epoch_loss=1.282527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=1.56709861755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch [25]#011Speed: 1072.83 samples/sec#011loss=1.567099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch[30] avg_epoch_loss=1.373372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=1.84576237202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch [30]#011Speed: 788.83 samples/sec#011loss=1.845762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch[35] avg_epoch_loss=1.399363\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=1.56051263809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch [35]#011Speed: 1084.38 samples/sec#011loss=1.560513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch[40] avg_epoch_loss=1.410529\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=1.49091780186\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:13 INFO 140074512123712] Epoch[2] Batch [40]#011Speed: 791.85 samples/sec#011loss=1.490918\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch[45] avg_epoch_loss=1.406505\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=1.37351503372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch [45]#011Speed: 1090.05 samples/sec#011loss=1.373515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch[50] avg_epoch_loss=1.414258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=1.48557970524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch [50]#011Speed: 761.94 samples/sec#011loss=1.485580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch[55] avg_epoch_loss=1.417695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=1.45275034904\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch [55]#011Speed: 1084.56 samples/sec#011loss=1.452750\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch[60] avg_epoch_loss=1.415062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=1.38558003902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch [60]#011Speed: 796.82 samples/sec#011loss=1.385580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch[65] avg_epoch_loss=1.403855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=1.26713044643\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch [65]#011Speed: 1062.26 samples/sec#011loss=1.267130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch[70] avg_epoch_loss=1.397348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=1.3114552021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:14 INFO 140074512123712] Epoch[2] Batch [70]#011Speed: 733.94 samples/sec#011loss=1.311455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch[75] avg_epoch_loss=1.388061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=1.25617763996\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch [75]#011Speed: 1074.09 samples/sec#011loss=1.256178\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch[80] avg_epoch_loss=1.385716\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=1.35008354187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch [80]#011Speed: 766.82 samples/sec#011loss=1.350084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch[85] avg_epoch_loss=1.386634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=1.40149466991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch [85]#011Speed: 1073.56 samples/sec#011loss=1.401495\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch[90] avg_epoch_loss=1.375661\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=1.1869383812\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch [90]#011Speed: 789.38 samples/sec#011loss=1.186938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch[95] avg_epoch_loss=1.460534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=3.00521147251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:15 INFO 140074512123712] Epoch[2] Batch [95]#011Speed: 1080.43 samples/sec#011loss=3.005211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch[100] avg_epoch_loss=1.461251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=1.47502744198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch [100]#011Speed: 782.08 samples/sec#011loss=1.475027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch[105] avg_epoch_loss=1.479411\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=1.84622893333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch [105]#011Speed: 1025.86 samples/sec#011loss=1.846229\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch[110] avg_epoch_loss=1.478395\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=1.45685603619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch [110]#011Speed: 783.22 samples/sec#011loss=1.456856\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch[115] avg_epoch_loss=1.475898\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=1.42046329975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch [115]#011Speed: 1064.63 samples/sec#011loss=1.420463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch[120] avg_epoch_loss=1.482336\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=1.63171560764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch [120]#011Speed: 1066.94 samples/sec#011loss=1.631716\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch[125] avg_epoch_loss=1.489792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=1.67021389008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:16 INFO 140074512123712] Epoch[2] Batch [125]#011Speed: 776.57 samples/sec#011loss=1.670214\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch[130] avg_epoch_loss=1.484990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=1.36398863792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch [130]#011Speed: 646.00 samples/sec#011loss=1.363989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch[135] avg_epoch_loss=1.481002\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=1.37650580406\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch [135]#011Speed: 999.91 samples/sec#011loss=1.376506\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch[140] avg_epoch_loss=1.479946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=1.45123653412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch [140]#011Speed: 802.07 samples/sec#011loss=1.451237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch[145] avg_epoch_loss=1.491827\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=1.82684838772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch [145]#011Speed: 992.89 samples/sec#011loss=1.826848\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch[150] avg_epoch_loss=1.484627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=1.27441256046\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:17 INFO 140074512123712] Epoch[2] Batch [150]#011Speed: 784.24 samples/sec#011loss=1.274413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch[155] avg_epoch_loss=1.476527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=1.2318936348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch [155]#011Speed: 1053.82 samples/sec#011loss=1.231894\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch[160] avg_epoch_loss=1.470007\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=1.26659402847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch [160]#011Speed: 758.71 samples/sec#011loss=1.266594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch[165] avg_epoch_loss=1.467665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=1.39224028587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch [165]#011Speed: 1053.98 samples/sec#011loss=1.392240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch[170] avg_epoch_loss=1.463596\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=1.32850148678\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch [170]#011Speed: 749.45 samples/sec#011loss=1.328501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch[175] avg_epoch_loss=1.493642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=2.52121224403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch [175]#011Speed: 1087.91 samples/sec#011loss=2.521212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch[180] avg_epoch_loss=1.491865\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=1.42932918072\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:18 INFO 140074512123712] Epoch[2] Batch [180]#011Speed: 775.44 samples/sec#011loss=1.429329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch[185] avg_epoch_loss=1.487977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=1.34721939564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch [185]#011Speed: 1052.48 samples/sec#011loss=1.347219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch[190] avg_epoch_loss=1.488657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=1.51395971775\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch [190]#011Speed: 761.18 samples/sec#011loss=1.513960\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch[195] avg_epoch_loss=1.490263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=1.55162863731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch [195]#011Speed: 1059.46 samples/sec#011loss=1.551629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch[200] avg_epoch_loss=1.490754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=1.50999925137\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch [200]#011Speed: 743.49 samples/sec#011loss=1.509999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch[205] avg_epoch_loss=1.492756\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=1.57320985794\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch [205]#011Speed: 1066.86 samples/sec#011loss=1.573210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch[210] avg_epoch_loss=1.494721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=1.57569439411\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:19 INFO 140074512123712] Epoch[2] Batch [210]#011Speed: 1073.08 samples/sec#011loss=1.575694\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch[215] avg_epoch_loss=1.495202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=1.51551277637\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch [215]#011Speed: 756.42 samples/sec#011loss=1.515513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch[220] avg_epoch_loss=1.495817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=1.5223482132\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch [220]#011Speed: 1061.66 samples/sec#011loss=1.522348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch[225] avg_epoch_loss=1.497767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=1.58399460316\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch [225]#011Speed: 776.73 samples/sec#011loss=1.583995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch[230] avg_epoch_loss=1.494449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=1.34447002411\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch [230]#011Speed: 1063.57 samples/sec#011loss=1.344470\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch[235] avg_epoch_loss=1.488929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=1.23391206264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:20 INFO 140074512123712] Epoch[2] Batch [235]#011Speed: 769.78 samples/sec#011loss=1.233912\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch[240] avg_epoch_loss=1.482815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=1.19419603348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch [240]#011Speed: 1066.56 samples/sec#011loss=1.194196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch[245] avg_epoch_loss=1.480589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=1.37329695225\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch [245]#011Speed: 746.98 samples/sec#011loss=1.373297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch[250] avg_epoch_loss=1.475258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=1.21298658848\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch [250]#011Speed: 1073.03 samples/sec#011loss=1.212987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch[255] avg_epoch_loss=1.468893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=1.14938054085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch [255]#011Speed: 779.78 samples/sec#011loss=1.149381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch[260] avg_epoch_loss=1.463669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=1.19616878033\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch [260]#011Speed: 1063.60 samples/sec#011loss=1.196169\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch[265] avg_epoch_loss=1.460736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=1.30767455101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:21 INFO 140074512123712] Epoch[2] Batch [265]#011Speed: 768.65 samples/sec#011loss=1.307675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch[270] avg_epoch_loss=1.456276\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=270 train loss <loss>=1.21900494099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch [270]#011Speed: 743.29 samples/sec#011loss=1.219005\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch[275] avg_epoch_loss=1.454688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=275 train loss <loss>=1.36861720085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch [275]#011Speed: 756.31 samples/sec#011loss=1.368617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch[280] avg_epoch_loss=1.449371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=280 train loss <loss>=1.15584306717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch [280]#011Speed: 1068.51 samples/sec#011loss=1.155843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch[285] avg_epoch_loss=1.445610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=285 train loss <loss>=1.23424882889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch [285]#011Speed: 764.75 samples/sec#011loss=1.234249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch[290] avg_epoch_loss=1.440409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=290 train loss <loss>=1.14289066792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:22 INFO 140074512123712] Epoch[2] Batch [290]#011Speed: 1012.15 samples/sec#011loss=1.142891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch[295] avg_epoch_loss=1.435538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=295 train loss <loss>=1.15205478668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch [295]#011Speed: 798.76 samples/sec#011loss=1.152055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch[300] avg_epoch_loss=1.431763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=300 train loss <loss>=1.20827379227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch [300]#011Speed: 1055.49 samples/sec#011loss=1.208274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch[305] avg_epoch_loss=1.433380\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=305 train loss <loss>=1.53076348305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch [305]#011Speed: 808.85 samples/sec#011loss=1.530763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch[310] avg_epoch_loss=1.430209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=310 train loss <loss>=1.23611159325\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch [310]#011Speed: 1042.31 samples/sec#011loss=1.236112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch[315] avg_epoch_loss=1.428583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=315 train loss <loss>=1.32746195793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch [315]#011Speed: 790.06 samples/sec#011loss=1.327462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch[320] avg_epoch_loss=1.431721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=320 train loss <loss>=1.6300352335\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:23 INFO 140074512123712] Epoch[2] Batch [320]#011Speed: 1085.75 samples/sec#011loss=1.630035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch[325] avg_epoch_loss=1.430334\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=325 train loss <loss>=1.34131855965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch [325]#011Speed: 795.19 samples/sec#011loss=1.341319\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch[330] avg_epoch_loss=1.444357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=330 train loss <loss>=2.35866632462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch [330]#011Speed: 997.72 samples/sec#011loss=2.358666\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch[335] avg_epoch_loss=1.444189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=335 train loss <loss>=1.4330698967\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch [335]#011Speed: 799.97 samples/sec#011loss=1.433070\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch[340] avg_epoch_loss=1.442608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=340 train loss <loss>=1.33635084629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch [340]#011Speed: 1067.66 samples/sec#011loss=1.336351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch[345] avg_epoch_loss=1.441357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=345 train loss <loss>=1.35600168705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:24 INFO 140074512123712] Epoch[2] Batch [345]#011Speed: 774.66 samples/sec#011loss=1.356002\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch[350] avg_epoch_loss=1.440999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=350 train loss <loss>=1.41625878811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch [350]#011Speed: 1074.62 samples/sec#011loss=1.416259\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch[355] avg_epoch_loss=1.438517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=355 train loss <loss>=1.26423230171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch [355]#011Speed: 733.78 samples/sec#011loss=1.264232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch[360] avg_epoch_loss=1.436389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=360 train loss <loss>=1.28487930298\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch [360]#011Speed: 1060.17 samples/sec#011loss=1.284879\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch[365] avg_epoch_loss=1.434893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=365 train loss <loss>=1.32690551281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch [365]#011Speed: 785.94 samples/sec#011loss=1.326906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch[370] avg_epoch_loss=1.433535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=370 train loss <loss>=1.33417024612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch [370]#011Speed: 1057.84 samples/sec#011loss=1.334170\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch[375] avg_epoch_loss=1.430198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=375 train loss <loss>=1.18255839348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:25 INFO 140074512123712] Epoch[2] Batch [375]#011Speed: 756.36 samples/sec#011loss=1.182558\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch[380] avg_epoch_loss=1.428022\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=380 train loss <loss>=1.26440947056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch [380]#011Speed: 1054.74 samples/sec#011loss=1.264409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch[385] avg_epoch_loss=1.426994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=385 train loss <loss>=1.34861700535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch [385]#011Speed: 742.09 samples/sec#011loss=1.348617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch[390] avg_epoch_loss=1.425453\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=390 train loss <loss>=1.30650475025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch [390]#011Speed: 1045.72 samples/sec#011loss=1.306505\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch[395] avg_epoch_loss=1.422499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=395 train loss <loss>=1.1914883852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch [395]#011Speed: 789.41 samples/sec#011loss=1.191488\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch[400] avg_epoch_loss=1.421945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=400 train loss <loss>=1.37807824612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:26 INFO 140074512123712] Epoch[2] Batch [400]#011Speed: 1063.60 samples/sec#011loss=1.378078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch[405] avg_epoch_loss=1.419071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=405 train loss <loss>=1.18855400085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch [405]#011Speed: 660.26 samples/sec#011loss=1.188554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch[410] avg_epoch_loss=1.418782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=410 train loss <loss>=1.39531257153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch [410]#011Speed: 837.89 samples/sec#011loss=1.395313\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch[415] avg_epoch_loss=1.419734\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=415 train loss <loss>=1.49804868698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch [415]#011Speed: 754.89 samples/sec#011loss=1.498049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch[420] avg_epoch_loss=1.420619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=420 train loss <loss>=1.49417741299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch [420]#011Speed: 1046.86 samples/sec#011loss=1.494177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch[425] avg_epoch_loss=1.418766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=425 train loss <loss>=1.26280891895\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:27 INFO 140074512123712] Epoch[2] Batch [425]#011Speed: 756.43 samples/sec#011loss=1.262809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch[430] avg_epoch_loss=1.415877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=430 train loss <loss>=1.16971511841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch [430]#011Speed: 1073.04 samples/sec#011loss=1.169715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch[435] avg_epoch_loss=1.412890\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=435 train loss <loss>=1.15537517071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch [435]#011Speed: 1049.26 samples/sec#011loss=1.155375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch[440] avg_epoch_loss=1.411661\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=440 train loss <loss>=1.30452880859\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch [440]#011Speed: 722.51 samples/sec#011loss=1.304529\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch[445] avg_epoch_loss=1.409813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=445 train loss <loss>=1.24679112434\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch [445]#011Speed: 1061.14 samples/sec#011loss=1.246791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch[450] avg_epoch_loss=1.408712\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=450 train loss <loss>=1.31049449444\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch [450]#011Speed: 769.09 samples/sec#011loss=1.310494\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch[455] avg_epoch_loss=1.409256\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=455 train loss <loss>=1.45839655399\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:28 INFO 140074512123712] Epoch[2] Batch [455]#011Speed: 1066.05 samples/sec#011loss=1.458397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch[460] avg_epoch_loss=1.408251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=460 train loss <loss>=1.31654121876\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch [460]#011Speed: 765.71 samples/sec#011loss=1.316541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch[465] avg_epoch_loss=1.408413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=465 train loss <loss>=1.42337303162\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch [465]#011Speed: 1057.30 samples/sec#011loss=1.423373\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch[470] avg_epoch_loss=1.405480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=470 train loss <loss>=1.13213777542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch [470]#011Speed: 762.85 samples/sec#011loss=1.132138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch[475] avg_epoch_loss=1.402979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=475 train loss <loss>=1.16737866402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch [475]#011Speed: 1063.64 samples/sec#011loss=1.167379\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch[480] avg_epoch_loss=1.400849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=480 train loss <loss>=1.19801371098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:29 INFO 140074512123712] Epoch[2] Batch [480]#011Speed: 774.21 samples/sec#011loss=1.198014\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch[485] avg_epoch_loss=1.399240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=485 train loss <loss>=1.24450364113\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch [485]#011Speed: 700.40 samples/sec#011loss=1.244504\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch[490] avg_epoch_loss=1.408390\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=490 train loss <loss>=2.29779877663\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch [490]#011Speed: 732.93 samples/sec#011loss=2.297799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch[495] avg_epoch_loss=1.405942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=495 train loss <loss>=1.1655520916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch [495]#011Speed: 1029.55 samples/sec#011loss=1.165552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch[500] avg_epoch_loss=1.404333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=500 train loss <loss>=1.24470150471\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch [500]#011Speed: 785.35 samples/sec#011loss=1.244702\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch[505] avg_epoch_loss=1.402815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=505 train loss <loss>=1.25065207481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch [505]#011Speed: 1071.84 samples/sec#011loss=1.250652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch[510] avg_epoch_loss=1.400271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=510 train loss <loss>=1.14287829399\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:30 INFO 140074512123712] Epoch[2] Batch [510]#011Speed: 781.97 samples/sec#011loss=1.142878\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch[515] avg_epoch_loss=1.397310\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=515 train loss <loss>=1.09463605881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch [515]#011Speed: 1074.86 samples/sec#011loss=1.094636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch[520] avg_epoch_loss=1.394573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=520 train loss <loss>=1.11220242977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch [520]#011Speed: 767.53 samples/sec#011loss=1.112202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch[525] avg_epoch_loss=1.393430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=525 train loss <loss>=1.27429397106\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch [525]#011Speed: 1058.05 samples/sec#011loss=1.274294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch[530] avg_epoch_loss=1.391850\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=530 train loss <loss>=1.22565953732\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch [530]#011Speed: 785.51 samples/sec#011loss=1.225660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch[535] avg_epoch_loss=1.389754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=535 train loss <loss>=1.1671402216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:31 INFO 140074512123712] Epoch[2] Batch [535]#011Speed: 1080.97 samples/sec#011loss=1.167140\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch[540] avg_epoch_loss=1.387915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=540 train loss <loss>=1.19080215693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch [540]#011Speed: 770.43 samples/sec#011loss=1.190802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch[545] avg_epoch_loss=1.385954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=545 train loss <loss>=1.17377591133\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch [545]#011Speed: 897.12 samples/sec#011loss=1.173776\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch[550] avg_epoch_loss=1.386079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=550 train loss <loss>=1.39963035583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch [550]#011Speed: 633.93 samples/sec#011loss=1.399630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch[555] avg_epoch_loss=1.384299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=555 train loss <loss>=1.18815201521\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch [555]#011Speed: 1072.29 samples/sec#011loss=1.188152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch[560] avg_epoch_loss=1.381602\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, batch=560 train loss <loss>=1.08178369999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Epoch[2] Batch [560]#011Speed: 847.08 samples/sec#011loss=1.081784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] processed a total of 18060 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20594.351053237915, \"sum\": 20594.351053237915, \"min\": 20594.351053237915}}, \"EndTime\": 1589445032.955307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445012.360888}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=876.935169123 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.38133173875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:32 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_f4b2e371-ef48-4c41-b4ea-2dc434d6d8d1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.325981140136719, \"sum\": 9.325981140136719, \"min\": 9.325981140136719}}, \"EndTime\": 1589445032.965491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445032.955376}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch[0] avg_epoch_loss=1.686523\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=1.68652296066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch[5] avg_epoch_loss=1.323199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=1.32319905361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch [5]#011Speed: 1037.84 samples/sec#011loss=1.323199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch[10] avg_epoch_loss=1.252550\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=1.16777122021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch [10]#011Speed: 1021.95 samples/sec#011loss=1.167771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch[15] avg_epoch_loss=1.198831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=1.08065030575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch [15]#011Speed: 740.77 samples/sec#011loss=1.080650\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch[20] avg_epoch_loss=1.177918\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=1.11099703312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch [20]#011Speed: 1033.99 samples/sec#011loss=1.110997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch[25] avg_epoch_loss=1.201961\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=1.30293755531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:33 INFO 140074512123712] Epoch[3] Batch [25]#011Speed: 779.30 samples/sec#011loss=1.302938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch[30] avg_epoch_loss=1.204236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=1.21606814861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch [30]#011Speed: 1068.11 samples/sec#011loss=1.216068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch[35] avg_epoch_loss=1.185202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=1.06718959808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch [35]#011Speed: 771.79 samples/sec#011loss=1.067190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch[40] avg_epoch_loss=1.182769\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=1.16525466442\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch [40]#011Speed: 1017.35 samples/sec#011loss=1.165255\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch[45] avg_epoch_loss=1.197212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=1.31564211845\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch [45]#011Speed: 790.83 samples/sec#011loss=1.315642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch[50] avg_epoch_loss=1.184249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=1.06499035358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:34 INFO 140074512123712] Epoch[3] Batch [50]#011Speed: 1067.51 samples/sec#011loss=1.064990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch[55] avg_epoch_loss=1.176819\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=1.10103094578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch [55]#011Speed: 788.96 samples/sec#011loss=1.101031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch[60] avg_epoch_loss=1.164484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=1.02633526325\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch [60]#011Speed: 1081.37 samples/sec#011loss=1.026335\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch[65] avg_epoch_loss=1.183603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=1.41684706211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch [65]#011Speed: 754.72 samples/sec#011loss=1.416847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch[70] avg_epoch_loss=1.190690\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=1.28424446583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch [70]#011Speed: 1069.41 samples/sec#011loss=1.284244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch[75] avg_epoch_loss=1.187323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=1.13951630592\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch [75]#011Speed: 793.67 samples/sec#011loss=1.139516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch[80] avg_epoch_loss=1.185288\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=1.15435744524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:35 INFO 140074512123712] Epoch[3] Batch [80]#011Speed: 1070.09 samples/sec#011loss=1.154357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch[85] avg_epoch_loss=1.354638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=4.09810655117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch [85]#011Speed: 793.56 samples/sec#011loss=4.098107\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch[90] avg_epoch_loss=1.367183\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=1.58295938969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch [90]#011Speed: 1066.42 samples/sec#011loss=1.582959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch[95] avg_epoch_loss=1.370621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=1.43318026066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch [95]#011Speed: 706.60 samples/sec#011loss=1.433180\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch[100] avg_epoch_loss=1.410615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=2.17850735188\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch [100]#011Speed: 1066.20 samples/sec#011loss=2.178507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch[105] avg_epoch_loss=1.419822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=1.60581045151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch [105]#011Speed: 785.40 samples/sec#011loss=1.605810\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch[110] avg_epoch_loss=1.426170\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=1.56074819565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:36 INFO 140074512123712] Epoch[3] Batch [110]#011Speed: 1054.52 samples/sec#011loss=1.560748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch[115] avg_epoch_loss=1.430979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=1.53773794174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch [115]#011Speed: 758.06 samples/sec#011loss=1.537738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch[120] avg_epoch_loss=1.429851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=1.40368258953\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch [120]#011Speed: 1072.40 samples/sec#011loss=1.403683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch[125] avg_epoch_loss=1.431224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=1.46445212364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch [125]#011Speed: 645.89 samples/sec#011loss=1.464452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch[130] avg_epoch_loss=1.426608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=1.31027445793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch [130]#011Speed: 1061.25 samples/sec#011loss=1.310274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch[135] avg_epoch_loss=1.420767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=1.26773786545\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:37 INFO 140074512123712] Epoch[3] Batch [135]#011Speed: 769.40 samples/sec#011loss=1.267738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch[140] avg_epoch_loss=1.411109\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=1.14840825796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch [140]#011Speed: 1068.09 samples/sec#011loss=1.148408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch[145] avg_epoch_loss=1.403619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=1.19238893986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch [145]#011Speed: 784.73 samples/sec#011loss=1.192389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch[150] avg_epoch_loss=1.393035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=1.08398925066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch [150]#011Speed: 1041.21 samples/sec#011loss=1.083989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch[155] avg_epoch_loss=1.382798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=1.07365283966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch [155]#011Speed: 761.88 samples/sec#011loss=1.073653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch[160] avg_epoch_loss=1.386846\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=1.51312100887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:38 INFO 140074512123712] Epoch[3] Batch [160]#011Speed: 960.23 samples/sec#011loss=1.513121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch[165] avg_epoch_loss=1.385975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=1.35793864727\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch [165]#011Speed: 778.77 samples/sec#011loss=1.357939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch[170] avg_epoch_loss=1.382240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=1.25823812485\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch [170]#011Speed: 1056.60 samples/sec#011loss=1.258238\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch[175] avg_epoch_loss=1.376258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=1.17165927887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch [175]#011Speed: 752.10 samples/sec#011loss=1.171659\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch[180] avg_epoch_loss=1.368410\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=1.09218537807\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch [180]#011Speed: 1013.74 samples/sec#011loss=1.092185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch[185] avg_epoch_loss=1.363593\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=1.18922350407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch [185]#011Speed: 787.81 samples/sec#011loss=1.189224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch[190] avg_epoch_loss=1.366673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=1.48122694492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:39 INFO 140074512123712] Epoch[3] Batch [190]#011Speed: 1046.80 samples/sec#011loss=1.481227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch[195] avg_epoch_loss=1.365967\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=1.33902449608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch [195]#011Speed: 787.56 samples/sec#011loss=1.339024\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch[200] avg_epoch_loss=1.378501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=1.86979868412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch [200]#011Speed: 1066.20 samples/sec#011loss=1.869799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch[205] avg_epoch_loss=1.381044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=1.48329367638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch [205]#011Speed: 1061.88 samples/sec#011loss=1.483294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch[210] avg_epoch_loss=1.380970\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=1.3779081583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch [210]#011Speed: 748.59 samples/sec#011loss=1.377908\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch[215] avg_epoch_loss=1.379927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=1.33591282368\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch [215]#011Speed: 1067.51 samples/sec#011loss=1.335913\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch[220] avg_epoch_loss=1.378577\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=1.32025675774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:40 INFO 140074512123712] Epoch[3] Batch [220]#011Speed: 738.80 samples/sec#011loss=1.320257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch[225] avg_epoch_loss=1.376481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=1.28384280205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch [225]#011Speed: 1076.59 samples/sec#011loss=1.283843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch[230] avg_epoch_loss=1.371744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=1.1576403141\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch [230]#011Speed: 793.75 samples/sec#011loss=1.157640\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch[235] avg_epoch_loss=1.368415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=1.21462116241\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch [235]#011Speed: 1033.60 samples/sec#011loss=1.214621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch[240] avg_epoch_loss=1.366811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=1.2910959363\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch [240]#011Speed: 806.89 samples/sec#011loss=1.291096\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch[245] avg_epoch_loss=1.364676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=1.26177617311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:41 INFO 140074512123712] Epoch[3] Batch [245]#011Speed: 808.44 samples/sec#011loss=1.261776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch[250] avg_epoch_loss=1.358914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=1.0754335165\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch [250]#011Speed: 1070.90 samples/sec#011loss=1.075434\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch[255] avg_epoch_loss=1.353917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=1.10306822062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch [255]#011Speed: 762.26 samples/sec#011loss=1.103068\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch[260] avg_epoch_loss=1.350208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=1.16029471159\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch [260]#011Speed: 1076.57 samples/sec#011loss=1.160295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch[265] avg_epoch_loss=1.348262\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=1.24667670727\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch [265]#011Speed: 645.03 samples/sec#011loss=1.246677\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch[270] avg_epoch_loss=1.345187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=270 train loss <loss>=1.1815762043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch [270]#011Speed: 1068.95 samples/sec#011loss=1.181576\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch[275] avg_epoch_loss=1.342956\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=275 train loss <loss>=1.22202675343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:42 INFO 140074512123712] Epoch[3] Batch [275]#011Speed: 791.53 samples/sec#011loss=1.222027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch[280] avg_epoch_loss=1.342358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=280 train loss <loss>=1.30937161446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch [280]#011Speed: 1061.79 samples/sec#011loss=1.309372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch[285] avg_epoch_loss=1.339211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=285 train loss <loss>=1.162332201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch [285]#011Speed: 774.08 samples/sec#011loss=1.162332\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch[290] avg_epoch_loss=1.334050\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=290 train loss <loss>=1.03887934685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch [290]#011Speed: 1038.10 samples/sec#011loss=1.038879\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch[295] avg_epoch_loss=1.329549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=295 train loss <loss>=1.06756899357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch [295]#011Speed: 769.53 samples/sec#011loss=1.067569\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch[300] avg_epoch_loss=1.329456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=300 train loss <loss>=1.32395031452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:43 INFO 140074512123712] Epoch[3] Batch [300]#011Speed: 1002.04 samples/sec#011loss=1.323950\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch[305] avg_epoch_loss=1.326943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=305 train loss <loss>=1.17564423084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch [305]#011Speed: 809.79 samples/sec#011loss=1.175644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch[310] avg_epoch_loss=1.328530\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=310 train loss <loss>=1.42568163872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch [310]#011Speed: 1088.69 samples/sec#011loss=1.425682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch[315] avg_epoch_loss=1.323708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=315 train loss <loss>=1.02375588417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch [315]#011Speed: 797.30 samples/sec#011loss=1.023756\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch[320] avg_epoch_loss=1.331136\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=320 train loss <loss>=1.80059967041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch [320]#011Speed: 1026.36 samples/sec#011loss=1.800600\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch[325] avg_epoch_loss=1.329722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=325 train loss <loss>=1.23896067142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch [325]#011Speed: 805.78 samples/sec#011loss=1.238961\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch[330] avg_epoch_loss=1.327999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=330 train loss <loss>=1.21565113068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:44 INFO 140074512123712] Epoch[3] Batch [330]#011Speed: 1089.14 samples/sec#011loss=1.215651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch[335] avg_epoch_loss=1.327433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=335 train loss <loss>=1.28995609283\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch [335]#011Speed: 779.77 samples/sec#011loss=1.289956\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch[340] avg_epoch_loss=1.326866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=340 train loss <loss>=1.28876199722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch [340]#011Speed: 1072.21 samples/sec#011loss=1.288762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch[345] avg_epoch_loss=1.324367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=345 train loss <loss>=1.15393705368\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch [345]#011Speed: 812.40 samples/sec#011loss=1.153937\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch[350] avg_epoch_loss=1.321250\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=350 train loss <loss>=1.10556721687\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch [350]#011Speed: 1042.83 samples/sec#011loss=1.105567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch[355] avg_epoch_loss=1.317643\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=355 train loss <loss>=1.06441001892\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch [355]#011Speed: 794.49 samples/sec#011loss=1.064410\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch[360] avg_epoch_loss=1.322662\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=360 train loss <loss>=1.68000769615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:45 INFO 140074512123712] Epoch[3] Batch [360]#011Speed: 1084.31 samples/sec#011loss=1.680008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch[365] avg_epoch_loss=1.319843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=365 train loss <loss>=1.11629242897\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch [365]#011Speed: 777.30 samples/sec#011loss=1.116292\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch[370] avg_epoch_loss=1.317430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=370 train loss <loss>=1.1408370018\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch [370]#011Speed: 1072.71 samples/sec#011loss=1.140837\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch[375] avg_epoch_loss=1.314689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=375 train loss <loss>=1.11132413149\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch [375]#011Speed: 767.81 samples/sec#011loss=1.111324\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch[380] avg_epoch_loss=1.313975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=380 train loss <loss>=1.26028473377\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch [380]#011Speed: 1056.23 samples/sec#011loss=1.260285\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch[385] avg_epoch_loss=1.310905\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=385 train loss <loss>=1.07696903944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:46 INFO 140074512123712] Epoch[3] Batch [385]#011Speed: 758.67 samples/sec#011loss=1.076969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch[390] avg_epoch_loss=1.311140\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=390 train loss <loss>=1.32923076153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch [390]#011Speed: 1077.00 samples/sec#011loss=1.329231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch[395] avg_epoch_loss=1.311922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=395 train loss <loss>=1.37312465906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch [395]#011Speed: 1022.68 samples/sec#011loss=1.373125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch[400] avg_epoch_loss=1.310499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=400 train loss <loss>=1.19775319099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch [400]#011Speed: 784.55 samples/sec#011loss=1.197753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch[405] avg_epoch_loss=1.307792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=405 train loss <loss>=1.09072264433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch [405]#011Speed: 852.98 samples/sec#011loss=1.090723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch[410] avg_epoch_loss=1.306095\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=410 train loss <loss>=1.16826212406\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch [410]#011Speed: 730.38 samples/sec#011loss=1.168262\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch[415] avg_epoch_loss=1.307131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=415 train loss <loss>=1.392273736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:47 INFO 140074512123712] Epoch[3] Batch [415]#011Speed: 1073.74 samples/sec#011loss=1.392274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch[420] avg_epoch_loss=1.306151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=420 train loss <loss>=1.22461884022\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch [420]#011Speed: 758.28 samples/sec#011loss=1.224619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch[425] avg_epoch_loss=1.305360\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=425 train loss <loss>=1.23881490231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch [425]#011Speed: 1078.66 samples/sec#011loss=1.238815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch[430] avg_epoch_loss=1.305466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=430 train loss <loss>=1.3144865036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch [430]#011Speed: 799.90 samples/sec#011loss=1.314487\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch[435] avg_epoch_loss=1.304214\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=435 train loss <loss>=1.19630746841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch [435]#011Speed: 1056.20 samples/sec#011loss=1.196307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch[440] avg_epoch_loss=1.303480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=440 train loss <loss>=1.23947958946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:48 INFO 140074512123712] Epoch[3] Batch [440]#011Speed: 742.93 samples/sec#011loss=1.239480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch[445] avg_epoch_loss=1.305067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=445 train loss <loss>=1.44502046108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch [445]#011Speed: 1087.47 samples/sec#011loss=1.445020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch[450] avg_epoch_loss=1.303460\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=450 train loss <loss>=1.16009192467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch [450]#011Speed: 795.26 samples/sec#011loss=1.160092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch[455] avg_epoch_loss=1.303042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=455 train loss <loss>=1.26534253359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch [455]#011Speed: 1087.95 samples/sec#011loss=1.265343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch[460] avg_epoch_loss=1.300719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=460 train loss <loss>=1.08885936737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch [460]#011Speed: 756.57 samples/sec#011loss=1.088859\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch[465] avg_epoch_loss=1.298497\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=465 train loss <loss>=1.09365735054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch [465]#011Speed: 1079.93 samples/sec#011loss=1.093657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch[470] avg_epoch_loss=1.298337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=470 train loss <loss>=1.28337550163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:49 INFO 140074512123712] Epoch[3] Batch [470]#011Speed: 785.43 samples/sec#011loss=1.283376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch[475] avg_epoch_loss=1.296281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=475 train loss <loss>=1.10265440941\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch [475]#011Speed: 1060.10 samples/sec#011loss=1.102654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch[480] avg_epoch_loss=1.293904\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=480 train loss <loss>=1.06763757467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch [480]#011Speed: 793.85 samples/sec#011loss=1.067638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch[485] avg_epoch_loss=1.291206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=485 train loss <loss>=1.03162958622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch [485]#011Speed: 1084.08 samples/sec#011loss=1.031630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch[490] avg_epoch_loss=1.297537\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=490 train loss <loss>=1.91288655996\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch [490]#011Speed: 771.78 samples/sec#011loss=1.912887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch[495] avg_epoch_loss=1.295123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=495 train loss <loss>=1.05808542967\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch [495]#011Speed: 1074.53 samples/sec#011loss=1.058085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch[500] avg_epoch_loss=1.299329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=500 train loss <loss>=1.71651031971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:50 INFO 140074512123712] Epoch[3] Batch [500]#011Speed: 1082.34 samples/sec#011loss=1.716510\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch[505] avg_epoch_loss=1.297619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=505 train loss <loss>=1.12628421783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch [505]#011Speed: 774.01 samples/sec#011loss=1.126284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch[510] avg_epoch_loss=1.295735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=510 train loss <loss>=1.10510389805\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch [510]#011Speed: 1076.90 samples/sec#011loss=1.105104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch[515] avg_epoch_loss=1.293867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=515 train loss <loss>=1.10300869942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch [515]#011Speed: 804.69 samples/sec#011loss=1.103009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch[520] avg_epoch_loss=1.290915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=520 train loss <loss>=0.986220741272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch [520]#011Speed: 1022.95 samples/sec#011loss=0.986221\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch[525] avg_epoch_loss=1.289974\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=525 train loss <loss>=1.19193490744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:51 INFO 140074512123712] Epoch[3] Batch [525]#011Speed: 764.63 samples/sec#011loss=1.191935\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch[530] avg_epoch_loss=1.287460\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=530 train loss <loss>=1.02302821875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch [530]#011Speed: 1071.52 samples/sec#011loss=1.023028\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch[535] avg_epoch_loss=1.285785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=535 train loss <loss>=1.10787982941\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch [535]#011Speed: 682.48 samples/sec#011loss=1.107880\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch[540] avg_epoch_loss=1.284391\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=540 train loss <loss>=1.13497060537\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch [540]#011Speed: 1085.71 samples/sec#011loss=1.134971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch[545] avg_epoch_loss=1.283743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=545 train loss <loss>=1.21362389326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch [545]#011Speed: 771.20 samples/sec#011loss=1.213624\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch[550] avg_epoch_loss=1.281977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=550 train loss <loss>=1.08911221027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch [550]#011Speed: 892.15 samples/sec#011loss=1.089112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch[555] avg_epoch_loss=1.280652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=555 train loss <loss>=1.13464503288\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:52 INFO 140074512123712] Epoch[3] Batch [555]#011Speed: 806.98 samples/sec#011loss=1.134645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[3] Batch[560] avg_epoch_loss=1.280507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=560 train loss <loss>=1.26437612772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[3] Batch [560]#011Speed: 1010.43 samples/sec#011loss=1.264376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[3] Batch[565] avg_epoch_loss=1.278465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, batch=565 train loss <loss>=1.04938893318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[3] Batch [565]#011Speed: 840.03 samples/sec#011loss=1.049389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] processed a total of 18220 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20493.98899078369, \"sum\": 20493.98899078369, \"min\": 20493.98899078369}}, \"EndTime\": 1589445053.459598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445032.965551}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=889.036828495 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=3, train loss <loss>=1.27797599236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_b069cd46-1d18-40f8-9d17-dee523cf6ec9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.193897247314453, \"sum\": 9.193897247314453, \"min\": 9.193897247314453}}, \"EndTime\": 1589445053.469342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445053.459667}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[4] Batch[0] avg_epoch_loss=1.576084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.57608389854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[4] Batch[5] avg_epoch_loss=1.501025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=1.50102469325\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[4] Batch [5]#011Speed: 1026.41 samples/sec#011loss=1.501025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[4] Batch[10] avg_epoch_loss=1.394205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.26602241993\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:53 INFO 140074512123712] Epoch[4] Batch [10]#011Speed: 731.13 samples/sec#011loss=1.266022\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch[15] avg_epoch_loss=1.349610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=1.25149869919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch [15]#011Speed: 1069.08 samples/sec#011loss=1.251499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch[20] avg_epoch_loss=1.291979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=1.10756255388\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch [20]#011Speed: 803.07 samples/sec#011loss=1.107563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch[25] avg_epoch_loss=1.252342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=1.08586580753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch [25]#011Speed: 1060.15 samples/sec#011loss=1.085866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch[30] avg_epoch_loss=1.256452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=1.2778222084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch [30]#011Speed: 760.63 samples/sec#011loss=1.277822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch[35] avg_epoch_loss=1.230740\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=1.07132813931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch [35]#011Speed: 1051.77 samples/sec#011loss=1.071328\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch[40] avg_epoch_loss=1.246984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=1.36393556595\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:54 INFO 140074512123712] Epoch[4] Batch [40]#011Speed: 1066.26 samples/sec#011loss=1.363936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch[45] avg_epoch_loss=1.237506\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=1.1597880125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch [45]#011Speed: 796.48 samples/sec#011loss=1.159788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch[50] avg_epoch_loss=1.250615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=1.37122199535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch [50]#011Speed: 1081.69 samples/sec#011loss=1.371222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch[55] avg_epoch_loss=1.249554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=1.23873040676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch [55]#011Speed: 796.26 samples/sec#011loss=1.238730\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch[60] avg_epoch_loss=1.237814\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=1.10632786751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch [60]#011Speed: 1003.29 samples/sec#011loss=1.106328\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch[65] avg_epoch_loss=1.242586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=1.30080103874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:55 INFO 140074512123712] Epoch[4] Batch [65]#011Speed: 781.06 samples/sec#011loss=1.300801\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch[70] avg_epoch_loss=1.247516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=1.31259477139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch [70]#011Speed: 1104.63 samples/sec#011loss=1.312595\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch[75] avg_epoch_loss=1.241223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=1.15186593533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch [75]#011Speed: 792.90 samples/sec#011loss=1.151866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch[80] avg_epoch_loss=1.234176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=1.12705779076\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch [80]#011Speed: 1077.77 samples/sec#011loss=1.127058\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch[85] avg_epoch_loss=1.230514\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=1.17119276524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch [85]#011Speed: 801.49 samples/sec#011loss=1.171193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch[90] avg_epoch_loss=1.225836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=1.1453699708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch [90]#011Speed: 1047.66 samples/sec#011loss=1.145370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch[95] avg_epoch_loss=1.221804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=1.14841171503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:56 INFO 140074512123712] Epoch[4] Batch [95]#011Speed: 799.06 samples/sec#011loss=1.148412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch[100] avg_epoch_loss=1.211044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=1.00446425676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch [100]#011Speed: 1072.28 samples/sec#011loss=1.004464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch[105] avg_epoch_loss=1.216225\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=1.32087136507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch [105]#011Speed: 780.99 samples/sec#011loss=1.320871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch[110] avg_epoch_loss=1.206029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=0.989886200428\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch [110]#011Speed: 1086.37 samples/sec#011loss=0.989886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch[115] avg_epoch_loss=1.206699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=1.2215726614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch [115]#011Speed: 795.09 samples/sec#011loss=1.221573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch[120] avg_epoch_loss=1.203496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=1.129190588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch [120]#011Speed: 847.94 samples/sec#011loss=1.129191\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch[125] avg_epoch_loss=1.203355\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=1.19992768764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:57 INFO 140074512123712] Epoch[4] Batch [125]#011Speed: 795.46 samples/sec#011loss=1.199928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch[130] avg_epoch_loss=1.203808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=1.21523051262\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch [130]#011Speed: 1064.88 samples/sec#011loss=1.215231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch[135] avg_epoch_loss=1.205757\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=1.25681824684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch [135]#011Speed: 763.30 samples/sec#011loss=1.256818\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch[140] avg_epoch_loss=1.207524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=1.25560059547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch [140]#011Speed: 1096.68 samples/sec#011loss=1.255601\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch[145] avg_epoch_loss=1.201304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=1.02588021755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch [145]#011Speed: 783.42 samples/sec#011loss=1.025880\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch[150] avg_epoch_loss=1.195555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=1.02768803835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:58 INFO 140074512123712] Epoch[4] Batch [150]#011Speed: 764.23 samples/sec#011loss=1.027688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch[155] avg_epoch_loss=1.191871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=1.08061389923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch [155]#011Speed: 1026.98 samples/sec#011loss=1.080614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch[160] avg_epoch_loss=1.189092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=1.1023953557\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch [160]#011Speed: 1072.59 samples/sec#011loss=1.102395\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch[165] avg_epoch_loss=1.185150\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=1.0582234621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch [165]#011Speed: 779.92 samples/sec#011loss=1.058223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch[170] avg_epoch_loss=1.178793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=0.967743599415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch [170]#011Speed: 1058.87 samples/sec#011loss=0.967744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch[175] avg_epoch_loss=1.174155\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=1.01553467512\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch [175]#011Speed: 754.87 samples/sec#011loss=1.015535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch[180] avg_epoch_loss=1.179208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=1.35705418587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:30:59 INFO 140074512123712] Epoch[4] Batch [180]#011Speed: 1085.26 samples/sec#011loss=1.357054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch[185] avg_epoch_loss=1.184720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=1.38426796198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch [185]#011Speed: 647.43 samples/sec#011loss=1.384268\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch[190] avg_epoch_loss=1.214272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=2.31358935833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch [190]#011Speed: 798.45 samples/sec#011loss=2.313589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch[195] avg_epoch_loss=1.221968\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=1.51597788334\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch [195]#011Speed: 793.18 samples/sec#011loss=1.515978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch[200] avg_epoch_loss=1.227603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=1.4484754324\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch [200]#011Speed: 1036.53 samples/sec#011loss=1.448475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch[205] avg_epoch_loss=1.232725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=1.43862097263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:00 INFO 140074512123712] Epoch[4] Batch [205]#011Speed: 786.28 samples/sec#011loss=1.438621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch[210] avg_epoch_loss=1.236250\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=1.38148007393\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch [210]#011Speed: 1061.65 samples/sec#011loss=1.381480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch[215] avg_epoch_loss=1.238567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=1.3363496542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch [215]#011Speed: 712.42 samples/sec#011loss=1.336350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch[220] avg_epoch_loss=1.238342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=1.22861671448\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch [220]#011Speed: 1077.80 samples/sec#011loss=1.228617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch[225] avg_epoch_loss=1.238193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=1.23160681725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch [225]#011Speed: 793.28 samples/sec#011loss=1.231607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch[230] avg_epoch_loss=1.238970\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=1.27408676147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:01 INFO 140074512123712] Epoch[4] Batch [230]#011Speed: 1010.96 samples/sec#011loss=1.274087\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch[235] avg_epoch_loss=1.263413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=2.3927131176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch [235]#011Speed: 790.21 samples/sec#011loss=2.392713\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch[240] avg_epoch_loss=1.261752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=1.18333318233\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch [240]#011Speed: 1075.70 samples/sec#011loss=1.183333\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch[245] avg_epoch_loss=1.259698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=1.16071586609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch [245]#011Speed: 762.28 samples/sec#011loss=1.160716\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch[250] avg_epoch_loss=1.257993\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=1.17409095764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch [250]#011Speed: 1082.05 samples/sec#011loss=1.174091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch[255] avg_epoch_loss=1.259536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=1.33700554371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch [255]#011Speed: 679.96 samples/sec#011loss=1.337006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch[260] avg_epoch_loss=1.257407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=1.14839754105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:02 INFO 140074512123712] Epoch[4] Batch [260]#011Speed: 945.95 samples/sec#011loss=1.148398\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch[265] avg_epoch_loss=1.264658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=1.64314332008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch [265]#011Speed: 789.44 samples/sec#011loss=1.643143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch[270] avg_epoch_loss=1.260896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=270 train loss <loss>=1.06076061726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch [270]#011Speed: 1044.67 samples/sec#011loss=1.060761\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch[275] avg_epoch_loss=1.260705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=275 train loss <loss>=1.25033950806\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch [275]#011Speed: 782.06 samples/sec#011loss=1.250340\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch[280] avg_epoch_loss=1.277104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=280 train loss <loss>=2.18237450123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch [280]#011Speed: 1074.79 samples/sec#011loss=2.182375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch[285] avg_epoch_loss=1.275030\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=285 train loss <loss>=1.15842459202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:03 INFO 140074512123712] Epoch[4] Batch [285]#011Speed: 762.16 samples/sec#011loss=1.158425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch[290] avg_epoch_loss=1.273959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=290 train loss <loss>=1.21273086071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch [290]#011Speed: 1010.91 samples/sec#011loss=1.212731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch[295] avg_epoch_loss=1.273782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=295 train loss <loss>=1.26345522404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch [295]#011Speed: 781.02 samples/sec#011loss=1.263455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch[300] avg_epoch_loss=1.272057\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=300 train loss <loss>=1.16996426582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch [300]#011Speed: 1077.81 samples/sec#011loss=1.169964\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch[305] avg_epoch_loss=1.270959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=305 train loss <loss>=1.20486197472\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch [305]#011Speed: 781.47 samples/sec#011loss=1.204862\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch[310] avg_epoch_loss=1.268359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=310 train loss <loss>=1.10921632051\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch [310]#011Speed: 1038.89 samples/sec#011loss=1.109216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch[315] avg_epoch_loss=1.277541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=315 train loss <loss>=1.84866027832\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:04 INFO 140074512123712] Epoch[4] Batch [315]#011Speed: 743.47 samples/sec#011loss=1.848660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch[320] avg_epoch_loss=1.275956\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=320 train loss <loss>=1.17582261562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch [320]#011Speed: 1090.08 samples/sec#011loss=1.175823\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch[325] avg_epoch_loss=1.273001\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=325 train loss <loss>=1.08325698376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch [325]#011Speed: 803.55 samples/sec#011loss=1.083257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch[330] avg_epoch_loss=1.271389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=330 train loss <loss>=1.16627862453\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch [330]#011Speed: 1096.76 samples/sec#011loss=1.166279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch[335] avg_epoch_loss=1.268930\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=335 train loss <loss>=1.10618293285\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch [335]#011Speed: 794.75 samples/sec#011loss=1.106183\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch[340] avg_epoch_loss=1.266483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=340 train loss <loss>=1.10199697018\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch [340]#011Speed: 1037.55 samples/sec#011loss=1.101997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch[345] avg_epoch_loss=1.264220\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=345 train loss <loss>=1.10992622375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:05 INFO 140074512123712] Epoch[4] Batch [345]#011Speed: 800.15 samples/sec#011loss=1.109926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch[350] avg_epoch_loss=1.260219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=350 train loss <loss>=0.983307731152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch [350]#011Speed: 1072.83 samples/sec#011loss=0.983308\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch[355] avg_epoch_loss=1.257942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=355 train loss <loss>=1.09813467264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch [355]#011Speed: 1072.97 samples/sec#011loss=1.098135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch[360] avg_epoch_loss=1.258680\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=360 train loss <loss>=1.31123225689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch [360]#011Speed: 780.61 samples/sec#011loss=1.311232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch[365] avg_epoch_loss=1.255392\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=365 train loss <loss>=1.01798677444\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch [365]#011Speed: 1083.20 samples/sec#011loss=1.017987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch[370] avg_epoch_loss=1.254615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=370 train loss <loss>=1.19772416353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:06 INFO 140074512123712] Epoch[4] Batch [370]#011Speed: 734.42 samples/sec#011loss=1.197724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch[375] avg_epoch_loss=1.255530\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=375 train loss <loss>=1.32345364094\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch [375]#011Speed: 1077.86 samples/sec#011loss=1.323454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch[380] avg_epoch_loss=1.255066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=380 train loss <loss>=1.22018110752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch [380]#011Speed: 785.15 samples/sec#011loss=1.220181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch[385] avg_epoch_loss=1.254604\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=385 train loss <loss>=1.21932680607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch [385]#011Speed: 999.67 samples/sec#011loss=1.219327\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch[390] avg_epoch_loss=1.254034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=390 train loss <loss>=1.21008148193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch [390]#011Speed: 778.68 samples/sec#011loss=1.210081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch[395] avg_epoch_loss=1.253978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=395 train loss <loss>=1.24958744049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch [395]#011Speed: 1062.66 samples/sec#011loss=1.249587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch[400] avg_epoch_loss=1.251713\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=400 train loss <loss>=1.07231303453\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:07 INFO 140074512123712] Epoch[4] Batch [400]#011Speed: 630.02 samples/sec#011loss=1.072313\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch[405] avg_epoch_loss=1.249469\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=405 train loss <loss>=1.06948337555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch [405]#011Speed: 1062.67 samples/sec#011loss=1.069483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch[410] avg_epoch_loss=1.247090\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=410 train loss <loss>=1.05395050049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch [410]#011Speed: 764.83 samples/sec#011loss=1.053951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch[415] avg_epoch_loss=1.246017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=415 train loss <loss>=1.1577927947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch [415]#011Speed: 1060.75 samples/sec#011loss=1.157793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch[420] avg_epoch_loss=1.246299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=420 train loss <loss>=1.2697729826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch [420]#011Speed: 789.53 samples/sec#011loss=1.269773\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch[425] avg_epoch_loss=1.244935\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=425 train loss <loss>=1.13006058931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:08 INFO 140074512123712] Epoch[4] Batch [425]#011Speed: 1001.67 samples/sec#011loss=1.130061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch[430] avg_epoch_loss=1.246138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=430 train loss <loss>=1.34868140221\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch [430]#011Speed: 765.35 samples/sec#011loss=1.348681\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch[435] avg_epoch_loss=1.245817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=435 train loss <loss>=1.21814968586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch [435]#011Speed: 1075.10 samples/sec#011loss=1.218150\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch[440] avg_epoch_loss=1.246084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=440 train loss <loss>=1.2693672657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch [440]#011Speed: 787.58 samples/sec#011loss=1.269367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch[445] avg_epoch_loss=1.246219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=445 train loss <loss>=1.25806319714\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch [445]#011Speed: 1060.51 samples/sec#011loss=1.258063\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch[450] avg_epoch_loss=1.245359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=450 train loss <loss>=1.16864080429\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch [450]#011Speed: 774.25 samples/sec#011loss=1.168641\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch[455] avg_epoch_loss=1.244486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=455 train loss <loss>=1.16577920914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:09 INFO 140074512123712] Epoch[4] Batch [455]#011Speed: 1073.86 samples/sec#011loss=1.165779\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch[460] avg_epoch_loss=1.246754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=460 train loss <loss>=1.4535806179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch [460]#011Speed: 777.10 samples/sec#011loss=1.453581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch[465] avg_epoch_loss=1.245799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=465 train loss <loss>=1.15777029991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch [465]#011Speed: 1087.70 samples/sec#011loss=1.157770\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch[470] avg_epoch_loss=1.245427\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=470 train loss <loss>=1.21074162722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch [470]#011Speed: 799.76 samples/sec#011loss=1.210742\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch[475] avg_epoch_loss=1.245158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=475 train loss <loss>=1.21979990005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch [475]#011Speed: 1099.93 samples/sec#011loss=1.219800\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch[480] avg_epoch_loss=1.243210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=480 train loss <loss>=1.05783244371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch [480]#011Speed: 773.17 samples/sec#011loss=1.057832\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch[485] avg_epoch_loss=1.247174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=485 train loss <loss>=1.62845739126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:10 INFO 140074512123712] Epoch[4] Batch [485]#011Speed: 1056.15 samples/sec#011loss=1.628457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch[490] avg_epoch_loss=1.246029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=490 train loss <loss>=1.13476686478\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch [490]#011Speed: 792.22 samples/sec#011loss=1.134767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch[495] avg_epoch_loss=1.243731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=495 train loss <loss>=1.01804704666\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch [495]#011Speed: 1061.37 samples/sec#011loss=1.018047\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch[500] avg_epoch_loss=1.243991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=500 train loss <loss>=1.26980227232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch [500]#011Speed: 787.67 samples/sec#011loss=1.269802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch[505] avg_epoch_loss=1.242197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=505 train loss <loss>=1.06241726875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch [505]#011Speed: 1088.01 samples/sec#011loss=1.062417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch[510] avg_epoch_loss=1.240020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=510 train loss <loss>=1.01974359751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:11 INFO 140074512123712] Epoch[4] Batch [510]#011Speed: 762.03 samples/sec#011loss=1.019744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch[515] avg_epoch_loss=1.239236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=515 train loss <loss>=1.15910494328\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch [515]#011Speed: 1080.61 samples/sec#011loss=1.159105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch[520] avg_epoch_loss=1.236853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=520 train loss <loss>=0.990858900547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch [520]#011Speed: 769.57 samples/sec#011loss=0.990859\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch[525] avg_epoch_loss=1.234356\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=525 train loss <loss>=0.974162006378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch [525]#011Speed: 1029.81 samples/sec#011loss=0.974162\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch[530] avg_epoch_loss=1.233744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=530 train loss <loss>=1.16944884062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch [530]#011Speed: 787.63 samples/sec#011loss=1.169449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch[535] avg_epoch_loss=1.232267\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=535 train loss <loss>=1.07540911436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:12 INFO 140074512123712] Epoch[4] Batch [535]#011Speed: 1076.72 samples/sec#011loss=1.075409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch[540] avg_epoch_loss=1.232364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=540 train loss <loss>=1.2427781105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch [540]#011Speed: 657.82 samples/sec#011loss=1.242778\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch[545] avg_epoch_loss=1.230579\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=545 train loss <loss>=1.03743430376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch [545]#011Speed: 1073.92 samples/sec#011loss=1.037434\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch[550] avg_epoch_loss=1.228766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=550 train loss <loss>=1.03072532415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch [550]#011Speed: 776.06 samples/sec#011loss=1.030725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch[555] avg_epoch_loss=1.228157\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=555 train loss <loss>=1.16108242273\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch [555]#011Speed: 1063.41 samples/sec#011loss=1.161082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch[560] avg_epoch_loss=1.227352\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, batch=560 train loss <loss>=1.13784509897\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[4] Batch [560]#011Speed: 950.45 samples/sec#011loss=1.137845\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] processed a total of 17995 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20277.793169021606, \"sum\": 20277.793169021606, \"min\": 20277.793169021606}}, \"EndTime\": 1589445073.747276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445053.469398}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=887.414843877 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.22707625149\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_c43306fb-516a-4992-bb82-905b3d126e57-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.219884872436523, \"sum\": 9.219884872436523, \"min\": 9.219884872436523}}, \"EndTime\": 1589445073.757488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445073.747421}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] Epoch[5] Batch[0] avg_epoch_loss=2.147638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.14763832092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch[5] avg_epoch_loss=1.332274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=1.33227372169\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch [5]#011Speed: 1049.03 samples/sec#011loss=1.332274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch[10] avg_epoch_loss=1.350039\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=1.37135810852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch [10]#011Speed: 759.85 samples/sec#011loss=1.371358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch[15] avg_epoch_loss=1.265555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=1.07968866825\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch [15]#011Speed: 1086.32 samples/sec#011loss=1.079689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch[20] avg_epoch_loss=1.223487\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=1.08887200356\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch [20]#011Speed: 797.30 samples/sec#011loss=1.088872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch[25] avg_epoch_loss=1.217295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=1.19128420353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch [25]#011Speed: 1077.19 samples/sec#011loss=1.191284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch[30] avg_epoch_loss=1.209439\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=1.16859045029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:14 INFO 140074512123712] Epoch[5] Batch [30]#011Speed: 745.90 samples/sec#011loss=1.168590\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch[35] avg_epoch_loss=1.244451\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=1.46152188778\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch [35]#011Speed: 1044.56 samples/sec#011loss=1.461522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch[40] avg_epoch_loss=1.268587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=1.44236552715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch [40]#011Speed: 802.65 samples/sec#011loss=1.442366\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch[45] avg_epoch_loss=1.261055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=1.19929261208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch [45]#011Speed: 1074.51 samples/sec#011loss=1.199293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch[50] avg_epoch_loss=1.249375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=1.14192452431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch [50]#011Speed: 787.93 samples/sec#011loss=1.141925\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch[55] avg_epoch_loss=1.236905\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=1.10970888138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch [55]#011Speed: 1064.18 samples/sec#011loss=1.109709\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch[60] avg_epoch_loss=1.231405\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=1.16981124878\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:15 INFO 140074512123712] Epoch[5] Batch [60]#011Speed: 760.23 samples/sec#011loss=1.169811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch[65] avg_epoch_loss=1.234979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=1.27857956886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch [65]#011Speed: 1073.96 samples/sec#011loss=1.278580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch[70] avg_epoch_loss=1.226335\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=1.11222676039\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch [70]#011Speed: 793.30 samples/sec#011loss=1.112227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch[75] avg_epoch_loss=1.213674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=1.03388490677\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch [75]#011Speed: 1072.13 samples/sec#011loss=1.033885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch[80] avg_epoch_loss=1.210341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=1.15969034433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch [80]#011Speed: 818.37 samples/sec#011loss=1.159690\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch[85] avg_epoch_loss=1.267389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=2.19155778885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:16 INFO 140074512123712] Epoch[5] Batch [85]#011Speed: 1074.81 samples/sec#011loss=2.191558\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch[90] avg_epoch_loss=1.262863\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=1.18502290249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch [90]#011Speed: 768.99 samples/sec#011loss=1.185023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch[95] avg_epoch_loss=1.281671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=1.62397687435\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch [95]#011Speed: 1057.87 samples/sec#011loss=1.623977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch[100] avg_epoch_loss=1.281070\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=1.26952223778\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch [100]#011Speed: 656.53 samples/sec#011loss=1.269522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch[105] avg_epoch_loss=1.280394\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=1.26673793793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch [105]#011Speed: 1088.35 samples/sec#011loss=1.266738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch[110] avg_epoch_loss=1.290750\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=1.5103051424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch [110]#011Speed: 790.78 samples/sec#011loss=1.510305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch[115] avg_epoch_loss=1.284821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=1.15319206715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:17 INFO 140074512123712] Epoch[5] Batch [115]#011Speed: 1041.38 samples/sec#011loss=1.153192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch[120] avg_epoch_loss=1.277019\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=1.09602849483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch [120]#011Speed: 699.41 samples/sec#011loss=1.096028\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch[125] avg_epoch_loss=1.280651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=1.36853276491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch [125]#011Speed: 1052.78 samples/sec#011loss=1.368533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch[130] avg_epoch_loss=1.277367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=1.19460353851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch [130]#011Speed: 764.18 samples/sec#011loss=1.194604\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch[135] avg_epoch_loss=1.280674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=1.36733766794\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch [135]#011Speed: 1082.27 samples/sec#011loss=1.367338\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch[140] avg_epoch_loss=1.275193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=1.12610815763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:18 INFO 140074512123712] Epoch[5] Batch [140]#011Speed: 777.63 samples/sec#011loss=1.126108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch[145] avg_epoch_loss=1.272604\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=1.19957716465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch [145]#011Speed: 1068.01 samples/sec#011loss=1.199577\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch[150] avg_epoch_loss=1.275628\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=1.36393027306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch [150]#011Speed: 749.36 samples/sec#011loss=1.363930\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch[155] avg_epoch_loss=1.272906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=1.19070258141\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch [155]#011Speed: 1080.91 samples/sec#011loss=1.190703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch[160] avg_epoch_loss=1.271571\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=1.2299254179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch [160]#011Speed: 791.48 samples/sec#011loss=1.229925\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch[165] avg_epoch_loss=1.271208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=1.25952453613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch [165]#011Speed: 1069.05 samples/sec#011loss=1.259525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch[170] avg_epoch_loss=1.264363\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=1.03709064722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:19 INFO 140074512123712] Epoch[5] Batch [170]#011Speed: 787.28 samples/sec#011loss=1.037091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch[175] avg_epoch_loss=1.263010\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=1.21673724651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch [175]#011Speed: 1061.18 samples/sec#011loss=1.216737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch[180] avg_epoch_loss=1.266594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=1.39275979996\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch [180]#011Speed: 779.70 samples/sec#011loss=1.392760\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch[185] avg_epoch_loss=1.273527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=1.52448933125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch [185]#011Speed: 1071.65 samples/sec#011loss=1.524489\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch[190] avg_epoch_loss=1.277552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=1.4272885561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch [190]#011Speed: 782.91 samples/sec#011loss=1.427289\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch[195] avg_epoch_loss=1.282163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=1.45831842422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:20 INFO 140074512123712] Epoch[5] Batch [195]#011Speed: 1099.49 samples/sec#011loss=1.458318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch[200] avg_epoch_loss=1.280486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=1.21472527981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch [200]#011Speed: 771.07 samples/sec#011loss=1.214725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch[205] avg_epoch_loss=1.282512\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=1.36395237446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch [205]#011Speed: 1086.62 samples/sec#011loss=1.363952\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch[210] avg_epoch_loss=1.281045\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=1.22062280178\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch [210]#011Speed: 797.02 samples/sec#011loss=1.220623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch[215] avg_epoch_loss=1.276116\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=1.06810100079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch [215]#011Speed: 1077.66 samples/sec#011loss=1.068101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch[220] avg_epoch_loss=1.272480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=1.11543611288\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch [220]#011Speed: 804.36 samples/sec#011loss=1.115436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch[225] avg_epoch_loss=1.266646\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=1.00878245831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:21 INFO 140074512123712] Epoch[5] Batch [225]#011Speed: 1076.83 samples/sec#011loss=1.008782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch[230] avg_epoch_loss=1.259790\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=0.949864113331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch [230]#011Speed: 750.59 samples/sec#011loss=0.949864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch[235] avg_epoch_loss=1.254249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=0.998257422447\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch [235]#011Speed: 1081.12 samples/sec#011loss=0.998257\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch[240] avg_epoch_loss=1.248268\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=0.966001963615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch [240]#011Speed: 1026.77 samples/sec#011loss=0.966002\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch[245] avg_epoch_loss=1.243404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=1.00894426107\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch [245]#011Speed: 775.08 samples/sec#011loss=1.008944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch[250] avg_epoch_loss=1.238599\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=1.00217092037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch [250]#011Speed: 1075.75 samples/sec#011loss=1.002171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch[255] avg_epoch_loss=1.233575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=0.98140194416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:22 INFO 140074512123712] Epoch[5] Batch [255]#011Speed: 746.21 samples/sec#011loss=0.981402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch[260] avg_epoch_loss=1.238130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=1.47132534981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch [260]#011Speed: 887.49 samples/sec#011loss=1.471325\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch[265] avg_epoch_loss=1.234868\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=1.06458674669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch [265]#011Speed: 774.56 samples/sec#011loss=1.064587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch[270] avg_epoch_loss=1.233485\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=270 train loss <loss>=1.15990149975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch [270]#011Speed: 1053.80 samples/sec#011loss=1.159901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch[275] avg_epoch_loss=1.230194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=275 train loss <loss>=1.05182843208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch [275]#011Speed: 766.24 samples/sec#011loss=1.051828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch[280] avg_epoch_loss=1.226672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=280 train loss <loss>=1.03227835894\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:23 INFO 140074512123712] Epoch[5] Batch [280]#011Speed: 1047.57 samples/sec#011loss=1.032278\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch[285] avg_epoch_loss=1.222875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=285 train loss <loss>=1.0094491601\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch [285]#011Speed: 753.36 samples/sec#011loss=1.009449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch[290] avg_epoch_loss=1.218456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=290 train loss <loss>=0.965695095062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch [290]#011Speed: 932.68 samples/sec#011loss=0.965695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch[295] avg_epoch_loss=1.215706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=295 train loss <loss>=1.05564652681\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch [295]#011Speed: 751.77 samples/sec#011loss=1.055647\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch[300] avg_epoch_loss=1.218726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=300 train loss <loss>=1.39753010273\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch [300]#011Speed: 1065.13 samples/sec#011loss=1.397530\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch[305] avg_epoch_loss=1.215377\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=305 train loss <loss>=1.01375653744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch [305]#011Speed: 779.09 samples/sec#011loss=1.013757\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch[310] avg_epoch_loss=1.217583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=310 train loss <loss>=1.35260672569\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:24 INFO 140074512123712] Epoch[5] Batch [310]#011Speed: 1028.01 samples/sec#011loss=1.352607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch[315] avg_epoch_loss=1.214201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=315 train loss <loss>=1.00381513834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch [315]#011Speed: 790.18 samples/sec#011loss=1.003815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch[320] avg_epoch_loss=1.212642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=320 train loss <loss>=1.11410785913\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch [320]#011Speed: 1072.26 samples/sec#011loss=1.114108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch[325] avg_epoch_loss=1.221006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=325 train loss <loss>=1.75803370476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch [325]#011Speed: 793.98 samples/sec#011loss=1.758034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch[330] avg_epoch_loss=1.220093\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=330 train loss <loss>=1.16051713228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch [330]#011Speed: 1077.85 samples/sec#011loss=1.160517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch[335] avg_epoch_loss=1.222116\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=335 train loss <loss>=1.35603065491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:25 INFO 140074512123712] Epoch[5] Batch [335]#011Speed: 794.79 samples/sec#011loss=1.356031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch[340] avg_epoch_loss=1.222234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=340 train loss <loss>=1.23018083572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch [340]#011Speed: 1023.92 samples/sec#011loss=1.230181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch[345] avg_epoch_loss=1.220704\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=345 train loss <loss>=1.11633732319\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch [345]#011Speed: 776.74 samples/sec#011loss=1.116337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch[350] avg_epoch_loss=1.219277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=350 train loss <loss>=1.12054502964\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch [350]#011Speed: 1063.79 samples/sec#011loss=1.120545\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch[355] avg_epoch_loss=1.217242\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=355 train loss <loss>=1.07440210581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch [355]#011Speed: 790.56 samples/sec#011loss=1.074402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch[360] avg_epoch_loss=1.216295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=360 train loss <loss>=1.14889819622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch [360]#011Speed: 1076.62 samples/sec#011loss=1.148898\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch[365] avg_epoch_loss=1.215482\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=365 train loss <loss>=1.15677651167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:26 INFO 140074512123712] Epoch[5] Batch [365]#011Speed: 784.83 samples/sec#011loss=1.156777\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch[370] avg_epoch_loss=1.215982\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=370 train loss <loss>=1.25257327557\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch [370]#011Speed: 1028.79 samples/sec#011loss=1.252573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch[375] avg_epoch_loss=1.218309\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=375 train loss <loss>=1.39093079567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch [375]#011Speed: 794.13 samples/sec#011loss=1.390931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch[380] avg_epoch_loss=1.220675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=380 train loss <loss>=1.39860908985\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch [380]#011Speed: 1031.40 samples/sec#011loss=1.398609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch[385] avg_epoch_loss=1.222171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=385 train loss <loss>=1.33618347645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch [385]#011Speed: 776.27 samples/sec#011loss=1.336183\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch[390] avg_epoch_loss=1.225500\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=390 train loss <loss>=1.48249878883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch [390]#011Speed: 1075.72 samples/sec#011loss=1.482499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch[395] avg_epoch_loss=1.225097\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=395 train loss <loss>=1.1935967207\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:27 INFO 140074512123712] Epoch[5] Batch [395]#011Speed: 1092.93 samples/sec#011loss=1.193597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch[400] avg_epoch_loss=1.225186\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=400 train loss <loss>=1.2321896553\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch [400]#011Speed: 632.54 samples/sec#011loss=1.232190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch[405] avg_epoch_loss=1.223200\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=405 train loss <loss>=1.06394901276\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch [405]#011Speed: 741.57 samples/sec#011loss=1.063949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch[410] avg_epoch_loss=1.221231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=410 train loss <loss>=1.06134464741\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch [410]#011Speed: 1081.68 samples/sec#011loss=1.061345\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch[415] avg_epoch_loss=1.218228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=415 train loss <loss>=0.97141712904\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch [415]#011Speed: 802.19 samples/sec#011loss=0.971417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch[420] avg_epoch_loss=1.217632\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=420 train loss <loss>=1.16797624826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:28 INFO 140074512123712] Epoch[5] Batch [420]#011Speed: 1077.87 samples/sec#011loss=1.167976\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch[425] avg_epoch_loss=1.215501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=425 train loss <loss>=1.0361385107\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch [425]#011Speed: 728.84 samples/sec#011loss=1.036139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch[430] avg_epoch_loss=1.214754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=430 train loss <loss>=1.15111272335\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch [430]#011Speed: 1021.97 samples/sec#011loss=1.151113\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch[435] avg_epoch_loss=1.215525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=435 train loss <loss>=1.28194742203\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch [435]#011Speed: 767.44 samples/sec#011loss=1.281947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch[440] avg_epoch_loss=1.215008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=440 train loss <loss>=1.16994478703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch [440]#011Speed: 1044.97 samples/sec#011loss=1.169945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch[445] avg_epoch_loss=1.213675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=445 train loss <loss>=1.09608751535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:29 INFO 140074512123712] Epoch[5] Batch [445]#011Speed: 1047.69 samples/sec#011loss=1.096088\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch[450] avg_epoch_loss=1.212561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=450 train loss <loss>=1.11322766542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch [450]#011Speed: 757.31 samples/sec#011loss=1.113228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch[455] avg_epoch_loss=1.210515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=455 train loss <loss>=1.02596859932\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch [455]#011Speed: 1006.41 samples/sec#011loss=1.025969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch[460] avg_epoch_loss=1.211688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=460 train loss <loss>=1.31863076687\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch [460]#011Speed: 657.78 samples/sec#011loss=1.318631\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch[465] avg_epoch_loss=1.211240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=465 train loss <loss>=1.16989450455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch [465]#011Speed: 823.34 samples/sec#011loss=1.169895\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch[470] avg_epoch_loss=1.210443\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=470 train loss <loss>=1.1361887455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch [470]#011Speed: 783.21 samples/sec#011loss=1.136189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch[475] avg_epoch_loss=1.209305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=475 train loss <loss>=1.1021420598\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:30 INFO 140074512123712] Epoch[5] Batch [475]#011Speed: 1060.62 samples/sec#011loss=1.102142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch[480] avg_epoch_loss=1.207118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=480 train loss <loss>=0.998848676682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch [480]#011Speed: 752.53 samples/sec#011loss=0.998849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch[485] avg_epoch_loss=1.205791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=485 train loss <loss>=1.0781973958\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch [485]#011Speed: 1053.28 samples/sec#011loss=1.078197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch[490] avg_epoch_loss=1.202824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=490 train loss <loss>=0.914444410801\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch [490]#011Speed: 791.82 samples/sec#011loss=0.914444\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch[495] avg_epoch_loss=1.200600\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=495 train loss <loss>=0.982121539116\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch [495]#011Speed: 1047.59 samples/sec#011loss=0.982122\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch[500] avg_epoch_loss=1.197958\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=500 train loss <loss>=0.935872089863\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:31 INFO 140074512123712] Epoch[5] Batch [500]#011Speed: 780.83 samples/sec#011loss=0.935872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch[505] avg_epoch_loss=1.196084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=505 train loss <loss>=1.0083327651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch [505]#011Speed: 1082.30 samples/sec#011loss=1.008333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch[510] avg_epoch_loss=1.196372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=510 train loss <loss>=1.22549413443\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch [510]#011Speed: 725.48 samples/sec#011loss=1.225494\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch[515] avg_epoch_loss=1.195245\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=515 train loss <loss>=1.08011701107\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch [515]#011Speed: 1027.56 samples/sec#011loss=1.080117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch[520] avg_epoch_loss=1.194598\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=520 train loss <loss>=1.12786320448\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch [520]#011Speed: 777.70 samples/sec#011loss=1.127863\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch[525] avg_epoch_loss=1.192025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=525 train loss <loss>=0.923899936676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch [525]#011Speed: 1096.60 samples/sec#011loss=0.923900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch[530] avg_epoch_loss=1.190582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=530 train loss <loss>=1.03872771263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:32 INFO 140074512123712] Epoch[5] Batch [530]#011Speed: 813.90 samples/sec#011loss=1.038728\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch[535] avg_epoch_loss=1.189742\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=535 train loss <loss>=1.10055989027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch [535]#011Speed: 1023.31 samples/sec#011loss=1.100560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch[540] avg_epoch_loss=1.190231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=540 train loss <loss>=1.24268375635\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch [540]#011Speed: 629.09 samples/sec#011loss=1.242684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch[545] avg_epoch_loss=1.189254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=545 train loss <loss>=1.08352528811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch [545]#011Speed: 1065.72 samples/sec#011loss=1.083525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch[550] avg_epoch_loss=1.189609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=550 train loss <loss>=1.22834994793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch [550]#011Speed: 793.18 samples/sec#011loss=1.228350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch[555] avg_epoch_loss=1.190453\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=555 train loss <loss>=1.28343098164\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:33 INFO 140074512123712] Epoch[5] Batch [555]#011Speed: 1067.35 samples/sec#011loss=1.283431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[5] Batch[560] avg_epoch_loss=1.191597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, batch=560 train loss <loss>=1.31880891323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[5] Batch [560]#011Speed: 952.14 samples/sec#011loss=1.318809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] processed a total of 17993 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20351.97687149048, \"sum\": 20351.97687149048, \"min\": 20351.97687149048}}, \"EndTime\": 1589445094.109603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445073.757555}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=884.086328768 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.19248083112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_db1a1134-3a2a-453c-be58-a0060ff89ef6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.567022323608398, \"sum\": 9.567022323608398, \"min\": 9.567022323608398}}, \"EndTime\": 1589445094.11996, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445094.109673}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch[0] avg_epoch_loss=2.051926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.0519258976\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch[5] avg_epoch_loss=1.361199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=1.3611985743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch [5]#011Speed: 1047.77 samples/sec#011loss=1.361199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch[10] avg_epoch_loss=1.303997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=1.23535408974\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch [10]#011Speed: 782.90 samples/sec#011loss=1.235354\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch[15] avg_epoch_loss=1.268264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=1.18965160847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch [15]#011Speed: 1081.99 samples/sec#011loss=1.189652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch[20] avg_epoch_loss=1.238087\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=1.14152076244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:34 INFO 140074512123712] Epoch[6] Batch [20]#011Speed: 796.41 samples/sec#011loss=1.141521\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch[25] avg_epoch_loss=1.208318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=1.08328691721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch [25]#011Speed: 1070.06 samples/sec#011loss=1.083287\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch[30] avg_epoch_loss=1.190719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=1.09920628071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch [30]#011Speed: 759.50 samples/sec#011loss=1.099206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch[35] avg_epoch_loss=1.191378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=1.19546567202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch [35]#011Speed: 1073.86 samples/sec#011loss=1.195466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch[40] avg_epoch_loss=1.170927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=1.02367582321\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch [40]#011Speed: 1082.62 samples/sec#011loss=1.023676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch[45] avg_epoch_loss=1.149884\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=0.977337741852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch [45]#011Speed: 786.93 samples/sec#011loss=0.977338\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch[50] avg_epoch_loss=1.140219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=1.05129364729\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:35 INFO 140074512123712] Epoch[6] Batch [50]#011Speed: 1083.87 samples/sec#011loss=1.051294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch[55] avg_epoch_loss=1.143174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=1.17331770658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch [55]#011Speed: 770.85 samples/sec#011loss=1.173318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch[60] avg_epoch_loss=1.139083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=1.09325950146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch [60]#011Speed: 793.31 samples/sec#011loss=1.093260\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch[65] avg_epoch_loss=1.146239\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=1.2335447073\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch [65]#011Speed: 1068.60 samples/sec#011loss=1.233545\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch[70] avg_epoch_loss=1.143189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=1.10292669535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch [70]#011Speed: 789.01 samples/sec#011loss=1.102927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch[75] avg_epoch_loss=1.137696\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=1.05969750881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:36 INFO 140074512123712] Epoch[6] Batch [75]#011Speed: 1080.99 samples/sec#011loss=1.059698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch[80] avg_epoch_loss=1.131572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=1.03849647045\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch [80]#011Speed: 808.93 samples/sec#011loss=1.038496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch[85] avg_epoch_loss=1.132804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=1.15275127888\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch [85]#011Speed: 1003.44 samples/sec#011loss=1.152751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch[90] avg_epoch_loss=1.129186\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=1.06696062088\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch [90]#011Speed: 747.62 samples/sec#011loss=1.066961\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch[95] avg_epoch_loss=1.125296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=1.0545021534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch [95]#011Speed: 1031.58 samples/sec#011loss=1.054502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch[100] avg_epoch_loss=1.273575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=4.12053658962\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch [100]#011Speed: 793.34 samples/sec#011loss=4.120537\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch[105] avg_epoch_loss=1.283322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=1.48019382954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:37 INFO 140074512123712] Epoch[6] Batch [105]#011Speed: 1101.20 samples/sec#011loss=1.480194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch[110] avg_epoch_loss=1.293857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=1.51720044613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch [110]#011Speed: 792.59 samples/sec#011loss=1.517200\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch[115] avg_epoch_loss=1.300638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=1.45117471218\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch [115]#011Speed: 1028.85 samples/sec#011loss=1.451175\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch[120] avg_epoch_loss=1.307830\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=1.47469651699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch [120]#011Speed: 653.33 samples/sec#011loss=1.474697\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch[125] avg_epoch_loss=1.313664\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=1.45483920574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch [125]#011Speed: 1062.88 samples/sec#011loss=1.454839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch[130] avg_epoch_loss=1.316639\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=1.39162220955\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:38 INFO 140074512123712] Epoch[6] Batch [130]#011Speed: 802.46 samples/sec#011loss=1.391622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch[135] avg_epoch_loss=1.313371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=1.22774786949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch [135]#011Speed: 1071.43 samples/sec#011loss=1.227748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch[140] avg_epoch_loss=1.318932\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=1.47019205093\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch [140]#011Speed: 762.21 samples/sec#011loss=1.470192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch[145] avg_epoch_loss=1.417328\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=4.19209258556\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch [145]#011Speed: 1055.83 samples/sec#011loss=4.192093\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch[150] avg_epoch_loss=1.415799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=1.37113173008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch [150]#011Speed: 780.29 samples/sec#011loss=1.371132\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch[155] avg_epoch_loss=1.418979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=1.51504175663\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch [155]#011Speed: 1080.72 samples/sec#011loss=1.515042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch[160] avg_epoch_loss=1.422468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=1.5313028574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:39 INFO 140074512123712] Epoch[6] Batch [160]#011Speed: 777.55 samples/sec#011loss=1.531303\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch[165] avg_epoch_loss=1.424317\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=1.48386542797\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch [165]#011Speed: 1035.26 samples/sec#011loss=1.483865\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch[170] avg_epoch_loss=1.423953\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=1.41185848713\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch [170]#011Speed: 766.14 samples/sec#011loss=1.411858\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch[175] avg_epoch_loss=1.423348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=1.4026781559\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch [175]#011Speed: 1070.10 samples/sec#011loss=1.402678\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch[180] avg_epoch_loss=1.420489\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=1.31982879639\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch [180]#011Speed: 1076.94 samples/sec#011loss=1.319829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch[185] avg_epoch_loss=1.418731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=1.35509092808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch [185]#011Speed: 790.19 samples/sec#011loss=1.355091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch[190] avg_epoch_loss=1.414535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=1.25846078396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:40 INFO 140074512123712] Epoch[6] Batch [190]#011Speed: 1078.13 samples/sec#011loss=1.258461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch[195] avg_epoch_loss=1.408247\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=1.16803660393\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch [195]#011Speed: 764.03 samples/sec#011loss=1.168037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch[200] avg_epoch_loss=1.409290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=1.45018792152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch [200]#011Speed: 984.71 samples/sec#011loss=1.450188\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch[205] avg_epoch_loss=1.405002\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=1.23262023926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch [205]#011Speed: 786.87 samples/sec#011loss=1.232620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch[210] avg_epoch_loss=1.401578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=1.26049396992\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch [210]#011Speed: 1088.32 samples/sec#011loss=1.260494\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch[215] avg_epoch_loss=1.392729\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=1.01933259964\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:41 INFO 140074512123712] Epoch[6] Batch [215]#011Speed: 792.95 samples/sec#011loss=1.019333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch[220] avg_epoch_loss=1.386396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=1.11279886961\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch [220]#011Speed: 1105.37 samples/sec#011loss=1.112799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch[225] avg_epoch_loss=1.378737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=1.04019575119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch [225]#011Speed: 782.20 samples/sec#011loss=1.040196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch[230] avg_epoch_loss=1.408427\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=2.75041754246\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch [230]#011Speed: 1094.53 samples/sec#011loss=2.750418\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch[235] avg_epoch_loss=1.401531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=1.08293638229\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch [235]#011Speed: 717.23 samples/sec#011loss=1.082936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch[240] avg_epoch_loss=1.395915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=1.13085763454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch [240]#011Speed: 1058.40 samples/sec#011loss=1.130858\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch[245] avg_epoch_loss=1.390905\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=1.14940726757\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:42 INFO 140074512123712] Epoch[6] Batch [245]#011Speed: 800.27 samples/sec#011loss=1.149407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch[250] avg_epoch_loss=1.384987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=1.09384429455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch [250]#011Speed: 1088.40 samples/sec#011loss=1.093844\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch[255] avg_epoch_loss=1.380256\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=1.1427200079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch [255]#011Speed: 778.61 samples/sec#011loss=1.142720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch[260] avg_epoch_loss=1.374875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=1.09935979843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch [260]#011Speed: 786.62 samples/sec#011loss=1.099360\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch[265] avg_epoch_loss=1.370084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=1.12000484467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch [265]#011Speed: 550.29 samples/sec#011loss=1.120005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch[270] avg_epoch_loss=1.364715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=270 train loss <loss>=1.07907772064\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:43 INFO 140074512123712] Epoch[6] Batch [270]#011Speed: 1067.33 samples/sec#011loss=1.079078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch[275] avg_epoch_loss=1.358682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=275 train loss <loss>=1.03170753717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch [275]#011Speed: 785.16 samples/sec#011loss=1.031708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch[280] avg_epoch_loss=1.356196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=280 train loss <loss>=1.21894803047\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch [280]#011Speed: 1005.19 samples/sec#011loss=1.218948\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch[285] avg_epoch_loss=1.363961\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=285 train loss <loss>=1.80035125017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch [285]#011Speed: 790.64 samples/sec#011loss=1.800351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch[290] avg_epoch_loss=1.357885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=290 train loss <loss>=1.01034412384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch [290]#011Speed: 1058.55 samples/sec#011loss=1.010344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch[295] avg_epoch_loss=1.355507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=295 train loss <loss>=1.21714541912\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:44 INFO 140074512123712] Epoch[6] Batch [295]#011Speed: 789.85 samples/sec#011loss=1.217145\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch[300] avg_epoch_loss=1.353648\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=300 train loss <loss>=1.24357955456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch [300]#011Speed: 1073.92 samples/sec#011loss=1.243580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch[305] avg_epoch_loss=1.350102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=305 train loss <loss>=1.13665213585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch [305]#011Speed: 732.49 samples/sec#011loss=1.136652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch[310] avg_epoch_loss=1.345573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=310 train loss <loss>=1.06836910248\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch [310]#011Speed: 1005.83 samples/sec#011loss=1.068369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch[315] avg_epoch_loss=1.353822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=315 train loss <loss>=1.86692638397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch [315]#011Speed: 796.56 samples/sec#011loss=1.866926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch[320] avg_epoch_loss=1.349924\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=320 train loss <loss>=1.1035846591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch [320]#011Speed: 1080.25 samples/sec#011loss=1.103585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch[325] avg_epoch_loss=1.346915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=325 train loss <loss>=1.15369250774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:45 INFO 140074512123712] Epoch[6] Batch [325]#011Speed: 782.90 samples/sec#011loss=1.153693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch[330] avg_epoch_loss=1.342368\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=330 train loss <loss>=1.04595903158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch [330]#011Speed: 1077.91 samples/sec#011loss=1.045959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch[335] avg_epoch_loss=1.339440\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=335 train loss <loss>=1.14557857513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch [335]#011Speed: 773.56 samples/sec#011loss=1.145579\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch[340] avg_epoch_loss=1.334278\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=340 train loss <loss>=0.987406241894\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch [340]#011Speed: 1102.21 samples/sec#011loss=0.987406\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch[345] avg_epoch_loss=1.329428\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=345 train loss <loss>=0.998641526699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch [345]#011Speed: 813.98 samples/sec#011loss=0.998642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch[350] avg_epoch_loss=1.323621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=350 train loss <loss>=0.921775519848\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch [350]#011Speed: 1094.81 samples/sec#011loss=0.921776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch[355] avg_epoch_loss=1.324267\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=355 train loss <loss>=1.36959514618\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:46 INFO 140074512123712] Epoch[6] Batch [355]#011Speed: 805.06 samples/sec#011loss=1.369595\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch[360] avg_epoch_loss=1.322238\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=360 train loss <loss>=1.17781652212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch [360]#011Speed: 1084.54 samples/sec#011loss=1.177817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch[365] avg_epoch_loss=1.318547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=365 train loss <loss>=1.05205211639\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch [365]#011Speed: 780.32 samples/sec#011loss=1.052052\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch[370] avg_epoch_loss=1.315037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=370 train loss <loss>=1.05810000896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch [370]#011Speed: 1063.15 samples/sec#011loss=1.058100\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch[375] avg_epoch_loss=1.319293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=375 train loss <loss>=1.63503813744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch [375]#011Speed: 763.90 samples/sec#011loss=1.635038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch[380] avg_epoch_loss=1.318994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=380 train loss <loss>=1.29656202793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:47 INFO 140074512123712] Epoch[6] Batch [380]#011Speed: 1076.89 samples/sec#011loss=1.296562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch[385] avg_epoch_loss=1.315300\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=385 train loss <loss>=1.03376814127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch [385]#011Speed: 787.79 samples/sec#011loss=1.033768\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch[390] avg_epoch_loss=1.311756\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=390 train loss <loss>=1.03815978765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch [390]#011Speed: 1073.31 samples/sec#011loss=1.038160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch[395] avg_epoch_loss=1.308990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=395 train loss <loss>=1.0927010417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch [395]#011Speed: 761.95 samples/sec#011loss=1.092701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch[400] avg_epoch_loss=1.304465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=400 train loss <loss>=0.946136188507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch [400]#011Speed: 1078.42 samples/sec#011loss=0.946136\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch[405] avg_epoch_loss=1.299897\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=405 train loss <loss>=0.93353600502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch [405]#011Speed: 688.79 samples/sec#011loss=0.933536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch[410] avg_epoch_loss=1.296914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=410 train loss <loss>=1.05464890003\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:48 INFO 140074512123712] Epoch[6] Batch [410]#011Speed: 938.57 samples/sec#011loss=1.054649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch[415] avg_epoch_loss=1.294054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=415 train loss <loss>=1.05902453661\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch [415]#011Speed: 786.33 samples/sec#011loss=1.059025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch[420] avg_epoch_loss=1.291665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=420 train loss <loss>=1.09286601543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch [420]#011Speed: 997.89 samples/sec#011loss=1.092866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch[425] avg_epoch_loss=1.294473\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=425 train loss <loss>=1.53091324568\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch [425]#011Speed: 780.94 samples/sec#011loss=1.530913\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch[430] avg_epoch_loss=1.293913\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=430 train loss <loss>=1.24616137743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch [430]#011Speed: 1047.85 samples/sec#011loss=1.246161\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch[435] avg_epoch_loss=1.292618\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=435 train loss <loss>=1.18102519512\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:49 INFO 140074512123712] Epoch[6] Batch [435]#011Speed: 797.56 samples/sec#011loss=1.181025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch[440] avg_epoch_loss=1.290270\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=440 train loss <loss>=1.08550322056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch [440]#011Speed: 1082.95 samples/sec#011loss=1.085503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch[445] avg_epoch_loss=1.287891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=445 train loss <loss>=1.07803821564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch [445]#011Speed: 775.90 samples/sec#011loss=1.078038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch[450] avg_epoch_loss=1.286774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=450 train loss <loss>=1.18718719482\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch [450]#011Speed: 1040.48 samples/sec#011loss=1.187187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch[455] avg_epoch_loss=1.285462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=455 train loss <loss>=1.16710371971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch [455]#011Speed: 802.15 samples/sec#011loss=1.167104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch[460] avg_epoch_loss=1.281781\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=460 train loss <loss>=0.946082270145\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch [460]#011Speed: 981.90 samples/sec#011loss=0.946082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch[465] avg_epoch_loss=1.278853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=465 train loss <loss>=1.00884521008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:50 INFO 140074512123712] Epoch[6] Batch [465]#011Speed: 794.70 samples/sec#011loss=1.008845\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch[470] avg_epoch_loss=1.276023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=470 train loss <loss>=1.01227581501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch [470]#011Speed: 1083.47 samples/sec#011loss=1.012276\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch[475] avg_epoch_loss=1.274761\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=475 train loss <loss>=1.15594812632\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch [475]#011Speed: 779.14 samples/sec#011loss=1.155948\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch[480] avg_epoch_loss=1.271515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=480 train loss <loss>=0.962497746944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch [480]#011Speed: 1069.89 samples/sec#011loss=0.962498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch[485] avg_epoch_loss=1.271606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=485 train loss <loss>=1.28031243086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch [485]#011Speed: 780.35 samples/sec#011loss=1.280312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch[490] avg_epoch_loss=1.269365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=490 train loss <loss>=1.05158734322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:51 INFO 140074512123712] Epoch[6] Batch [490]#011Speed: 1083.37 samples/sec#011loss=1.051587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch[495] avg_epoch_loss=1.268098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=495 train loss <loss>=1.14361798763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch [495]#011Speed: 791.06 samples/sec#011loss=1.143618\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch[500] avg_epoch_loss=1.264625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=500 train loss <loss>=0.920118832588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch [500]#011Speed: 1061.95 samples/sec#011loss=0.920119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch[505] avg_epoch_loss=1.260775\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=505 train loss <loss>=0.875048208237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch [505]#011Speed: 770.07 samples/sec#011loss=0.875048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch[510] avg_epoch_loss=1.257532\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=510 train loss <loss>=0.929343414307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch [510]#011Speed: 1043.87 samples/sec#011loss=0.929343\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch[515] avg_epoch_loss=1.254555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=515 train loss <loss>=0.950273787975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch [515]#011Speed: 762.83 samples/sec#011loss=0.950274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch[520] avg_epoch_loss=1.253210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=520 train loss <loss>=1.11437598467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:52 INFO 140074512123712] Epoch[6] Batch [520]#011Speed: 1059.44 samples/sec#011loss=1.114376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch[525] avg_epoch_loss=1.251364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=525 train loss <loss>=1.05898673534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch [525]#011Speed: 786.26 samples/sec#011loss=1.058987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch[530] avg_epoch_loss=1.250120\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=530 train loss <loss>=1.11934175491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch [530]#011Speed: 1071.86 samples/sec#011loss=1.119342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch[535] avg_epoch_loss=1.248125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=535 train loss <loss>=1.03622807264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch [535]#011Speed: 765.43 samples/sec#011loss=1.036228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch[540] avg_epoch_loss=1.246836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=540 train loss <loss>=1.10868455172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch [540]#011Speed: 1071.18 samples/sec#011loss=1.108685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch[545] avg_epoch_loss=1.243627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=545 train loss <loss>=0.896366941929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch [545]#011Speed: 781.53 samples/sec#011loss=0.896367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch[550] avg_epoch_loss=1.242118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=550 train loss <loss>=1.0773314476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:53 INFO 140074512123712] Epoch[6] Batch [550]#011Speed: 814.19 samples/sec#011loss=1.077331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[6] Batch[555] avg_epoch_loss=1.240486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, batch=555 train loss <loss>=1.06060973406\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[6] Batch [555]#011Speed: 896.32 samples/sec#011loss=1.060610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] processed a total of 17864 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20143.075227737427, \"sum\": 20143.075227737427, \"min\": 20143.075227737427}}, \"EndTime\": 1589445114.263167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445094.120033}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=886.849757516 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.23883531782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch[0] avg_epoch_loss=0.994005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=0.994005441666\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch[5] avg_epoch_loss=0.910667\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=0.910666674376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch [5]#011Speed: 1071.93 samples/sec#011loss=0.910667\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch[10] avg_epoch_loss=0.946740\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=0.990027105808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch [10]#011Speed: 784.21 samples/sec#011loss=0.990027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch[15] avg_epoch_loss=1.022594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=1.18947284222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:54 INFO 140074512123712] Epoch[7] Batch [15]#011Speed: 1049.69 samples/sec#011loss=1.189473\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch[20] avg_epoch_loss=0.989717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=0.884512281418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch [20]#011Speed: 811.57 samples/sec#011loss=0.884512\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch[25] avg_epoch_loss=0.992638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=1.00490674973\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch [25]#011Speed: 1067.65 samples/sec#011loss=1.004907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch[30] avg_epoch_loss=0.972803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=0.86965816021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch [30]#011Speed: 781.98 samples/sec#011loss=0.869658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch[35] avg_epoch_loss=0.971465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=0.963172864914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch [35]#011Speed: 1099.01 samples/sec#011loss=0.963173\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch[40] avg_epoch_loss=0.963058\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=0.902528548241\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch [40]#011Speed: 794.56 samples/sec#011loss=0.902529\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch[45] avg_epoch_loss=0.967528\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=1.00418137312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:55 INFO 140074512123712] Epoch[7] Batch [45]#011Speed: 1093.98 samples/sec#011loss=1.004181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch[50] avg_epoch_loss=1.010521\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=1.40605642796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch [50]#011Speed: 801.63 samples/sec#011loss=1.406056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch[55] avg_epoch_loss=1.035581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=1.29119307995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch [55]#011Speed: 1082.66 samples/sec#011loss=1.291193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch[60] avg_epoch_loss=1.044397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=1.14313036203\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch [60]#011Speed: 771.10 samples/sec#011loss=1.143130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch[65] avg_epoch_loss=1.045991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=1.06544028521\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch [65]#011Speed: 1069.50 samples/sec#011loss=1.065440\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch[70] avg_epoch_loss=1.042824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=1.00102465153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch [70]#011Speed: 808.95 samples/sec#011loss=1.001025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch[75] avg_epoch_loss=1.041090\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=1.01645715237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:56 INFO 140074512123712] Epoch[7] Batch [75]#011Speed: 1084.05 samples/sec#011loss=1.016457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch[80] avg_epoch_loss=1.035926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=0.957438540459\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch [80]#011Speed: 794.55 samples/sec#011loss=0.957439\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch[85] avg_epoch_loss=1.033212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=0.989251101017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch [85]#011Speed: 1077.14 samples/sec#011loss=0.989251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch[90] avg_epoch_loss=1.036317\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=1.08971005678\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch [90]#011Speed: 753.15 samples/sec#011loss=1.089710\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch[95] avg_epoch_loss=1.032049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=0.954382109642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch [95]#011Speed: 1030.76 samples/sec#011loss=0.954382\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch[100] avg_epoch_loss=1.028767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=0.965753078461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:57 INFO 140074512123712] Epoch[7] Batch [100]#011Speed: 793.17 samples/sec#011loss=0.965753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch[105] avg_epoch_loss=1.023234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=0.911463582516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch [105]#011Speed: 1053.42 samples/sec#011loss=0.911464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch[110] avg_epoch_loss=1.074870\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=2.16954762936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch [110]#011Speed: 797.51 samples/sec#011loss=2.169548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch[115] avg_epoch_loss=1.075164\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=1.08170814514\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch [115]#011Speed: 1011.47 samples/sec#011loss=1.081708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch[120] avg_epoch_loss=1.078743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=1.16176588535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch [120]#011Speed: 794.97 samples/sec#011loss=1.161766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch[125] avg_epoch_loss=1.077883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=1.057079041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch [125]#011Speed: 1007.70 samples/sec#011loss=1.057079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch[130] avg_epoch_loss=1.075855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=1.02475192547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:58 INFO 140074512123712] Epoch[7] Batch [130]#011Speed: 710.06 samples/sec#011loss=1.024752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch[135] avg_epoch_loss=1.070824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=0.938990116119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch [135]#011Speed: 1012.47 samples/sec#011loss=0.938990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch[140] avg_epoch_loss=1.064784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=0.900495994091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch [140]#011Speed: 771.16 samples/sec#011loss=0.900496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch[145] avg_epoch_loss=1.062943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=1.01104625463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch [145]#011Speed: 949.75 samples/sec#011loss=1.011046\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch[150] avg_epoch_loss=1.061853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=1.03000570536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch [150]#011Speed: 780.51 samples/sec#011loss=1.030006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch[155] avg_epoch_loss=1.063766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=1.12155758142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:31:59 INFO 140074512123712] Epoch[7] Batch [155]#011Speed: 1080.85 samples/sec#011loss=1.121558\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch[160] avg_epoch_loss=1.060826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=0.969096589088\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch [160]#011Speed: 786.72 samples/sec#011loss=0.969097\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch[165] avg_epoch_loss=1.058010\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=0.967340707779\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch [165]#011Speed: 1043.86 samples/sec#011loss=0.967341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch[170] avg_epoch_loss=1.055788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=0.981991064548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch [170]#011Speed: 736.61 samples/sec#011loss=0.981991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch[175] avg_epoch_loss=1.050188\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=0.858674991131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch [175]#011Speed: 824.65 samples/sec#011loss=0.858675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch[180] avg_epoch_loss=1.045962\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=0.897198784351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:00 INFO 140074512123712] Epoch[7] Batch [180]#011Speed: 646.85 samples/sec#011loss=0.897199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch[185] avg_epoch_loss=1.051951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=1.26877137423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch [185]#011Speed: 1081.43 samples/sec#011loss=1.268771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch[190] avg_epoch_loss=1.057177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=1.25157449245\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch [190]#011Speed: 1083.73 samples/sec#011loss=1.251574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch[195] avg_epoch_loss=1.058326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=1.10221018791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch [195]#011Speed: 715.76 samples/sec#011loss=1.102210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch[200] avg_epoch_loss=1.058338\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=1.05882297754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch [200]#011Speed: 1034.25 samples/sec#011loss=1.058823\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch[205] avg_epoch_loss=1.085147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=2.16287307739\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch [205]#011Speed: 771.05 samples/sec#011loss=2.162873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch[210] avg_epoch_loss=1.087598\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=1.18858048916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:01 INFO 140074512123712] Epoch[7] Batch [210]#011Speed: 1066.20 samples/sec#011loss=1.188580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch[215] avg_epoch_loss=1.088496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=1.12638547421\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch [215]#011Speed: 782.23 samples/sec#011loss=1.126385\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch[220] avg_epoch_loss=1.089797\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=1.14601614475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch [220]#011Speed: 1067.49 samples/sec#011loss=1.146016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch[225] avg_epoch_loss=1.090135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=1.10503685474\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch [225]#011Speed: 791.38 samples/sec#011loss=1.105037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch[230] avg_epoch_loss=1.089263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=1.04985889196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch [230]#011Speed: 1075.46 samples/sec#011loss=1.049859\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch[235] avg_epoch_loss=1.114021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=2.25783426762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch [235]#011Speed: 766.85 samples/sec#011loss=2.257834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch[240] avg_epoch_loss=1.112239\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=1.0281298995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:02 INFO 140074512123712] Epoch[7] Batch [240]#011Speed: 1086.21 samples/sec#011loss=1.028130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch[245] avg_epoch_loss=1.111148\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=1.05857306719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch [245]#011Speed: 791.39 samples/sec#011loss=1.058573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch[250] avg_epoch_loss=1.111847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=1.14626544714\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch [250]#011Speed: 1083.33 samples/sec#011loss=1.146265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch[255] avg_epoch_loss=1.111631\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=1.1007807374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch [255]#011Speed: 788.83 samples/sec#011loss=1.100781\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch[260] avg_epoch_loss=1.110436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=1.04923552275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch [260]#011Speed: 1072.62 samples/sec#011loss=1.049236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch[265] avg_epoch_loss=1.109784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=1.07573487759\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:03 INFO 140074512123712] Epoch[7] Batch [265]#011Speed: 756.70 samples/sec#011loss=1.075735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch[270] avg_epoch_loss=1.109290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=270 train loss <loss>=1.08301935196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch [270]#011Speed: 843.82 samples/sec#011loss=1.083019\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch[275] avg_epoch_loss=1.108572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=275 train loss <loss>=1.0696620822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch [275]#011Speed: 721.13 samples/sec#011loss=1.069662\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch[280] avg_epoch_loss=1.107390\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=280 train loss <loss>=1.0421230197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch [280]#011Speed: 1019.43 samples/sec#011loss=1.042123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch[285] avg_epoch_loss=1.104215\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=285 train loss <loss>=0.925820553303\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch [285]#011Speed: 778.93 samples/sec#011loss=0.925821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch[290] avg_epoch_loss=1.101832\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=290 train loss <loss>=0.965484082699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:04 INFO 140074512123712] Epoch[7] Batch [290]#011Speed: 1075.90 samples/sec#011loss=0.965484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch[295] avg_epoch_loss=1.098930\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=295 train loss <loss>=0.930074512959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch [295]#011Speed: 802.35 samples/sec#011loss=0.930075\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch[300] avg_epoch_loss=1.096163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=300 train loss <loss>=0.932360804081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch [300]#011Speed: 1076.00 samples/sec#011loss=0.932361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch[305] avg_epoch_loss=1.132578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=305 train loss <loss>=3.32475252151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch [305]#011Speed: 761.97 samples/sec#011loss=3.324753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch[310] avg_epoch_loss=1.130984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=310 train loss <loss>=1.03341443539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch [310]#011Speed: 1059.84 samples/sec#011loss=1.033414\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch[315] avg_epoch_loss=1.130536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=315 train loss <loss>=1.10266346931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch [315]#011Speed: 793.57 samples/sec#011loss=1.102663\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch[320] avg_epoch_loss=1.138631\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=320 train loss <loss>=1.65023248196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:05 INFO 140074512123712] Epoch[7] Batch [320]#011Speed: 1099.35 samples/sec#011loss=1.650232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch[325] avg_epoch_loss=1.144375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=325 train loss <loss>=1.51313781738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch [325]#011Speed: 798.85 samples/sec#011loss=1.513138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch[330] avg_epoch_loss=1.146743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=330 train loss <loss>=1.30112884045\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch [330]#011Speed: 1048.12 samples/sec#011loss=1.301129\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch[335] avg_epoch_loss=1.148430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=335 train loss <loss>=1.26014733315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch [335]#011Speed: 765.13 samples/sec#011loss=1.260147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch[340] avg_epoch_loss=1.149329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=340 train loss <loss>=1.20969018936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch [340]#011Speed: 1036.64 samples/sec#011loss=1.209690\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch[345] avg_epoch_loss=1.148100\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=345 train loss <loss>=1.06430613995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch [345]#011Speed: 777.12 samples/sec#011loss=1.064306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch[350] avg_epoch_loss=1.146680\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=350 train loss <loss>=1.04842400551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:06 INFO 140074512123712] Epoch[7] Batch [350]#011Speed: 1075.20 samples/sec#011loss=1.048424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch[355] avg_epoch_loss=1.144278\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=355 train loss <loss>=0.9756321311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch [355]#011Speed: 772.23 samples/sec#011loss=0.975632\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch[360] avg_epoch_loss=1.143152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=360 train loss <loss>=1.06297502518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch [360]#011Speed: 1069.12 samples/sec#011loss=1.062975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch[365] avg_epoch_loss=1.140939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=365 train loss <loss>=0.98116518259\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch [365]#011Speed: 748.55 samples/sec#011loss=0.981165\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch[370] avg_epoch_loss=1.139310\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=370 train loss <loss>=1.02008311749\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch [370]#011Speed: 966.11 samples/sec#011loss=1.020083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch[375] avg_epoch_loss=1.138281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=375 train loss <loss>=1.06192303896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:07 INFO 140074512123712] Epoch[7] Batch [375]#011Speed: 928.56 samples/sec#011loss=1.061923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch[380] avg_epoch_loss=1.138861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=380 train loss <loss>=1.18249833584\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch [380]#011Speed: 786.98 samples/sec#011loss=1.182498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch[385] avg_epoch_loss=1.139129\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=385 train loss <loss>=1.15953849554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch [385]#011Speed: 1082.39 samples/sec#011loss=1.159538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch[390] avg_epoch_loss=1.137316\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=390 train loss <loss>=0.997349596024\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch [390]#011Speed: 760.49 samples/sec#011loss=0.997350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch[395] avg_epoch_loss=1.135877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=395 train loss <loss>=1.02336986065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch [395]#011Speed: 887.45 samples/sec#011loss=1.023370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch[400] avg_epoch_loss=1.135692\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=400 train loss <loss>=1.12100635767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:08 INFO 140074512123712] Epoch[7] Batch [400]#011Speed: 568.11 samples/sec#011loss=1.121006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch[405] avg_epoch_loss=1.134083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=405 train loss <loss>=1.005098176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch [405]#011Speed: 1074.69 samples/sec#011loss=1.005098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch[410] avg_epoch_loss=1.133290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=410 train loss <loss>=1.06890023947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch [410]#011Speed: 664.79 samples/sec#011loss=1.068900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch[415] avg_epoch_loss=1.132228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=415 train loss <loss>=1.04490236044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch [415]#011Speed: 755.95 samples/sec#011loss=1.044902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch[420] avg_epoch_loss=1.133415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=420 train loss <loss>=1.23212587833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch [420]#011Speed: 1001.50 samples/sec#011loss=1.232126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch[425] avg_epoch_loss=1.132065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=425 train loss <loss>=1.01846317053\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch [425]#011Speed: 805.64 samples/sec#011loss=1.018463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch[430] avg_epoch_loss=1.130141\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=430 train loss <loss>=0.966181409359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:09 INFO 140074512123712] Epoch[7] Batch [430]#011Speed: 1094.95 samples/sec#011loss=0.966181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch[435] avg_epoch_loss=1.129185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=435 train loss <loss>=1.04675934315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch [435]#011Speed: 755.33 samples/sec#011loss=1.046759\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch[440] avg_epoch_loss=1.129431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=440 train loss <loss>=1.15092055798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch [440]#011Speed: 1053.37 samples/sec#011loss=1.150921\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch[445] avg_epoch_loss=1.129963\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=445 train loss <loss>=1.17690057755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch [445]#011Speed: 1090.00 samples/sec#011loss=1.176901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch[450] avg_epoch_loss=1.131940\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=450 train loss <loss>=1.30825010538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch [450]#011Speed: 760.97 samples/sec#011loss=1.308250\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch[455] avg_epoch_loss=1.129706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=455 train loss <loss>=0.928225922585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:10 INFO 140074512123712] Epoch[7] Batch [455]#011Speed: 1078.64 samples/sec#011loss=0.928226\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch[460] avg_epoch_loss=1.128977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=460 train loss <loss>=1.06245377064\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch [460]#011Speed: 806.95 samples/sec#011loss=1.062454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch[465] avg_epoch_loss=1.128046\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=465 train loss <loss>=1.04219270945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch [465]#011Speed: 774.18 samples/sec#011loss=1.042193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch[470] avg_epoch_loss=1.130952\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=470 train loss <loss>=1.4018001914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch [470]#011Speed: 1058.09 samples/sec#011loss=1.401800\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch[475] avg_epoch_loss=1.130799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=475 train loss <loss>=1.11642252207\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch [475]#011Speed: 1038.40 samples/sec#011loss=1.116423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch[480] avg_epoch_loss=1.130646\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=480 train loss <loss>=1.11603233814\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch [480]#011Speed: 775.72 samples/sec#011loss=1.116032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch[485] avg_epoch_loss=1.135112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=485 train loss <loss>=1.5647763133\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:11 INFO 140074512123712] Epoch[7] Batch [485]#011Speed: 1061.76 samples/sec#011loss=1.564776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch[490] avg_epoch_loss=1.133999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=490 train loss <loss>=1.0258285284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch [490]#011Speed: 803.10 samples/sec#011loss=1.025829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch[495] avg_epoch_loss=1.132491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=495 train loss <loss>=0.98443621397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch [495]#011Speed: 1082.83 samples/sec#011loss=0.984436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch[500] avg_epoch_loss=1.130834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=500 train loss <loss>=0.966397929192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch [500]#011Speed: 800.78 samples/sec#011loss=0.966398\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch[505] avg_epoch_loss=1.130114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=505 train loss <loss>=1.0579911232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch [505]#011Speed: 993.78 samples/sec#011loss=1.057991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch[510] avg_epoch_loss=1.129010\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=510 train loss <loss>=1.01726683378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:12 INFO 140074512123712] Epoch[7] Batch [510]#011Speed: 758.29 samples/sec#011loss=1.017267\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch[515] avg_epoch_loss=1.127337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=515 train loss <loss>=0.956420958042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch [515]#011Speed: 800.83 samples/sec#011loss=0.956421\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch[520] avg_epoch_loss=1.126025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=520 train loss <loss>=0.990553677082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch [520]#011Speed: 1071.98 samples/sec#011loss=0.990554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch[525] avg_epoch_loss=1.127092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=525 train loss <loss>=1.23826515675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch [525]#011Speed: 803.95 samples/sec#011loss=1.238265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch[530] avg_epoch_loss=1.126835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=530 train loss <loss>=1.09982097149\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch [530]#011Speed: 1081.16 samples/sec#011loss=1.099821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch[535] avg_epoch_loss=1.126771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=535 train loss <loss>=1.11999505758\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch [535]#011Speed: 756.81 samples/sec#011loss=1.119995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch[540] avg_epoch_loss=1.126652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=540 train loss <loss>=1.11390588284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:13 INFO 140074512123712] Epoch[7] Batch [540]#011Speed: 1045.15 samples/sec#011loss=1.113906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch[545] avg_epoch_loss=1.126204\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=545 train loss <loss>=1.07776130438\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch [545]#011Speed: 813.32 samples/sec#011loss=1.077761\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch[550] avg_epoch_loss=1.125112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=550 train loss <loss>=1.00579041243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch [550]#011Speed: 798.25 samples/sec#011loss=1.005790\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch[555] avg_epoch_loss=1.123222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=555 train loss <loss>=0.91491714716\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch [555]#011Speed: 837.23 samples/sec#011loss=0.914917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch[560] avg_epoch_loss=1.121699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, batch=560 train loss <loss>=0.952431285381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[7] Batch [560]#011Speed: 1005.57 samples/sec#011loss=0.952431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] processed a total of 17992 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20443.115949630737, \"sum\": 20443.115949630737, \"min\": 20443.115949630737}}, \"EndTime\": 1589445134.707029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445114.263265}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=880.094375927 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=7, train loss <loss>=1.12138903152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_32142dc9-e3a5-4292-8ef5-3548ee5f5311-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.19795036315918, \"sum\": 9.19795036315918, \"min\": 9.19795036315918}}, \"EndTime\": 1589445134.717007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445134.707114}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[8] Batch[0] avg_epoch_loss=0.871435\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=0.871434628963\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[8] Batch[5] avg_epoch_loss=0.875025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=0.875024706125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:14 INFO 140074512123712] Epoch[8] Batch [5]#011Speed: 1054.44 samples/sec#011loss=0.875025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch[10] avg_epoch_loss=0.890095\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=0.908179998398\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch [10]#011Speed: 1084.62 samples/sec#011loss=0.908180\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch[15] avg_epoch_loss=0.892496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=0.897778475285\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch [15]#011Speed: 777.42 samples/sec#011loss=0.897778\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch[20] avg_epoch_loss=1.022025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=1.4365162611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch [20]#011Speed: 806.22 samples/sec#011loss=1.436516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch[25] avg_epoch_loss=1.046091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=1.14716930389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch [25]#011Speed: 1032.69 samples/sec#011loss=1.147169\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch[30] avg_epoch_loss=1.055311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=1.10325436592\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:15 INFO 140074512123712] Epoch[8] Batch [30]#011Speed: 770.52 samples/sec#011loss=1.103254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch[35] avg_epoch_loss=1.041057\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=0.952679169178\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch [35]#011Speed: 1074.79 samples/sec#011loss=0.952679\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch[40] avg_epoch_loss=1.039656\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=1.02956883907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch [40]#011Speed: 1082.09 samples/sec#011loss=1.029569\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch[45] avg_epoch_loss=1.027257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=0.925588166714\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch [45]#011Speed: 783.51 samples/sec#011loss=0.925588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch[50] avg_epoch_loss=1.011847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=0.87007471323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch [50]#011Speed: 1079.91 samples/sec#011loss=0.870075\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch[55] avg_epoch_loss=1.000442\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=0.884111309052\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch [55]#011Speed: 747.52 samples/sec#011loss=0.884111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch[60] avg_epoch_loss=0.998782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=0.980193412304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:16 INFO 140074512123712] Epoch[8] Batch [60]#011Speed: 1067.54 samples/sec#011loss=0.980193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch[65] avg_epoch_loss=0.994302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=0.939645028114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch [65]#011Speed: 791.38 samples/sec#011loss=0.939645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch[70] avg_epoch_loss=0.997615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=1.04134631157\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch [70]#011Speed: 1082.91 samples/sec#011loss=1.041346\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch[75] avg_epoch_loss=0.996709\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=0.983839440346\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch [75]#011Speed: 778.61 samples/sec#011loss=0.983839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch[80] avg_epoch_loss=0.992112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=0.922245573997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch [80]#011Speed: 1063.07 samples/sec#011loss=0.922246\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch[85] avg_epoch_loss=0.994481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=1.03285508156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch [85]#011Speed: 753.33 samples/sec#011loss=1.032855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch[90] avg_epoch_loss=1.002652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=1.14318493605\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:17 INFO 140074512123712] Epoch[8] Batch [90]#011Speed: 1050.11 samples/sec#011loss=1.143185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch[95] avg_epoch_loss=0.996531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=0.885134387016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch [95]#011Speed: 790.19 samples/sec#011loss=0.885134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch[100] avg_epoch_loss=0.992436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=0.913814735413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch [100]#011Speed: 1078.30 samples/sec#011loss=0.913815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch[105] avg_epoch_loss=0.988127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=0.901075911522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch [105]#011Speed: 785.14 samples/sec#011loss=0.901076\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch[110] avg_epoch_loss=0.989435\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=1.01716961861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch [110]#011Speed: 1041.87 samples/sec#011loss=1.017170\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch[115] avg_epoch_loss=0.986228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=0.915031564236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:18 INFO 140074512123712] Epoch[8] Batch [115]#011Speed: 779.91 samples/sec#011loss=0.915032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch[120] avg_epoch_loss=0.984822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=0.952209961414\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch [120]#011Speed: 1059.01 samples/sec#011loss=0.952210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch[125] avg_epoch_loss=0.983918\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=0.962025332451\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch [125]#011Speed: 814.42 samples/sec#011loss=0.962025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch[130] avg_epoch_loss=0.979801\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=0.876058852673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch [130]#011Speed: 849.05 samples/sec#011loss=0.876059\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch[135] avg_epoch_loss=0.979597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=0.974264013767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch [135]#011Speed: 776.83 samples/sec#011loss=0.974264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch[140] avg_epoch_loss=1.034103\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=2.51664947271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch [140]#011Speed: 1036.95 samples/sec#011loss=2.516649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch[145] avg_epoch_loss=1.042948\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=1.29239349365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:19 INFO 140074512123712] Epoch[8] Batch [145]#011Speed: 808.67 samples/sec#011loss=1.292393\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch[150] avg_epoch_loss=1.048928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=1.22354922295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch [150]#011Speed: 1046.55 samples/sec#011loss=1.223549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch[155] avg_epoch_loss=1.073660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=1.82054588795\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch [155]#011Speed: 793.39 samples/sec#011loss=1.820546\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch[160] avg_epoch_loss=1.077920\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=1.21083858013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch [160]#011Speed: 1058.50 samples/sec#011loss=1.210839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch[165] avg_epoch_loss=1.083016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=1.24710183144\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch [165]#011Speed: 774.01 samples/sec#011loss=1.247102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch[170] avg_epoch_loss=1.085526\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=1.16886401176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:20 INFO 140074512123712] Epoch[8] Batch [170]#011Speed: 806.44 samples/sec#011loss=1.168864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch[175] avg_epoch_loss=1.084909\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=1.06381394863\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch [175]#011Speed: 1067.20 samples/sec#011loss=1.063814\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch[180] avg_epoch_loss=1.083513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=1.03438202143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch [180]#011Speed: 782.80 samples/sec#011loss=1.034382\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch[185] avg_epoch_loss=1.083875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=1.09696552753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch [185]#011Speed: 1077.19 samples/sec#011loss=1.096966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch[190] avg_epoch_loss=1.094662\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=1.49592839479\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch [190]#011Speed: 806.23 samples/sec#011loss=1.495928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch[195] avg_epoch_loss=1.094190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=1.07615379095\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch [195]#011Speed: 1006.64 samples/sec#011loss=1.076154\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch[200] avg_epoch_loss=1.095654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=1.15305507183\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:21 INFO 140074512123712] Epoch[8] Batch [200]#011Speed: 786.86 samples/sec#011loss=1.153055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch[205] avg_epoch_loss=1.105434\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=1.49857847691\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch [205]#011Speed: 1084.35 samples/sec#011loss=1.498578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch[210] avg_epoch_loss=1.107468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=1.191292274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch [210]#011Speed: 1090.14 samples/sec#011loss=1.191292\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch[215] avg_epoch_loss=1.105765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=1.03391135931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch [215]#011Speed: 778.79 samples/sec#011loss=1.033911\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch[220] avg_epoch_loss=1.104432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=1.0468375802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch [220]#011Speed: 1086.13 samples/sec#011loss=1.046838\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch[225] avg_epoch_loss=1.106271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=1.18752549887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch [225]#011Speed: 751.64 samples/sec#011loss=1.187525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch[230] avg_epoch_loss=1.105136\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=1.05384682417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:22 INFO 140074512123712] Epoch[8] Batch [230]#011Speed: 1046.57 samples/sec#011loss=1.053847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch[235] avg_epoch_loss=1.100972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=0.908607363701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch [235]#011Speed: 801.78 samples/sec#011loss=0.908607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch[240] avg_epoch_loss=1.097364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=0.92708325386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch [240]#011Speed: 1080.33 samples/sec#011loss=0.927083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch[245] avg_epoch_loss=1.093949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=0.929322755337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch [245]#011Speed: 805.05 samples/sec#011loss=0.929323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch[250] avg_epoch_loss=1.092518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=1.02213299274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch [250]#011Speed: 1083.72 samples/sec#011loss=1.022133\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch[255] avg_epoch_loss=1.100231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=1.48738927841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:23 INFO 140074512123712] Epoch[8] Batch [255]#011Speed: 779.27 samples/sec#011loss=1.487389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch[260] avg_epoch_loss=1.101618\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=1.17266567945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch [260]#011Speed: 1050.83 samples/sec#011loss=1.172666\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch[265] avg_epoch_loss=1.099156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=265 train loss <loss>=0.970606231689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch [265]#011Speed: 782.69 samples/sec#011loss=0.970606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch[270] avg_epoch_loss=1.110554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=270 train loss <loss>=1.71693643332\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch [270]#011Speed: 1054.89 samples/sec#011loss=1.716936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch[275] avg_epoch_loss=1.110026\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=275 train loss <loss>=1.0814302206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch [275]#011Speed: 677.19 samples/sec#011loss=1.081430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch[280] avg_epoch_loss=1.122393\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=280 train loss <loss>=1.80505752563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch [280]#011Speed: 1021.37 samples/sec#011loss=1.805058\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch[285] avg_epoch_loss=1.121961\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=285 train loss <loss>=1.09765324593\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:24 INFO 140074512123712] Epoch[8] Batch [285]#011Speed: 791.09 samples/sec#011loss=1.097653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch[290] avg_epoch_loss=1.121730\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=290 train loss <loss>=1.10852787495\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch [290]#011Speed: 1087.48 samples/sec#011loss=1.108528\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch[295] avg_epoch_loss=1.121119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=295 train loss <loss>=1.08553476334\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch [295]#011Speed: 788.25 samples/sec#011loss=1.085535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch[300] avg_epoch_loss=1.120486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=300 train loss <loss>=1.0830234766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch [300]#011Speed: 1066.53 samples/sec#011loss=1.083023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch[305] avg_epoch_loss=1.119511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=305 train loss <loss>=1.06081894636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch [305]#011Speed: 755.04 samples/sec#011loss=1.060819\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch[310] avg_epoch_loss=1.118597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=310 train loss <loss>=1.06264488697\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:25 INFO 140074512123712] Epoch[8] Batch [310]#011Speed: 1005.02 samples/sec#011loss=1.062645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch[315] avg_epoch_loss=1.124099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=315 train loss <loss>=1.46636266708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch [315]#011Speed: 789.13 samples/sec#011loss=1.466363\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch[320] avg_epoch_loss=1.121504\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=320 train loss <loss>=0.95745215416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch [320]#011Speed: 1071.27 samples/sec#011loss=0.957452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch[325] avg_epoch_loss=1.119098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=325 train loss <loss>=0.964672446251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch [325]#011Speed: 795.64 samples/sec#011loss=0.964672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch[330] avg_epoch_loss=1.118184\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=330 train loss <loss>=1.05854995251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch [330]#011Speed: 1083.27 samples/sec#011loss=1.058550\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch[335] avg_epoch_loss=1.115579\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=335 train loss <loss>=0.943187689781\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch [335]#011Speed: 766.75 samples/sec#011loss=0.943188\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch[340] avg_epoch_loss=1.113773\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=340 train loss <loss>=0.992388617992\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:26 INFO 140074512123712] Epoch[8] Batch [340]#011Speed: 1063.20 samples/sec#011loss=0.992389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch[345] avg_epoch_loss=1.110165\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=345 train loss <loss>=0.864092457294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch [345]#011Speed: 773.80 samples/sec#011loss=0.864092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch[350] avg_epoch_loss=1.106266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=350 train loss <loss>=0.836422789097\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch [350]#011Speed: 1033.85 samples/sec#011loss=0.836423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch[355] avg_epoch_loss=1.108839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=355 train loss <loss>=1.28949754238\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch [355]#011Speed: 817.64 samples/sec#011loss=1.289498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch[360] avg_epoch_loss=1.115613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=360 train loss <loss>=1.59788883924\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch [360]#011Speed: 789.60 samples/sec#011loss=1.597889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch[365] avg_epoch_loss=1.115023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=365 train loss <loss>=1.07244764566\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:27 INFO 140074512123712] Epoch[8] Batch [365]#011Speed: 973.56 samples/sec#011loss=1.072448\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch[370] avg_epoch_loss=1.114055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=370 train loss <loss>=1.04318704605\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch [370]#011Speed: 756.82 samples/sec#011loss=1.043187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch[375] avg_epoch_loss=1.112742\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=375 train loss <loss>=1.01535249949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch [375]#011Speed: 1061.69 samples/sec#011loss=1.015352\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch[380] avg_epoch_loss=1.111830\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=380 train loss <loss>=1.04320811033\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch [380]#011Speed: 805.48 samples/sec#011loss=1.043208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch[385] avg_epoch_loss=1.110062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=385 train loss <loss>=0.975355041027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch [385]#011Speed: 1089.22 samples/sec#011loss=0.975355\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch[390] avg_epoch_loss=1.107683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=390 train loss <loss>=0.924004101753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch [390]#011Speed: 790.07 samples/sec#011loss=0.924004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch[395] avg_epoch_loss=1.105178\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=395 train loss <loss>=0.909288477898\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:28 INFO 140074512123712] Epoch[8] Batch [395]#011Speed: 932.08 samples/sec#011loss=0.909288\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch[400] avg_epoch_loss=1.102860\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=400 train loss <loss>=0.919299030304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch [400]#011Speed: 776.16 samples/sec#011loss=0.919299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch[405] avg_epoch_loss=1.099413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=405 train loss <loss>=0.822990965843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch [405]#011Speed: 1086.01 samples/sec#011loss=0.822991\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch[410] avg_epoch_loss=1.099365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=410 train loss <loss>=1.09543164968\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch [410]#011Speed: 737.58 samples/sec#011loss=1.095432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch[415] avg_epoch_loss=1.098934\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=415 train loss <loss>=1.06348485947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch [415]#011Speed: 876.70 samples/sec#011loss=1.063485\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch[420] avg_epoch_loss=1.101916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=420 train loss <loss>=1.35008401871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:29 INFO 140074512123712] Epoch[8] Batch [420]#011Speed: 749.88 samples/sec#011loss=1.350084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch[425] avg_epoch_loss=1.100529\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=425 train loss <loss>=0.983668494225\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch [425]#011Speed: 1064.88 samples/sec#011loss=0.983668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch[430] avg_epoch_loss=1.098531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=430 train loss <loss>=0.928353095055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch [430]#011Speed: 789.01 samples/sec#011loss=0.928353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch[435] avg_epoch_loss=1.098813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=435 train loss <loss>=1.12310167551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch [435]#011Speed: 1061.27 samples/sec#011loss=1.123102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch[440] avg_epoch_loss=1.097919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=440 train loss <loss>=1.02000796795\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch [440]#011Speed: 768.19 samples/sec#011loss=1.020008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch[445] avg_epoch_loss=1.097360\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=445 train loss <loss>=1.04804842472\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch [445]#011Speed: 989.40 samples/sec#011loss=1.048048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch[450] avg_epoch_loss=1.097649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=450 train loss <loss>=1.12336704731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:30 INFO 140074512123712] Epoch[8] Batch [450]#011Speed: 663.27 samples/sec#011loss=1.123367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch[455] avg_epoch_loss=1.098108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=455 train loss <loss>=1.13958516121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch [455]#011Speed: 782.89 samples/sec#011loss=1.139585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch[460] avg_epoch_loss=1.098333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=460 train loss <loss>=1.11882308722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch [460]#011Speed: 1075.74 samples/sec#011loss=1.118823\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch[465] avg_epoch_loss=1.097809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=465 train loss <loss>=1.04946130514\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch [465]#011Speed: 794.58 samples/sec#011loss=1.049461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch[470] avg_epoch_loss=1.096847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=470 train loss <loss>=1.00721647739\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch [470]#011Speed: 1077.14 samples/sec#011loss=1.007216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch[475] avg_epoch_loss=1.095265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=475 train loss <loss>=0.946272492409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:31 INFO 140074512123712] Epoch[8] Batch [475]#011Speed: 764.26 samples/sec#011loss=0.946272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch[480] avg_epoch_loss=1.104254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=480 train loss <loss>=1.95999350548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch [480]#011Speed: 1099.88 samples/sec#011loss=1.959994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch[485] avg_epoch_loss=1.102990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=485 train loss <loss>=0.981340432167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch [485]#011Speed: 774.91 samples/sec#011loss=0.981340\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch[490] avg_epoch_loss=1.102951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=490 train loss <loss>=1.09917023182\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch [490]#011Speed: 1089.47 samples/sec#011loss=1.099170\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch[495] avg_epoch_loss=1.102468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=495 train loss <loss>=1.05507522821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch [495]#011Speed: 811.13 samples/sec#011loss=1.055075\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch[500] avg_epoch_loss=1.101016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=500 train loss <loss>=0.956986403465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch [500]#011Speed: 1030.31 samples/sec#011loss=0.956986\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch[505] avg_epoch_loss=1.098859\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=505 train loss <loss>=0.882742464542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:32 INFO 140074512123712] Epoch[8] Batch [505]#011Speed: 672.32 samples/sec#011loss=0.882742\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch[510] avg_epoch_loss=1.096692\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=510 train loss <loss>=0.877306735516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch [510]#011Speed: 1066.23 samples/sec#011loss=0.877307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch[515] avg_epoch_loss=1.096962\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=515 train loss <loss>=1.12455254793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch [515]#011Speed: 797.72 samples/sec#011loss=1.124553\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch[520] avg_epoch_loss=1.099972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=520 train loss <loss>=1.41061863899\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch [520]#011Speed: 1077.73 samples/sec#011loss=1.410619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch[525] avg_epoch_loss=1.100126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=525 train loss <loss>=1.1162442565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch [525]#011Speed: 795.94 samples/sec#011loss=1.116244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch[530] avg_epoch_loss=1.099128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=530 train loss <loss>=0.994105708599\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:33 INFO 140074512123712] Epoch[8] Batch [530]#011Speed: 1047.98 samples/sec#011loss=0.994106\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch[535] avg_epoch_loss=1.098285\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=535 train loss <loss>=1.00877363682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch [535]#011Speed: 768.53 samples/sec#011loss=1.008774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch[540] avg_epoch_loss=1.097688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=540 train loss <loss>=1.03363018036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch [540]#011Speed: 1045.07 samples/sec#011loss=1.033630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch[545] avg_epoch_loss=1.097776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=545 train loss <loss>=1.10738602877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch [545]#011Speed: 722.09 samples/sec#011loss=1.107386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch[550] avg_epoch_loss=1.098541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=550 train loss <loss>=1.18204460144\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch [550]#011Speed: 927.69 samples/sec#011loss=1.182045\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch[555] avg_epoch_loss=1.103892\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, batch=555 train loss <loss>=1.69355024099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[8] Batch [555]#011Speed: 723.23 samples/sec#011loss=1.693550\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] processed a total of 17819 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20138.66901397705, \"sum\": 20138.66901397705, \"min\": 20138.66901397705}}, \"EndTime\": 1589445154.855792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445134.717063}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=884.805770968 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=8, train loss <loss>=1.10369288311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_62f94cc2-e661-45cc-ab43-fec1ca36f3fb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.093999862670898, \"sum\": 9.093999862670898, \"min\": 9.093999862670898}}, \"EndTime\": 1589445154.865802, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445154.855861}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] Epoch[9] Batch[0] avg_epoch_loss=0.958497\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=0.958497464657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch[5] avg_epoch_loss=1.023783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=1.02378349503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch [5]#011Speed: 1032.65 samples/sec#011loss=1.023783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch[10] avg_epoch_loss=1.027349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=1.03162767887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch [10]#011Speed: 811.59 samples/sec#011loss=1.031628\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch[15] avg_epoch_loss=1.016286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=0.991946971416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch [15]#011Speed: 1081.40 samples/sec#011loss=0.991947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch[20] avg_epoch_loss=1.010794\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=0.993220865726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch [20]#011Speed: 782.82 samples/sec#011loss=0.993221\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch[25] avg_epoch_loss=1.029747\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=1.10935101509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:35 INFO 140074512123712] Epoch[9] Batch [25]#011Speed: 1018.56 samples/sec#011loss=1.109351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch[30] avg_epoch_loss=1.048025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=1.14306840897\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch [30]#011Speed: 761.99 samples/sec#011loss=1.143068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch[35] avg_epoch_loss=1.039736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=0.988342750072\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch [35]#011Speed: 1092.84 samples/sec#011loss=0.988343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch[40] avg_epoch_loss=1.036204\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=1.01077568531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch [40]#011Speed: 805.27 samples/sec#011loss=1.010776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch[45] avg_epoch_loss=1.029471\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=0.974261915684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch [45]#011Speed: 1093.59 samples/sec#011loss=0.974262\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch[50] avg_epoch_loss=1.025297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=0.986893045902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch [50]#011Speed: 817.93 samples/sec#011loss=0.986893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch[55] avg_epoch_loss=1.043423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=1.22830616236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:36 INFO 140074512123712] Epoch[9] Batch [55]#011Speed: 1017.86 samples/sec#011loss=1.228306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch[60] avg_epoch_loss=1.045582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=1.06976413727\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch [60]#011Speed: 797.09 samples/sec#011loss=1.069764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch[65] avg_epoch_loss=1.049669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=1.09953145981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch [65]#011Speed: 1077.14 samples/sec#011loss=1.099531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch[70] avg_epoch_loss=1.050006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=1.054456985\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch [70]#011Speed: 797.48 samples/sec#011loss=1.054457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch[75] avg_epoch_loss=1.054402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=1.11681596041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch [75]#011Speed: 1067.04 samples/sec#011loss=1.116816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch[80] avg_epoch_loss=1.056560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=1.08936630487\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch [80]#011Speed: 768.77 samples/sec#011loss=1.089366\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch[85] avg_epoch_loss=1.055725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=1.04220696688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:37 INFO 140074512123712] Epoch[9] Batch [85]#011Speed: 1025.33 samples/sec#011loss=1.042207\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch[90] avg_epoch_loss=1.120903\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=2.24195916653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch [90]#011Speed: 756.04 samples/sec#011loss=2.241959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch[95] avg_epoch_loss=1.122815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=1.15760862827\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch [95]#011Speed: 1085.06 samples/sec#011loss=1.157609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch[100] avg_epoch_loss=1.122700\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=1.12049362659\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch [100]#011Speed: 789.78 samples/sec#011loss=1.120494\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch[105] avg_epoch_loss=1.127295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=1.22011706829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch [105]#011Speed: 1076.70 samples/sec#011loss=1.220117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch[110] avg_epoch_loss=1.124960\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=1.0754633069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:38 INFO 140074512123712] Epoch[9] Batch [110]#011Speed: 793.73 samples/sec#011loss=1.075463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch[115] avg_epoch_loss=1.121201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=1.03775273561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch [115]#011Speed: 1021.19 samples/sec#011loss=1.037753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch[120] avg_epoch_loss=1.115588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=0.985368931293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch [120]#011Speed: 785.33 samples/sec#011loss=0.985369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch[125] avg_epoch_loss=1.109051\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=0.950838088989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch [125]#011Speed: 1082.98 samples/sec#011loss=0.950838\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch[130] avg_epoch_loss=1.102619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=0.940552031994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch [130]#011Speed: 775.55 samples/sec#011loss=0.940552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch[135] avg_epoch_loss=1.095736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=0.915384161472\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch [135]#011Speed: 1084.16 samples/sec#011loss=0.915384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch[140] avg_epoch_loss=1.091992\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=0.990173411369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:39 INFO 140074512123712] Epoch[9] Batch [140]#011Speed: 601.54 samples/sec#011loss=0.990173\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch[145] avg_epoch_loss=1.084148\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=0.862938523293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch [145]#011Speed: 1038.37 samples/sec#011loss=0.862939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch[150] avg_epoch_loss=1.081052\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=0.990634405613\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch [150]#011Speed: 786.18 samples/sec#011loss=0.990634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch[155] avg_epoch_loss=1.076430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=0.936853206158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch [155]#011Speed: 1099.52 samples/sec#011loss=0.936853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch[160] avg_epoch_loss=1.077063\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=1.09681273699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch [160]#011Speed: 781.59 samples/sec#011loss=1.096813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch[165] avg_epoch_loss=1.073457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=0.957341110706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:40 INFO 140074512123712] Epoch[9] Batch [165]#011Speed: 1054.89 samples/sec#011loss=0.957341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch[170] avg_epoch_loss=1.068032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=0.887919449806\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch [170]#011Speed: 764.83 samples/sec#011loss=0.887919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch[175] avg_epoch_loss=1.068723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=1.09236586094\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch [175]#011Speed: 1010.92 samples/sec#011loss=1.092366\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch[180] avg_epoch_loss=1.066903\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=1.0028493166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch [180]#011Speed: 805.13 samples/sec#011loss=1.002849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch[185] avg_epoch_loss=1.063364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=0.93524479866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch [185]#011Speed: 1047.07 samples/sec#011loss=0.935245\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch[190] avg_epoch_loss=1.089634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=2.06685589552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch [190]#011Speed: 793.10 samples/sec#011loss=2.066856\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch[195] avg_epoch_loss=1.116337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=2.13640058041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:41 INFO 140074512123712] Epoch[9] Batch [195]#011Speed: 1068.51 samples/sec#011loss=2.136401\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch[200] avg_epoch_loss=1.119480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=1.24269835949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch [200]#011Speed: 770.60 samples/sec#011loss=1.242698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch[205] avg_epoch_loss=1.124994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=1.34664549828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch [205]#011Speed: 797.54 samples/sec#011loss=1.346645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch[210] avg_epoch_loss=1.128290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=1.26410958767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch [210]#011Speed: 1083.61 samples/sec#011loss=1.264110\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch[215] avg_epoch_loss=1.130653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=1.23035898209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch [215]#011Speed: 1094.41 samples/sec#011loss=1.230359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch[220] avg_epoch_loss=1.130867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=1.14010212421\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch [220]#011Speed: 768.83 samples/sec#011loss=1.140102\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch[225] avg_epoch_loss=1.129270\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=1.0587033987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:42 INFO 140074512123712] Epoch[9] Batch [225]#011Speed: 1021.52 samples/sec#011loss=1.058703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch[230] avg_epoch_loss=1.126762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=1.01337020397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch [230]#011Speed: 749.43 samples/sec#011loss=1.013370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch[235] avg_epoch_loss=1.168078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=3.07687478065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch [235]#011Speed: 1074.56 samples/sec#011loss=3.076875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch[240] avg_epoch_loss=1.166423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=1.08830184937\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch [240]#011Speed: 791.10 samples/sec#011loss=1.088302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch[245] avg_epoch_loss=1.167949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=1.24152197838\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch [245]#011Speed: 796.53 samples/sec#011loss=1.241522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch[250] avg_epoch_loss=1.167906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=1.16578741074\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:43 INFO 140074512123712] Epoch[9] Batch [250]#011Speed: 1060.88 samples/sec#011loss=1.165787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch[255] avg_epoch_loss=1.169209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=1.23462047577\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch [255]#011Speed: 754.24 samples/sec#011loss=1.234620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch[260] avg_epoch_loss=1.173752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=1.40634448528\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch [260]#011Speed: 1076.22 samples/sec#011loss=1.406344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch[265] avg_epoch_loss=1.171915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=1.07603406906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch [265]#011Speed: 1092.43 samples/sec#011loss=1.076034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch[270] avg_epoch_loss=1.169382\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=1.03460065126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch [270]#011Speed: 763.44 samples/sec#011loss=1.034601\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch[275] avg_epoch_loss=1.167641\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=275 train loss <loss>=1.07329317331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:44 INFO 140074512123712] Epoch[9] Batch [275]#011Speed: 1095.06 samples/sec#011loss=1.073293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch[280] avg_epoch_loss=1.163922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=280 train loss <loss>=0.958673274517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch [280]#011Speed: 629.02 samples/sec#011loss=0.958673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch[285] avg_epoch_loss=1.159361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=285 train loss <loss>=0.902987241745\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch [285]#011Speed: 1054.82 samples/sec#011loss=0.902987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch[290] avg_epoch_loss=1.187901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=290 train loss <loss>=2.82042001486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch [290]#011Speed: 771.47 samples/sec#011loss=2.820420\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch[295] avg_epoch_loss=1.187861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=295 train loss <loss>=1.18553619385\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch [295]#011Speed: 1113.82 samples/sec#011loss=1.185536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch[300] avg_epoch_loss=1.187297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=300 train loss <loss>=1.15387194157\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch [300]#011Speed: 789.66 samples/sec#011loss=1.153872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch[305] avg_epoch_loss=1.187693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=305 train loss <loss>=1.21153934002\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:45 INFO 140074512123712] Epoch[9] Batch [305]#011Speed: 1061.68 samples/sec#011loss=1.211539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch[310] avg_epoch_loss=1.202305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=310 train loss <loss>=2.0965719223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch [310]#011Speed: 760.43 samples/sec#011loss=2.096572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch[315] avg_epoch_loss=1.200586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=315 train loss <loss>=1.09367562532\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch [315]#011Speed: 1031.02 samples/sec#011loss=1.093676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch[320] avg_epoch_loss=1.199171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=320 train loss <loss>=1.10974760056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch [320]#011Speed: 799.67 samples/sec#011loss=1.109748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch[325] avg_epoch_loss=1.197671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=325 train loss <loss>=1.10137104988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch [325]#011Speed: 1088.30 samples/sec#011loss=1.101371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch[330] avg_epoch_loss=1.195715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=330 train loss <loss>=1.06819806099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch [330]#011Speed: 806.28 samples/sec#011loss=1.068198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch[335] avg_epoch_loss=1.194831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=335 train loss <loss>=1.13626732826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:46 INFO 140074512123712] Epoch[9] Batch [335]#011Speed: 1066.18 samples/sec#011loss=1.136267\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch[340] avg_epoch_loss=1.191418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=340 train loss <loss>=0.962085688114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch [340]#011Speed: 756.84 samples/sec#011loss=0.962086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch[345] avg_epoch_loss=1.187331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=345 train loss <loss>=0.908615839481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch [345]#011Speed: 1072.11 samples/sec#011loss=0.908616\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch[350] avg_epoch_loss=1.182446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=350 train loss <loss>=0.844380128384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch [350]#011Speed: 784.15 samples/sec#011loss=0.844380\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch[355] avg_epoch_loss=1.177937\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=355 train loss <loss>=0.861375200748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch [355]#011Speed: 1077.80 samples/sec#011loss=0.861375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch[360] avg_epoch_loss=1.176378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=360 train loss <loss>=1.06539297104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:47 INFO 140074512123712] Epoch[9] Batch [360]#011Speed: 774.84 samples/sec#011loss=1.065393\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch[365] avg_epoch_loss=1.172516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=365 train loss <loss>=0.89369815588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch [365]#011Speed: 1005.84 samples/sec#011loss=0.893698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch[370] avg_epoch_loss=1.172462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=370 train loss <loss>=1.168522048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch [370]#011Speed: 753.12 samples/sec#011loss=1.168522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch[375] avg_epoch_loss=1.172941\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=375 train loss <loss>=1.20844092369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch [375]#011Speed: 1073.89 samples/sec#011loss=1.208441\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch[380] avg_epoch_loss=1.170190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=380 train loss <loss>=0.963331282139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch [380]#011Speed: 795.84 samples/sec#011loss=0.963331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch[385] avg_epoch_loss=1.169881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=385 train loss <loss>=1.14637612104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch [385]#011Speed: 1082.14 samples/sec#011loss=1.146376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch[390] avg_epoch_loss=1.167016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=390 train loss <loss>=0.945790541172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:48 INFO 140074512123712] Epoch[9] Batch [390]#011Speed: 769.00 samples/sec#011loss=0.945791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch[395] avg_epoch_loss=1.166164\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=395 train loss <loss>=1.09958640337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch [395]#011Speed: 1009.08 samples/sec#011loss=1.099586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch[400] avg_epoch_loss=1.163511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=400 train loss <loss>=0.953390598297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch [400]#011Speed: 800.09 samples/sec#011loss=0.953391\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch[405] avg_epoch_loss=1.160899\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=405 train loss <loss>=0.951380038261\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch [405]#011Speed: 1081.81 samples/sec#011loss=0.951380\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch[410] avg_epoch_loss=1.159306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=410 train loss <loss>=1.02998820543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch [410]#011Speed: 761.49 samples/sec#011loss=1.029988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch[415] avg_epoch_loss=1.157626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=415 train loss <loss>=1.01952619553\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:49 INFO 140074512123712] Epoch[9] Batch [415]#011Speed: 1086.00 samples/sec#011loss=1.019526\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch[420] avg_epoch_loss=1.154780\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=420 train loss <loss>=0.917998588085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch [420]#011Speed: 638.09 samples/sec#011loss=0.917999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch[425] avg_epoch_loss=1.152487\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=425 train loss <loss>=0.959391856194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch [425]#011Speed: 1070.21 samples/sec#011loss=0.959392\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch[430] avg_epoch_loss=1.150385\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=430 train loss <loss>=0.971257615089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch [430]#011Speed: 798.81 samples/sec#011loss=0.971258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch[435] avg_epoch_loss=1.149013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=435 train loss <loss>=1.03077245951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch [435]#011Speed: 1069.56 samples/sec#011loss=1.030772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch[440] avg_epoch_loss=1.145880\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=440 train loss <loss>=0.872677695751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch [440]#011Speed: 805.40 samples/sec#011loss=0.872678\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch[445] avg_epoch_loss=1.144936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=445 train loss <loss>=1.06167260408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:50 INFO 140074512123712] Epoch[9] Batch [445]#011Speed: 1043.66 samples/sec#011loss=1.061673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch[450] avg_epoch_loss=1.145127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=450 train loss <loss>=1.16216567755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch [450]#011Speed: 784.13 samples/sec#011loss=1.162166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch[455] avg_epoch_loss=1.145092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=455 train loss <loss>=1.14191310406\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch [455]#011Speed: 1081.23 samples/sec#011loss=1.141913\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch[460] avg_epoch_loss=1.146645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=460 train loss <loss>=1.28835163116\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch [460]#011Speed: 784.79 samples/sec#011loss=1.288352\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch[465] avg_epoch_loss=1.145146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=465 train loss <loss>=1.00685619116\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch [465]#011Speed: 1102.35 samples/sec#011loss=1.006856\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch[470] avg_epoch_loss=1.144083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=470 train loss <loss>=1.04503052235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch [470]#011Speed: 781.78 samples/sec#011loss=1.045031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch[475] avg_epoch_loss=1.148023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=475 train loss <loss>=1.51922940016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:51 INFO 140074512123712] Epoch[9] Batch [475]#011Speed: 1082.68 samples/sec#011loss=1.519229\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch[480] avg_epoch_loss=1.146718\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=480 train loss <loss>=1.02240339518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch [480]#011Speed: 762.06 samples/sec#011loss=1.022403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch[485] avg_epoch_loss=1.147511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=485 train loss <loss>=1.22381293774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch [485]#011Speed: 1086.79 samples/sec#011loss=1.223813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch[490] avg_epoch_loss=1.146102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=490 train loss <loss>=1.0091388464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch [490]#011Speed: 799.15 samples/sec#011loss=1.009139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch[495] avg_epoch_loss=1.144548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=495 train loss <loss>=0.991960978508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch [495]#011Speed: 1086.06 samples/sec#011loss=0.991961\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch[500] avg_epoch_loss=1.142574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=500 train loss <loss>=0.946753799915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:52 INFO 140074512123712] Epoch[9] Batch [500]#011Speed: 668.67 samples/sec#011loss=0.946754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch[505] avg_epoch_loss=1.141822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=505 train loss <loss>=1.0664495945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch [505]#011Speed: 1065.74 samples/sec#011loss=1.066450\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch[510] avg_epoch_loss=1.140121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=510 train loss <loss>=0.968022453785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch [510]#011Speed: 720.83 samples/sec#011loss=0.968022\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch[515] avg_epoch_loss=1.137684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=515 train loss <loss>=0.888577759266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch [515]#011Speed: 1080.18 samples/sec#011loss=0.888578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch[520] avg_epoch_loss=1.135712\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=520 train loss <loss>=0.932214725018\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch [520]#011Speed: 786.40 samples/sec#011loss=0.932215\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch[525] avg_epoch_loss=1.133682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=525 train loss <loss>=0.922176802158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch [525]#011Speed: 1080.84 samples/sec#011loss=0.922177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch[530] avg_epoch_loss=1.134431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=530 train loss <loss>=1.21325098276\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:53 INFO 140074512123712] Epoch[9] Batch [530]#011Speed: 781.91 samples/sec#011loss=1.213251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch[535] avg_epoch_loss=1.137649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=535 train loss <loss>=1.47934824228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch [535]#011Speed: 1042.66 samples/sec#011loss=1.479348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch[540] avg_epoch_loss=1.136808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=540 train loss <loss>=1.04671953917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch [540]#011Speed: 787.65 samples/sec#011loss=1.046720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch[545] avg_epoch_loss=1.135609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=545 train loss <loss>=1.00587007999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch [545]#011Speed: 1082.51 samples/sec#011loss=1.005870\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch[550] avg_epoch_loss=1.135233\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, batch=550 train loss <loss>=1.09415584803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[9] Batch [550]#011Speed: 986.18 samples/sec#011loss=1.094156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] processed a total of 17622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 19770.209789276123, \"sum\": 19770.209789276123, \"min\": 19770.209789276123}}, \"EndTime\": 1589445174.636142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445154.865874}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=891.336461299 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=9, train loss <loss>=1.13523306572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[10] Batch[0] avg_epoch_loss=0.947154\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.947154402733\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[10] Batch[5] avg_epoch_loss=0.938652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.938652018706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:54 INFO 140074512123712] Epoch[10] Batch [5]#011Speed: 1067.56 samples/sec#011loss=0.938652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch[10] avg_epoch_loss=0.934005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=0.928429198265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch [10]#011Speed: 611.91 samples/sec#011loss=0.928429\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch[15] avg_epoch_loss=0.912841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=0.866278076172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch [15]#011Speed: 1073.03 samples/sec#011loss=0.866278\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch[20] avg_epoch_loss=0.898890\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=0.854248297215\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch [20]#011Speed: 784.55 samples/sec#011loss=0.854248\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch[25] avg_epoch_loss=0.930700\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=1.06430268288\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch [25]#011Speed: 1086.39 samples/sec#011loss=1.064303\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch[30] avg_epoch_loss=0.971724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=1.18505020142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch [30]#011Speed: 789.24 samples/sec#011loss=1.185050\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch[35] avg_epoch_loss=0.969556\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=0.956112003326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:55 INFO 140074512123712] Epoch[10] Batch [35]#011Speed: 1047.63 samples/sec#011loss=0.956112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch[40] avg_epoch_loss=0.958482\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=0.878750145435\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch [40]#011Speed: 770.95 samples/sec#011loss=0.878750\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch[45] avg_epoch_loss=0.950089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=0.881262636185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch [45]#011Speed: 1083.84 samples/sec#011loss=0.881263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch[50] avg_epoch_loss=0.941258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=0.860011839867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch [50]#011Speed: 797.32 samples/sec#011loss=0.860012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch[55] avg_epoch_loss=0.955179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=1.09718199968\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch [55]#011Speed: 1080.31 samples/sec#011loss=1.097182\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch[60] avg_epoch_loss=0.954833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=0.950949406624\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:56 INFO 140074512123712] Epoch[10] Batch [60]#011Speed: 1068.24 samples/sec#011loss=0.950949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch[65] avg_epoch_loss=0.959300\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=1.01379947662\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch [65]#011Speed: 784.93 samples/sec#011loss=1.013799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch[70] avg_epoch_loss=0.969746\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=1.10763477087\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch [70]#011Speed: 1045.50 samples/sec#011loss=1.107635\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch[75] avg_epoch_loss=0.970597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=0.982679724693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch [75]#011Speed: 800.33 samples/sec#011loss=0.982680\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch[80] avg_epoch_loss=0.975135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=1.04410816431\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch [80]#011Speed: 799.22 samples/sec#011loss=1.044108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch[85] avg_epoch_loss=0.971266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=0.908602070808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch [85]#011Speed: 992.24 samples/sec#011loss=0.908602\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch[90] avg_epoch_loss=0.967030\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=0.894160783291\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:57 INFO 140074512123712] Epoch[10] Batch [90]#011Speed: 1063.61 samples/sec#011loss=0.894161\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch[95] avg_epoch_loss=0.961763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=0.865899920464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch [95]#011Speed: 713.10 samples/sec#011loss=0.865900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch[100] avg_epoch_loss=0.954179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=0.808579707146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch [100]#011Speed: 1045.38 samples/sec#011loss=0.808580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch[105] avg_epoch_loss=0.950735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=0.881165742874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch [105]#011Speed: 780.68 samples/sec#011loss=0.881166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch[110] avg_epoch_loss=1.008803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=2.23984644413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch [110]#011Speed: 1093.85 samples/sec#011loss=2.239846\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch[115] avg_epoch_loss=1.016034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=1.17656257153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch [115]#011Speed: 787.38 samples/sec#011loss=1.176563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch[120] avg_epoch_loss=1.013474\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=0.954069066048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:58 INFO 140074512123712] Epoch[10] Batch [120]#011Speed: 1076.37 samples/sec#011loss=0.954069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch[125] avg_epoch_loss=1.014149\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=1.03047755957\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch [125]#011Speed: 793.20 samples/sec#011loss=1.030478\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch[130] avg_epoch_loss=1.013307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=0.992105269432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch [130]#011Speed: 1092.08 samples/sec#011loss=0.992105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch[135] avg_epoch_loss=1.009467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=0.908842134476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch [135]#011Speed: 792.42 samples/sec#011loss=0.908842\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch[140] avg_epoch_loss=1.007118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=0.943245685101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch [140]#011Speed: 1079.50 samples/sec#011loss=0.943246\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch[145] avg_epoch_loss=1.003913\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=0.913532853127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:32:59 INFO 140074512123712] Epoch[10] Batch [145]#011Speed: 774.62 samples/sec#011loss=0.913533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch[150] avg_epoch_loss=1.097490\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=3.82992942333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch [150]#011Speed: 1077.29 samples/sec#011loss=3.829929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch[155] avg_epoch_loss=1.099836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=1.17068400383\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch [155]#011Speed: 617.17 samples/sec#011loss=1.170684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch[160] avg_epoch_loss=1.101873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=1.16542348862\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch [160]#011Speed: 1082.96 samples/sec#011loss=1.165423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch[165] avg_epoch_loss=1.102954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=1.13775346279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch [165]#011Speed: 804.44 samples/sec#011loss=1.137753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch[170] avg_epoch_loss=1.102364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=1.08277161121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:00 INFO 140074512123712] Epoch[10] Batch [170]#011Speed: 1036.12 samples/sec#011loss=1.082772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch[175] avg_epoch_loss=1.099355\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=0.996455466747\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch [175]#011Speed: 650.46 samples/sec#011loss=0.996455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch[180] avg_epoch_loss=1.095981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=0.977236390114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch [180]#011Speed: 804.73 samples/sec#011loss=0.977236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch[185] avg_epoch_loss=1.091856\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=0.9425157547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch [185]#011Speed: 697.35 samples/sec#011loss=0.942516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch[190] avg_epoch_loss=1.093304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=1.14718108177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch [190]#011Speed: 1076.41 samples/sec#011loss=1.147181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch[195] avg_epoch_loss=1.102474\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=1.45275295973\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch [195]#011Speed: 778.56 samples/sec#011loss=1.452753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch[200] avg_epoch_loss=1.106602\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=1.26841832399\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:01 INFO 140074512123712] Epoch[10] Batch [200]#011Speed: 1022.10 samples/sec#011loss=1.268418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch[205] avg_epoch_loss=1.108675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=1.1920270443\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch [205]#011Speed: 746.93 samples/sec#011loss=1.192027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch[210] avg_epoch_loss=1.111420\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=1.22450349331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch [210]#011Speed: 1065.69 samples/sec#011loss=1.224503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch[215] avg_epoch_loss=1.111227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=1.10307420492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch [215]#011Speed: 794.20 samples/sec#011loss=1.103074\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch[220] avg_epoch_loss=1.109575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=1.03820911646\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch [220]#011Speed: 1073.24 samples/sec#011loss=1.038209\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch[225] avg_epoch_loss=1.108135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=1.0445150733\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:02 INFO 140074512123712] Epoch[10] Batch [225]#011Speed: 765.40 samples/sec#011loss=1.044515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch[230] avg_epoch_loss=1.104076\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=0.920587265491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch [230]#011Speed: 1075.12 samples/sec#011loss=0.920587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch[235] avg_epoch_loss=1.100190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=0.920656955242\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch [235]#011Speed: 699.40 samples/sec#011loss=0.920657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch[240] avg_epoch_loss=1.096474\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=0.921065926552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch [240]#011Speed: 1064.76 samples/sec#011loss=0.921066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch[245] avg_epoch_loss=1.104549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=1.49378566742\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch [245]#011Speed: 788.28 samples/sec#011loss=1.493786\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch[250] avg_epoch_loss=1.101331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=0.942992579937\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:03 INFO 140074512123712] Epoch[10] Batch [250]#011Speed: 1083.75 samples/sec#011loss=0.942993\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch[255] avg_epoch_loss=1.099520\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=1.00862675905\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch [255]#011Speed: 791.89 samples/sec#011loss=1.008627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch[260] avg_epoch_loss=1.099496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=1.09824888706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch [260]#011Speed: 1083.21 samples/sec#011loss=1.098249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch[265] avg_epoch_loss=1.103254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=1.29941170216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch [265]#011Speed: 788.10 samples/sec#011loss=1.299412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch[270] avg_epoch_loss=1.102007\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=1.03566528559\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch [270]#011Speed: 1083.68 samples/sec#011loss=1.035665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch[275] avg_epoch_loss=1.101787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=275 train loss <loss>=1.08990309238\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch [275]#011Speed: 783.15 samples/sec#011loss=1.089903\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch[280] avg_epoch_loss=1.102054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=280 train loss <loss>=1.11674807072\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:04 INFO 140074512123712] Epoch[10] Batch [280]#011Speed: 1053.01 samples/sec#011loss=1.116748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch[285] avg_epoch_loss=1.100095\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=285 train loss <loss>=0.990000784397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch [285]#011Speed: 799.24 samples/sec#011loss=0.990001\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch[290] avg_epoch_loss=1.097030\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=290 train loss <loss>=0.921708881855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch [290]#011Speed: 947.36 samples/sec#011loss=0.921709\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch[295] avg_epoch_loss=1.109333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=295 train loss <loss>=1.8254011631\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch [295]#011Speed: 700.68 samples/sec#011loss=1.825401\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch[300] avg_epoch_loss=1.105802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=300 train loss <loss>=0.896765339375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch [300]#011Speed: 1086.19 samples/sec#011loss=0.896765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch[305] avg_epoch_loss=1.104235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=305 train loss <loss>=1.0098831296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch [305]#011Speed: 805.40 samples/sec#011loss=1.009883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch[310] avg_epoch_loss=1.102753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=310 train loss <loss>=1.01206082106\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:05 INFO 140074512123712] Epoch[10] Batch [310]#011Speed: 1062.87 samples/sec#011loss=1.012061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch[315] avg_epoch_loss=1.102405\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=315 train loss <loss>=1.08076307774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch [315]#011Speed: 778.63 samples/sec#011loss=1.080763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch[320] avg_epoch_loss=1.117282\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=320 train loss <loss>=2.05753413439\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch [320]#011Speed: 1030.20 samples/sec#011loss=2.057534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch[325] avg_epoch_loss=1.117035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=325 train loss <loss>=1.10112206936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch [325]#011Speed: 788.08 samples/sec#011loss=1.101122\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch[330] avg_epoch_loss=1.116491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=330 train loss <loss>=1.08108222485\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch [330]#011Speed: 1086.59 samples/sec#011loss=1.081082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch[335] avg_epoch_loss=1.115356\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=335 train loss <loss>=1.04020026922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:06 INFO 140074512123712] Epoch[10] Batch [335]#011Speed: 765.27 samples/sec#011loss=1.040200\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch[340] avg_epoch_loss=1.113853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=340 train loss <loss>=1.01284915209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch [340]#011Speed: 1070.68 samples/sec#011loss=1.012849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch[345] avg_epoch_loss=1.111757\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=345 train loss <loss>=0.968785834312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch [345]#011Speed: 791.08 samples/sec#011loss=0.968786\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch[350] avg_epoch_loss=1.121067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=350 train loss <loss>=1.76536149979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch [350]#011Speed: 1007.32 samples/sec#011loss=1.765361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch[355] avg_epoch_loss=1.118975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=355 train loss <loss>=0.972082996368\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch [355]#011Speed: 794.87 samples/sec#011loss=0.972083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch[360] avg_epoch_loss=1.119331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=360 train loss <loss>=1.14465863705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch [360]#011Speed: 1097.13 samples/sec#011loss=1.144659\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch[365] avg_epoch_loss=1.117794\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=365 train loss <loss>=1.00684190989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:07 INFO 140074512123712] Epoch[10] Batch [365]#011Speed: 750.29 samples/sec#011loss=1.006842\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch[370] avg_epoch_loss=1.118048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=370 train loss <loss>=1.13664571047\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch [370]#011Speed: 1102.13 samples/sec#011loss=1.136646\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch[375] avg_epoch_loss=1.114966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=375 train loss <loss>=0.886291003227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch [375]#011Speed: 737.79 samples/sec#011loss=0.886291\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch[380] avg_epoch_loss=1.112578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=380 train loss <loss>=0.932974326611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch [380]#011Speed: 1026.62 samples/sec#011loss=0.932974\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch[385] avg_epoch_loss=1.110382\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=385 train loss <loss>=0.943072474003\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch [385]#011Speed: 786.84 samples/sec#011loss=0.943072\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch[390] avg_epoch_loss=1.107888\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=390 train loss <loss>=0.915359425545\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:08 INFO 140074512123712] Epoch[10] Batch [390]#011Speed: 1066.89 samples/sec#011loss=0.915359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch[395] avg_epoch_loss=1.104471\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=395 train loss <loss>=0.837264096737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch [395]#011Speed: 779.42 samples/sec#011loss=0.837264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch[400] avg_epoch_loss=1.101432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=400 train loss <loss>=0.860713362694\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch [400]#011Speed: 1080.65 samples/sec#011loss=0.860713\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch[405] avg_epoch_loss=1.098968\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=405 train loss <loss>=0.901344108582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch [405]#011Speed: 777.52 samples/sec#011loss=0.901344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch[410] avg_epoch_loss=1.095396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=410 train loss <loss>=0.805357205868\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch [410]#011Speed: 1082.45 samples/sec#011loss=0.805357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch[415] avg_epoch_loss=1.094723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=415 train loss <loss>=1.03944195509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch [415]#011Speed: 770.37 samples/sec#011loss=1.039442\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch[420] avg_epoch_loss=1.103134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=420 train loss <loss>=1.80288853645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:09 INFO 140074512123712] Epoch[10] Batch [420]#011Speed: 1052.10 samples/sec#011loss=1.802889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch[425] avg_epoch_loss=1.104648\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=425 train loss <loss>=1.23210016489\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch [425]#011Speed: 752.93 samples/sec#011loss=1.232100\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch[430] avg_epoch_loss=1.103651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=430 train loss <loss>=1.01877264977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch [430]#011Speed: 1077.73 samples/sec#011loss=1.018773\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch[435] avg_epoch_loss=1.103151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=435 train loss <loss>=1.06003808975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch [435]#011Speed: 646.25 samples/sec#011loss=1.060038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch[440] avg_epoch_loss=1.102681\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=440 train loss <loss>=1.06167843342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch [440]#011Speed: 1078.82 samples/sec#011loss=1.061678\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch[445] avg_epoch_loss=1.101171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=445 train loss <loss>=0.967959260941\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:10 INFO 140074512123712] Epoch[10] Batch [445]#011Speed: 752.13 samples/sec#011loss=0.967959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch[450] avg_epoch_loss=1.100497\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=450 train loss <loss>=1.04038140774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch [450]#011Speed: 1054.33 samples/sec#011loss=1.040381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch[455] avg_epoch_loss=1.099574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=455 train loss <loss>=1.01632665396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch [455]#011Speed: 1020.89 samples/sec#011loss=1.016327\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch[460] avg_epoch_loss=1.098408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=460 train loss <loss>=0.992072713375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch [460]#011Speed: 761.45 samples/sec#011loss=0.992073\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch[465] avg_epoch_loss=1.097013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=465 train loss <loss>=0.968420708179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch [465]#011Speed: 1036.83 samples/sec#011loss=0.968421\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch[470] avg_epoch_loss=1.094284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=470 train loss <loss>=0.839909934998\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch [470]#011Speed: 797.46 samples/sec#011loss=0.839910\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch[475] avg_epoch_loss=1.091814\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=475 train loss <loss>=0.859199357033\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:11 INFO 140074512123712] Epoch[10] Batch [475]#011Speed: 1052.87 samples/sec#011loss=0.859199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch[480] avg_epoch_loss=1.088874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=480 train loss <loss>=0.80897154808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch [480]#011Speed: 783.01 samples/sec#011loss=0.808972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch[485] avg_epoch_loss=1.100657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=485 train loss <loss>=2.23419371843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch [485]#011Speed: 1067.69 samples/sec#011loss=2.234194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch[490] avg_epoch_loss=1.099720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=490 train loss <loss>=1.00857156515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch [490]#011Speed: 770.35 samples/sec#011loss=1.008572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch[495] avg_epoch_loss=1.097815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=495 train loss <loss>=0.910815620422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch [495]#011Speed: 1096.14 samples/sec#011loss=0.910816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch[500] avg_epoch_loss=1.097223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=500 train loss <loss>=1.03850750923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch [500]#011Speed: 810.12 samples/sec#011loss=1.038508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch[505] avg_epoch_loss=1.096540\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=505 train loss <loss>=1.02804123163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:12 INFO 140074512123712] Epoch[10] Batch [505]#011Speed: 1056.33 samples/sec#011loss=1.028041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch[510] avg_epoch_loss=1.098126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=510 train loss <loss>=1.25865447521\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch [510]#011Speed: 797.21 samples/sec#011loss=1.258654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch[515] avg_epoch_loss=1.097041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=515 train loss <loss>=0.986176455021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch [515]#011Speed: 1079.37 samples/sec#011loss=0.986176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch[520] avg_epoch_loss=1.095560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=520 train loss <loss>=0.942643713951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch [520]#011Speed: 741.35 samples/sec#011loss=0.942644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch[525] avg_epoch_loss=1.093638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=525 train loss <loss>=0.893424224854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch [525]#011Speed: 1082.28 samples/sec#011loss=0.893424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch[530] avg_epoch_loss=1.091460\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=530 train loss <loss>=0.862374615669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:13 INFO 140074512123712] Epoch[10] Batch [530]#011Speed: 783.16 samples/sec#011loss=0.862375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch[535] avg_epoch_loss=1.089283\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=535 train loss <loss>=0.858048868179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch [535]#011Speed: 1062.65 samples/sec#011loss=0.858049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch[540] avg_epoch_loss=1.087020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=540 train loss <loss>=0.844373869896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch [540]#011Speed: 797.73 samples/sec#011loss=0.844374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch[545] avg_epoch_loss=1.088547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=545 train loss <loss>=1.25376782417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch [545]#011Speed: 1028.17 samples/sec#011loss=1.253768\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch[550] avg_epoch_loss=1.088304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=550 train loss <loss>=1.06181504726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch [550]#011Speed: 800.23 samples/sec#011loss=1.061815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch[555] avg_epoch_loss=1.087151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, batch=555 train loss <loss>=0.96003446579\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[10] Batch [555]#011Speed: 1059.64 samples/sec#011loss=0.960034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] processed a total of 17879 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20182.302951812744, \"sum\": 20182.302951812744, \"min\": 20182.302951812744}}, \"EndTime\": 1589445194.818914, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445174.63621}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=885.870732717 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=10, train loss <loss>=1.09091909606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_765c61ed-8e5b-402e-828e-a19793efcf69-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.835958480834961, \"sum\": 9.835958480834961, \"min\": 9.835958480834961}}, \"EndTime\": 1589445194.829293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445194.818981}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] Epoch[11] Batch[0] avg_epoch_loss=1.036470\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=1.03646957874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch[5] avg_epoch_loss=0.928207\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=0.92820729812\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch [5]#011Speed: 1065.10 samples/sec#011loss=0.928207\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch[10] avg_epoch_loss=1.056146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=1.2096716404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch [10]#011Speed: 783.46 samples/sec#011loss=1.209672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch[15] avg_epoch_loss=1.066527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=1.08936451674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch [15]#011Speed: 763.28 samples/sec#011loss=1.089365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch[20] avg_epoch_loss=1.042192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=0.964321374893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch [20]#011Speed: 923.07 samples/sec#011loss=0.964321\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch[25] avg_epoch_loss=1.054340\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=1.10536407232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:15 INFO 140074512123712] Epoch[11] Batch [25]#011Speed: 771.43 samples/sec#011loss=1.105364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch[30] avg_epoch_loss=1.045822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=1.00152728558\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch [30]#011Speed: 1061.12 samples/sec#011loss=1.001527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch[35] avg_epoch_loss=1.034193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=0.962094938755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch [35]#011Speed: 765.48 samples/sec#011loss=0.962095\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch[40] avg_epoch_loss=1.036139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=1.05014433861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch [40]#011Speed: 1016.99 samples/sec#011loss=1.050144\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch[45] avg_epoch_loss=1.024850\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=0.932279801369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch [45]#011Speed: 770.57 samples/sec#011loss=0.932280\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch[50] avg_epoch_loss=1.011052\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=0.884114682674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch [50]#011Speed: 1082.14 samples/sec#011loss=0.884115\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch[55] avg_epoch_loss=1.001124\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=0.89986076355\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:16 INFO 140074512123712] Epoch[11] Batch [55]#011Speed: 788.80 samples/sec#011loss=0.899861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch[60] avg_epoch_loss=1.024677\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=1.28847068548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch [60]#011Speed: 1073.49 samples/sec#011loss=1.288471\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch[65] avg_epoch_loss=1.022240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=0.992511475086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch [65]#011Speed: 785.36 samples/sec#011loss=0.992511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch[70] avg_epoch_loss=1.020543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=0.998130548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch [70]#011Speed: 1038.73 samples/sec#011loss=0.998131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch[75] avg_epoch_loss=1.016923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=0.965517759323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch [75]#011Speed: 804.07 samples/sec#011loss=0.965518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch[80] avg_epoch_loss=1.006922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=0.85491092205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:17 INFO 140074512123712] Epoch[11] Batch [80]#011Speed: 1078.04 samples/sec#011loss=0.854911\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch[85] avg_epoch_loss=1.006101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=0.992796099186\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch [85]#011Speed: 740.54 samples/sec#011loss=0.992796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch[90] avg_epoch_loss=0.996785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=0.836565470695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch [90]#011Speed: 1081.76 samples/sec#011loss=0.836565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch[95] avg_epoch_loss=0.988886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=0.845120823383\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch [95]#011Speed: 736.82 samples/sec#011loss=0.845121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch[100] avg_epoch_loss=1.007029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=1.35537941456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch [100]#011Speed: 1032.19 samples/sec#011loss=1.355379\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch[105] avg_epoch_loss=1.000269\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=0.863706731796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch [105]#011Speed: 792.33 samples/sec#011loss=0.863707\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch[110] avg_epoch_loss=0.993798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=0.85660982132\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:18 INFO 140074512123712] Epoch[11] Batch [110]#011Speed: 1077.93 samples/sec#011loss=0.856610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch[115] avg_epoch_loss=0.993823\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=0.994391572475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch [115]#011Speed: 753.42 samples/sec#011loss=0.994392\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch[120] avg_epoch_loss=0.991454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=0.936483824253\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch [120]#011Speed: 1083.42 samples/sec#011loss=0.936484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch[125] avg_epoch_loss=0.991416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=0.990502405167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch [125]#011Speed: 771.85 samples/sec#011loss=0.990502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch[130] avg_epoch_loss=0.986131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=0.852933180332\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch [130]#011Speed: 1083.81 samples/sec#011loss=0.852933\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch[135] avg_epoch_loss=0.983606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=0.917464375496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch [135]#011Speed: 792.50 samples/sec#011loss=0.917464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch[140] avg_epoch_loss=0.982117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=0.941599714756\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:19 INFO 140074512123712] Epoch[11] Batch [140]#011Speed: 1074.50 samples/sec#011loss=0.941600\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch[145] avg_epoch_loss=0.993622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=1.3180852294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch [145]#011Speed: 786.72 samples/sec#011loss=1.318085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch[150] avg_epoch_loss=0.989526\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=0.869910776615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch [150]#011Speed: 1093.61 samples/sec#011loss=0.869911\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch[155] avg_epoch_loss=0.985270\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=0.856728947163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch [155]#011Speed: 772.40 samples/sec#011loss=0.856729\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch[160] avg_epoch_loss=0.988082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=1.07584066391\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch [160]#011Speed: 842.70 samples/sec#011loss=1.075841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch[165] avg_epoch_loss=0.986077\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=0.92150452137\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:20 INFO 140074512123712] Epoch[11] Batch [165]#011Speed: 768.82 samples/sec#011loss=0.921505\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch[170] avg_epoch_loss=0.983784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=0.907661247253\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch [170]#011Speed: 1078.54 samples/sec#011loss=0.907661\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch[175] avg_epoch_loss=0.986277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=1.07152277231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch [175]#011Speed: 1085.08 samples/sec#011loss=1.071523\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch[180] avg_epoch_loss=0.982921\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=0.864783060551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch [180]#011Speed: 736.32 samples/sec#011loss=0.864783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch[185] avg_epoch_loss=0.980249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=0.883529913425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch [185]#011Speed: 1082.40 samples/sec#011loss=0.883530\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch[190] avg_epoch_loss=0.982480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=1.06549026966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch [190]#011Speed: 789.57 samples/sec#011loss=1.065490\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch[195] avg_epoch_loss=0.983069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=1.00555105209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:21 INFO 140074512123712] Epoch[11] Batch [195]#011Speed: 1057.04 samples/sec#011loss=1.005551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch[200] avg_epoch_loss=0.985817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=1.09353762865\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch [200]#011Speed: 793.69 samples/sec#011loss=1.093538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch[205] avg_epoch_loss=0.987745\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=1.06524274349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch [205]#011Speed: 753.19 samples/sec#011loss=1.065243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch[210] avg_epoch_loss=0.986743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=0.945491290092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch [210]#011Speed: 1022.50 samples/sec#011loss=0.945491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch[215] avg_epoch_loss=0.984776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=0.901763701439\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch [215]#011Speed: 793.26 samples/sec#011loss=0.901764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch[220] avg_epoch_loss=0.982542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=0.886040687561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:22 INFO 140074512123712] Epoch[11] Batch [220]#011Speed: 1035.22 samples/sec#011loss=0.886041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch[225] avg_epoch_loss=0.988414\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=1.24793618917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch [225]#011Speed: 794.14 samples/sec#011loss=1.247936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch[230] avg_epoch_loss=0.989067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=1.01858304739\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch [230]#011Speed: 984.16 samples/sec#011loss=1.018583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch[235] avg_epoch_loss=0.992425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=1.14754785299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch [235]#011Speed: 758.94 samples/sec#011loss=1.147548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch[240] avg_epoch_loss=0.992907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=1.01569907665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch [240]#011Speed: 981.83 samples/sec#011loss=1.015699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch[245] avg_epoch_loss=0.997585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=1.22302687168\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch [245]#011Speed: 785.27 samples/sec#011loss=1.223027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch[250] avg_epoch_loss=0.996515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=0.943911039829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:23 INFO 140074512123712] Epoch[11] Batch [250]#011Speed: 1061.28 samples/sec#011loss=0.943911\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch[255] avg_epoch_loss=0.994837\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=0.910586750507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch [255]#011Speed: 776.22 samples/sec#011loss=0.910587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch[260] avg_epoch_loss=0.996220\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=1.06704385281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch [260]#011Speed: 1087.07 samples/sec#011loss=1.067044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch[265] avg_epoch_loss=0.995719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=0.969567251205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch [265]#011Speed: 780.55 samples/sec#011loss=0.969567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch[270] avg_epoch_loss=0.996096\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=270 train loss <loss>=1.01613235474\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch [270]#011Speed: 1069.87 samples/sec#011loss=1.016132\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch[275] avg_epoch_loss=0.993325\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=275 train loss <loss>=0.843133223057\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:24 INFO 140074512123712] Epoch[11] Batch [275]#011Speed: 795.17 samples/sec#011loss=0.843133\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch[280] avg_epoch_loss=0.991978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=280 train loss <loss>=0.917629349232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch [280]#011Speed: 1078.49 samples/sec#011loss=0.917629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch[285] avg_epoch_loss=0.991957\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=285 train loss <loss>=0.990757727623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch [285]#011Speed: 811.06 samples/sec#011loss=0.990758\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch[290] avg_epoch_loss=0.991501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=290 train loss <loss>=0.965446841717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch [290]#011Speed: 1084.53 samples/sec#011loss=0.965447\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch[295] avg_epoch_loss=0.990657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=295 train loss <loss>=0.941515278816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch [295]#011Speed: 765.12 samples/sec#011loss=0.941515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch[300] avg_epoch_loss=0.991324\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=300 train loss <loss>=1.03083889484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch [300]#011Speed: 1074.50 samples/sec#011loss=1.030839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch[305] avg_epoch_loss=1.000704\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=305 train loss <loss>=1.56538105011\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:25 INFO 140074512123712] Epoch[11] Batch [305]#011Speed: 780.77 samples/sec#011loss=1.565381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch[310] avg_epoch_loss=1.001922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=310 train loss <loss>=1.07641667128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch [310]#011Speed: 1066.08 samples/sec#011loss=1.076417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch[315] avg_epoch_loss=1.007661\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=315 train loss <loss>=1.36462919712\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch [315]#011Speed: 797.85 samples/sec#011loss=1.364629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch[320] avg_epoch_loss=1.008340\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=320 train loss <loss>=1.05126538277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch [320]#011Speed: 1075.91 samples/sec#011loss=1.051265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch[325] avg_epoch_loss=1.008617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=325 train loss <loss>=1.02641934156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch [325]#011Speed: 771.76 samples/sec#011loss=1.026419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch[330] avg_epoch_loss=1.008227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=330 train loss <loss>=0.982763636112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch [330]#011Speed: 1075.72 samples/sec#011loss=0.982764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch[335] avg_epoch_loss=1.008430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=335 train loss <loss>=1.02191598415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:26 INFO 140074512123712] Epoch[11] Batch [335]#011Speed: 789.47 samples/sec#011loss=1.021916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch[340] avg_epoch_loss=1.010175\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=340 train loss <loss>=1.12740322351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch [340]#011Speed: 1048.44 samples/sec#011loss=1.127403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch[345] avg_epoch_loss=1.008042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=345 train loss <loss>=0.862588143349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch [345]#011Speed: 769.75 samples/sec#011loss=0.862588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch[350] avg_epoch_loss=1.007883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=350 train loss <loss>=0.996884453297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch [350]#011Speed: 1037.88 samples/sec#011loss=0.996884\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch[355] avg_epoch_loss=1.006908\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=355 train loss <loss>=0.938432192802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch [355]#011Speed: 776.21 samples/sec#011loss=0.938432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch[360] avg_epoch_loss=1.005873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=360 train loss <loss>=0.932171809673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:27 INFO 140074512123712] Epoch[11] Batch [360]#011Speed: 1067.26 samples/sec#011loss=0.932172\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch[365] avg_epoch_loss=1.005375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=365 train loss <loss>=0.969472444057\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch [365]#011Speed: 759.55 samples/sec#011loss=0.969472\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch[370] avg_epoch_loss=1.005686\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=370 train loss <loss>=1.02842291594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch [370]#011Speed: 1084.22 samples/sec#011loss=1.028423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch[375] avg_epoch_loss=1.004089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=375 train loss <loss>=0.885590422153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch [375]#011Speed: 758.85 samples/sec#011loss=0.885590\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch[380] avg_epoch_loss=1.005572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=380 train loss <loss>=1.11713960171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch [380]#011Speed: 973.68 samples/sec#011loss=1.117140\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch[385] avg_epoch_loss=1.004062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=385 train loss <loss>=0.888956069946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch [385]#011Speed: 799.80 samples/sec#011loss=0.888956\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch[390] avg_epoch_loss=1.002161\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=390 train loss <loss>=0.855420541763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:28 INFO 140074512123712] Epoch[11] Batch [390]#011Speed: 1057.96 samples/sec#011loss=0.855421\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch[395] avg_epoch_loss=1.002350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=395 train loss <loss>=1.01715772152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch [395]#011Speed: 742.72 samples/sec#011loss=1.017158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch[400] avg_epoch_loss=1.000334\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=400 train loss <loss>=0.840644061565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch [400]#011Speed: 1084.44 samples/sec#011loss=0.840644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch[405] avg_epoch_loss=0.998501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=405 train loss <loss>=0.851450538635\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch [405]#011Speed: 788.62 samples/sec#011loss=0.851451\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch[410] avg_epoch_loss=0.997824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=410 train loss <loss>=0.942853486538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch [410]#011Speed: 767.18 samples/sec#011loss=0.942853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch[415] avg_epoch_loss=1.016869\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=415 train loss <loss>=2.58243342638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:29 INFO 140074512123712] Epoch[11] Batch [415]#011Speed: 1054.05 samples/sec#011loss=2.582433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch[420] avg_epoch_loss=1.018495\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=420 train loss <loss>=1.15373191833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch [420]#011Speed: 779.03 samples/sec#011loss=1.153732\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch[425] avg_epoch_loss=1.020195\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=425 train loss <loss>=1.16336984634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch [425]#011Speed: 1063.91 samples/sec#011loss=1.163370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch[430] avg_epoch_loss=1.022104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=430 train loss <loss>=1.18475751877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch [430]#011Speed: 781.94 samples/sec#011loss=1.184758\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch[435] avg_epoch_loss=1.024098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=435 train loss <loss>=1.19597268105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch [435]#011Speed: 1022.29 samples/sec#011loss=1.195973\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch[440] avg_epoch_loss=1.027541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=440 train loss <loss>=1.32776401043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch [440]#011Speed: 803.09 samples/sec#011loss=1.327764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch[445] avg_epoch_loss=1.027821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=445 train loss <loss>=1.05251386166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:30 INFO 140074512123712] Epoch[11] Batch [445]#011Speed: 1054.70 samples/sec#011loss=1.052514\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch[450] avg_epoch_loss=1.027261\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=450 train loss <loss>=0.97727919817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch [450]#011Speed: 785.93 samples/sec#011loss=0.977279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch[455] avg_epoch_loss=1.026951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=455 train loss <loss>=0.998984348774\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch [455]#011Speed: 775.60 samples/sec#011loss=0.998984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch[460] avg_epoch_loss=1.026900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=460 train loss <loss>=1.02224436998\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch [460]#011Speed: 685.11 samples/sec#011loss=1.022244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch[465] avg_epoch_loss=1.026969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=465 train loss <loss>=1.03337703943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch [465]#011Speed: 1066.10 samples/sec#011loss=1.033377\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch[470] avg_epoch_loss=1.025203\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=470 train loss <loss>=0.860567677021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:31 INFO 140074512123712] Epoch[11] Batch [470]#011Speed: 1080.37 samples/sec#011loss=0.860568\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch[475] avg_epoch_loss=1.023804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=475 train loss <loss>=0.892016422749\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch [475]#011Speed: 794.03 samples/sec#011loss=0.892016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch[480] avg_epoch_loss=1.022403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=480 train loss <loss>=0.889032411575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch [480]#011Speed: 1080.12 samples/sec#011loss=0.889032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch[485] avg_epoch_loss=1.025926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=485 train loss <loss>=1.36487033367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch [485]#011Speed: 777.89 samples/sec#011loss=1.364870\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch[490] avg_epoch_loss=1.026174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=490 train loss <loss>=1.05029723644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch [490]#011Speed: 1038.15 samples/sec#011loss=1.050297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch[495] avg_epoch_loss=1.024832\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=495 train loss <loss>=0.892996513844\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch [495]#011Speed: 791.73 samples/sec#011loss=0.892997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch[500] avg_epoch_loss=1.023093\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=500 train loss <loss>=0.850563430786\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:32 INFO 140074512123712] Epoch[11] Batch [500]#011Speed: 1067.06 samples/sec#011loss=0.850563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch[505] avg_epoch_loss=1.021855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=505 train loss <loss>=0.897888875008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch [505]#011Speed: 781.12 samples/sec#011loss=0.897889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch[510] avg_epoch_loss=1.019497\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=510 train loss <loss>=0.780871033669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch [510]#011Speed: 1068.13 samples/sec#011loss=0.780871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch[515] avg_epoch_loss=1.017559\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=515 train loss <loss>=0.819409346581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch [515]#011Speed: 780.67 samples/sec#011loss=0.819409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch[520] avg_epoch_loss=1.016829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=520 train loss <loss>=0.941575360298\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch [520]#011Speed: 1000.31 samples/sec#011loss=0.941575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch[525] avg_epoch_loss=1.019765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=525 train loss <loss>=1.32562963963\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch [525]#011Speed: 797.88 samples/sec#011loss=1.325630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch[530] avg_epoch_loss=1.020587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=530 train loss <loss>=1.10711085796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:33 INFO 140074512123712] Epoch[11] Batch [530]#011Speed: 1058.08 samples/sec#011loss=1.107111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch[535] avg_epoch_loss=1.020147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=535 train loss <loss>=0.973394906521\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch [535]#011Speed: 777.23 samples/sec#011loss=0.973395\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch[540] avg_epoch_loss=1.019354\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=540 train loss <loss>=0.934305596352\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch [540]#011Speed: 1073.59 samples/sec#011loss=0.934306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch[545] avg_epoch_loss=1.018374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=545 train loss <loss>=0.912404477596\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch [545]#011Speed: 778.90 samples/sec#011loss=0.912404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch[550] avg_epoch_loss=1.016763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=550 train loss <loss>=0.840827441216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch [550]#011Speed: 1067.24 samples/sec#011loss=0.840827\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch[555] avg_epoch_loss=1.015527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=555 train loss <loss>=0.879322898388\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:34 INFO 140074512123712] Epoch[11] Batch [555]#011Speed: 843.39 samples/sec#011loss=0.879323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[11] Batch[560] avg_epoch_loss=1.013971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, batch=560 train loss <loss>=0.840900945663\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[11] Batch [560]#011Speed: 1013.82 samples/sec#011loss=0.840901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] processed a total of 17958 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20256.598949432373, \"sum\": 20256.598949432373, \"min\": 20256.598949432373}}, \"EndTime\": 1589445215.08601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445194.829355}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=886.52167227 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=11, train loss <loss>=1.01342739128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_29639b6d-0386-4b02-8753-3d6a0ded3155-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.800910949707031, \"sum\": 9.800910949707031, \"min\": 9.800910949707031}}, \"EndTime\": 1589445215.096587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445215.086075}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch[0] avg_epoch_loss=0.838552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=0.838552236557\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch[5] avg_epoch_loss=1.038808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=1.03880790869\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch [5]#011Speed: 1076.19 samples/sec#011loss=1.038808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch[10] avg_epoch_loss=0.935764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=0.812111186981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch [10]#011Speed: 796.40 samples/sec#011loss=0.812111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch[15] avg_epoch_loss=0.903698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=0.833151698112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch [15]#011Speed: 1037.56 samples/sec#011loss=0.833152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch[20] avg_epoch_loss=0.891655\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=0.853119409084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:35 INFO 140074512123712] Epoch[12] Batch [20]#011Speed: 794.97 samples/sec#011loss=0.853119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch[25] avg_epoch_loss=0.899359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=0.931714034081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch [25]#011Speed: 1076.27 samples/sec#011loss=0.931714\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch[30] avg_epoch_loss=0.886464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=0.819413387775\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch [30]#011Speed: 782.53 samples/sec#011loss=0.819413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch[35] avg_epoch_loss=0.903910\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=1.01207112074\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch [35]#011Speed: 1075.78 samples/sec#011loss=1.012071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch[40] avg_epoch_loss=0.903082\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=0.897125029564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch [40]#011Speed: 776.81 samples/sec#011loss=0.897125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch[45] avg_epoch_loss=0.902150\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=0.89450289011\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch [45]#011Speed: 1074.35 samples/sec#011loss=0.894503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch[50] avg_epoch_loss=0.895782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=0.837201690674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:36 INFO 140074512123712] Epoch[12] Batch [50]#011Speed: 791.32 samples/sec#011loss=0.837202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch[55] avg_epoch_loss=0.888943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=0.819184529781\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch [55]#011Speed: 1069.53 samples/sec#011loss=0.819185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch[60] avg_epoch_loss=0.883635\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=0.824183499813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch [60]#011Speed: 789.76 samples/sec#011loss=0.824183\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch[65] avg_epoch_loss=0.888119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=0.942829406261\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch [65]#011Speed: 1053.82 samples/sec#011loss=0.942829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch[70] avg_epoch_loss=0.906907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=1.15490105152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch [70]#011Speed: 790.62 samples/sec#011loss=1.154901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch[75] avg_epoch_loss=0.916479\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=1.05240296125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:37 INFO 140074512123712] Epoch[12] Batch [75]#011Speed: 1076.73 samples/sec#011loss=1.052403\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch[80] avg_epoch_loss=0.931245\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=1.15569012165\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch [80]#011Speed: 766.45 samples/sec#011loss=1.155690\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch[85] avg_epoch_loss=0.933051\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=0.962307059765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch [85]#011Speed: 1085.36 samples/sec#011loss=0.962307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch[90] avg_epoch_loss=0.932126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=0.916223025322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch [90]#011Speed: 788.02 samples/sec#011loss=0.916223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch[95] avg_epoch_loss=0.929116\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=0.874331438541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch [95]#011Speed: 1020.09 samples/sec#011loss=0.874331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch[100] avg_epoch_loss=0.924815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=0.842219984531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch [100]#011Speed: 773.17 samples/sec#011loss=0.842220\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch[105] avg_epoch_loss=0.918539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=0.79177852869\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:38 INFO 140074512123712] Epoch[12] Batch [105]#011Speed: 1076.50 samples/sec#011loss=0.791779\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch[110] avg_epoch_loss=0.922881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=1.01492961645\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch [110]#011Speed: 792.97 samples/sec#011loss=1.014930\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch[115] avg_epoch_loss=0.917927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=0.80795456171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch [115]#011Speed: 1050.86 samples/sec#011loss=0.807955\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch[120] avg_epoch_loss=0.917904\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=0.917350101471\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch [120]#011Speed: 801.52 samples/sec#011loss=0.917350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch[125] avg_epoch_loss=0.918341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=0.928921723366\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch [125]#011Speed: 1075.84 samples/sec#011loss=0.928922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch[130] avg_epoch_loss=0.914463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=0.816750574112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch [130]#011Speed: 753.95 samples/sec#011loss=0.816751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch[135] avg_epoch_loss=0.912134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=0.851104938984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:39 INFO 140074512123712] Epoch[12] Batch [135]#011Speed: 1050.73 samples/sec#011loss=0.851105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch[140] avg_epoch_loss=0.908634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=0.813422417641\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch [140]#011Speed: 756.95 samples/sec#011loss=0.813422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch[145] avg_epoch_loss=0.903676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=0.763868701458\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch [145]#011Speed: 1078.41 samples/sec#011loss=0.763869\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch[150] avg_epoch_loss=1.038111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=4.96361249685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch [150]#011Speed: 1069.30 samples/sec#011loss=4.963612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch[155] avg_epoch_loss=1.044435\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=1.23541257381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch [155]#011Speed: 735.43 samples/sec#011loss=1.235413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch[160] avg_epoch_loss=1.055240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=1.39237418175\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:40 INFO 140074512123712] Epoch[12] Batch [160]#011Speed: 1072.06 samples/sec#011loss=1.392374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch[165] avg_epoch_loss=1.064728\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=1.37023255825\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch [165]#011Speed: 784.34 samples/sec#011loss=1.370233\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch[170] avg_epoch_loss=1.074007\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=1.38208024502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch [170]#011Speed: 1034.24 samples/sec#011loss=1.382080\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch[175] avg_epoch_loss=1.080547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=1.30420241356\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch [175]#011Speed: 797.25 samples/sec#011loss=1.304202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch[180] avg_epoch_loss=1.084457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=1.22208912373\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch [180]#011Speed: 1073.57 samples/sec#011loss=1.222089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch[185] avg_epoch_loss=1.088653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=1.24056229591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch [185]#011Speed: 764.90 samples/sec#011loss=1.240562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch[190] avg_epoch_loss=1.088753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=1.09247493744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:41 INFO 140074512123712] Epoch[12] Batch [190]#011Speed: 1052.37 samples/sec#011loss=1.092475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch[195] avg_epoch_loss=1.088330\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=1.07216846943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch [195]#011Speed: 766.50 samples/sec#011loss=1.072168\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch[200] avg_epoch_loss=1.085265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=0.965102493763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch [200]#011Speed: 1070.74 samples/sec#011loss=0.965102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch[205] avg_epoch_loss=1.085987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=1.11502753496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch [205]#011Speed: 778.22 samples/sec#011loss=1.115028\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch[210] avg_epoch_loss=1.084454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=1.02126427889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch [210]#011Speed: 1088.90 samples/sec#011loss=1.021264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch[215] avg_epoch_loss=1.096130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=1.58888025284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch [215]#011Speed: 766.17 samples/sec#011loss=1.588880\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch[220] avg_epoch_loss=1.095680\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=1.07622802258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:42 INFO 140074512123712] Epoch[12] Batch [220]#011Speed: 1067.00 samples/sec#011loss=1.076228\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch[225] avg_epoch_loss=1.094396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=1.0376539588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch [225]#011Speed: 798.22 samples/sec#011loss=1.037654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch[230] avg_epoch_loss=1.091887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=0.978474724293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch [230]#011Speed: 1096.75 samples/sec#011loss=0.978475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch[235] avg_epoch_loss=1.089141\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=0.962295615673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch [235]#011Speed: 764.35 samples/sec#011loss=0.962296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch[240] avg_epoch_loss=1.117620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=2.46180833578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch [240]#011Speed: 1033.49 samples/sec#011loss=2.461808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch[245] avg_epoch_loss=1.114463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=0.962305057049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:43 INFO 140074512123712] Epoch[12] Batch [245]#011Speed: 814.20 samples/sec#011loss=0.962305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch[250] avg_epoch_loss=1.113792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=1.08077181578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch [250]#011Speed: 1067.09 samples/sec#011loss=1.080772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch[255] avg_epoch_loss=1.111938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=1.01884895563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch [255]#011Speed: 795.22 samples/sec#011loss=1.018849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch[260] avg_epoch_loss=1.110056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=1.01370475292\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch [260]#011Speed: 1055.70 samples/sec#011loss=1.013705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch[265] avg_epoch_loss=1.106943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=0.944446456432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch [265]#011Speed: 809.08 samples/sec#011loss=0.944446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch[270] avg_epoch_loss=1.108030\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=270 train loss <loss>=1.16585320234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch [270]#011Speed: 1003.76 samples/sec#011loss=1.165853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch[275] avg_epoch_loss=1.103874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=275 train loss <loss>=0.878640115261\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:44 INFO 140074512123712] Epoch[12] Batch [275]#011Speed: 795.61 samples/sec#011loss=0.878640\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch[280] avg_epoch_loss=1.100054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=280 train loss <loss>=0.889211189747\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch [280]#011Speed: 1063.38 samples/sec#011loss=0.889211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch[285] avg_epoch_loss=1.094959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=285 train loss <loss>=0.808605825901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch [285]#011Speed: 787.71 samples/sec#011loss=0.808606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch[290] avg_epoch_loss=1.091857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=290 train loss <loss>=0.914433169365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch [290]#011Speed: 1075.28 samples/sec#011loss=0.914433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch[295] avg_epoch_loss=1.089167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=295 train loss <loss>=0.932569861412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch [295]#011Speed: 799.09 samples/sec#011loss=0.932570\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch[300] avg_epoch_loss=1.090990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=300 train loss <loss>=1.19894372225\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch [300]#011Speed: 1053.07 samples/sec#011loss=1.198944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch[305] avg_epoch_loss=1.090916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=305 train loss <loss>=1.08642373085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:45 INFO 140074512123712] Epoch[12] Batch [305]#011Speed: 780.51 samples/sec#011loss=1.086424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch[310] avg_epoch_loss=1.091239\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=310 train loss <loss>=1.11101714373\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch [310]#011Speed: 1078.13 samples/sec#011loss=1.111017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch[315] avg_epoch_loss=1.088415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=315 train loss <loss>=0.912754797935\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch [315]#011Speed: 788.61 samples/sec#011loss=0.912755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch[320] avg_epoch_loss=1.088005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=320 train loss <loss>=1.06208857298\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch [320]#011Speed: 1069.20 samples/sec#011loss=1.062089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch[325] avg_epoch_loss=1.085814\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=325 train loss <loss>=0.945168018341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch [325]#011Speed: 794.86 samples/sec#011loss=0.945168\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch[330] avg_epoch_loss=1.082596\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=330 train loss <loss>=0.872801721096\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:46 INFO 140074512123712] Epoch[12] Batch [330]#011Speed: 1026.76 samples/sec#011loss=0.872802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch[335] avg_epoch_loss=1.080643\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=335 train loss <loss>=0.951338994503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch [335]#011Speed: 799.74 samples/sec#011loss=0.951339\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch[340] avg_epoch_loss=1.077267\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=340 train loss <loss>=0.850435853004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch [340]#011Speed: 1082.14 samples/sec#011loss=0.850436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch[345] avg_epoch_loss=1.078350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=345 train loss <loss>=1.15216016769\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch [345]#011Speed: 781.16 samples/sec#011loss=1.152160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch[350] avg_epoch_loss=1.075762\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=350 train loss <loss>=0.896677839756\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch [350]#011Speed: 1080.45 samples/sec#011loss=0.896678\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch[355] avg_epoch_loss=1.071843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=355 train loss <loss>=0.796721255779\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch [355]#011Speed: 787.90 samples/sec#011loss=0.796721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch[360] avg_epoch_loss=1.071900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=360 train loss <loss>=1.07597852945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:47 INFO 140074512123712] Epoch[12] Batch [360]#011Speed: 1093.66 samples/sec#011loss=1.075979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch[365] avg_epoch_loss=1.069286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=365 train loss <loss>=0.880561840534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch [365]#011Speed: 785.03 samples/sec#011loss=0.880562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch[370] avg_epoch_loss=1.065085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=370 train loss <loss>=0.757559168339\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch [370]#011Speed: 1097.24 samples/sec#011loss=0.757559\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch[375] avg_epoch_loss=1.062670\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=375 train loss <loss>=0.883480596542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch [375]#011Speed: 765.73 samples/sec#011loss=0.883481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch[380] avg_epoch_loss=1.062620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=380 train loss <loss>=1.05883173943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch [380]#011Speed: 1074.84 samples/sec#011loss=1.058832\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch[385] avg_epoch_loss=1.064724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=385 train loss <loss>=1.225091362\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch [385]#011Speed: 754.41 samples/sec#011loss=1.225091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch[390] avg_epoch_loss=1.064176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=390 train loss <loss>=1.0218801856\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:48 INFO 140074512123712] Epoch[12] Batch [390]#011Speed: 1070.33 samples/sec#011loss=1.021880\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch[395] avg_epoch_loss=1.061795\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=395 train loss <loss>=0.875588834286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch [395]#011Speed: 809.70 samples/sec#011loss=0.875589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch[400] avg_epoch_loss=1.060522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=400 train loss <loss>=0.959729528427\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch [400]#011Speed: 1031.10 samples/sec#011loss=0.959730\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch[405] avg_epoch_loss=1.058265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=405 train loss <loss>=0.877196764946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch [405]#011Speed: 797.56 samples/sec#011loss=0.877197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch[410] avg_epoch_loss=1.055472\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=410 train loss <loss>=0.828726780415\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch [410]#011Speed: 1064.52 samples/sec#011loss=0.828727\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch[415] avg_epoch_loss=1.053916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=415 train loss <loss>=0.925958991051\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:49 INFO 140074512123712] Epoch[12] Batch [415]#011Speed: 741.97 samples/sec#011loss=0.925959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch[420] avg_epoch_loss=1.052605\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=420 train loss <loss>=0.943547832966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch [420]#011Speed: 1047.53 samples/sec#011loss=0.943548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch[425] avg_epoch_loss=1.051676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=425 train loss <loss>=0.973471593857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch [425]#011Speed: 790.90 samples/sec#011loss=0.973472\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch[430] avg_epoch_loss=1.051331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=430 train loss <loss>=1.02196455002\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch [430]#011Speed: 1066.83 samples/sec#011loss=1.021965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch[435] avg_epoch_loss=1.050429\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=435 train loss <loss>=0.972634482384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch [435]#011Speed: 789.29 samples/sec#011loss=0.972634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch[440] avg_epoch_loss=1.048326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=440 train loss <loss>=0.86494988203\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch [440]#011Speed: 1051.32 samples/sec#011loss=0.864950\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch[445] avg_epoch_loss=1.046549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=445 train loss <loss>=0.889784514904\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:50 INFO 140074512123712] Epoch[12] Batch [445]#011Speed: 799.52 samples/sec#011loss=0.889785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch[450] avg_epoch_loss=1.044411\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=450 train loss <loss>=0.853745818138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch [450]#011Speed: 1074.50 samples/sec#011loss=0.853746\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch[455] avg_epoch_loss=1.042843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=455 train loss <loss>=0.901413798332\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch [455]#011Speed: 800.27 samples/sec#011loss=0.901414\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch[460] avg_epoch_loss=1.040811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=460 train loss <loss>=0.855480730534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch [460]#011Speed: 1050.53 samples/sec#011loss=0.855481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch[465] avg_epoch_loss=1.039424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=465 train loss <loss>=0.911526584625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch [465]#011Speed: 794.92 samples/sec#011loss=0.911527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch[470] avg_epoch_loss=1.042874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=470 train loss <loss>=1.36440457106\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:51 INFO 140074512123712] Epoch[12] Batch [470]#011Speed: 1045.96 samples/sec#011loss=1.364405\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch[475] avg_epoch_loss=1.040898\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=475 train loss <loss>=0.854816639423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch [475]#011Speed: 805.64 samples/sec#011loss=0.854817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch[480] avg_epoch_loss=1.038236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=480 train loss <loss>=0.784751105309\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch [480]#011Speed: 1067.48 samples/sec#011loss=0.784751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch[485] avg_epoch_loss=1.038417\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=485 train loss <loss>=1.05585446358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch [485]#011Speed: 801.78 samples/sec#011loss=1.055854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch[490] avg_epoch_loss=1.044197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=490 train loss <loss>=1.60605329275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch [490]#011Speed: 1064.06 samples/sec#011loss=1.606053\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch[495] avg_epoch_loss=1.043181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=495 train loss <loss>=0.943377315998\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch [495]#011Speed: 797.74 samples/sec#011loss=0.943377\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch[500] avg_epoch_loss=1.041759\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=500 train loss <loss>=0.900692689419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:52 INFO 140074512123712] Epoch[12] Batch [500]#011Speed: 1019.43 samples/sec#011loss=0.900693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch[505] avg_epoch_loss=1.040157\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=505 train loss <loss>=0.879611837864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch [505]#011Speed: 778.10 samples/sec#011loss=0.879612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch[510] avg_epoch_loss=1.038221\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=510 train loss <loss>=0.842359745502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch [510]#011Speed: 1073.87 samples/sec#011loss=0.842360\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch[515] avg_epoch_loss=1.036101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=515 train loss <loss>=0.819423103333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch [515]#011Speed: 1085.06 samples/sec#011loss=0.819423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch[520] avg_epoch_loss=1.033857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=520 train loss <loss>=0.802287602425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch [520]#011Speed: 779.99 samples/sec#011loss=0.802288\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch[525] avg_epoch_loss=1.031732\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=525 train loss <loss>=0.810285925865\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch [525]#011Speed: 1066.35 samples/sec#011loss=0.810286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch[530] avg_epoch_loss=1.030688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=530 train loss <loss>=0.920835876465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:53 INFO 140074512123712] Epoch[12] Batch [530]#011Speed: 757.93 samples/sec#011loss=0.920836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch[535] avg_epoch_loss=1.030160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=535 train loss <loss>=0.97408374548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch [535]#011Speed: 1062.28 samples/sec#011loss=0.974084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch[540] avg_epoch_loss=1.028740\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=540 train loss <loss>=0.87648639679\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch [540]#011Speed: 805.51 samples/sec#011loss=0.876486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch[545] avg_epoch_loss=1.026854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=545 train loss <loss>=0.82284090519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch [545]#011Speed: 1051.72 samples/sec#011loss=0.822841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch[550] avg_epoch_loss=1.025227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=550 train loss <loss>=0.847578549385\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch [550]#011Speed: 797.32 samples/sec#011loss=0.847579\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch[555] avg_epoch_loss=1.025566\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=555 train loss <loss>=1.06291158199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch [555]#011Speed: 759.27 samples/sec#011loss=1.062912\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch[560] avg_epoch_loss=1.024894\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=560 train loss <loss>=0.950160443783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:54 INFO 140074512123712] Epoch[12] Batch [560]#011Speed: 1083.40 samples/sec#011loss=0.950160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[12] Batch[565] avg_epoch_loss=1.024500\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, batch=565 train loss <loss>=0.980315423012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[12] Batch [565]#011Speed: 1067.68 samples/sec#011loss=0.980315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] processed a total of 18104 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20044.713973999023, \"sum\": 20044.713973999023, \"min\": 20044.713973999023}}, \"EndTime\": 1589445235.141452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445215.09668}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=903.176248023 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=12, train loss <loss>=1.02450032011\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch[0] avg_epoch_loss=0.887362\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=0.88736218214\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch[5] avg_epoch_loss=0.831581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=0.831581175327\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch [5]#011Speed: 1089.99 samples/sec#011loss=0.831581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch[10] avg_epoch_loss=0.962674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=1.11998647451\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch [10]#011Speed: 789.09 samples/sec#011loss=1.119986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch[15] avg_epoch_loss=0.917143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=0.816972148418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch [15]#011Speed: 1072.78 samples/sec#011loss=0.816972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch[20] avg_epoch_loss=0.899873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=0.844611024857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:55 INFO 140074512123712] Epoch[13] Batch [20]#011Speed: 754.57 samples/sec#011loss=0.844611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch[25] avg_epoch_loss=0.951601\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=1.16886007786\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch [25]#011Speed: 1075.27 samples/sec#011loss=1.168860\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch[30] avg_epoch_loss=0.933909\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=0.841905999184\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch [30]#011Speed: 800.22 samples/sec#011loss=0.841906\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch[35] avg_epoch_loss=0.932812\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=0.926016163826\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch [35]#011Speed: 1073.42 samples/sec#011loss=0.926016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch[40] avg_epoch_loss=0.927896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=0.892501878738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch [40]#011Speed: 799.31 samples/sec#011loss=0.892502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch[45] avg_epoch_loss=0.922625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=0.879402637482\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch [45]#011Speed: 1079.00 samples/sec#011loss=0.879403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch[50] avg_epoch_loss=0.909734\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=0.791131269932\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:56 INFO 140074512123712] Epoch[13] Batch [50]#011Speed: 764.50 samples/sec#011loss=0.791131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch[55] avg_epoch_loss=0.903224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=0.836818993092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch [55]#011Speed: 1066.34 samples/sec#011loss=0.836819\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch[60] avg_epoch_loss=0.895295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=0.806495368481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch [60]#011Speed: 779.62 samples/sec#011loss=0.806495\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch[65] avg_epoch_loss=0.930499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=1.35998679399\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch [65]#011Speed: 1066.65 samples/sec#011loss=1.359987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch[70] avg_epoch_loss=0.923166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=0.826373493671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch [70]#011Speed: 796.15 samples/sec#011loss=0.826373\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch[75] avg_epoch_loss=0.924474\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=0.943038582802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:57 INFO 140074512123712] Epoch[13] Batch [75]#011Speed: 1047.15 samples/sec#011loss=0.943039\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch[80] avg_epoch_loss=0.918118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=0.821519351006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch [80]#011Speed: 772.56 samples/sec#011loss=0.821519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch[85] avg_epoch_loss=0.932785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=1.17037712336\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch [85]#011Speed: 1031.78 samples/sec#011loss=1.170377\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch[90] avg_epoch_loss=0.931265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=0.90513021946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch [90]#011Speed: 1087.14 samples/sec#011loss=0.905130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch[95] avg_epoch_loss=0.926176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=0.833560729027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch [95]#011Speed: 774.70 samples/sec#011loss=0.833561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch[100] avg_epoch_loss=0.918805\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=0.777276575565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch [100]#011Speed: 1063.52 samples/sec#011loss=0.777277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch[105] avg_epoch_loss=0.965065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=1.8995133996\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:58 INFO 140074512123712] Epoch[13] Batch [105]#011Speed: 773.41 samples/sec#011loss=1.899513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch[110] avg_epoch_loss=0.965483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=0.974356150627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch [110]#011Speed: 1074.60 samples/sec#011loss=0.974356\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch[115] avg_epoch_loss=0.965907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=0.975314640999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch [115]#011Speed: 788.13 samples/sec#011loss=0.975315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch[120] avg_epoch_loss=0.969986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=1.06461125612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch [120]#011Speed: 1101.27 samples/sec#011loss=1.064611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch[125] avg_epoch_loss=0.968386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=0.929665195942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch [125]#011Speed: 765.83 samples/sec#011loss=0.929665\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch[130] avg_epoch_loss=0.965736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=0.898959267139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch [130]#011Speed: 1093.56 samples/sec#011loss=0.898959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch[135] avg_epoch_loss=0.967983\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=1.02686408758\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:33:59 INFO 140074512123712] Epoch[13] Batch [135]#011Speed: 763.64 samples/sec#011loss=1.026864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch[140] avg_epoch_loss=0.974698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=1.15734447241\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch [140]#011Speed: 1041.44 samples/sec#011loss=1.157344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch[145] avg_epoch_loss=0.976189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=1.01822690964\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch [145]#011Speed: 787.57 samples/sec#011loss=1.018227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch[150] avg_epoch_loss=1.016532\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=2.1945405364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch [150]#011Speed: 1083.14 samples/sec#011loss=2.194541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch[155] avg_epoch_loss=1.015864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=0.995694625378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch [155]#011Speed: 787.03 samples/sec#011loss=0.995695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch[160] avg_epoch_loss=1.013849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=0.950989425182\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:00 INFO 140074512123712] Epoch[13] Batch [160]#011Speed: 1083.16 samples/sec#011loss=0.950989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch[165] avg_epoch_loss=1.010275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=0.895176374912\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch [165]#011Speed: 735.65 samples/sec#011loss=0.895176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch[170] avg_epoch_loss=1.007386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=0.911482751369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch [170]#011Speed: 1060.24 samples/sec#011loss=0.911483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch[175] avg_epoch_loss=1.002067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=0.820172250271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch [175]#011Speed: 604.21 samples/sec#011loss=0.820172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch[180] avg_epoch_loss=1.001078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=0.966242694855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch [180]#011Speed: 728.82 samples/sec#011loss=0.966243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch[185] avg_epoch_loss=0.994799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=0.767491400242\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:01 INFO 140074512123712] Epoch[13] Batch [185]#011Speed: 759.06 samples/sec#011loss=0.767491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch[190] avg_epoch_loss=0.992198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=0.895469248295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch [190]#011Speed: 1077.77 samples/sec#011loss=0.895469\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch[195] avg_epoch_loss=0.989670\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=0.893090391159\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch [195]#011Speed: 787.86 samples/sec#011loss=0.893090\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch[200] avg_epoch_loss=0.990205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=1.01117812395\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch [200]#011Speed: 1065.64 samples/sec#011loss=1.011178\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch[205] avg_epoch_loss=0.988085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=0.902867412567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch [205]#011Speed: 781.88 samples/sec#011loss=0.902867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch[210] avg_epoch_loss=0.987639\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=0.969269239902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch [210]#011Speed: 1078.62 samples/sec#011loss=0.969269\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch[215] avg_epoch_loss=0.987266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=0.971493065357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:02 INFO 140074512123712] Epoch[13] Batch [215]#011Speed: 766.83 samples/sec#011loss=0.971493\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch[220] avg_epoch_loss=0.985925\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=0.928018438816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch [220]#011Speed: 1089.37 samples/sec#011loss=0.928018\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch[225] avg_epoch_loss=0.982042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=0.81042290926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch [225]#011Speed: 794.73 samples/sec#011loss=0.810423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch[230] avg_epoch_loss=1.011382\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=2.33753601313\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch [230]#011Speed: 1080.61 samples/sec#011loss=2.337536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch[235] avg_epoch_loss=1.009806\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=0.936968314648\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch [235]#011Speed: 729.94 samples/sec#011loss=0.936968\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch[240] avg_epoch_loss=1.010804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=1.05794684887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:03 INFO 140074512123712] Epoch[13] Batch [240]#011Speed: 1048.05 samples/sec#011loss=1.057947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch[245] avg_epoch_loss=1.010693\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=1.00530502796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch [245]#011Speed: 754.48 samples/sec#011loss=1.005305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch[250] avg_epoch_loss=1.011587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=1.05561583042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch [250]#011Speed: 1068.91 samples/sec#011loss=1.055616\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch[255] avg_epoch_loss=1.011338\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=0.998796582222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch [255]#011Speed: 792.44 samples/sec#011loss=0.998797\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch[260] avg_epoch_loss=1.011061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=0.996874022484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch [260]#011Speed: 1055.65 samples/sec#011loss=0.996874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch[265] avg_epoch_loss=1.008881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=0.895112621784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch [265]#011Speed: 791.17 samples/sec#011loss=0.895113\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch[270] avg_epoch_loss=1.007166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=270 train loss <loss>=0.91590514183\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:04 INFO 140074512123712] Epoch[13] Batch [270]#011Speed: 1002.68 samples/sec#011loss=0.915905\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch[275] avg_epoch_loss=1.003988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=275 train loss <loss>=0.831754791737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch [275]#011Speed: 795.24 samples/sec#011loss=0.831755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch[280] avg_epoch_loss=1.021842\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=280 train loss <loss>=2.00738813877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch [280]#011Speed: 1083.72 samples/sec#011loss=2.007388\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch[285] avg_epoch_loss=1.018509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=285 train loss <loss>=0.831194245815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch [285]#011Speed: 806.74 samples/sec#011loss=0.831194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch[290] avg_epoch_loss=1.016142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=290 train loss <loss>=0.880770170689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch [290]#011Speed: 1053.44 samples/sec#011loss=0.880770\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch[295] avg_epoch_loss=1.014131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=295 train loss <loss>=0.897080218792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch [295]#011Speed: 787.10 samples/sec#011loss=0.897080\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch[300] avg_epoch_loss=1.012509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=300 train loss <loss>=0.91646270752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:05 INFO 140074512123712] Epoch[13] Batch [300]#011Speed: 1026.46 samples/sec#011loss=0.916463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch[305] avg_epoch_loss=1.010965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=305 train loss <loss>=0.918038249016\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch [305]#011Speed: 760.90 samples/sec#011loss=0.918038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch[310] avg_epoch_loss=1.009262\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=310 train loss <loss>=0.905004262924\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch [310]#011Speed: 1087.24 samples/sec#011loss=0.905004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch[315] avg_epoch_loss=1.013850\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=315 train loss <loss>=1.29927085638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch [315]#011Speed: 786.83 samples/sec#011loss=1.299271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch[320] avg_epoch_loss=1.024629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=320 train loss <loss>=1.705852139\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch [320]#011Speed: 1078.11 samples/sec#011loss=1.705852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch[325] avg_epoch_loss=1.022396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=325 train loss <loss>=0.879026508331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:06 INFO 140074512123712] Epoch[13] Batch [325]#011Speed: 788.19 samples/sec#011loss=0.879027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch[330] avg_epoch_loss=1.020978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=330 train loss <loss>=0.928531146049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch [330]#011Speed: 1025.00 samples/sec#011loss=0.928531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch[335] avg_epoch_loss=1.019282\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=335 train loss <loss>=0.906978094578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch [335]#011Speed: 795.26 samples/sec#011loss=0.906978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch[340] avg_epoch_loss=1.016322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=340 train loss <loss>=0.817451941967\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch [340]#011Speed: 1068.67 samples/sec#011loss=0.817452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch[345] avg_epoch_loss=1.013410\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=345 train loss <loss>=0.814775109291\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch [345]#011Speed: 801.75 samples/sec#011loss=0.814775\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch[350] avg_epoch_loss=1.010172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=350 train loss <loss>=0.786124265194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch [350]#011Speed: 1095.48 samples/sec#011loss=0.786124\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch[355] avg_epoch_loss=1.008079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=355 train loss <loss>=0.861178743839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:07 INFO 140074512123712] Epoch[13] Batch [355]#011Speed: 751.36 samples/sec#011loss=0.861179\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch[360] avg_epoch_loss=1.006815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=360 train loss <loss>=0.916790437698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch [360]#011Speed: 1061.86 samples/sec#011loss=0.916790\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch[365] avg_epoch_loss=1.006787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=365 train loss <loss>=1.00476149321\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch [365]#011Speed: 786.08 samples/sec#011loss=1.004761\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch[370] avg_epoch_loss=1.004235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=370 train loss <loss>=0.817458844185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch [370]#011Speed: 1068.03 samples/sec#011loss=0.817459\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch[375] avg_epoch_loss=1.002803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=375 train loss <loss>=0.896485650539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch [375]#011Speed: 790.54 samples/sec#011loss=0.896486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch[380] avg_epoch_loss=1.000290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=380 train loss <loss>=0.811358845234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:08 INFO 140074512123712] Epoch[13] Batch [380]#011Speed: 1058.82 samples/sec#011loss=0.811359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch[385] avg_epoch_loss=0.998941\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=385 train loss <loss>=0.896130800247\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch [385]#011Speed: 758.15 samples/sec#011loss=0.896131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch[390] avg_epoch_loss=0.998880\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=390 train loss <loss>=0.994201743603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch [390]#011Speed: 1086.08 samples/sec#011loss=0.994202\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch[395] avg_epoch_loss=1.003549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=395 train loss <loss>=1.36860303879\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch [395]#011Speed: 793.41 samples/sec#011loss=1.368603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch[400] avg_epoch_loss=1.001864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=400 train loss <loss>=0.868458271027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch [400]#011Speed: 1070.97 samples/sec#011loss=0.868458\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch[405] avg_epoch_loss=1.000110\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=405 train loss <loss>=0.859423029423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch [405]#011Speed: 799.58 samples/sec#011loss=0.859423\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch[410] avg_epoch_loss=0.998743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=410 train loss <loss>=0.887722539902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:09 INFO 140074512123712] Epoch[13] Batch [410]#011Speed: 1049.06 samples/sec#011loss=0.887723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch[415] avg_epoch_loss=0.996893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=415 train loss <loss>=0.84486759901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch [415]#011Speed: 744.47 samples/sec#011loss=0.844868\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch[420] avg_epoch_loss=1.005672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=420 train loss <loss>=1.73607981205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch [420]#011Speed: 1059.17 samples/sec#011loss=1.736080\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch[425] avg_epoch_loss=1.004418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=425 train loss <loss>=0.898816275597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch [425]#011Speed: 807.86 samples/sec#011loss=0.898816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch[430] avg_epoch_loss=1.003450\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=430 train loss <loss>=0.920977759361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch [430]#011Speed: 1072.18 samples/sec#011loss=0.920978\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch[435] avg_epoch_loss=1.002969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=435 train loss <loss>=0.961476314068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch [435]#011Speed: 776.62 samples/sec#011loss=0.961476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch[440] avg_epoch_loss=1.002457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=440 train loss <loss>=0.957818675041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:10 INFO 140074512123712] Epoch[13] Batch [440]#011Speed: 1075.57 samples/sec#011loss=0.957819\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch[445] avg_epoch_loss=1.002173\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=445 train loss <loss>=0.977173435688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch [445]#011Speed: 765.70 samples/sec#011loss=0.977173\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch[450] avg_epoch_loss=1.001908\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=450 train loss <loss>=0.978229033947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch [450]#011Speed: 1028.17 samples/sec#011loss=0.978229\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch[455] avg_epoch_loss=1.001274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=455 train loss <loss>=0.944077420235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch [455]#011Speed: 790.85 samples/sec#011loss=0.944077\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch[460] avg_epoch_loss=1.000465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=460 train loss <loss>=0.926721453667\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch [460]#011Speed: 1100.41 samples/sec#011loss=0.926721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch[465] avg_epoch_loss=0.998869\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=465 train loss <loss>=0.851728916168\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:11 INFO 140074512123712] Epoch[13] Batch [465]#011Speed: 795.52 samples/sec#011loss=0.851729\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch[470] avg_epoch_loss=0.998365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=470 train loss <loss>=0.95136423111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch [470]#011Speed: 995.33 samples/sec#011loss=0.951364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch[475] avg_epoch_loss=0.995959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=475 train loss <loss>=0.769318306446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch [475]#011Speed: 807.66 samples/sec#011loss=0.769318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch[480] avg_epoch_loss=0.998985\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=480 train loss <loss>=1.28705471754\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch [480]#011Speed: 1056.04 samples/sec#011loss=1.287055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch[485] avg_epoch_loss=1.001580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=485 train loss <loss>=1.25125366449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch [485]#011Speed: 802.33 samples/sec#011loss=1.251254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch[490] avg_epoch_loss=0.999955\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=490 train loss <loss>=0.841948795319\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch [490]#011Speed: 1063.55 samples/sec#011loss=0.841949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch[495] avg_epoch_loss=0.999808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=495 train loss <loss>=0.985435497761\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:12 INFO 140074512123712] Epoch[13] Batch [495]#011Speed: 767.39 samples/sec#011loss=0.985435\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch[500] avg_epoch_loss=0.998511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=500 train loss <loss>=0.86982177496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch [500]#011Speed: 1021.92 samples/sec#011loss=0.869822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch[505] avg_epoch_loss=0.997143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=505 train loss <loss>=0.860044944286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch [505]#011Speed: 804.74 samples/sec#011loss=0.860045\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch[510] avg_epoch_loss=0.997044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=510 train loss <loss>=0.987078285217\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch [510]#011Speed: 1081.69 samples/sec#011loss=0.987078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch[515] avg_epoch_loss=0.996063\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=515 train loss <loss>=0.895783853531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch [515]#011Speed: 754.29 samples/sec#011loss=0.895784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch[520] avg_epoch_loss=0.994094\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=520 train loss <loss>=0.790828096867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:13 INFO 140074512123712] Epoch[13] Batch [520]#011Speed: 1063.48 samples/sec#011loss=0.790828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch[525] avg_epoch_loss=0.992620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=525 train loss <loss>=0.839060127735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch [525]#011Speed: 785.35 samples/sec#011loss=0.839060\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch[530] avg_epoch_loss=0.990338\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=530 train loss <loss>=0.750331962109\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch [530]#011Speed: 1019.39 samples/sec#011loss=0.750332\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch[535] avg_epoch_loss=0.990175\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=535 train loss <loss>=0.972852516174\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch [535]#011Speed: 780.52 samples/sec#011loss=0.972853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch[540] avg_epoch_loss=0.990361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=540 train loss <loss>=1.01031605005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch [540]#011Speed: 1064.41 samples/sec#011loss=1.010316\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch[545] avg_epoch_loss=0.988696\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=545 train loss <loss>=0.808479368687\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch [545]#011Speed: 770.03 samples/sec#011loss=0.808479\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch[550] avg_epoch_loss=0.987284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=550 train loss <loss>=0.833120954037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:14 INFO 140074512123712] Epoch[13] Batch [550]#011Speed: 1043.36 samples/sec#011loss=0.833121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[13] Batch[555] avg_epoch_loss=0.986143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, batch=555 train loss <loss>=0.860410690308\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[13] Batch [555]#011Speed: 892.50 samples/sec#011loss=0.860411\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] processed a total of 17915 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20033.06007385254, \"sum\": 20033.06007385254, \"min\": 20033.06007385254}}, \"EndTime\": 1589445255.174991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445235.141519}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=894.264932743 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=13, train loss <loss>=0.984652070701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_e71edd4f-ed34-4d03-baeb-b672b0251a12-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.524106979370117, \"sum\": 9.524106979370117, \"min\": 9.524106979370117}}, \"EndTime\": 1589445255.18528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445255.175095}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch[0] avg_epoch_loss=0.732783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=0.732782781124\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch[5] avg_epoch_loss=0.852971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=0.852970729272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch [5]#011Speed: 1058.78 samples/sec#011loss=0.852971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch[10] avg_epoch_loss=0.811307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=0.761311197281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch [10]#011Speed: 959.80 samples/sec#011loss=0.761311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch[15] avg_epoch_loss=0.790445\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=0.744546747208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:15 INFO 140074512123712] Epoch[14] Batch [15]#011Speed: 764.76 samples/sec#011loss=0.744547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch[20] avg_epoch_loss=0.797972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=0.822060143948\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch [20]#011Speed: 785.96 samples/sec#011loss=0.822060\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch[25] avg_epoch_loss=0.820342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=0.91429605484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch [25]#011Speed: 1019.92 samples/sec#011loss=0.914296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch[30] avg_epoch_loss=0.852892\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=1.02215117216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch [30]#011Speed: 798.14 samples/sec#011loss=1.022151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch[35] avg_epoch_loss=0.874948\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=1.0116975069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch [35]#011Speed: 1075.41 samples/sec#011loss=1.011698\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch[40] avg_epoch_loss=0.898110\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=1.06487158537\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch [40]#011Speed: 794.79 samples/sec#011loss=1.064872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch[45] avg_epoch_loss=0.904189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=0.954035317898\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:16 INFO 140074512123712] Epoch[14] Batch [45]#011Speed: 1075.94 samples/sec#011loss=0.954035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch[50] avg_epoch_loss=0.918370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=1.04883704185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch [50]#011Speed: 781.45 samples/sec#011loss=1.048837\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch[55] avg_epoch_loss=0.925041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=0.993087923527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch [55]#011Speed: 1100.75 samples/sec#011loss=0.993088\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch[60] avg_epoch_loss=0.927513\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=0.955193984509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch [60]#011Speed: 808.17 samples/sec#011loss=0.955194\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch[65] avg_epoch_loss=0.932801\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=0.997318589687\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch [65]#011Speed: 1083.27 samples/sec#011loss=0.997319\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch[70] avg_epoch_loss=0.925527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=0.829511141777\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch [70]#011Speed: 791.73 samples/sec#011loss=0.829511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch[75] avg_epoch_loss=0.925310\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=0.922231340408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:17 INFO 140074512123712] Epoch[14] Batch [75]#011Speed: 1061.59 samples/sec#011loss=0.922231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch[80] avg_epoch_loss=0.925518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=0.928684806824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch [80]#011Speed: 738.66 samples/sec#011loss=0.928685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch[85] avg_epoch_loss=0.959199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=1.50482386351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch [85]#011Speed: 1069.91 samples/sec#011loss=1.504824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch[90] avg_epoch_loss=0.954960\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=0.882047426701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch [90]#011Speed: 750.43 samples/sec#011loss=0.882047\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch[95] avg_epoch_loss=0.950036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=0.860418844223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch [95]#011Speed: 1077.69 samples/sec#011loss=0.860419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch[100] avg_epoch_loss=0.949887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=0.947026002407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:18 INFO 140074512123712] Epoch[14] Batch [100]#011Speed: 693.84 samples/sec#011loss=0.947026\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch[105] avg_epoch_loss=0.948798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=0.926803183556\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch [105]#011Speed: 1027.40 samples/sec#011loss=0.926803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch[110] avg_epoch_loss=0.979134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=1.62226393223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch [110]#011Speed: 740.63 samples/sec#011loss=1.622264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch[115] avg_epoch_loss=0.974181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=0.864218509197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch [115]#011Speed: 1075.27 samples/sec#011loss=0.864219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch[120] avg_epoch_loss=0.968578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=0.838587296009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch [120]#011Speed: 1081.89 samples/sec#011loss=0.838587\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch[125] avg_epoch_loss=0.968420\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=0.964596199989\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch [125]#011Speed: 788.08 samples/sec#011loss=0.964596\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch[130] avg_epoch_loss=0.986061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=1.43060897589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:19 INFO 140074512123712] Epoch[14] Batch [130]#011Speed: 774.52 samples/sec#011loss=1.430609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch[135] avg_epoch_loss=0.987891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=1.03585140705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch [135]#011Speed: 994.85 samples/sec#011loss=1.035851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch[140] avg_epoch_loss=0.986283\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=0.942546510696\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch [140]#011Speed: 653.33 samples/sec#011loss=0.942547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch[145] avg_epoch_loss=0.982497\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=0.87571978569\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch [145]#011Speed: 1069.79 samples/sec#011loss=0.875720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch[150] avg_epoch_loss=0.980237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=0.914232540131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch [150]#011Speed: 792.07 samples/sec#011loss=0.914233\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch[155] avg_epoch_loss=0.975556\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=0.834204673767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:20 INFO 140074512123712] Epoch[14] Batch [155]#011Speed: 1070.01 samples/sec#011loss=0.834205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch[160] avg_epoch_loss=0.973066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=0.895376813412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch [160]#011Speed: 776.61 samples/sec#011loss=0.895377\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch[165] avg_epoch_loss=0.970020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=0.871924901009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch [165]#011Speed: 1032.86 samples/sec#011loss=0.871925\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch[170] avg_epoch_loss=0.967759\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=0.892722082138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch [170]#011Speed: 1090.83 samples/sec#011loss=0.892722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch[175] avg_epoch_loss=0.970550\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=1.06600389481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch [175]#011Speed: 805.07 samples/sec#011loss=1.066004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch[180] avg_epoch_loss=0.971886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=1.01888554096\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch [180]#011Speed: 1098.68 samples/sec#011loss=1.018886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch[185] avg_epoch_loss=0.994240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=1.80348467827\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:21 INFO 140074512123712] Epoch[14] Batch [185]#011Speed: 784.32 samples/sec#011loss=1.803485\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch[190] avg_epoch_loss=0.993735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=0.974949383736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch [190]#011Speed: 1083.58 samples/sec#011loss=0.974949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch[195] avg_epoch_loss=0.998986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=1.19956305027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch [195]#011Speed: 781.24 samples/sec#011loss=1.199563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch[200] avg_epoch_loss=1.004301\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=1.2126221776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch [200]#011Speed: 1089.58 samples/sec#011loss=1.212622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch[205] avg_epoch_loss=1.008140\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=1.16247272491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch [205]#011Speed: 778.12 samples/sec#011loss=1.162473\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch[210] avg_epoch_loss=1.008981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=1.04366059303\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch [210]#011Speed: 1061.75 samples/sec#011loss=1.043661\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch[215] avg_epoch_loss=1.007075\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=0.926607525349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:22 INFO 140074512123712] Epoch[14] Batch [215]#011Speed: 775.58 samples/sec#011loss=0.926608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch[220] avg_epoch_loss=1.006146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=0.966043317318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch [220]#011Speed: 1006.57 samples/sec#011loss=0.966043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch[225] avg_epoch_loss=1.001542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=0.798030734062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch [225]#011Speed: 788.35 samples/sec#011loss=0.798031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch[230] avg_epoch_loss=0.998317\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=0.852536273003\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch [230]#011Speed: 1087.68 samples/sec#011loss=0.852536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch[235] avg_epoch_loss=0.994785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=0.83162958622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch [235]#011Speed: 789.19 samples/sec#011loss=0.831630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch[240] avg_epoch_loss=0.989972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=0.762784063816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:23 INFO 140074512123712] Epoch[14] Batch [240]#011Speed: 1084.06 samples/sec#011loss=0.762784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch[245] avg_epoch_loss=0.988320\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=0.908701372147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch [245]#011Speed: 758.00 samples/sec#011loss=0.908701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch[250] avg_epoch_loss=0.984043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=0.773606002331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch [250]#011Speed: 1009.80 samples/sec#011loss=0.773606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch[255] avg_epoch_loss=0.982282\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=0.89388833046\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch [255]#011Speed: 780.75 samples/sec#011loss=0.893888\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch[260] avg_epoch_loss=0.983345\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=1.03778171539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch [260]#011Speed: 1072.67 samples/sec#011loss=1.037782\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch[265] avg_epoch_loss=0.984815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=1.06153646708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch [265]#011Speed: 766.48 samples/sec#011loss=1.061536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch[270] avg_epoch_loss=0.982109\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=270 train loss <loss>=0.838130939007\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:24 INFO 140074512123712] Epoch[14] Batch [270]#011Speed: 1066.96 samples/sec#011loss=0.838131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch[275] avg_epoch_loss=0.979603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=275 train loss <loss>=0.843801271915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch [275]#011Speed: 1076.74 samples/sec#011loss=0.843801\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch[280] avg_epoch_loss=0.977954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=280 train loss <loss>=0.886927747726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch [280]#011Speed: 779.58 samples/sec#011loss=0.886928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch[285] avg_epoch_loss=0.978426\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=285 train loss <loss>=1.00492848158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch [285]#011Speed: 811.51 samples/sec#011loss=1.004928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch[290] avg_epoch_loss=0.976811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=290 train loss <loss>=0.884436666965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch [290]#011Speed: 1081.63 samples/sec#011loss=0.884437\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch[295] avg_epoch_loss=0.973108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=295 train loss <loss>=0.757607769966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch [295]#011Speed: 794.01 samples/sec#011loss=0.757608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch[300] avg_epoch_loss=0.973071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=300 train loss <loss>=0.970888900757\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:25 INFO 140074512123712] Epoch[14] Batch [300]#011Speed: 1084.22 samples/sec#011loss=0.970889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch[305] avg_epoch_loss=0.972090\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=305 train loss <loss>=0.913031828403\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch [305]#011Speed: 847.80 samples/sec#011loss=0.913032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch[310] avg_epoch_loss=0.972899\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=310 train loss <loss>=1.02238867283\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch [310]#011Speed: 758.85 samples/sec#011loss=1.022389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch[315] avg_epoch_loss=0.971009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=315 train loss <loss>=0.85343657732\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch [315]#011Speed: 1082.71 samples/sec#011loss=0.853437\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch[320] avg_epoch_loss=0.978738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=320 train loss <loss>=1.46725028753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch [320]#011Speed: 795.12 samples/sec#011loss=1.467250\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch[325] avg_epoch_loss=0.982030\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=325 train loss <loss>=1.19335873127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:26 INFO 140074512123712] Epoch[14] Batch [325]#011Speed: 1064.48 samples/sec#011loss=1.193359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch[330] avg_epoch_loss=0.983134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=330 train loss <loss>=1.0551122427\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch [330]#011Speed: 763.95 samples/sec#011loss=1.055112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch[335] avg_epoch_loss=0.982833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=335 train loss <loss>=0.962934660912\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch [335]#011Speed: 1005.49 samples/sec#011loss=0.962935\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch[340] avg_epoch_loss=0.986070\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=340 train loss <loss>=1.20357958078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch [340]#011Speed: 772.53 samples/sec#011loss=1.203580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch[345] avg_epoch_loss=0.984358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=345 train loss <loss>=0.867611420155\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch [345]#011Speed: 1071.18 samples/sec#011loss=0.867611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch[350] avg_epoch_loss=0.982853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=350 train loss <loss>=0.878671216965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch [350]#011Speed: 802.31 samples/sec#011loss=0.878671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch[355] avg_epoch_loss=0.980409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=355 train loss <loss>=0.808854067326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:27 INFO 140074512123712] Epoch[14] Batch [355]#011Speed: 774.42 samples/sec#011loss=0.808854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch[360] avg_epoch_loss=0.979043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=360 train loss <loss>=0.881824886799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch [360]#011Speed: 1044.19 samples/sec#011loss=0.881825\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch[365] avg_epoch_loss=0.977216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=365 train loss <loss>=0.845302295685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch [365]#011Speed: 960.85 samples/sec#011loss=0.845302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch[370] avg_epoch_loss=0.976509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=370 train loss <loss>=0.924732625484\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch [370]#011Speed: 764.66 samples/sec#011loss=0.924733\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch[375] avg_epoch_loss=0.974722\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=375 train loss <loss>=0.842108047009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch [375]#011Speed: 1054.87 samples/sec#011loss=0.842108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch[380] avg_epoch_loss=0.972777\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=380 train loss <loss>=0.826491677761\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:28 INFO 140074512123712] Epoch[14] Batch [380]#011Speed: 776.64 samples/sec#011loss=0.826492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch[385] avg_epoch_loss=0.970883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=385 train loss <loss>=0.826570403576\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch [385]#011Speed: 947.76 samples/sec#011loss=0.826570\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch[390] avg_epoch_loss=0.968947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=390 train loss <loss>=0.819525051117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch [390]#011Speed: 782.68 samples/sec#011loss=0.819525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch[395] avg_epoch_loss=0.970311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=395 train loss <loss>=1.0769431591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch [395]#011Speed: 732.34 samples/sec#011loss=1.076943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch[400] avg_epoch_loss=0.967955\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=400 train loss <loss>=0.781353378296\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch [400]#011Speed: 1068.01 samples/sec#011loss=0.781353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch[405] avg_epoch_loss=0.965692\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=405 train loss <loss>=0.78419162035\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch [405]#011Speed: 784.20 samples/sec#011loss=0.784192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch[410] avg_epoch_loss=0.965010\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=410 train loss <loss>=0.909684514999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:29 INFO 140074512123712] Epoch[14] Batch [410]#011Speed: 1083.54 samples/sec#011loss=0.909685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch[415] avg_epoch_loss=0.965367\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=415 train loss <loss>=0.994671213627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch [415]#011Speed: 791.69 samples/sec#011loss=0.994671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch[420] avg_epoch_loss=0.974122\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=420 train loss <loss>=1.70256175995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch [420]#011Speed: 1011.10 samples/sec#011loss=1.702562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch[425] avg_epoch_loss=0.973281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=425 train loss <loss>=0.902468383312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch [425]#011Speed: 783.61 samples/sec#011loss=0.902468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch[430] avg_epoch_loss=0.973124\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=430 train loss <loss>=0.959750032425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch [430]#011Speed: 1088.17 samples/sec#011loss=0.959750\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch[435] avg_epoch_loss=0.973322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=435 train loss <loss>=0.990429890156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:30 INFO 140074512123712] Epoch[14] Batch [435]#011Speed: 796.39 samples/sec#011loss=0.990430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch[440] avg_epoch_loss=0.972580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=440 train loss <loss>=0.907854199409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch [440]#011Speed: 1071.57 samples/sec#011loss=0.907854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch[445] avg_epoch_loss=0.974490\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=445 train loss <loss>=1.14295458794\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch [445]#011Speed: 862.49 samples/sec#011loss=1.142955\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch[450] avg_epoch_loss=0.973482\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=450 train loss <loss>=0.883586001396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch [450]#011Speed: 728.70 samples/sec#011loss=0.883586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch[455] avg_epoch_loss=0.972798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=455 train loss <loss>=0.911020338535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch [455]#011Speed: 1044.27 samples/sec#011loss=0.911020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch[460] avg_epoch_loss=0.971550\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=460 train loss <loss>=0.85774538517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:31 INFO 140074512123712] Epoch[14] Batch [460]#011Speed: 562.21 samples/sec#011loss=0.857745\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch[465] avg_epoch_loss=0.971100\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=465 train loss <loss>=0.929684102535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch [465]#011Speed: 780.93 samples/sec#011loss=0.929684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch[470] avg_epoch_loss=0.972080\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=470 train loss <loss>=1.06340185404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch [470]#011Speed: 1004.29 samples/sec#011loss=1.063402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch[475] avg_epoch_loss=0.974344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=475 train loss <loss>=1.18761966228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch [475]#011Speed: 1078.23 samples/sec#011loss=1.187620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch[480] avg_epoch_loss=0.974776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=480 train loss <loss>=1.0158995986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch [480]#011Speed: 786.33 samples/sec#011loss=1.015900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch[485] avg_epoch_loss=0.973525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=485 train loss <loss>=0.853192138672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch [485]#011Speed: 1048.97 samples/sec#011loss=0.853192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch[490] avg_epoch_loss=0.972495\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=490 train loss <loss>=0.872338604927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:32 INFO 140074512123712] Epoch[14] Batch [490]#011Speed: 764.56 samples/sec#011loss=0.872339\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch[495] avg_epoch_loss=0.971457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=495 train loss <loss>=0.869508230686\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch [495]#011Speed: 1066.03 samples/sec#011loss=0.869508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch[500] avg_epoch_loss=0.969290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=500 train loss <loss>=0.754298508167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch [500]#011Speed: 753.01 samples/sec#011loss=0.754299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch[505] avg_epoch_loss=0.967147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=505 train loss <loss>=0.752438414097\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch [505]#011Speed: 1061.94 samples/sec#011loss=0.752438\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch[510] avg_epoch_loss=0.964682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=510 train loss <loss>=0.71526427269\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch [510]#011Speed: 788.12 samples/sec#011loss=0.715264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch[515] avg_epoch_loss=0.962193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=515 train loss <loss>=0.707801806927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:33 INFO 140074512123712] Epoch[14] Batch [515]#011Speed: 1085.84 samples/sec#011loss=0.707802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch[520] avg_epoch_loss=0.960180\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=520 train loss <loss>=0.75240906477\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch [520]#011Speed: 781.69 samples/sec#011loss=0.752409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch[525] avg_epoch_loss=0.958469\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=525 train loss <loss>=0.780210673809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch [525]#011Speed: 1087.84 samples/sec#011loss=0.780211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch[530] avg_epoch_loss=0.957322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=530 train loss <loss>=0.836667966843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch [530]#011Speed: 756.66 samples/sec#011loss=0.836668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch[535] avg_epoch_loss=0.957253\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=535 train loss <loss>=0.94995777607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch [535]#011Speed: 1089.20 samples/sec#011loss=0.949958\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch[540] avg_epoch_loss=0.955422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=540 train loss <loss>=0.759121143818\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch [540]#011Speed: 797.61 samples/sec#011loss=0.759121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch[545] avg_epoch_loss=0.954676\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=545 train loss <loss>=0.873948895931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:34 INFO 140074512123712] Epoch[14] Batch [545]#011Speed: 1060.60 samples/sec#011loss=0.873949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch[550] avg_epoch_loss=0.955907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=550 train loss <loss>=1.09032047987\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch [550]#011Speed: 763.25 samples/sec#011loss=1.090320\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch[555] avg_epoch_loss=0.955647\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=555 train loss <loss>=0.927008843422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch [555]#011Speed: 1065.33 samples/sec#011loss=0.927009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch[560] avg_epoch_loss=0.954668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=560 train loss <loss>=0.845779263973\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch [560]#011Speed: 816.58 samples/sec#011loss=0.845779\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch[565] avg_epoch_loss=0.953828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, batch=565 train loss <loss>=0.859551000595\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[14] Batch [565]#011Speed: 1076.39 samples/sec#011loss=0.859551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] processed a total of 18109 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20409.648180007935, \"sum\": 20409.648180007935, \"min\": 20409.648180007935}}, \"EndTime\": 1589445275.595042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445255.185338}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=887.272616421 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=14, train loss <loss>=0.953827761719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_0d854626-0ca3-448a-8458-cc0e74ce81c0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.315967559814453, \"sum\": 9.315967559814453, \"min\": 9.315967559814453}}, \"EndTime\": 1589445275.604874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445275.595098}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[15] Batch[0] avg_epoch_loss=0.988354\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=0.988353788853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[15] Batch[5] avg_epoch_loss=0.912271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=0.912270506223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:35 INFO 140074512123712] Epoch[15] Batch [5]#011Speed: 1066.89 samples/sec#011loss=0.912271\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch[10] avg_epoch_loss=0.891959\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=0.867586278915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch [10]#011Speed: 778.05 samples/sec#011loss=0.867586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch[15] avg_epoch_loss=0.913003\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=0.959298431873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch [15]#011Speed: 1063.18 samples/sec#011loss=0.959298\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch[20] avg_epoch_loss=0.908354\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=0.893476486206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch [20]#011Speed: 657.44 samples/sec#011loss=0.893476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch[25] avg_epoch_loss=0.907255\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=0.902638351917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch [25]#011Speed: 1089.00 samples/sec#011loss=0.902638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch[30] avg_epoch_loss=0.908916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=0.917554473877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch [30]#011Speed: 802.62 samples/sec#011loss=0.917554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch[35] avg_epoch_loss=0.915547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=0.956660056114\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:36 INFO 140074512123712] Epoch[15] Batch [35]#011Speed: 1045.01 samples/sec#011loss=0.956660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch[40] avg_epoch_loss=0.905258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=0.83117672205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch [40]#011Speed: 775.07 samples/sec#011loss=0.831177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch[45] avg_epoch_loss=0.901372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=0.86950917244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch [45]#011Speed: 1008.26 samples/sec#011loss=0.869509\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch[50] avg_epoch_loss=0.898230\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=0.869322347641\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch [50]#011Speed: 781.70 samples/sec#011loss=0.869322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch[55] avg_epoch_loss=0.884136\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=0.740371227264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch [55]#011Speed: 1067.88 samples/sec#011loss=0.740371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch[60] avg_epoch_loss=0.882614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=0.865573084354\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:37 INFO 140074512123712] Epoch[15] Batch [60]#011Speed: 776.11 samples/sec#011loss=0.865573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch[65] avg_epoch_loss=0.884416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=0.906403946877\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch [65]#011Speed: 1055.17 samples/sec#011loss=0.906404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch[70] avg_epoch_loss=0.881354\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=0.840924632549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch [70]#011Speed: 778.17 samples/sec#011loss=0.840925\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch[75] avg_epoch_loss=0.892205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=1.0463021636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch [75]#011Speed: 1024.58 samples/sec#011loss=1.046302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch[80] avg_epoch_loss=0.887022\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=0.808234226704\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch [80]#011Speed: 808.55 samples/sec#011loss=0.808234\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch[85] avg_epoch_loss=0.880600\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=0.776568472385\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch [85]#011Speed: 1070.42 samples/sec#011loss=0.776568\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch[90] avg_epoch_loss=0.880480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=0.878407692909\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:38 INFO 140074512123712] Epoch[15] Batch [90]#011Speed: 786.75 samples/sec#011loss=0.878408\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch[95] avg_epoch_loss=0.879634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=0.864243042469\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch [95]#011Speed: 1047.13 samples/sec#011loss=0.864243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch[100] avg_epoch_loss=0.947290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=2.24628341198\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch [100]#011Speed: 763.81 samples/sec#011loss=2.246283\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch[105] avg_epoch_loss=0.958466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=1.18421108723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch [105]#011Speed: 939.50 samples/sec#011loss=1.184211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch[110] avg_epoch_loss=0.960053\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=0.993704879284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch [110]#011Speed: 800.59 samples/sec#011loss=0.993705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch[115] avg_epoch_loss=0.963413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=1.03800381422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:39 INFO 140074512123712] Epoch[15] Batch [115]#011Speed: 1078.57 samples/sec#011loss=1.038004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch[120] avg_epoch_loss=0.968104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=1.07694660425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch [120]#011Speed: 750.15 samples/sec#011loss=1.076947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch[125] avg_epoch_loss=0.966901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=0.937791645527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch [125]#011Speed: 1078.04 samples/sec#011loss=0.937792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch[130] avg_epoch_loss=0.966931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=0.967667973042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch [130]#011Speed: 783.65 samples/sec#011loss=0.967668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch[135] avg_epoch_loss=0.965556\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=0.929546654224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch [135]#011Speed: 1065.24 samples/sec#011loss=0.929547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch[140] avg_epoch_loss=0.959731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=0.801268672943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch [140]#011Speed: 791.53 samples/sec#011loss=0.801269\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch[145] avg_epoch_loss=0.957006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=0.880181014538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:40 INFO 140074512123712] Epoch[15] Batch [145]#011Speed: 1080.33 samples/sec#011loss=0.880181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch[150] avg_epoch_loss=0.951803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=0.799869096279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch [150]#011Speed: 783.87 samples/sec#011loss=0.799869\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch[155] avg_epoch_loss=0.946829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=0.796614193916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch [155]#011Speed: 1068.29 samples/sec#011loss=0.796614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch[160] avg_epoch_loss=0.946414\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=0.933479702473\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch [160]#011Speed: 565.27 samples/sec#011loss=0.933480\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch[165] avg_epoch_loss=0.946792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=0.958951687813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch [165]#011Speed: 1075.99 samples/sec#011loss=0.958952\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch[170] avg_epoch_loss=0.958120\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=1.33422510624\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:41 INFO 140074512123712] Epoch[15] Batch [170]#011Speed: 794.37 samples/sec#011loss=1.334225\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch[175] avg_epoch_loss=0.959130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=0.99365375042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch [175]#011Speed: 1069.08 samples/sec#011loss=0.993654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch[180] avg_epoch_loss=0.960660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=1.01452356577\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch [180]#011Speed: 772.53 samples/sec#011loss=1.014524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch[185] avg_epoch_loss=0.962128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=1.01525948048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch [185]#011Speed: 1012.30 samples/sec#011loss=1.015259\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch[190] avg_epoch_loss=0.961428\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=0.93539686203\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch [190]#011Speed: 786.52 samples/sec#011loss=0.935397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch[195] avg_epoch_loss=0.958821\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=0.859243738651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch [195]#011Speed: 1073.31 samples/sec#011loss=0.859244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch[200] avg_epoch_loss=0.957829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=0.918921720982\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:42 INFO 140074512123712] Epoch[15] Batch [200]#011Speed: 772.85 samples/sec#011loss=0.918922\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch[205] avg_epoch_loss=0.973624\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=1.60860530138\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch [205]#011Speed: 1069.17 samples/sec#011loss=1.608605\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch[210] avg_epoch_loss=0.974903\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=1.02756354809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch [210]#011Speed: 719.59 samples/sec#011loss=1.027564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch[215] avg_epoch_loss=0.974371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=0.951955544949\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch [215]#011Speed: 991.48 samples/sec#011loss=0.951956\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch[220] avg_epoch_loss=0.972517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=0.892408680916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch [220]#011Speed: 802.12 samples/sec#011loss=0.892409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch[225] avg_epoch_loss=0.971897\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=0.944499254227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:43 INFO 140074512123712] Epoch[15] Batch [225]#011Speed: 1073.27 samples/sec#011loss=0.944499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch[230] avg_epoch_loss=0.997796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=2.16844431162\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch [230]#011Speed: 783.09 samples/sec#011loss=2.168444\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch[235] avg_epoch_loss=0.996334\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=0.928747463226\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch [235]#011Speed: 1053.22 samples/sec#011loss=0.928747\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch[240] avg_epoch_loss=0.996124\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=0.98624651432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch [240]#011Speed: 767.00 samples/sec#011loss=0.986247\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch[245] avg_epoch_loss=0.995279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=0.95452837944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch [245]#011Speed: 1031.95 samples/sec#011loss=0.954528\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch[250] avg_epoch_loss=0.993927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=0.927408850193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch [250]#011Speed: 792.71 samples/sec#011loss=0.927409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch[255] avg_epoch_loss=0.993077\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=0.950426256657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:44 INFO 140074512123712] Epoch[15] Batch [255]#011Speed: 1063.05 samples/sec#011loss=0.950426\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch[260] avg_epoch_loss=0.990903\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=0.879566311836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch [260]#011Speed: 783.37 samples/sec#011loss=0.879566\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch[265] avg_epoch_loss=1.000412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=1.49677796364\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch [265]#011Speed: 1080.11 samples/sec#011loss=1.496778\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch[270] avg_epoch_loss=0.997196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=270 train loss <loss>=0.826117062569\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch [270]#011Speed: 752.10 samples/sec#011loss=0.826117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch[275] avg_epoch_loss=0.994217\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=275 train loss <loss>=0.83276964426\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch [275]#011Speed: 1073.60 samples/sec#011loss=0.832770\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch[280] avg_epoch_loss=0.993336\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=280 train loss <loss>=0.944676816463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch [280]#011Speed: 725.35 samples/sec#011loss=0.944677\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch[285] avg_epoch_loss=0.990850\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=285 train loss <loss>=0.851145303249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:45 INFO 140074512123712] Epoch[15] Batch [285]#011Speed: 1060.22 samples/sec#011loss=0.851145\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch[290] avg_epoch_loss=0.992486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=290 train loss <loss>=1.08610219955\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch [290]#011Speed: 769.82 samples/sec#011loss=1.086102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch[295] avg_epoch_loss=0.989828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=295 train loss <loss>=0.835134530067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch [295]#011Speed: 1065.69 samples/sec#011loss=0.835135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch[300] avg_epoch_loss=0.988591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=300 train loss <loss>=0.915326154232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch [300]#011Speed: 636.07 samples/sec#011loss=0.915326\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch[305] avg_epoch_loss=0.985612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=305 train loss <loss>=0.80627720356\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch [305]#011Speed: 1089.81 samples/sec#011loss=0.806277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch[310] avg_epoch_loss=0.984845\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=310 train loss <loss>=0.93792937994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:46 INFO 140074512123712] Epoch[15] Batch [310]#011Speed: 801.61 samples/sec#011loss=0.937929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch[315] avg_epoch_loss=0.986151\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=315 train loss <loss>=1.0673551321\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch [315]#011Speed: 1073.41 samples/sec#011loss=1.067355\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch[320] avg_epoch_loss=0.983295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=320 train loss <loss>=0.802782618999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch [320]#011Speed: 774.79 samples/sec#011loss=0.802783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch[325] avg_epoch_loss=0.979486\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=325 train loss <loss>=0.734985780716\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch [325]#011Speed: 1025.50 samples/sec#011loss=0.734986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch[330] avg_epoch_loss=0.976371\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=330 train loss <loss>=0.773253953457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch [330]#011Speed: 772.42 samples/sec#011loss=0.773254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch[335] avg_epoch_loss=0.973600\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=335 train loss <loss>=0.790172302723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:47 INFO 140074512123712] Epoch[15] Batch [335]#011Speed: 1084.25 samples/sec#011loss=0.790172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch[340] avg_epoch_loss=0.983658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=340 train loss <loss>=1.65956376791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch [340]#011Speed: 773.31 samples/sec#011loss=1.659564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch[345] avg_epoch_loss=0.981952\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=345 train loss <loss>=0.865609967709\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch [345]#011Speed: 1001.43 samples/sec#011loss=0.865610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch[350] avg_epoch_loss=0.981127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=350 train loss <loss>=0.924047279358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch [350]#011Speed: 781.18 samples/sec#011loss=0.924047\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch[355] avg_epoch_loss=0.979723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=355 train loss <loss>=0.881129872799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch [355]#011Speed: 1024.94 samples/sec#011loss=0.881130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch[360] avg_epoch_loss=0.977017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=360 train loss <loss>=0.784368991852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch [360]#011Speed: 1073.47 samples/sec#011loss=0.784369\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch[365] avg_epoch_loss=0.974889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=365 train loss <loss>=0.821236872673\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:48 INFO 140074512123712] Epoch[15] Batch [365]#011Speed: 785.68 samples/sec#011loss=0.821237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch[370] avg_epoch_loss=0.976206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=370 train loss <loss>=1.07261462212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch [370]#011Speed: 1064.51 samples/sec#011loss=1.072615\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch[375] avg_epoch_loss=0.975316\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=375 train loss <loss>=0.909251844883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch [375]#011Speed: 765.87 samples/sec#011loss=0.909252\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch[380] avg_epoch_loss=0.975656\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=380 train loss <loss>=1.00120959282\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch [380]#011Speed: 1071.84 samples/sec#011loss=1.001210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch[385] avg_epoch_loss=0.974607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=385 train loss <loss>=0.894727373123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch [385]#011Speed: 732.57 samples/sec#011loss=0.894727\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch[390] avg_epoch_loss=0.972580\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=390 train loss <loss>=0.816107797623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch [390]#011Speed: 1078.59 samples/sec#011loss=0.816108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch[395] avg_epoch_loss=0.970831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=395 train loss <loss>=0.834044444561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:49 INFO 140074512123712] Epoch[15] Batch [395]#011Speed: 783.64 samples/sec#011loss=0.834044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch[400] avg_epoch_loss=0.968924\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=400 train loss <loss>=0.81783260107\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch [400]#011Speed: 1018.89 samples/sec#011loss=0.817833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch[405] avg_epoch_loss=0.967996\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=405 train loss <loss>=0.893627285957\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch [405]#011Speed: 806.43 samples/sec#011loss=0.893627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch[410] avg_epoch_loss=0.965695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=410 train loss <loss>=0.778833985329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch [410]#011Speed: 1008.50 samples/sec#011loss=0.778834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch[415] avg_epoch_loss=0.965101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=415 train loss <loss>=0.916242551804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch [415]#011Speed: 779.99 samples/sec#011loss=0.916243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch[420] avg_epoch_loss=0.965715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=420 train loss <loss>=1.0168056488\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:50 INFO 140074512123712] Epoch[15] Batch [420]#011Speed: 1089.98 samples/sec#011loss=1.016806\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch[425] avg_epoch_loss=0.965798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=425 train loss <loss>=0.972812819481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch [425]#011Speed: 787.26 samples/sec#011loss=0.972813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch[430] avg_epoch_loss=0.966204\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=430 train loss <loss>=1.00081471205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch [430]#011Speed: 1078.71 samples/sec#011loss=1.000815\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch[435] avg_epoch_loss=0.968353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=435 train loss <loss>=1.153592062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch [435]#011Speed: 788.99 samples/sec#011loss=1.153592\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch[440] avg_epoch_loss=0.968855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=440 train loss <loss>=1.01258797646\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch [440]#011Speed: 930.67 samples/sec#011loss=1.012588\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch[445] avg_epoch_loss=0.968083\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=445 train loss <loss>=0.90002001524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch [445]#011Speed: 677.31 samples/sec#011loss=0.900020\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch[450] avg_epoch_loss=0.967411\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=450 train loss <loss>=0.907450783253\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:51 INFO 140074512123712] Epoch[15] Batch [450]#011Speed: 1078.94 samples/sec#011loss=0.907451\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch[455] avg_epoch_loss=0.967591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=455 train loss <loss>=0.983808040619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch [455]#011Speed: 799.88 samples/sec#011loss=0.983808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch[460] avg_epoch_loss=0.966455\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=460 train loss <loss>=0.862913548946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch [460]#011Speed: 1063.74 samples/sec#011loss=0.862914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch[465] avg_epoch_loss=0.965299\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=465 train loss <loss>=0.858701038361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch [465]#011Speed: 784.35 samples/sec#011loss=0.858701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch[470] avg_epoch_loss=0.963500\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=470 train loss <loss>=0.795860886574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch [470]#011Speed: 1050.44 samples/sec#011loss=0.795861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch[475] avg_epoch_loss=0.961361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=475 train loss <loss>=0.759816908836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:52 INFO 140074512123712] Epoch[15] Batch [475]#011Speed: 799.03 samples/sec#011loss=0.759817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch[480] avg_epoch_loss=0.958835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=480 train loss <loss>=0.718386232853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch [480]#011Speed: 1069.12 samples/sec#011loss=0.718386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch[485] avg_epoch_loss=0.959851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=485 train loss <loss>=1.05756183863\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch [485]#011Speed: 759.11 samples/sec#011loss=1.057562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch[490] avg_epoch_loss=0.960871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=490 train loss <loss>=1.06004935503\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch [490]#011Speed: 1051.10 samples/sec#011loss=1.060049\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch[495] avg_epoch_loss=0.959800\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=495 train loss <loss>=0.854626023769\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch [495]#011Speed: 752.54 samples/sec#011loss=0.854626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch[500] avg_epoch_loss=0.958459\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=500 train loss <loss>=0.825385439396\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch [500]#011Speed: 1060.61 samples/sec#011loss=0.825385\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch[505] avg_epoch_loss=0.956560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=505 train loss <loss>=0.766302359104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:53 INFO 140074512123712] Epoch[15] Batch [505]#011Speed: 780.36 samples/sec#011loss=0.766302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch[510] avg_epoch_loss=0.955394\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=510 train loss <loss>=0.837380087376\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch [510]#011Speed: 1058.71 samples/sec#011loss=0.837380\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch[515] avg_epoch_loss=0.953941\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=515 train loss <loss>=0.805465972424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch [515]#011Speed: 776.83 samples/sec#011loss=0.805466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch[520] avg_epoch_loss=0.958322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=520 train loss <loss>=1.41038891077\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch [520]#011Speed: 1074.89 samples/sec#011loss=1.410389\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch[525] avg_epoch_loss=0.960245\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=525 train loss <loss>=1.16068685055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch [525]#011Speed: 741.19 samples/sec#011loss=1.160687\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch[530] avg_epoch_loss=0.960510\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=530 train loss <loss>=0.988341164589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:54 INFO 140074512123712] Epoch[15] Batch [530]#011Speed: 1079.55 samples/sec#011loss=0.988341\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch[535] avg_epoch_loss=0.961409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=535 train loss <loss>=1.05690287352\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch [535]#011Speed: 779.61 samples/sec#011loss=1.056903\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch[540] avg_epoch_loss=0.961498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=540 train loss <loss>=0.971024608612\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch [540]#011Speed: 1072.75 samples/sec#011loss=0.971025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch[545] avg_epoch_loss=0.960909\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=545 train loss <loss>=0.897215998173\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch [545]#011Speed: 801.42 samples/sec#011loss=0.897216\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch[550] avg_epoch_loss=0.960189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=550 train loss <loss>=0.881592309475\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch [550]#011Speed: 1013.85 samples/sec#011loss=0.881592\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch[555] avg_epoch_loss=0.959705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, batch=555 train loss <loss>=0.906274855137\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[15] Batch [555]#011Speed: 879.20 samples/sec#011loss=0.906275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] processed a total of 17891 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20214.12992477417, \"sum\": 20214.12992477417, \"min\": 20214.12992477417}}, \"EndTime\": 1589445295.819117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445275.604931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=885.069793791 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=15, train loss <loss>=0.958850215056\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] Epoch[16] Batch[0] avg_epoch_loss=1.006204\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=1.00620448589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch[5] avg_epoch_loss=0.839374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=0.839374423027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch [5]#011Speed: 1043.83 samples/sec#011loss=0.839374\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch[10] avg_epoch_loss=0.819980\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=0.796706700325\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch [10]#011Speed: 777.45 samples/sec#011loss=0.796707\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch[15] avg_epoch_loss=0.786407\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=0.71254786253\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch [15]#011Speed: 1071.11 samples/sec#011loss=0.712548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch[20] avg_epoch_loss=0.814735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=0.905383610725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch [20]#011Speed: 710.47 samples/sec#011loss=0.905384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch[25] avg_epoch_loss=0.819775\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=0.840944719315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:56 INFO 140074512123712] Epoch[16] Batch [25]#011Speed: 695.02 samples/sec#011loss=0.840945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch[30] avg_epoch_loss=0.826611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=0.862156379223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch [30]#011Speed: 798.71 samples/sec#011loss=0.862156\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch[35] avg_epoch_loss=0.842103\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=0.938151860237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch [35]#011Speed: 793.94 samples/sec#011loss=0.938152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch[40] avg_epoch_loss=0.837488\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=0.804258644581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch [40]#011Speed: 789.91 samples/sec#011loss=0.804259\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch[45] avg_epoch_loss=0.850603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=0.95815192461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch [45]#011Speed: 1010.95 samples/sec#011loss=0.958152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch[50] avg_epoch_loss=0.842694\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=0.769927871227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch [50]#011Speed: 799.33 samples/sec#011loss=0.769928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch[55] avg_epoch_loss=0.846799\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=0.88867367506\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:57 INFO 140074512123712] Epoch[16] Batch [55]#011Speed: 1057.31 samples/sec#011loss=0.888674\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch[60] avg_epoch_loss=0.854726\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=0.943507516384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch [60]#011Speed: 775.57 samples/sec#011loss=0.943508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch[65] avg_epoch_loss=0.868289\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=1.03375120163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch [65]#011Speed: 1076.85 samples/sec#011loss=1.033751\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch[70] avg_epoch_loss=0.881915\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=1.06177557707\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch [70]#011Speed: 738.99 samples/sec#011loss=1.061776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch[75] avg_epoch_loss=0.872564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=0.739787936211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch [75]#011Speed: 1075.83 samples/sec#011loss=0.739788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch[80] avg_epoch_loss=0.869125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=0.816851890087\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:58 INFO 140074512123712] Epoch[16] Batch [80]#011Speed: 794.17 samples/sec#011loss=0.816852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch[85] avg_epoch_loss=0.930000\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=1.91616501808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch [85]#011Speed: 1063.59 samples/sec#011loss=1.916165\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch[90] avg_epoch_loss=0.924539\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=0.830625748634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch [90]#011Speed: 803.67 samples/sec#011loss=0.830626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch[95] avg_epoch_loss=0.924593\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=0.925559520721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch [95]#011Speed: 1090.51 samples/sec#011loss=0.925560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch[100] avg_epoch_loss=0.924413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=0.920961642265\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch [100]#011Speed: 709.17 samples/sec#011loss=0.920962\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch[105] avg_epoch_loss=0.920142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=0.833879315853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch [105]#011Speed: 1081.90 samples/sec#011loss=0.833879\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch[110] avg_epoch_loss=0.920025\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=0.917542862892\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:34:59 INFO 140074512123712] Epoch[16] Batch [110]#011Speed: 793.24 samples/sec#011loss=0.917543\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch[115] avg_epoch_loss=0.913775\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=0.775028789043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch [115]#011Speed: 1047.22 samples/sec#011loss=0.775029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch[120] avg_epoch_loss=0.906686\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=0.74221111536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch [120]#011Speed: 768.56 samples/sec#011loss=0.742211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch[125] avg_epoch_loss=0.901196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=0.768332004547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch [125]#011Speed: 1082.49 samples/sec#011loss=0.768332\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch[130] avg_epoch_loss=0.895547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=0.753205311298\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch [130]#011Speed: 762.64 samples/sec#011loss=0.753205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch[135] avg_epoch_loss=0.892439\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=0.811009430885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:00 INFO 140074512123712] Epoch[16] Batch [135]#011Speed: 1051.08 samples/sec#011loss=0.811009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch[140] avg_epoch_loss=0.893699\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=0.927969110012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch [140]#011Speed: 792.02 samples/sec#011loss=0.927969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch[145] avg_epoch_loss=0.898402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=1.03102908134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch [145]#011Speed: 1070.63 samples/sec#011loss=1.031029\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch[150] avg_epoch_loss=0.936227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=2.04069674015\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch [150]#011Speed: 774.47 samples/sec#011loss=2.040697\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch[155] avg_epoch_loss=0.936464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=0.943622040749\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch [155]#011Speed: 895.37 samples/sec#011loss=0.943622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch[160] avg_epoch_loss=0.936445\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=0.935854125023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch [160]#011Speed: 806.18 samples/sec#011loss=0.935854\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch[165] avg_epoch_loss=0.934066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=0.857482123375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:01 INFO 140074512123712] Epoch[16] Batch [165]#011Speed: 749.28 samples/sec#011loss=0.857482\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch[170] avg_epoch_loss=0.933560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=0.916736865044\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch [170]#011Speed: 521.82 samples/sec#011loss=0.916737\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch[175] avg_epoch_loss=0.930379\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=0.821617949009\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch [175]#011Speed: 987.44 samples/sec#011loss=0.821618\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch[180] avg_epoch_loss=0.926451\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=0.78818666935\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch [180]#011Speed: 756.74 samples/sec#011loss=0.788187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch[185] avg_epoch_loss=0.926919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=0.943852972984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:02 INFO 140074512123712] Epoch[16] Batch [185]#011Speed: 1082.81 samples/sec#011loss=0.943853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch[190] avg_epoch_loss=0.926160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=0.897933840752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch [190]#011Speed: 787.05 samples/sec#011loss=0.897934\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch[195] avg_epoch_loss=0.931224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=1.12466362715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch [195]#011Speed: 1042.43 samples/sec#011loss=1.124664\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch[200] avg_epoch_loss=0.932262\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=0.972930073738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch [200]#011Speed: 775.45 samples/sec#011loss=0.972930\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch[205] avg_epoch_loss=0.933342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=0.97678412199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch [205]#011Speed: 1085.39 samples/sec#011loss=0.976784\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch[210] avg_epoch_loss=0.935068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=1.00617754459\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch [210]#011Speed: 760.26 samples/sec#011loss=1.006178\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch[215] avg_epoch_loss=0.937104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=1.02301498652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:03 INFO 140074512123712] Epoch[16] Batch [215]#011Speed: 1072.24 samples/sec#011loss=1.023015\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch[220] avg_epoch_loss=0.936657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=0.917330980301\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch [220]#011Speed: 780.77 samples/sec#011loss=0.917331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch[225] avg_epoch_loss=0.935440\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=0.88165627718\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch [225]#011Speed: 1053.20 samples/sec#011loss=0.881656\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch[230] avg_epoch_loss=0.934610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=0.897111260891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch [230]#011Speed: 1067.10 samples/sec#011loss=0.897111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch[235] avg_epoch_loss=0.931454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=0.78561604023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch [235]#011Speed: 727.41 samples/sec#011loss=0.785616\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch[240] avg_epoch_loss=0.928779\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=0.80253790617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch [240]#011Speed: 1081.68 samples/sec#011loss=0.802538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch[245] avg_epoch_loss=0.924625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=0.724383866787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:04 INFO 140074512123712] Epoch[16] Batch [245]#011Speed: 774.72 samples/sec#011loss=0.724384\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch[250] avg_epoch_loss=0.922432\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=0.814570462704\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch [250]#011Speed: 1077.75 samples/sec#011loss=0.814570\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch[255] avg_epoch_loss=0.922155\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=0.908229005337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch [255]#011Speed: 769.55 samples/sec#011loss=0.908229\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch[260] avg_epoch_loss=0.926908\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=1.17024288177\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch [260]#011Speed: 1070.02 samples/sec#011loss=1.170243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch[265] avg_epoch_loss=0.927219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=0.943454349041\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch [265]#011Speed: 767.92 samples/sec#011loss=0.943454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch[270] avg_epoch_loss=0.928229\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=270 train loss <loss>=0.981999242306\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:05 INFO 140074512123712] Epoch[16] Batch [270]#011Speed: 1075.57 samples/sec#011loss=0.981999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch[275] avg_epoch_loss=0.927437\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=275 train loss <loss>=0.884501767159\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch [275]#011Speed: 789.59 samples/sec#011loss=0.884502\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch[280] avg_epoch_loss=0.925651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=280 train loss <loss>=0.827065324783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch [280]#011Speed: 1067.56 samples/sec#011loss=0.827065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch[285] avg_epoch_loss=0.924851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=285 train loss <loss>=0.879852044582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch [285]#011Speed: 785.52 samples/sec#011loss=0.879852\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch[290] avg_epoch_loss=0.922157\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=290 train loss <loss>=0.768073451519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch [290]#011Speed: 1079.67 samples/sec#011loss=0.768073\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch[295] avg_epoch_loss=0.918620\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=295 train loss <loss>=0.712788009644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch [295]#011Speed: 778.02 samples/sec#011loss=0.712788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch[300] avg_epoch_loss=0.915488\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=300 train loss <loss>=0.73007184267\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:06 INFO 140074512123712] Epoch[16] Batch [300]#011Speed: 1075.17 samples/sec#011loss=0.730072\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch[305] avg_epoch_loss=0.950686\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=305 train loss <loss>=3.06962124109\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch [305]#011Speed: 697.63 samples/sec#011loss=3.069621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch[310] avg_epoch_loss=0.951272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=310 train loss <loss>=0.987088549137\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch [310]#011Speed: 869.60 samples/sec#011loss=0.987089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch[315] avg_epoch_loss=0.953034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=315 train loss <loss>=1.06264032125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch [315]#011Speed: 735.79 samples/sec#011loss=1.062640\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch[320] avg_epoch_loss=0.954939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=320 train loss <loss>=1.07537312508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch [320]#011Speed: 996.21 samples/sec#011loss=1.075373\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch[325] avg_epoch_loss=0.956468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=325 train loss <loss>=1.05462491512\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:07 INFO 140074512123712] Epoch[16] Batch [325]#011Speed: 781.53 samples/sec#011loss=1.054625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch[330] avg_epoch_loss=0.956772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=330 train loss <loss>=0.976586151123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch [330]#011Speed: 1055.51 samples/sec#011loss=0.976586\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch[335] avg_epoch_loss=0.956333\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=335 train loss <loss>=0.92725071907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch [335]#011Speed: 1064.27 samples/sec#011loss=0.927251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch[340] avg_epoch_loss=0.956468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=340 train loss <loss>=0.965555953979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch [340]#011Speed: 759.95 samples/sec#011loss=0.965556\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch[345] avg_epoch_loss=0.955570\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=345 train loss <loss>=0.894290077686\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch [345]#011Speed: 1076.22 samples/sec#011loss=0.894290\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch[350] avg_epoch_loss=0.954736\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=350 train loss <loss>=0.897058987617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch [350]#011Speed: 794.42 samples/sec#011loss=0.897059\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch[355] avg_epoch_loss=0.952798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=355 train loss <loss>=0.81674785614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:08 INFO 140074512123712] Epoch[16] Batch [355]#011Speed: 801.74 samples/sec#011loss=0.816748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch[360] avg_epoch_loss=0.950027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=360 train loss <loss>=0.752748072147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch [360]#011Speed: 1067.49 samples/sec#011loss=0.752748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch[365] avg_epoch_loss=0.947672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=365 train loss <loss>=0.777594184875\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch [365]#011Speed: 778.97 samples/sec#011loss=0.777594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch[370] avg_epoch_loss=0.946657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=370 train loss <loss>=0.872390830517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch [370]#011Speed: 1034.34 samples/sec#011loss=0.872391\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch[375] avg_epoch_loss=0.947454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=375 train loss <loss>=1.0066157937\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch [375]#011Speed: 772.27 samples/sec#011loss=1.006616\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch[380] avg_epoch_loss=0.948222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=380 train loss <loss>=1.00595331192\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:09 INFO 140074512123712] Epoch[16] Batch [380]#011Speed: 1073.83 samples/sec#011loss=1.005953\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch[385] avg_epoch_loss=0.947161\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=385 train loss <loss>=0.866279542446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch [385]#011Speed: 773.57 samples/sec#011loss=0.866280\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch[390] avg_epoch_loss=0.950634\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=390 train loss <loss>=1.21878809929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch [390]#011Speed: 1076.90 samples/sec#011loss=1.218788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch[395] avg_epoch_loss=0.949218\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=395 train loss <loss>=0.838462162018\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch [395]#011Speed: 787.91 samples/sec#011loss=0.838462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch[400] avg_epoch_loss=0.947078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=400 train loss <loss>=0.777590930462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch [400]#011Speed: 1061.59 samples/sec#011loss=0.777591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch[405] avg_epoch_loss=0.945343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=405 train loss <loss>=0.806190276146\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch [405]#011Speed: 765.35 samples/sec#011loss=0.806190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch[410] avg_epoch_loss=0.943383\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=410 train loss <loss>=0.784244287014\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:10 INFO 140074512123712] Epoch[16] Batch [410]#011Speed: 1074.24 samples/sec#011loss=0.784244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch[415] avg_epoch_loss=0.941433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=415 train loss <loss>=0.781143343449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch [415]#011Speed: 794.22 samples/sec#011loss=0.781143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch[420] avg_epoch_loss=0.946206\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=420 train loss <loss>=1.34334914684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch [420]#011Speed: 1066.95 samples/sec#011loss=1.343349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch[425] avg_epoch_loss=0.946304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=425 train loss <loss>=0.95453568697\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch [425]#011Speed: 768.05 samples/sec#011loss=0.954536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch[430] avg_epoch_loss=0.947257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=430 train loss <loss>=1.02846330404\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch [430]#011Speed: 1068.54 samples/sec#011loss=1.028463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch[435] avg_epoch_loss=0.947889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=435 train loss <loss>=1.00238128901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch [435]#011Speed: 750.32 samples/sec#011loss=1.002381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch[440] avg_epoch_loss=0.946883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=440 train loss <loss>=0.859129738808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:11 INFO 140074512123712] Epoch[16] Batch [440]#011Speed: 1067.88 samples/sec#011loss=0.859130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch[445] avg_epoch_loss=0.946574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=445 train loss <loss>=0.919348883629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch [445]#011Speed: 1087.58 samples/sec#011loss=0.919349\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch[450] avg_epoch_loss=0.945466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=450 train loss <loss>=0.846616327763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch [450]#011Speed: 689.06 samples/sec#011loss=0.846616\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch[455] avg_epoch_loss=0.944532\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=455 train loss <loss>=0.860268211365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch [455]#011Speed: 1055.46 samples/sec#011loss=0.860268\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch[460] avg_epoch_loss=0.943554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=460 train loss <loss>=0.854328978062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch [460]#011Speed: 774.57 samples/sec#011loss=0.854329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch[465] avg_epoch_loss=0.943927\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=465 train loss <loss>=0.978314208984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:12 INFO 140074512123712] Epoch[16] Batch [465]#011Speed: 996.84 samples/sec#011loss=0.978314\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch[470] avg_epoch_loss=0.943820\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=470 train loss <loss>=0.933846580982\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch [470]#011Speed: 776.82 samples/sec#011loss=0.933847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch[475] avg_epoch_loss=0.944641\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=475 train loss <loss>=1.02197854519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch [475]#011Speed: 1062.71 samples/sec#011loss=1.021979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch[480] avg_epoch_loss=0.943923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=480 train loss <loss>=0.875564730167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch [480]#011Speed: 766.19 samples/sec#011loss=0.875565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch[485] avg_epoch_loss=0.947562\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=485 train loss <loss>=1.29768373966\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch [485]#011Speed: 1083.00 samples/sec#011loss=1.297684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch[490] avg_epoch_loss=0.946884\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=490 train loss <loss>=0.881010425091\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch [490]#011Speed: 764.89 samples/sec#011loss=0.881010\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch[495] avg_epoch_loss=0.945763\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=495 train loss <loss>=0.835626447201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:13 INFO 140074512123712] Epoch[16] Batch [495]#011Speed: 1076.06 samples/sec#011loss=0.835626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch[500] avg_epoch_loss=0.944413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=500 train loss <loss>=0.810515224934\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch [500]#011Speed: 784.64 samples/sec#011loss=0.810515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch[505] avg_epoch_loss=0.943128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=505 train loss <loss>=0.814360570908\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch [505]#011Speed: 1100.32 samples/sec#011loss=0.814361\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch[510] avg_epoch_loss=0.942098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=510 train loss <loss>=0.83789306879\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch [510]#011Speed: 799.27 samples/sec#011loss=0.837893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch[515] avg_epoch_loss=0.941133\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=515 train loss <loss>=0.842448616028\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch [515]#011Speed: 1063.01 samples/sec#011loss=0.842449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch[520] avg_epoch_loss=0.939979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=520 train loss <loss>=0.820901322365\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch [520]#011Speed: 776.24 samples/sec#011loss=0.820901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:14 INFO 140074512123712] Epoch[16] Batch[525] avg_epoch_loss=0.938555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=525 train loss <loss>=0.790176093578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch [525]#011Speed: 1054.96 samples/sec#011loss=0.790176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch[530] avg_epoch_loss=0.936657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=530 train loss <loss>=0.737036180496\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch [530]#011Speed: 786.80 samples/sec#011loss=0.737036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch[535] avg_epoch_loss=0.934391\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=535 train loss <loss>=0.693719816208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch [535]#011Speed: 1051.66 samples/sec#011loss=0.693720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch[540] avg_epoch_loss=0.934692\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=540 train loss <loss>=0.966918194294\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch [540]#011Speed: 779.45 samples/sec#011loss=0.966918\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch[545] avg_epoch_loss=0.936329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=545 train loss <loss>=1.11347734928\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch [545]#011Speed: 1085.75 samples/sec#011loss=1.113477\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch[550] avg_epoch_loss=0.934379\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=550 train loss <loss>=0.7213996768\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:15 INFO 140074512123712] Epoch[16] Batch [550]#011Speed: 771.19 samples/sec#011loss=0.721400\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[16] Batch[555] avg_epoch_loss=0.934757\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=555 train loss <loss>=0.976419258118\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[16] Batch [555]#011Speed: 1067.97 samples/sec#011loss=0.976419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[16] Batch[560] avg_epoch_loss=0.934256\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, batch=560 train loss <loss>=0.878555345535\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[16] Batch [560]#011Speed: 916.12 samples/sec#011loss=0.878555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] processed a total of 17981 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20453.033924102783, \"sum\": 20453.033924102783, \"min\": 20453.033924102783}}, \"EndTime\": 1589445316.272649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445295.81918}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=879.127683649 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=16, train loss <loss>=0.933896571292\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_16d4354d-83b4-4365-a7c2-5aeb23a55b8a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.332895278930664, \"sum\": 9.332895278930664, \"min\": 9.332895278930664}}, \"EndTime\": 1589445316.28288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445316.272776}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch[0] avg_epoch_loss=0.803108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=0.803108334541\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch[5] avg_epoch_loss=0.823575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=0.823575258255\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch [5]#011Speed: 1078.28 samples/sec#011loss=0.823575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch[10] avg_epoch_loss=0.851597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=0.885222053528\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch [10]#011Speed: 800.92 samples/sec#011loss=0.885222\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch[15] avg_epoch_loss=0.860768\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=0.880946016312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:16 INFO 140074512123712] Epoch[17] Batch [15]#011Speed: 1039.22 samples/sec#011loss=0.880946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch[20] avg_epoch_loss=0.846772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=0.801985418797\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch [20]#011Speed: 771.90 samples/sec#011loss=0.801985\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch[25] avg_epoch_loss=0.837963\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=0.800962936878\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch [25]#011Speed: 1074.98 samples/sec#011loss=0.800963\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch[30] avg_epoch_loss=0.847838\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=0.89918769598\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch [30]#011Speed: 644.48 samples/sec#011loss=0.899188\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch[35] avg_epoch_loss=0.863070\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=0.957510256767\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch [35]#011Speed: 1057.97 samples/sec#011loss=0.957510\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch[40] avg_epoch_loss=0.860574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=0.84260289669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch [40]#011Speed: 764.81 samples/sec#011loss=0.842603\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch[45] avg_epoch_loss=0.868434\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=0.932880663872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:17 INFO 140074512123712] Epoch[17] Batch [45]#011Speed: 1082.76 samples/sec#011loss=0.932881\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch[50] avg_epoch_loss=0.874590\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=0.931228303909\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch [50]#011Speed: 795.64 samples/sec#011loss=0.931228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch[55] avg_epoch_loss=0.883938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=0.979287397861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch [55]#011Speed: 1078.41 samples/sec#011loss=0.979287\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch[60] avg_epoch_loss=0.896828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=1.04120131731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch [60]#011Speed: 767.14 samples/sec#011loss=1.041201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch[65] avg_epoch_loss=0.920292\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=1.20654320717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch [65]#011Speed: 1078.27 samples/sec#011loss=1.206543\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch[70] avg_epoch_loss=0.925092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=0.988461887836\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:18 INFO 140074512123712] Epoch[17] Batch [70]#011Speed: 779.96 samples/sec#011loss=0.988462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch[75] avg_epoch_loss=0.924865\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=0.92164400816\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch [75]#011Speed: 1074.87 samples/sec#011loss=0.921644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch[80] avg_epoch_loss=0.920252\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=0.850128436089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch [80]#011Speed: 773.53 samples/sec#011loss=0.850128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch[85] avg_epoch_loss=0.918057\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=0.882490861416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch [85]#011Speed: 1085.08 samples/sec#011loss=0.882491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch[90] avg_epoch_loss=0.911284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=0.794791591167\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch [90]#011Speed: 752.70 samples/sec#011loss=0.794792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch[95] avg_epoch_loss=0.907189\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=0.832661616802\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch [95]#011Speed: 1052.66 samples/sec#011loss=0.832662\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch[100] avg_epoch_loss=0.933739\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=1.4435084939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:19 INFO 140074512123712] Epoch[17] Batch [100]#011Speed: 755.39 samples/sec#011loss=1.443508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch[105] avg_epoch_loss=0.931104\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=0.877859663963\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch [105]#011Speed: 1022.29 samples/sec#011loss=0.877860\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch[110] avg_epoch_loss=0.926835\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=0.836335027218\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch [110]#011Speed: 794.26 samples/sec#011loss=0.836335\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch[115] avg_epoch_loss=0.984452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=2.26354874372\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch [115]#011Speed: 1054.59 samples/sec#011loss=2.263549\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch[120] avg_epoch_loss=0.979274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=0.85914798975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch [120]#011Speed: 787.70 samples/sec#011loss=0.859148\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch[125] avg_epoch_loss=0.978128\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=0.950396692753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch [125]#011Speed: 1003.14 samples/sec#011loss=0.950397\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch[130] avg_epoch_loss=0.976575\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=0.93744635582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:20 INFO 140074512123712] Epoch[17] Batch [130]#011Speed: 1072.72 samples/sec#011loss=0.937446\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch[135] avg_epoch_loss=0.975828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=0.956257927418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch [135]#011Speed: 731.61 samples/sec#011loss=0.956258\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch[140] avg_epoch_loss=0.982986\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=1.17766948938\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch [140]#011Speed: 1073.94 samples/sec#011loss=1.177669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch[145] avg_epoch_loss=0.978290\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=0.845870745182\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch [145]#011Speed: 795.70 samples/sec#011loss=0.845871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch[150] avg_epoch_loss=0.975498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=0.893982839584\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch [150]#011Speed: 1078.31 samples/sec#011loss=0.893983\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch[155] avg_epoch_loss=0.971301\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=0.8445327878\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:21 INFO 140074512123712] Epoch[17] Batch [155]#011Speed: 759.67 samples/sec#011loss=0.844533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch[160] avg_epoch_loss=0.966560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=0.818647873402\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch [160]#011Speed: 1025.21 samples/sec#011loss=0.818648\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch[165] avg_epoch_loss=0.963952\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=0.879981672764\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch [165]#011Speed: 804.43 samples/sec#011loss=0.879982\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch[170] avg_epoch_loss=0.959100\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=0.79800555706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch [170]#011Speed: 835.42 samples/sec#011loss=0.798006\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch[175] avg_epoch_loss=0.953751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=0.770816874504\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch [175]#011Speed: 787.83 samples/sec#011loss=0.770817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch[180] avg_epoch_loss=0.948853\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=0.776452636719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:22 INFO 140074512123712] Epoch[17] Batch [180]#011Speed: 1022.57 samples/sec#011loss=0.776453\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch[185] avg_epoch_loss=0.950159\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=0.997419857979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch [185]#011Speed: 789.31 samples/sec#011loss=0.997420\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch[190] avg_epoch_loss=0.949302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=0.917415738106\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch [190]#011Speed: 1080.22 samples/sec#011loss=0.917416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch[195] avg_epoch_loss=0.952215\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=1.06351099014\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch [195]#011Speed: 764.11 samples/sec#011loss=1.063511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch[200] avg_epoch_loss=0.951652\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=0.929594159126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch [200]#011Speed: 1094.54 samples/sec#011loss=0.929594\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch[205] avg_epoch_loss=0.956223\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=1.13997123241\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch [205]#011Speed: 797.51 samples/sec#011loss=1.139971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch[210] avg_epoch_loss=0.960534\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=1.1381352067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:23 INFO 140074512123712] Epoch[17] Batch [210]#011Speed: 1042.15 samples/sec#011loss=1.138135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch[215] avg_epoch_loss=0.958907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=0.890243971348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch [215]#011Speed: 780.80 samples/sec#011loss=0.890244\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch[220] avg_epoch_loss=0.955789\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=0.821098220348\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch [220]#011Speed: 1079.63 samples/sec#011loss=0.821098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch[225] avg_epoch_loss=0.953004\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=0.829907476902\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch [225]#011Speed: 790.56 samples/sec#011loss=0.829907\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch[230] avg_epoch_loss=0.952538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=0.931453895569\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch [230]#011Speed: 1081.02 samples/sec#011loss=0.931454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch[235] avg_epoch_loss=0.950552\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=0.858804035187\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch [235]#011Speed: 775.42 samples/sec#011loss=0.858804\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch[240] avg_epoch_loss=0.946783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=0.76890386343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:24 INFO 140074512123712] Epoch[17] Batch [240]#011Speed: 1041.17 samples/sec#011loss=0.768904\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch[245] avg_epoch_loss=0.941522\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=0.687956500053\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch [245]#011Speed: 792.44 samples/sec#011loss=0.687957\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch[250] avg_epoch_loss=0.938809\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=0.805301737785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch [250]#011Speed: 1041.21 samples/sec#011loss=0.805302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch[255] avg_epoch_loss=0.940788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=1.04015864134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch [255]#011Speed: 741.30 samples/sec#011loss=1.040159\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch[260] avg_epoch_loss=0.942654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=1.03819321394\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch [260]#011Speed: 1077.96 samples/sec#011loss=1.038193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch[265] avg_epoch_loss=0.951378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=1.40674421787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:25 INFO 140074512123712] Epoch[17] Batch [265]#011Speed: 769.92 samples/sec#011loss=1.406744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch[270] avg_epoch_loss=0.949452\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=270 train loss <loss>=0.847000420094\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch [270]#011Speed: 1066.59 samples/sec#011loss=0.847000\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch[275] avg_epoch_loss=0.949382\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=275 train loss <loss>=0.945601630211\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch [275]#011Speed: 767.56 samples/sec#011loss=0.945602\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch[280] avg_epoch_loss=0.948460\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=280 train loss <loss>=0.897572565079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch [280]#011Speed: 1082.17 samples/sec#011loss=0.897573\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch[285] avg_epoch_loss=0.946738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=285 train loss <loss>=0.849930417538\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch [285]#011Speed: 797.05 samples/sec#011loss=0.849930\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch[290] avg_epoch_loss=0.943970\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=290 train loss <loss>=0.785656785965\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch [290]#011Speed: 1082.26 samples/sec#011loss=0.785657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch[295] avg_epoch_loss=0.943000\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=295 train loss <loss>=0.886548435688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:26 INFO 140074512123712] Epoch[17] Batch [295]#011Speed: 771.71 samples/sec#011loss=0.886548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch[300] avg_epoch_loss=0.940738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=300 train loss <loss>=0.80683324337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch [300]#011Speed: 1081.31 samples/sec#011loss=0.806833\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch[305] avg_epoch_loss=0.939529\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=305 train loss <loss>=0.866745078564\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch [305]#011Speed: 800.14 samples/sec#011loss=0.866745\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch[310] avg_epoch_loss=0.936995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=310 train loss <loss>=0.781898903847\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch [310]#011Speed: 1092.63 samples/sec#011loss=0.781899\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch[315] avg_epoch_loss=0.936110\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=315 train loss <loss>=0.881080448627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch [315]#011Speed: 622.04 samples/sec#011loss=0.881080\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch[320] avg_epoch_loss=0.934085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=320 train loss <loss>=0.806111776829\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:27 INFO 140074512123712] Epoch[17] Batch [320]#011Speed: 1087.37 samples/sec#011loss=0.806112\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch[325] avg_epoch_loss=0.932155\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=325 train loss <loss>=0.808213543892\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch [325]#011Speed: 762.49 samples/sec#011loss=0.808214\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch[330] avg_epoch_loss=0.931386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=330 train loss <loss>=0.881241643429\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch [330]#011Speed: 1070.89 samples/sec#011loss=0.881242\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch[335] avg_epoch_loss=0.930689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=335 train loss <loss>=0.884575819969\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch [335]#011Speed: 770.90 samples/sec#011loss=0.884576\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch[340] avg_epoch_loss=0.928092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=340 train loss <loss>=0.753539586067\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch [340]#011Speed: 1029.61 samples/sec#011loss=0.753540\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch[345] avg_epoch_loss=0.928243\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=345 train loss <loss>=0.938559532166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch [345]#011Speed: 782.27 samples/sec#011loss=0.938560\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch[350] avg_epoch_loss=0.928563\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=350 train loss <loss>=0.950707447529\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:28 INFO 140074512123712] Epoch[17] Batch [350]#011Speed: 980.28 samples/sec#011loss=0.950707\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch[355] avg_epoch_loss=0.926900\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=355 train loss <loss>=0.810190951824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch [355]#011Speed: 745.75 samples/sec#011loss=0.810191\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch[360] avg_epoch_loss=0.925524\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=360 train loss <loss>=0.827519249916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch [360]#011Speed: 1065.35 samples/sec#011loss=0.827519\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch[365] avg_epoch_loss=0.924606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=365 train loss <loss>=0.858352589607\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch [365]#011Speed: 785.46 samples/sec#011loss=0.858353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch[370] avg_epoch_loss=0.922031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=370 train loss <loss>=0.733517813683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch [370]#011Speed: 1073.84 samples/sec#011loss=0.733518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch[375] avg_epoch_loss=0.920759\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=375 train loss <loss>=0.826386594772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:29 INFO 140074512123712] Epoch[17] Batch [375]#011Speed: 725.14 samples/sec#011loss=0.826387\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch[380] avg_epoch_loss=0.920469\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=380 train loss <loss>=0.898622775078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch [380]#011Speed: 1009.32 samples/sec#011loss=0.898623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch[385] avg_epoch_loss=0.920992\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=385 train loss <loss>=0.960895061493\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch [385]#011Speed: 792.90 samples/sec#011loss=0.960895\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch[390] avg_epoch_loss=0.924383\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=390 train loss <loss>=1.18616617918\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch [390]#011Speed: 1077.94 samples/sec#011loss=1.186166\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch[395] avg_epoch_loss=0.923788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=395 train loss <loss>=0.877219951153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch [395]#011Speed: 789.65 samples/sec#011loss=0.877220\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch[400] avg_epoch_loss=0.924127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=400 train loss <loss>=0.951022660732\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch [400]#011Speed: 1061.11 samples/sec#011loss=0.951023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch[405] avg_epoch_loss=0.923232\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=405 train loss <loss>=0.851418244839\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:30 INFO 140074512123712] Epoch[17] Batch [405]#011Speed: 778.87 samples/sec#011loss=0.851418\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch[410] avg_epoch_loss=0.922436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=410 train loss <loss>=0.857787048817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch [410]#011Speed: 1086.47 samples/sec#011loss=0.857787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch[415] avg_epoch_loss=0.926557\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=415 train loss <loss>=1.26531486511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch [415]#011Speed: 796.25 samples/sec#011loss=1.265315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch[420] avg_epoch_loss=0.930454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=420 train loss <loss>=1.25465364456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch [420]#011Speed: 1085.25 samples/sec#011loss=1.254654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch[425] avg_epoch_loss=0.929990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=425 train loss <loss>=0.890990316868\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch [425]#011Speed: 770.62 samples/sec#011loss=0.890990\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch[430] avg_epoch_loss=0.929719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=430 train loss <loss>=0.906582915783\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:31 INFO 140074512123712] Epoch[17] Batch [430]#011Speed: 1088.62 samples/sec#011loss=0.906583\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch[435] avg_epoch_loss=0.928658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=435 train loss <loss>=0.837208604813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch [435]#011Speed: 750.82 samples/sec#011loss=0.837209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch[440] avg_epoch_loss=0.927820\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=440 train loss <loss>=0.854724407196\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch [440]#011Speed: 758.31 samples/sec#011loss=0.854724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch[445] avg_epoch_loss=0.926375\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=445 train loss <loss>=0.79899302721\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch [445]#011Speed: 758.47 samples/sec#011loss=0.798993\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch[450] avg_epoch_loss=0.924559\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=450 train loss <loss>=0.762513506413\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch [450]#011Speed: 948.96 samples/sec#011loss=0.762514\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch[455] avg_epoch_loss=0.923425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=455 train loss <loss>=0.821125888824\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch [455]#011Speed: 747.92 samples/sec#011loss=0.821126\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch[460] avg_epoch_loss=0.922153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=460 train loss <loss>=0.80618185997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:32 INFO 140074512123712] Epoch[17] Batch [460]#011Speed: 1039.14 samples/sec#011loss=0.806182\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch[465] avg_epoch_loss=0.922190\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=465 train loss <loss>=0.925647008419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch [465]#011Speed: 792.69 samples/sec#011loss=0.925647\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch[470] avg_epoch_loss=0.920650\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=470 train loss <loss>=0.777053642273\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch [470]#011Speed: 1076.28 samples/sec#011loss=0.777054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch[475] avg_epoch_loss=0.918893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=475 train loss <loss>=0.75343580246\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch [475]#011Speed: 778.18 samples/sec#011loss=0.753436\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch[480] avg_epoch_loss=0.917743\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=480 train loss <loss>=0.80826818943\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch [480]#011Speed: 1060.21 samples/sec#011loss=0.808268\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch[485] avg_epoch_loss=0.917671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=485 train loss <loss>=0.910717248917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:33 INFO 140074512123712] Epoch[17] Batch [485]#011Speed: 792.37 samples/sec#011loss=0.910717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch[490] avg_epoch_loss=0.915712\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=490 train loss <loss>=0.725291240215\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch [490]#011Speed: 1031.29 samples/sec#011loss=0.725291\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch[495] avg_epoch_loss=0.914281\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=495 train loss <loss>=0.773754906654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch [495]#011Speed: 758.91 samples/sec#011loss=0.773755\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch[500] avg_epoch_loss=0.912528\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=500 train loss <loss>=0.738605570793\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch [500]#011Speed: 1070.20 samples/sec#011loss=0.738606\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch[505] avg_epoch_loss=0.910342\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=505 train loss <loss>=0.691369926929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch [505]#011Speed: 758.72 samples/sec#011loss=0.691370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch[510] avg_epoch_loss=0.908995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=510 train loss <loss>=0.772619378567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch [510]#011Speed: 1019.31 samples/sec#011loss=0.772619\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch[515] avg_epoch_loss=0.906636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=515 train loss <loss>=0.665553998947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:34 INFO 140074512123712] Epoch[17] Batch [515]#011Speed: 792.04 samples/sec#011loss=0.665554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch[520] avg_epoch_loss=0.904887\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=520 train loss <loss>=0.724421989918\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch [520]#011Speed: 1017.02 samples/sec#011loss=0.724422\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch[525] avg_epoch_loss=0.902947\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=525 train loss <loss>=0.700828111172\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch [525]#011Speed: 795.95 samples/sec#011loss=0.700828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch[530] avg_epoch_loss=0.901515\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=530 train loss <loss>=0.750857448578\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch [530]#011Speed: 1089.33 samples/sec#011loss=0.750857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch[535] avg_epoch_loss=0.900544\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=535 train loss <loss>=0.797424674034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch [535]#011Speed: 796.70 samples/sec#011loss=0.797425\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch[540] avg_epoch_loss=0.903129\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=540 train loss <loss>=1.18021959066\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:35 INFO 140074512123712] Epoch[17] Batch [540]#011Speed: 1092.42 samples/sec#011loss=1.180220\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[17] Batch[545] avg_epoch_loss=0.902363\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=545 train loss <loss>=0.819456613064\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[17] Batch [545]#011Speed: 774.77 samples/sec#011loss=0.819457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[17] Batch[550] avg_epoch_loss=0.900308\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=550 train loss <loss>=0.675948405266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[17] Batch [550]#011Speed: 1084.85 samples/sec#011loss=0.675948\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[17] Batch[555] avg_epoch_loss=0.899180\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, batch=555 train loss <loss>=0.774784624577\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[17] Batch [555]#011Speed: 998.75 samples/sec#011loss=0.774785\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] processed a total of 17853 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20113.21997642517, \"sum\": 20113.21997642517, \"min\": 20113.21997642517}}, \"EndTime\": 1589445336.396242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445316.282936}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=887.620830624 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=17, train loss <loss>=0.898514880608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_027b9a02-0e0c-4a86-9a14-9d4f680067bb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.216070175170898, \"sum\": 9.216070175170898, \"min\": 9.216070175170898}}, \"EndTime\": 1589445336.406163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445336.396307}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch[0] avg_epoch_loss=0.733632\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=0.733631968498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch[5] avg_epoch_loss=0.756419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=0.756419032812\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch [5]#011Speed: 1073.52 samples/sec#011loss=0.756419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch[10] avg_epoch_loss=0.774416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=0.796012997627\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch [10]#011Speed: 793.33 samples/sec#011loss=0.796013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch[15] avg_epoch_loss=0.761039\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=0.731609117985\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:36 INFO 140074512123712] Epoch[18] Batch [15]#011Speed: 1080.19 samples/sec#011loss=0.731609\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch[20] avg_epoch_loss=0.788131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=0.87482714653\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch [20]#011Speed: 775.00 samples/sec#011loss=0.874827\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch[25] avg_epoch_loss=0.812280\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=0.913703036308\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch [25]#011Speed: 1080.32 samples/sec#011loss=0.913703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch[30] avg_epoch_loss=0.852274\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=1.06024500132\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch [30]#011Speed: 793.30 samples/sec#011loss=1.060245\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch[35] avg_epoch_loss=0.856873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=0.885387849808\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch [35]#011Speed: 846.38 samples/sec#011loss=0.885388\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch[40] avg_epoch_loss=0.847380\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=0.779026818275\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:37 INFO 140074512123712] Epoch[18] Batch [40]#011Speed: 788.18 samples/sec#011loss=0.779027\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch[45] avg_epoch_loss=0.844127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=0.817449533939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch [45]#011Speed: 1046.71 samples/sec#011loss=0.817450\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch[50] avg_epoch_loss=0.837867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=0.780279695988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch [50]#011Speed: 789.41 samples/sec#011loss=0.780280\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch[55] avg_epoch_loss=0.835977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=0.816700720787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch [55]#011Speed: 999.57 samples/sec#011loss=0.816701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch[60] avg_epoch_loss=0.826984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=0.726262700558\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch [60]#011Speed: 763.37 samples/sec#011loss=0.726263\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch[65] avg_epoch_loss=0.852572\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=1.16474837065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:38 INFO 140074512123712] Epoch[18] Batch [65]#011Speed: 1051.04 samples/sec#011loss=1.164748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch[70] avg_epoch_loss=0.854117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=0.874504554272\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch [70]#011Speed: 774.58 samples/sec#011loss=0.874505\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch[75] avg_epoch_loss=0.854806\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=0.864595007896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch [75]#011Speed: 1015.28 samples/sec#011loss=0.864595\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch[80] avg_epoch_loss=0.856449\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=0.881418633461\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch [80]#011Speed: 797.64 samples/sec#011loss=0.881419\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch[85] avg_epoch_loss=0.858205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=0.886659145355\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch [85]#011Speed: 1068.56 samples/sec#011loss=0.886659\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch[90] avg_epoch_loss=0.854024\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=0.782097005844\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch [90]#011Speed: 1046.26 samples/sec#011loss=0.782097\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch[95] avg_epoch_loss=0.867849\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=1.11946845055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:39 INFO 140074512123712] Epoch[18] Batch [95]#011Speed: 759.92 samples/sec#011loss=1.119468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch[100] avg_epoch_loss=0.862999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=0.769873416424\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch [100]#011Speed: 1026.86 samples/sec#011loss=0.769873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch[105] avg_epoch_loss=0.883220\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=1.2916842103\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch [105]#011Speed: 807.44 samples/sec#011loss=1.291684\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch[110] avg_epoch_loss=0.880787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=0.82920525074\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch [110]#011Speed: 805.82 samples/sec#011loss=0.829205\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch[115] avg_epoch_loss=0.880981\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=0.885301172733\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch [115]#011Speed: 1062.74 samples/sec#011loss=0.885301\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch[120] avg_epoch_loss=0.877772\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=0.803320097923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch [120]#011Speed: 787.94 samples/sec#011loss=0.803320\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch[125] avg_epoch_loss=0.874214\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=0.788101351261\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:40 INFO 140074512123712] Epoch[18] Batch [125]#011Speed: 1065.36 samples/sec#011loss=0.788101\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch[130] avg_epoch_loss=0.873226\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=0.848349845409\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch [130]#011Speed: 767.89 samples/sec#011loss=0.848350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch[135] avg_epoch_loss=0.869540\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=0.772958230972\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch [135]#011Speed: 1032.97 samples/sec#011loss=0.772958\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch[140] avg_epoch_loss=0.867850\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=0.821873855591\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch [140]#011Speed: 805.70 samples/sec#011loss=0.821874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch[145] avg_epoch_loss=0.863467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=0.739876413345\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch [145]#011Speed: 1074.68 samples/sec#011loss=0.739876\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch[150] avg_epoch_loss=0.858655\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=0.718129217625\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:41 INFO 140074512123712] Epoch[18] Batch [150]#011Speed: 801.09 samples/sec#011loss=0.718129\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch[155] avg_epoch_loss=0.855936\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=0.773840510845\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch [155]#011Speed: 1080.58 samples/sec#011loss=0.773841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch[160] avg_epoch_loss=0.855120\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=0.829657995701\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch [160]#011Speed: 777.83 samples/sec#011loss=0.829658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch[165] avg_epoch_loss=0.857649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=0.93907572031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch [165]#011Speed: 1083.55 samples/sec#011loss=0.939076\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch[170] avg_epoch_loss=0.857858\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=0.864791083336\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch [170]#011Speed: 775.80 samples/sec#011loss=0.864791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch[175] avg_epoch_loss=0.911031\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=2.72956100702\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch [175]#011Speed: 996.86 samples/sec#011loss=2.729561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch[180] avg_epoch_loss=0.912303\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=0.957084965706\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:42 INFO 140074512123712] Epoch[18] Batch [180]#011Speed: 691.34 samples/sec#011loss=0.957085\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch[185] avg_epoch_loss=0.916042\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=1.0513684988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch [185]#011Speed: 1044.46 samples/sec#011loss=1.051368\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch[190] avg_epoch_loss=0.922179\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=1.15048066378\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch [190]#011Speed: 771.08 samples/sec#011loss=1.150481\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch[195] avg_epoch_loss=0.930883\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=1.26338126659\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch [195]#011Speed: 1058.12 samples/sec#011loss=1.263381\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch[200] avg_epoch_loss=0.953843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=1.85387094021\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch [200]#011Speed: 758.80 samples/sec#011loss=1.853871\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch[205] avg_epoch_loss=0.958790\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=1.15766680241\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:43 INFO 140074512123712] Epoch[18] Batch [205]#011Speed: 1066.19 samples/sec#011loss=1.157667\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch[210] avg_epoch_loss=0.962086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=1.09787627459\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch [210]#011Speed: 791.72 samples/sec#011loss=1.097876\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch[215] avg_epoch_loss=0.964123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=1.05006930828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch [215]#011Speed: 1053.74 samples/sec#011loss=1.050069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch[220] avg_epoch_loss=0.962516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=0.893093299866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch [220]#011Speed: 823.76 samples/sec#011loss=0.893093\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch[225] avg_epoch_loss=0.958794\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=0.794295012951\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch [225]#011Speed: 1096.14 samples/sec#011loss=0.794295\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch[230] avg_epoch_loss=0.963623\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=1.1818821311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch [230]#011Speed: 780.02 samples/sec#011loss=1.181882\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch[235] avg_epoch_loss=0.964264\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=0.993888390064\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:44 INFO 140074512123712] Epoch[18] Batch [235]#011Speed: 1013.09 samples/sec#011loss=0.993888\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch[240] avg_epoch_loss=0.960649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=0.790005207062\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch [240]#011Speed: 806.25 samples/sec#011loss=0.790005\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch[245] avg_epoch_loss=0.957648\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=0.813043057919\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch [245]#011Speed: 1018.95 samples/sec#011loss=0.813043\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch[250] avg_epoch_loss=0.958343\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=0.992523384094\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch [250]#011Speed: 799.78 samples/sec#011loss=0.992523\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch[255] avg_epoch_loss=0.955318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=0.803437745571\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch [255]#011Speed: 1062.71 samples/sec#011loss=0.803438\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch[260] avg_epoch_loss=0.952751\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=260 train loss <loss>=0.82134540081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch [260]#011Speed: 817.31 samples/sec#011loss=0.821345\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch[265] avg_epoch_loss=0.951135\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=265 train loss <loss>=0.866753280163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:45 INFO 140074512123712] Epoch[18] Batch [265]#011Speed: 1048.73 samples/sec#011loss=0.866753\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch[270] avg_epoch_loss=0.949744\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=270 train loss <loss>=0.875776278973\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch [270]#011Speed: 720.28 samples/sec#011loss=0.875776\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch[275] avg_epoch_loss=0.947081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=275 train loss <loss>=0.80270472765\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch [275]#011Speed: 1072.98 samples/sec#011loss=0.802705\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch[280] avg_epoch_loss=0.944885\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=280 train loss <loss>=0.823716521263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch [280]#011Speed: 811.56 samples/sec#011loss=0.823717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch[285] avg_epoch_loss=0.944311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=285 train loss <loss>=0.912014889717\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch [285]#011Speed: 1076.38 samples/sec#011loss=0.912015\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch[290] avg_epoch_loss=0.942427\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=290 train loss <loss>=0.834681689739\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:46 INFO 140074512123712] Epoch[18] Batch [290]#011Speed: 778.46 samples/sec#011loss=0.834682\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch[295] avg_epoch_loss=0.942130\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=295 train loss <loss>=0.924842739105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch [295]#011Speed: 1070.85 samples/sec#011loss=0.924843\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch[300] avg_epoch_loss=0.940834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=300 train loss <loss>=0.864125478268\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch [300]#011Speed: 788.58 samples/sec#011loss=0.864125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch[305] avg_epoch_loss=0.942263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=305 train loss <loss>=1.02824628353\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch [305]#011Speed: 1077.80 samples/sec#011loss=1.028246\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch[310] avg_epoch_loss=0.940828\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=310 train loss <loss>=0.852999079227\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch [310]#011Speed: 788.82 samples/sec#011loss=0.852999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch[315] avg_epoch_loss=0.940648\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=315 train loss <loss>=0.92946164608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:47 INFO 140074512123712] Epoch[18] Batch [315]#011Speed: 1078.66 samples/sec#011loss=0.929462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch[320] avg_epoch_loss=0.939683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=320 train loss <loss>=0.878729200363\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch [320]#011Speed: 535.98 samples/sec#011loss=0.878729\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch[325] avg_epoch_loss=0.938582\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=325 train loss <loss>=0.867905151844\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch [325]#011Speed: 1041.58 samples/sec#011loss=0.867905\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch[330] avg_epoch_loss=0.937329\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=330 train loss <loss>=0.855621349812\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch [330]#011Speed: 789.70 samples/sec#011loss=0.855621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch[335] avg_epoch_loss=0.936201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=335 train loss <loss>=0.861507737637\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch [335]#011Speed: 1075.88 samples/sec#011loss=0.861508\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch[340] avg_epoch_loss=0.934201\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=340 train loss <loss>=0.799795472622\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch [340]#011Speed: 785.45 samples/sec#011loss=0.799795\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch[345] avg_epoch_loss=0.932467\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=345 train loss <loss>=0.814229679108\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:48 INFO 140074512123712] Epoch[18] Batch [345]#011Speed: 1091.70 samples/sec#011loss=0.814230\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch[350] avg_epoch_loss=0.930483\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=350 train loss <loss>=0.793170666695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch [350]#011Speed: 780.67 samples/sec#011loss=0.793171\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch[355] avg_epoch_loss=0.928260\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=355 train loss <loss>=0.772219395638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch [355]#011Speed: 1054.99 samples/sec#011loss=0.772219\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch[360] avg_epoch_loss=0.926874\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=360 train loss <loss>=0.828196763992\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch [360]#011Speed: 794.51 samples/sec#011loss=0.828197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch[365] avg_epoch_loss=0.924867\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=365 train loss <loss>=0.779923784733\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch [365]#011Speed: 1075.96 samples/sec#011loss=0.779924\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch[370] avg_epoch_loss=0.923327\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=370 train loss <loss>=0.810636103153\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch [370]#011Speed: 756.13 samples/sec#011loss=0.810636\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch[375] avg_epoch_loss=0.921975\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=375 train loss <loss>=0.821688759327\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:49 INFO 140074512123712] Epoch[18] Batch [375]#011Speed: 1033.40 samples/sec#011loss=0.821689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch[380] avg_epoch_loss=0.919643\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=380 train loss <loss>=0.744208455086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch [380]#011Speed: 776.80 samples/sec#011loss=0.744208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch[385] avg_epoch_loss=0.918738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=385 train loss <loss>=0.84983676672\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch [385]#011Speed: 1003.45 samples/sec#011loss=0.849837\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch[390] avg_epoch_loss=0.918908\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=390 train loss <loss>=0.931988441944\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch [390]#011Speed: 799.80 samples/sec#011loss=0.931988\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch[395] avg_epoch_loss=0.917971\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=395 train loss <loss>=0.844717884064\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch [395]#011Speed: 1049.30 samples/sec#011loss=0.844718\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch[400] avg_epoch_loss=0.915318\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=400 train loss <loss>=0.705209696293\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:50 INFO 140074512123712] Epoch[18] Batch [400]#011Speed: 791.86 samples/sec#011loss=0.705210\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch[405] avg_epoch_loss=0.913980\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=405 train loss <loss>=0.806694400311\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch [405]#011Speed: 1067.93 samples/sec#011loss=0.806694\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch[410] avg_epoch_loss=0.913163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=410 train loss <loss>=0.846791887283\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch [410]#011Speed: 764.82 samples/sec#011loss=0.846792\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch[415] avg_epoch_loss=0.916134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=415 train loss <loss>=1.16030369997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch [415]#011Speed: 1076.40 samples/sec#011loss=1.160304\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch[420] avg_epoch_loss=0.918017\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=420 train loss <loss>=1.07473196983\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch [420]#011Speed: 774.73 samples/sec#011loss=1.074732\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch[425] avg_epoch_loss=0.918838\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=425 train loss <loss>=0.987939167023\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch [425]#011Speed: 1057.39 samples/sec#011loss=0.987939\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch[430] avg_epoch_loss=0.918945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=430 train loss <loss>=0.928121888638\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:51 INFO 140074512123712] Epoch[18] Batch [430]#011Speed: 793.94 samples/sec#011loss=0.928122\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch[435] avg_epoch_loss=0.918756\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=435 train loss <loss>=0.902405178547\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch [435]#011Speed: 1067.75 samples/sec#011loss=0.902405\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch[440] avg_epoch_loss=0.919061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=440 train loss <loss>=0.945655655861\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch [440]#011Speed: 761.34 samples/sec#011loss=0.945656\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch[445] avg_epoch_loss=0.918888\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=445 train loss <loss>=0.903613615036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch [445]#011Speed: 1083.01 samples/sec#011loss=0.903614\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch[450] avg_epoch_loss=0.918688\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=450 train loss <loss>=0.900856733322\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch [450]#011Speed: 814.08 samples/sec#011loss=0.900857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch[455] avg_epoch_loss=0.917530\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=455 train loss <loss>=0.813142383099\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:52 INFO 140074512123712] Epoch[18] Batch [455]#011Speed: 1065.09 samples/sec#011loss=0.813142\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch[460] avg_epoch_loss=0.919251\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=460 train loss <loss>=1.07612500191\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch [460]#011Speed: 649.82 samples/sec#011loss=1.076125\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch[465] avg_epoch_loss=0.918891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=465 train loss <loss>=0.885747683048\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch [465]#011Speed: 1073.56 samples/sec#011loss=0.885748\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch[470] avg_epoch_loss=0.917896\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=470 train loss <loss>=0.825181257725\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch [470]#011Speed: 724.36 samples/sec#011loss=0.825181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch[475] avg_epoch_loss=0.917277\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=475 train loss <loss>=0.858936977386\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch [475]#011Speed: 1063.70 samples/sec#011loss=0.858937\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch[480] avg_epoch_loss=0.915557\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=480 train loss <loss>=0.75184237957\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch [480]#011Speed: 793.42 samples/sec#011loss=0.751842\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch[485] avg_epoch_loss=0.916297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=485 train loss <loss>=0.987472975254\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:53 INFO 140074512123712] Epoch[18] Batch [485]#011Speed: 1074.65 samples/sec#011loss=0.987473\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch[490] avg_epoch_loss=0.918848\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=490 train loss <loss>=1.16678647995\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch [490]#011Speed: 765.76 samples/sec#011loss=1.166786\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch[495] avg_epoch_loss=0.917628\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=495 train loss <loss>=0.79786311388\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch [495]#011Speed: 1007.91 samples/sec#011loss=0.797863\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch[500] avg_epoch_loss=0.915685\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=500 train loss <loss>=0.722867548466\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch [500]#011Speed: 781.78 samples/sec#011loss=0.722868\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch[505] avg_epoch_loss=0.914400\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=505 train loss <loss>=0.78564735651\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch [505]#011Speed: 1059.67 samples/sec#011loss=0.785647\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch[510] avg_epoch_loss=0.912873\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=510 train loss <loss>=0.7583365798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:54 INFO 140074512123712] Epoch[18] Batch [510]#011Speed: 717.78 samples/sec#011loss=0.758337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch[515] avg_epoch_loss=0.911771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=515 train loss <loss>=0.799151933193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch [515]#011Speed: 1058.73 samples/sec#011loss=0.799152\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch[520] avg_epoch_loss=0.910061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=520 train loss <loss>=0.733642053604\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch [520]#011Speed: 762.89 samples/sec#011loss=0.733642\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch[525] avg_epoch_loss=0.907984\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=525 train loss <loss>=0.69155446291\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch [525]#011Speed: 1029.50 samples/sec#011loss=0.691554\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch[530] avg_epoch_loss=0.906929\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=530 train loss <loss>=0.795913910866\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch [530]#011Speed: 790.27 samples/sec#011loss=0.795914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch[535] avg_epoch_loss=0.907617\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=535 train loss <loss>=0.980747139454\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch [535]#011Speed: 1075.25 samples/sec#011loss=0.980747\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch[540] avg_epoch_loss=0.907059\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=540 train loss <loss>=0.847211873531\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:55 INFO 140074512123712] Epoch[18] Batch [540]#011Speed: 792.62 samples/sec#011loss=0.847212\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[18] Batch[545] avg_epoch_loss=0.906616\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=545 train loss <loss>=0.858658003807\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[18] Batch [545]#011Speed: 1060.49 samples/sec#011loss=0.858658\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[18] Batch[550] avg_epoch_loss=0.904851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=550 train loss <loss>=0.712119996548\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[18] Batch [550]#011Speed: 815.37 samples/sec#011loss=0.712120\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[18] Batch[555] avg_epoch_loss=0.903324\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, batch=555 train loss <loss>=0.735080289841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[18] Batch [555]#011Speed: 1076.43 samples/sec#011loss=0.735080\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] processed a total of 17866 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20121.460914611816, \"sum\": 20121.460914611816, \"min\": 20121.460914611816}}, \"EndTime\": 1589445356.527772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445336.406223}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=887.903235165 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=18, train loss <loss>=0.902323533789\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[19] Batch[0] avg_epoch_loss=0.703551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=0.703551411629\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[19] Batch[5] avg_epoch_loss=0.792176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=0.792176137368\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:56 INFO 140074512123712] Epoch[19] Batch [5]#011Speed: 818.24 samples/sec#011loss=0.792176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch[10] avg_epoch_loss=0.750800\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=0.701147770882\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch [10]#011Speed: 960.94 samples/sec#011loss=0.701148\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch[15] avg_epoch_loss=0.796160\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=0.895954370499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch [15]#011Speed: 783.59 samples/sec#011loss=0.895954\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch[20] avg_epoch_loss=0.846236\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=1.00647691488\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch [20]#011Speed: 1044.79 samples/sec#011loss=1.006477\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch[25] avg_epoch_loss=0.865055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=0.944097673893\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch [25]#011Speed: 795.95 samples/sec#011loss=0.944098\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch[30] avg_epoch_loss=0.860084\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=0.834234774113\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch [30]#011Speed: 1070.58 samples/sec#011loss=0.834235\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch[35] avg_epoch_loss=0.851350\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=0.797198903561\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:57 INFO 140074512123712] Epoch[19] Batch [35]#011Speed: 791.57 samples/sec#011loss=0.797199\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch[40] avg_epoch_loss=0.854723\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=0.879008316994\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch [40]#011Speed: 860.89 samples/sec#011loss=0.879008\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch[45] avg_epoch_loss=0.868308\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=0.979702830315\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch [45]#011Speed: 658.47 samples/sec#011loss=0.979703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch[50] avg_epoch_loss=0.862173\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=0.805730581284\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch [50]#011Speed: 1081.59 samples/sec#011loss=0.805731\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch[55] avg_epoch_loss=0.858465\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=0.820640480518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch [55]#011Speed: 788.35 samples/sec#011loss=0.820640\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch[60] avg_epoch_loss=0.860517\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=0.883497488499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:58 INFO 140074512123712] Epoch[19] Batch [60]#011Speed: 1051.04 samples/sec#011loss=0.883497\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch[65] avg_epoch_loss=0.874584\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=1.04620815516\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch [65]#011Speed: 778.98 samples/sec#011loss=1.046208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch[70] avg_epoch_loss=0.874925\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=0.879426121712\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch [70]#011Speed: 1067.71 samples/sec#011loss=0.879426\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch[75] avg_epoch_loss=0.866255\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=0.743134248257\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch [75]#011Speed: 781.10 samples/sec#011loss=0.743134\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch[80] avg_epoch_loss=0.863037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=0.814129340649\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch [80]#011Speed: 1088.72 samples/sec#011loss=0.814129\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch[85] avg_epoch_loss=0.862370\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=0.851565849781\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch [85]#011Speed: 757.98 samples/sec#011loss=0.851566\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch[90] avg_epoch_loss=0.867391\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=0.953752410412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:35:59 INFO 140074512123712] Epoch[19] Batch [90]#011Speed: 1055.51 samples/sec#011loss=0.953752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch[95] avg_epoch_loss=0.861813\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=0.760297966003\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch [95]#011Speed: 751.16 samples/sec#011loss=0.760298\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch[100] avg_epoch_loss=0.854429\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=0.712647378445\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch [100]#011Speed: 1030.88 samples/sec#011loss=0.712647\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch[105] avg_epoch_loss=0.848291\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=0.724300861359\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch [105]#011Speed: 769.21 samples/sec#011loss=0.724301\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch[110] avg_epoch_loss=0.847463\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=0.829923319817\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch [110]#011Speed: 1082.82 samples/sec#011loss=0.829923\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch[115] avg_epoch_loss=0.840709\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=0.69077000618\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:00 INFO 140074512123712] Epoch[19] Batch [115]#011Speed: 778.77 samples/sec#011loss=0.690770\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch[120] avg_epoch_loss=0.842191\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=0.876569581032\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch [120]#011Speed: 1070.16 samples/sec#011loss=0.876570\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch[125] avg_epoch_loss=0.840610\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=0.802357661724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch [125]#011Speed: 812.69 samples/sec#011loss=0.802358\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch[130] avg_epoch_loss=0.837544\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=0.76027803421\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch [130]#011Speed: 1060.07 samples/sec#011loss=0.760278\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch[135] avg_epoch_loss=0.839626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=0.894168758392\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch [135]#011Speed: 743.27 samples/sec#011loss=0.894169\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch[140] avg_epoch_loss=0.836068\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=0.739289057255\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch [140]#011Speed: 1025.66 samples/sec#011loss=0.739289\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch[145] avg_epoch_loss=0.833752\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=0.768433022499\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:01 INFO 140074512123712] Epoch[19] Batch [145]#011Speed: 791.86 samples/sec#011loss=0.768433\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch[150] avg_epoch_loss=0.833654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=0.830806279182\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch [150]#011Speed: 1051.92 samples/sec#011loss=0.830806\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch[155] avg_epoch_loss=0.830430\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=0.733070313931\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch [155]#011Speed: 674.05 samples/sec#011loss=0.733070\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch[160] avg_epoch_loss=0.829102\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=0.787667310238\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch [160]#011Speed: 743.43 samples/sec#011loss=0.787667\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch[165] avg_epoch_loss=0.827997\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=0.79240142107\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch [165]#011Speed: 794.73 samples/sec#011loss=0.792401\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch[170] avg_epoch_loss=0.825735\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=0.75065433979\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:02 INFO 140074512123712] Epoch[19] Batch [170]#011Speed: 1069.68 samples/sec#011loss=0.750654\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch[175] avg_epoch_loss=0.878841\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=2.69506481886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch [175]#011Speed: 792.64 samples/sec#011loss=2.695065\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch[180] avg_epoch_loss=0.884916\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=1.09875861406\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch [180]#011Speed: 796.25 samples/sec#011loss=1.098759\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch[185] avg_epoch_loss=0.892769\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=1.17702412605\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch [185]#011Speed: 729.52 samples/sec#011loss=1.177024\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch[190] avg_epoch_loss=0.898630\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=1.11668293476\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch [190]#011Speed: 1051.14 samples/sec#011loss=1.116683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch[195] avg_epoch_loss=0.903998\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=1.10902246237\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:03 INFO 140074512123712] Epoch[19] Batch [195]#011Speed: 768.81 samples/sec#011loss=1.109022\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch[200] avg_epoch_loss=0.907468\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=1.04350110292\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch [200]#011Speed: 1068.38 samples/sec#011loss=1.043501\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch[205] avg_epoch_loss=0.911796\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=1.0857976079\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch [205]#011Speed: 783.80 samples/sec#011loss=1.085798\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch[210] avg_epoch_loss=0.915412\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=1.06439520121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch [210]#011Speed: 1047.30 samples/sec#011loss=1.064395\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch[215] avg_epoch_loss=0.914302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=0.867437183857\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch [215]#011Speed: 786.99 samples/sec#011loss=0.867437\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch[220] avg_epoch_loss=0.911945\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=0.810147404671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch [220]#011Speed: 1047.86 samples/sec#011loss=0.810147\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch[225] avg_epoch_loss=0.910834\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=0.861691939831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:04 INFO 140074512123712] Epoch[19] Batch [225]#011Speed: 735.97 samples/sec#011loss=0.861692\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch[230] avg_epoch_loss=0.908045\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=0.782012844086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch [230]#011Speed: 1045.12 samples/sec#011loss=0.782013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch[235] avg_epoch_loss=0.904567\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=0.743855214119\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch [235]#011Speed: 753.47 samples/sec#011loss=0.743855\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch[240] avg_epoch_loss=0.916925\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=1.50025607347\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch [240]#011Speed: 1015.13 samples/sec#011loss=1.500256\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch[245] avg_epoch_loss=0.915719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=0.857574343681\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch [245]#011Speed: 782.68 samples/sec#011loss=0.857574\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch[250] avg_epoch_loss=0.913797\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=0.81923006773\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:05 INFO 140074512123712] Epoch[19] Batch [250]#011Speed: 1064.30 samples/sec#011loss=0.819230\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch[255] avg_epoch_loss=0.913597\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=0.90358440876\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch [255]#011Speed: 783.15 samples/sec#011loss=0.903584\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch[260] avg_epoch_loss=0.912886\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=0.876453185081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch [260]#011Speed: 1058.93 samples/sec#011loss=0.876453\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch[265] avg_epoch_loss=0.912766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=0.906517827511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch [265]#011Speed: 743.00 samples/sec#011loss=0.906518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch[270] avg_epoch_loss=0.910716\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=0.801632964611\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch [270]#011Speed: 1063.60 samples/sec#011loss=0.801633\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch[275] avg_epoch_loss=0.908660\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=275 train loss <loss>=0.797242391109\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch [275]#011Speed: 777.33 samples/sec#011loss=0.797242\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch[280] avg_epoch_loss=0.917170\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=280 train loss <loss>=1.38692572117\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:06 INFO 140074512123712] Epoch[19] Batch [280]#011Speed: 1053.35 samples/sec#011loss=1.386926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch[285] avg_epoch_loss=0.915279\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=285 train loss <loss>=0.809006857872\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch [285]#011Speed: 782.42 samples/sec#011loss=0.809007\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch[290] avg_epoch_loss=0.913148\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=290 train loss <loss>=0.791228175163\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch [290]#011Speed: 1062.54 samples/sec#011loss=0.791228\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch[295] avg_epoch_loss=0.911185\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=295 train loss <loss>=0.79698009491\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch [295]#011Speed: 779.37 samples/sec#011loss=0.796980\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch[300] avg_epoch_loss=0.908977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=300 train loss <loss>=0.778239798546\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch [300]#011Speed: 1003.14 samples/sec#011loss=0.778240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch[305] avg_epoch_loss=0.909181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=305 train loss <loss>=0.921441662312\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch [305]#011Speed: 781.54 samples/sec#011loss=0.921442\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch[310] avg_epoch_loss=0.906750\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=310 train loss <loss>=0.758019340038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:07 INFO 140074512123712] Epoch[19] Batch [310]#011Speed: 1054.49 samples/sec#011loss=0.758019\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch[315] avg_epoch_loss=0.905811\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=315 train loss <loss>=0.8473919034\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch [315]#011Speed: 774.96 samples/sec#011loss=0.847392\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch[320] avg_epoch_loss=0.904585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=320 train loss <loss>=0.827091574669\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch [320]#011Speed: 902.90 samples/sec#011loss=0.827092\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch[325] avg_epoch_loss=0.904013\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=325 train loss <loss>=0.867300391197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch [325]#011Speed: 728.84 samples/sec#011loss=0.867300\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch[330] avg_epoch_loss=0.902715\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=330 train loss <loss>=0.818063569069\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch [330]#011Speed: 1067.14 samples/sec#011loss=0.818064\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch[335] avg_epoch_loss=0.900533\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=335 train loss <loss>=0.756093072891\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:08 INFO 140074512123712] Epoch[19] Batch [335]#011Speed: 782.51 samples/sec#011loss=0.756093\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch[340] avg_epoch_loss=0.897812\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=340 train loss <loss>=0.714966738224\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch [340]#011Speed: 1033.99 samples/sec#011loss=0.714967\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch[345] avg_epoch_loss=0.895859\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=345 train loss <loss>=0.762668383121\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch [345]#011Speed: 784.24 samples/sec#011loss=0.762668\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch[350] avg_epoch_loss=0.895036\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=350 train loss <loss>=0.838078308105\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch [350]#011Speed: 1004.55 samples/sec#011loss=0.838078\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch[355] avg_epoch_loss=0.894864\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=355 train loss <loss>=0.882788431644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch [355]#011Speed: 794.54 samples/sec#011loss=0.882788\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch[360] avg_epoch_loss=0.892977\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=360 train loss <loss>=0.758643519878\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:09 INFO 140074512123712] Epoch[19] Batch [360]#011Speed: 1034.07 samples/sec#011loss=0.758644\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch[365] avg_epoch_loss=0.890769\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=365 train loss <loss>=0.731320357323\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch [365]#011Speed: 776.42 samples/sec#011loss=0.731320\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch[370] avg_epoch_loss=0.889527\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=370 train loss <loss>=0.798608088493\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch [370]#011Speed: 1051.76 samples/sec#011loss=0.798608\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch[375] avg_epoch_loss=0.890520\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=375 train loss <loss>=0.964197254181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch [375]#011Speed: 777.71 samples/sec#011loss=0.964197\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch[380] avg_epoch_loss=0.890039\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=380 train loss <loss>=0.853861773014\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch [380]#011Speed: 1034.30 samples/sec#011loss=0.853862\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch[385] avg_epoch_loss=0.889070\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=385 train loss <loss>=0.815239775181\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch [385]#011Speed: 793.29 samples/sec#011loss=0.815240\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch[390] avg_epoch_loss=0.887526\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=390 train loss <loss>=0.768350744247\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:10 INFO 140074512123712] Epoch[19] Batch [390]#011Speed: 1053.07 samples/sec#011loss=0.768351\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch[395] avg_epoch_loss=0.884708\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=395 train loss <loss>=0.66433699131\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch [395]#011Speed: 771.29 samples/sec#011loss=0.664337\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch[400] avg_epoch_loss=0.882822\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=400 train loss <loss>=0.733455789089\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch [400]#011Speed: 1078.52 samples/sec#011loss=0.733456\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch[405] avg_epoch_loss=0.881248\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=405 train loss <loss>=0.755001342297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch [405]#011Speed: 752.97 samples/sec#011loss=0.755001\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch[410] avg_epoch_loss=0.879555\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=410 train loss <loss>=0.742123174667\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch [410]#011Speed: 1072.48 samples/sec#011loss=0.742123\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch[415] avg_epoch_loss=0.884846\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=415 train loss <loss>=1.31969548464\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch [415]#011Speed: 790.33 samples/sec#011loss=1.319695\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch[420] avg_epoch_loss=0.894416\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=420 train loss <loss>=1.69071235657\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:11 INFO 140074512123712] Epoch[19] Batch [420]#011Speed: 1076.24 samples/sec#011loss=1.690712\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch[425] avg_epoch_loss=0.895037\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=425 train loss <loss>=0.947266244888\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch [425]#011Speed: 793.40 samples/sec#011loss=0.947266\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch[430] avg_epoch_loss=0.896599\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=430 train loss <loss>=1.02970303297\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch [430]#011Speed: 1076.44 samples/sec#011loss=1.029703\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch[435] avg_epoch_loss=0.897621\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=435 train loss <loss>=0.985724449158\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch [435]#011Speed: 753.65 samples/sec#011loss=0.985724\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch[440] avg_epoch_loss=0.899209\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=440 train loss <loss>=1.03768898249\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch [440]#011Speed: 1071.75 samples/sec#011loss=1.037689\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch[445] avg_epoch_loss=0.898914\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=445 train loss <loss>=0.872917234898\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:12 INFO 140074512123712] Epoch[19] Batch [445]#011Speed: 788.21 samples/sec#011loss=0.872917\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch[450] avg_epoch_loss=0.898127\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=450 train loss <loss>=0.827926337719\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch [450]#011Speed: 1087.19 samples/sec#011loss=0.827926\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch[455] avg_epoch_loss=0.898302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=455 train loss <loss>=0.914070701599\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch [455]#011Speed: 806.08 samples/sec#011loss=0.914071\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch[460] avg_epoch_loss=0.898511\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=460 train loss <loss>=0.917589306831\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch [460]#011Speed: 1079.83 samples/sec#011loss=0.917589\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch[465] avg_epoch_loss=0.898305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=465 train loss <loss>=0.879259085655\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch [465]#011Speed: 573.35 samples/sec#011loss=0.879259\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch[470] avg_epoch_loss=0.897086\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=470 train loss <loss>=0.783498418331\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch [470]#011Speed: 1061.13 samples/sec#011loss=0.783498\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch[475] avg_epoch_loss=0.896061\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=475 train loss <loss>=0.799525463581\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:13 INFO 140074512123712] Epoch[19] Batch [475]#011Speed: 1052.88 samples/sec#011loss=0.799525\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch[480] avg_epoch_loss=0.898542\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=480 train loss <loss>=1.1346752286\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch [480]#011Speed: 783.61 samples/sec#011loss=1.134675\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch[485] avg_epoch_loss=0.896720\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=485 train loss <loss>=0.721461570263\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch [485]#011Speed: 1083.90 samples/sec#011loss=0.721462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch[490] avg_epoch_loss=0.895261\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=490 train loss <loss>=0.753492248058\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch [490]#011Speed: 772.33 samples/sec#011loss=0.753492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch[495] avg_epoch_loss=0.893940\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=495 train loss <loss>=0.764193165302\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch [495]#011Speed: 1071.94 samples/sec#011loss=0.764193\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch[500] avg_epoch_loss=0.891942\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=500 train loss <loss>=0.693738162518\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:14 INFO 140074512123712] Epoch[19] Batch [500]#011Speed: 751.83 samples/sec#011loss=0.693738\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch[505] avg_epoch_loss=0.889787\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=505 train loss <loss>=0.673836815357\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch [505]#011Speed: 1041.64 samples/sec#011loss=0.673837\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch[510] avg_epoch_loss=0.888143\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=510 train loss <loss>=0.721803450584\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch [510]#011Speed: 780.28 samples/sec#011loss=0.721803\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch[515] avg_epoch_loss=0.886307\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=515 train loss <loss>=0.698626208305\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch [515]#011Speed: 1054.57 samples/sec#011loss=0.698626\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch[520] avg_epoch_loss=0.885028\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=520 train loss <loss>=0.753059184551\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch [520]#011Speed: 738.28 samples/sec#011loss=0.753059\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch[525] avg_epoch_loss=0.883507\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=525 train loss <loss>=0.725012123585\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch [525]#011Speed: 1068.28 samples/sec#011loss=0.725012\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch[530] avg_epoch_loss=0.881671\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=530 train loss <loss>=0.688492333889\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:15 INFO 140074512123712] Epoch[19] Batch [530]#011Speed: 791.02 samples/sec#011loss=0.688492\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch[535] avg_epoch_loss=0.880462\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=535 train loss <loss>=0.752110731602\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch [535]#011Speed: 1067.91 samples/sec#011loss=0.752111\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch[540] avg_epoch_loss=0.880457\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=540 train loss <loss>=0.879946088791\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch [540]#011Speed: 795.40 samples/sec#011loss=0.879946\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch[545] avg_epoch_loss=0.880176\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=545 train loss <loss>=0.849682784081\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch [545]#011Speed: 1076.56 samples/sec#011loss=0.849683\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch[550] avg_epoch_loss=0.881208\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=550 train loss <loss>=0.993982791901\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch [550]#011Speed: 769.79 samples/sec#011loss=0.993983\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch[555] avg_epoch_loss=0.882565\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=555 train loss <loss>=1.03205472231\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch [555]#011Speed: 1076.35 samples/sec#011loss=1.032055\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch[560] avg_epoch_loss=0.881686\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, batch=560 train loss <loss>=0.783998656273\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:16 INFO 140074512123712] Epoch[19] Batch [560]#011Speed: 915.10 samples/sec#011loss=0.783999\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] processed a total of 17990 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 20518.02110671997, \"sum\": 20518.02110671997, \"min\": 20518.02110671997}}, \"EndTime\": 1589445377.046698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445356.52784}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] #throughput_metric: host=algo-1, train throughput=876.784187072 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] #quality_metric: host=algo-1, epoch=19, train loss <loss>=0.881118922314\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/state_6fb7ee5b-62c9-4996-a97b-91b4315391f9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.996891021728516, \"sum\": 9.996891021728516, \"min\": 9.996891021728516}}, \"EndTime\": 1589445377.057435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445377.046767}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Final loss: 0.881118922314 (occurred at epoch 19)\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] #quality_metric: host=algo-1, train final_loss <loss>=0.881118922314\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 WARNING 140074512123712] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 35.771846771240234, \"sum\": 35.771846771240234, \"min\": 35.771846771240234}}, \"EndTime\": 1589445377.094008, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445377.057527}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 60.00995635986328, \"sum\": 60.00995635986328, \"min\": 60.00995635986328}}, \"EndTime\": 1589445377.118184, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445377.094056}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 4.587888717651367, \"sum\": 4.587888717651367, \"min\": 4.587888717651367}}, \"EndTime\": 1589445377.122894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445377.118272}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:17 INFO 140074512123712] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03409385681152344, \"sum\": 0.03409385681152344, \"min\": 0.03409385681152344}}, \"EndTime\": 1589445377.123643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445377.122931}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/14/2020 08:36:20 INFO 140074512123712] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:24 INFO 140074512123712] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:27 INFO 140074512123712] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:31 INFO 140074512123712] Number of test batches scored: 40\u001b[0m\n",
      "\n",
      "2020-05-14 08:36:46 Uploading - Uploading generated training model\n",
      "2020-05-14 08:36:46 Completed - Training job completed\n",
      "\u001b[34m[05/14/2020 08:36:35 INFO 140074512123712] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/numpy/ma/core.py:2785: UserWarning: Warning: converting a masked element to nan.\n",
      "  order=order, subok=True, ndmin=ndmin)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 19131.500005722046, \"sum\": 19131.500005722046, \"min\": 19131.500005722046}}, \"EndTime\": 1589445396.255078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445377.123695}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, RMSE): 5.51593952344\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, mean_absolute_QuantileLoss): 20403.226844618053\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, mean_wQuantileLoss): 0.056332471485142054\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.1]): 0.019505157480392766\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.2]): 0.0347752966346038\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.3]): 0.04746418376689771\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.4]): 0.05795000214176536\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.5]): 0.06611536589701324\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.6]): 0.07177477546332935\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.7]): 0.07436120344488702\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.8]): 0.07238390729335398\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #test_score (algo-1, wQuantileLoss[0.9]): 0.06266235124403526\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.0563324714851\u001b[0m\n",
      "\u001b[34m[05/14/2020 08:36:36 INFO 140074512123712] #quality_metric: host=algo-1, test RMSE <loss>=5.51593952344\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 429267.0450210571, \"sum\": 429267.0450210571, \"min\": 429267.0450210571}, \"setuptime\": {\"count\": 1, \"max\": 9.425878524780273, \"sum\": 9.425878524780273, \"min\": 9.425878524780273}}, \"EndTime\": 1589445396.264777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589445396.255143}\n",
      "\u001b[0m\n",
      "Training seconds: 498\n",
      "Billable seconds: 498\n"
     ]
    }
   ],
   "source": [
    "dar_estimator.fit(inputs=dar_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-battery-deepar-2020-05-14-08-26-43-841'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_job_name = dar_estimator.latest_training_job.name\n",
    "dar_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_instance_type=\"ml.m5.large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-battery-deepar-2020-05-14-08-26-43-841'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=dar_job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=infer_instance_type,\n",
    "    deployment_image=dar_image_name,\n",
    "    role=role\n",
    ")\n",
    "dar_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances.append(train_tss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = {\n",
    "    \"instances\": instances,\n",
    "    \"configuration\": {\n",
    "         \"output_types\": [\"mean\", \"quantiles\"],\n",
    "         \"quantiles\": [\"0.1\",\"0.5\", \"0.9\",\"0.99\",\"0.999\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        1\n",
      "      ],\n",
      "      \"target\": [\n",
      "        76.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        74.0,\n",
      "        74.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        75.0,\n",
      "        73.0,\n",
      "        72.0,\n",
      "        71.0,\n",
      "        71.0,\n",
      "        70.0,\n",
      "        69.0,\n",
      "        69.0,\n",
      "        68.0,\n",
      "        68.0,\n",
      "        67.0,\n",
      "        66.0,\n",
      "        66.0,\n",
      "        65.0,\n",
      "        65.0,\n",
      "        64.0,\n",
      "        64.0,\n",
      "        63.0,\n",
      "        64.0,\n",
      "        65.0,\n",
      "        69.0\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"configuration\": {\n",
      "    \"output_types\": [\n",
      "      \"mean\",\n",
      "      \"quantiles\"\n",
      "    ],\n",
      "    \"quantiles\": [\n",
      "      \"0.1\",\n",
      "      \"0.5\",\n",
      "      \"0.9\",\n",
      "      \"0.99\",\n",
      "      \"0.999\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "inference_json = json.dumps(inference, indent=2)\n",
    "print(inference_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.RealTimePredictor at 0x7fadccda61d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = sagemaker.predictor.RealTimePredictor(\n",
    "    dar_endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    content_type=\"application/json\")\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'quantiles': {'0.1': [68.6882095337,\n",
       "     70.4349746704,\n",
       "     71.1184921265,\n",
       "     70.9644546509],\n",
       "    '0.9': [73.2764511108, 74.948097229, 76.2079391479, 77.1484832764],\n",
       "    '0.99': [75.6390533447, 78.6246871948, 77.9913330078, 80.0468139648],\n",
       "    '0.999': [75.6390533447, 78.6246871948, 77.9913330078, 80.0468139648],\n",
       "    '0.5': [71.0771026611, 72.943572998, 73.5716552734, 74.2535324097]},\n",
       "   'mean': [71.0576934814, 72.8184051514, 73.5401153564, 74.3529968262]}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor.predict(inference_json)\n",
    "prediction = json.loads(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quantiles': {'0.1': [68.6882095337,\n",
       "    70.4349746704,\n",
       "    71.1184921265,\n",
       "    70.9644546509],\n",
       "   '0.9': [73.2764511108, 74.948097229, 76.2079391479, 77.1484832764],\n",
       "   '0.99': [75.6390533447, 78.6246871948, 77.9913330078, 80.0468139648],\n",
       "   '0.999': [75.6390533447, 78.6246871948, 77.9913330078, 80.0468139648],\n",
       "   '0.5': [71.0771026611, 72.943572998, 73.5716552734, 74.2535324097]},\n",
       "  'mean': [71.0576934814, 72.8184051514, 73.5401153564, 74.3529968262]}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = prediction[\"predictions\"]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quantiles': {'0.1': [68.6882095337,\n",
       "   70.4349746704,\n",
       "   71.1184921265,\n",
       "   70.9644546509],\n",
       "  '0.9': [73.2764511108, 74.948097229, 76.2079391479, 77.1484832764],\n",
       "  '0.99': [75.6390533447, 78.6246871948, 77.9913330078, 80.0468139648],\n",
       "  '0.999': [75.6390533447, 78.6246871948, 77.9913330078, 80.0468139648],\n",
       "  '0.5': [71.0771026611, 72.943572998, 73.5716552734, 74.2535324097]},\n",
       " 'mean': [71.0576934814, 72.8184051514, 73.5401153564, 74.3529968262]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred0 = predictions[0]\n",
    "pred0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean = pred0[\"mean\"]\n",
    "quantiles = pred0[\"quantiles\"]\n",
    "q01 = quantiles[\"0.1\"]\n",
    "q90 = quantiles[\"0.9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76., 75., 75., 75.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = sample_test[\"battery\"][0:4].values\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fadccd2aa90>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.grid(which='major', axis='both')\n",
    "\n",
    "ax1.set_ylabel('Actual Battery', color='C0')\n",
    "ax2.set_ylabel('Predicted Battery', color='C1')\n",
    "\n",
    "\n",
    "ax1.plot(actual, color='C0')\n",
    "ax2.plot(mean, color='C1')\n",
    "ax2.plot(q01, color='C2')\n",
    "ax2.plot(q90, color='C2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job! Now let's work on detecting [motor anomalies](mt-motor-anomaly.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

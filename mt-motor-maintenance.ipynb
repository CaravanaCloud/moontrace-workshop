{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>7517a917b42450470661cec1bd4654f8</td>\n",
       "      <td>1335</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1577</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>572ddf9d82d5675ed2db832081b70103</td>\n",
       "      <td>1585</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>b17bbc29ce61265a6212c689a597d4d8</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>19d3c55b134ab7780d2b711211b7cf7c</td>\n",
       "      <td>1286</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA  battery\n",
       "timestamp                                                                    \n",
       "2020-02-22 23:59:59  7517a917b42450470661cec1bd4654f8           1335       73\n",
       "2020-02-22 23:59:59  8e4a851ed2317a249a0903f29d894361           1577       73\n",
       "2020-02-22 23:59:59  572ddf9d82d5675ed2db832081b70103           1585       73\n",
       "2020-02-22 23:59:59  b17bbc29ce61265a6212c689a597d4d8              0       73\n",
       "2020-02-22 23:59:59  19d3c55b134ab7780d2b711211b7cf7c           1286       73"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001495ce5f079703599a94c32dab2b0</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00134c004e33e830e5dbce3355a485b9</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019400877c460d9b66298649162179d</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001e70f66ab7a9d4bd6a5a074f288f0f</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00211448f7814aea70f2c8d5aebd2aa9</th>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  motor_peak_mA  battery\n",
       "device_id                                               \n",
       "0001495ce5f079703599a94c32dab2b0            124      124\n",
       "00134c004e33e830e5dbce3355a485b9            121      121\n",
       "0019400877c460d9b66298649162179d            124      124\n",
       "001e70f66ab7a9d4bd6a5a074f288f0f            109      109\n",
       "00211448f7814aea70f2c8d5aebd2aa9            116      116"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"device_id\").count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8e4a851ed2317a249a0903f29d894361'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_pos = 1\n",
    "sample_device_id = data.iloc[device_pos][\"device_id\"]\n",
    "sample_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data[data[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor = sample_data[\"motor_peak_mA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfe951a0b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "motor.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = data[data[\"motor_peak_mA\"] > 0]\n",
    "hourly = (hourly.groupby(\"device_id\")\n",
    "          .motor_peak_mA\n",
    "          .resample(\"H\")\n",
    "          .max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                         timestamp          \n",
       "0001495ce5f079703599a94c32dab2b0  2020-02-24 15:00:00    1843.0\n",
       "                                  2020-02-24 16:00:00    1906.0\n",
       "                                  2020-02-24 17:00:00    1909.0\n",
       "                                  2020-02-24 18:00:00    1540.0\n",
       "                                  2020-02-24 19:00:00     476.0\n",
       "                                                          ...  \n",
       "fffaee1fbb9c96703850f64d3262e843  2020-02-25 17:00:00    2211.0\n",
       "                                  2020-02-25 18:00:00    1663.0\n",
       "                                  2020-02-25 19:00:00     841.0\n",
       "                                  2020-02-25 20:00:00     650.0\n",
       "                                  2020-02-25 21:00:00     741.0\n",
       "Name: motor_peak_mA, Length: 529940, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly.reset_index().set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-24 15:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 16:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 17:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 18:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>2211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-24 15:00:00  0001495ce5f079703599a94c32dab2b0         1843.0\n",
       "2020-02-24 16:00:00  0001495ce5f079703599a94c32dab2b0         1906.0\n",
       "2020-02-24 17:00:00  0001495ce5f079703599a94c32dab2b0         1909.0\n",
       "2020-02-24 18:00:00  0001495ce5f079703599a94c32dab2b0         1540.0\n",
       "2020-02-24 19:00:00  0001495ce5f079703599a94c32dab2b0          476.0\n",
       "...                                               ...            ...\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843         2211.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843         1663.0\n",
       "2020-02-25 19:00:00  fffaee1fbb9c96703850f64d3262e843          841.0\n",
       "2020-02-25 20:00:00  fffaee1fbb9c96703850f64d3262e843          650.0\n",
       "2020-02-25 21:00:00  fffaee1fbb9c96703850f64d3262e843          741.0\n",
       "\n",
       "[529940 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsample = hourly[hourly[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfe5a3cba8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.tail(12).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfe5a3ca20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEhCAYAAAB2h3f0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztvXmYHGd56Pt7e5+eXTOjXbIl43jDtgxeMZA4ZjGbbQIkLNcYG+IQyA3n3CRcSMgxWcgJl9wk4JBwIBEhD8bEYMBOjhMwi8NibCODbNmWjIUsW5KlGWmkWXt6/84fVdXd09M9XdX78v6ep5/p/rq6qnq+rnq/dxdjDIqiKErv4Wv1CSiKoiitQQWAoihKj6ICQFEUpUdRAaAoitKjqABQFEXpUVQAKIqi9CgqABRFUXoUFQCKoig9igoARVGUHiXQ6hNYjfHxcXP66ae3+jQURVE6ikceeeSEMWai0nZtLQBOP/10du3a1erTUBRF6ShE5Fk326kJSFEUpUdRAaAoitKjqABQFEXpUdraB6B0JqlUisOHDxOPx1t9KkqNRCIRNm/eTDAYbPWpKA1ABYBSdw4fPszg4CCnn346ItLq01GqxBjD9PQ0hw8fZtu2ba0+HaUBqAlIqTvxeJyxsTG9+Xc4IsLY2Jhqcl2MCgClIejNvzvQeexuVAAoirIq8/EUP33uVKtPQ2kAKgAURVmVuXiab/zsSKtPQ2kAKgAUpYj777+fBx54oNWnsYKBgYGG7HfHjh289a1vLfmeMQZj4FQs1ZBjK61FBYCiFFGNAEin0w06m8ayd+9eMpkMP/jBD1hcXFzxvjHW35lYsslnpjQDDQNVGsqf/NsTPPn8XF33ee7GIW59w3mrbnPw4EGuueYaLr/8ch544AEuueQSbrrpJm699Vampqa4/fbbecELXsDNN9/MgQMHiEajfPazn2VoaIjPfOYz+P1+vvjFL3LbbbexZcsWbr75Zk6cOMHExASf//zn2bp1K+9617uIRCL87Gc/48orr+Sv//qvV5zHRz/6UX7xi1+wf/9+Tpw4wQc/+EF+8zd/E4BPfOIT3HnnnSQSCd74xjfyJ3/yJwBcf/31HDp0iHg8zgc+8AFuueWWZfs8ceIEb3jDG/jIRz7C6173uhXHvP/++7n11lsZGRlhz549/Pqv/zrnn38+n/zkJ1laWuIb3/gGZ5xxBgB33HEHN9xwA3v37uXuu+/m7W9/+7J9ZW0JMLukGkA3ogJA6Vr279/PV77yFXbu3Mkll1zCl770JX74wx9yzz338Bd/8Rds2bKFiy66iG984xt897vf5Z3vfCe7d+/mve99LwMDA/z+7/8+AG94wxu48cYbufHGG9m5cye/+7u/yze+8Q3Aynl44IEH8Pv9Zc/jscce48EHH2RxcZGLLrqI173udTz++OM8/fTTPPzwwxhjuPbaa/n+97/Py1/+cnbu3MmaNWtYWlrikksu4U1vehNjY2MATE5Ocu211/Lnf/7nvPKVryx7zEcffZS9e/eyZs0atm/fznve8x4efvhhPvnJT3Lbbbfxt3/7twD867/+K/fddx/79u3jtttuWyEAbAWAU6oBdCUqAJSGUmml3ki2bdvG+eefD8B5553H1VdfjYhw/vnnc/DgQZ599lnuuusuAH71V3+V6elp5uZWais//vGP+drXvgbADTfcwAc/+MHce295y1tWvfkDXHfddfT19dHX18dVV13Fww8/zA9/+EO+9a1vcdFFFwGwsLDA008/zctf/nI+9alP8fWvfx2AQ4cO8fTTTzM2NkYqleLqq6/m05/+NL/8y7+86jEvueQSNmzYAMAZZ5zBq171KgDOP/98vve97wGwa9cuxsfH2bp1K5s2beLmm2/m5MmTrFmzJrcfRwOYUR9AV6ICQOlawuFw7rnP58u99vl8pNPpupQ36O/vr7hNcSy9iGCM4cMf/jC/9Vu/tey9+++/n29/+9v8+Mc/JhqN8iu/8iu5RKxAIMCLX/xivvnNb1YUAJW+O1jmn3379uH03Jibm+Ouu+7Kmagg7wOYj6dJZ7IE/Oo27CZ0NpWe5WUvexm33347YN14x8fHGRoaYnBwkPn5+dx2L3nJS/jyl78MwO23387LXvYyT8e5++67icfjTE9Pc//993PJJZfw6le/mp07d7KwsADAkSNHmJqaYnZ2ltHRUaLRKPv27ePBBx/M7UdE2LlzJ/v27ePjH/94Td89m81y5513smfPHg4ePMjBgwe5++67ueOOO5ZtZxwJgPoBuhHVAJSe5aMf/Sg333wzF1xwAdFolC984QuAZfN/85vfzN13381tt93Gbbfdxk033cQnPvGJnBPYCxdccAFXXXUVJ06c4I//+I/ZuHEjGzduZO/evVxxxRWAFeL5xS9+kWuuuYbPfOYznHPOOZx11llcfvnly/bl9/u54447uPbaaxkcHOR973tfVd/9Bz/4AZs2bWLjxo25sZe//OU8+eSTHD16NGc+yubv/8wspRgbCBfvSulgpFDCtxsXX3yx0Y5gncfevXs555xzWn0abcFHP/rRZQ7lTmMhnuLHP93Db95zlLt++wpefNqayh9SWo6IPGKMubjSdmoCUhSlLMs0AHUEdx1qAupSTi0mecVf/xe3vf0iXnLGeKtPp+v5/Oc/zyc/+cllY1deeSWf/vSnG3bMPXv2cMMNNywbC4fDPPTQQ3U7RqGFQAVA96ECoEvZf3yB6cUk39071RIBYIzpqUqSN910EzfddFNTj3n++eeze/fuhh4jYwzGzgbQXIDuQ01AXcrRWSt08GeHZpp+7EgkwvT0NO3sX1IqY4xhbuYUz85YK3+NAuo+VAPoUo7NLgHw+JFZUpkswSbGb2/evJnDhw9z/Pjxph1TaQwnlrLc9tApRFQD6EZUAHQpz89YGkAinWXf0XnO3zzctGMHg0FtIdglfO77B5hLZJkYDKsPoAtRE1CXcmw2zmDEku+7D2kzD6U6EukMAOuGwmoC6kJUAHQpR+fi7NgywvhAqCV+AKU7iKey+ATGB8JqAupCVAB0KUdnltgwHGHHlhF2qwBQqiSRzhAJ+hmNhtQE1IWoAOhCUpksxxcSrB/uY8eWEQ4cX2RWL16lChLpLOGAj5FoUAVAF6ICoAuZnItjDGwcjnDR1lEAHj2sWoDinUQqSzjgZ6QvxEIiTSqTbfUpKXVEBUAXcszOAVg/HOGCzcOIwM+eUwGgeCeRzhAOWhoAaC5At6ECoAtxksA2DPcxGAnygokBjQRSqqLQBATaG7jbUAHQhRy1k8A2jEQAco5gzcxVvGIJAD8j0RCg9YC6DRUAXcjR2Tj9IT+DYSsPYMfWEU7FUjx3MtbiM1M6jUQ6QzjgY9TWAE6pAOgqVAB0Icdm42wY6csVY9uxZQRAw0E7kD/79yf50f4TLTt+IpW1fAB9jgagJqBuQgVAF/L8bJwNw5Hc67PWDdIX9KsjuMMwxvD5Hz3Dlx5+rmXnEE9niAT8DKsTuCupKABEZIuIfE9EnhSRJ0TkA/b4GhG5T0Setv+O2uMiIp8Skf0i8piIvKhgXzfa2z8tIjc27mv1Nsdml1g/lBcAAb+P8zcNqwbQYaQyhqyBR1s4b44GMBQJ4PeJZgN3GW40gDTwe8aYc4HLgfeLyLnAh4DvGGPOBL5jvwZ4DXCm/bgF+AewBAZwK3AZcClwqyM0lPqRymSZmk+wYaRv2fiOrSM8+fxcrraL0v7E7bk6fGqJ6YVES87BcQKLCMN9mgzWbVQUAMaYo8aYn9rP54G9wCbgOuAL9mZfAK63n18H/IuxeBAYEZENwKuB+4wxJ40xp4D7gGvq+m0UpuYTGMMyExDARVtGSGay7D0636IzU7wST+WF9WOHZ1tyDo4TGLCygdUE1FV48gGIyOnARcBDwDpjzFH7rWPAOvv5JuBQwccO22PlxpU64vQBWF8kAHZstRzBP3tO8wE6hUQqn3XbqkxuJw8AYKQvqE7gLsO1ABCRAeAu4L8ZY+YK3zNWgHldgsxF5BYR2SUiu7ShiHecPgAbh5ebgDYM97FuKKx+gA6iUANolR/A8gH4AbQgXBfiSgCISBDr5n+7MeZr9vCkbdrB/jtljx8BthR8fLM9Vm58GcaYzxpjLjbGXDwxMeHluygsLwNRjFYG7SzitgYwGg3y2OHZpifyGWOWmYCGtSBc1+EmCkiAfwL2GmP+uuCtewAnkudG4O6C8Xfa0UCXA7O2qeibwKtEZNR2/r7KHlPqyPOzS/SH/AxFVjZ7u3DLCM9OxzSUr0NwnMCXblvD9GKSw6eWmnr8dNaKQsqbgEJqAuoy3GgAVwI3AL8qIrvtx2uBvwReKSJPA6+wXwPcCxwA9gOfA94HYIw5CfwZ8BP78af2mFJHjs3GWT8cySWBFbJ5NArA1Fy82aelVIFjArps2xjQfEewc/xwwDEBBVlMZkimtSJot1CxJ7Ax5ofAyruJxdUltjfA+8vsayew08sJKt44OhtnQ5H932HtYBiA4/MJzlw32MzTUqrAMQFduGWEkN/Ho4dneN0FG5p2/IR9o48E81FAADNLSdYOrjQxKp2HZgJ3GUdnl1aEgDpMOAKgRTHlijecFfhQJMA5G4ea7gh2BICjATgF4bS5UPegAqCLyCWBVRAAU3MqADoBRwBEgn52bB5mz5FZMtnmOYITjgmoSAPQgnDdgwqALuK4kwQ2UtoENBgOEA74VAPoEOLOCjzo44LNI8SSGX5xfKFpx89rAHknMGhBuG5CBUAXcbRMEpiDiDAxGOb4vAqATiBRoAFcaFd0baYZaKUJyPEBqAbQLagA6CLyncDKO+jWqgDoGHImoICf7eP9DIYDTc0IzpmAAkVOYNUAPJHNGrJNNN15QQVAF3F0Jt8KshwTg2Gm5jUMtBOIp7L4BIJ+wecTzt883NRQ0ESBCQpgIBwg4BNNBvPIe/5lF3/w1cdafRolUQHQRRydjRMtkwTmoCagziGeyhAJ+nM5HRdsHmHv0eZVdC3OAxARRqJBdQJ7IJs1PHhgmm/vnWxLLUAFQBdxbM4KAS2VBOYwMRDhVCylyTwdQDxtCQCHHVuGSWVM0yq6FucBgBUKOrukJiC3PHcyRiyZYXYpxb5j7VeJVwVAF/H8TPkkMAcnFHR6UbWAdieeyhIJ5C/RCzY31xFc7AQGpyKoagBu2XcsXzfzwQPTLTyT0qgA6CKcMhCrUZgNrLQ3jgnIYcNwhInBcNMcwY6pKRwo1ADUBOSFvUfn8QmsH4qoAFAaRzqTZWo+zsYKAkCTwTqHeEEpZrBs8BduHm6eBpAqoQFEQ8xqFJBr9h2b4/Txfl7+S+M8fPBk2/kBVAB0CVPzCbIG1rs0AWkyWPuTSGeW2d8BLtw8woETi8zFG78KL44CAssEpBqAe/Ydm+ec9UNctm2MmViKpybbyw+gAqBLyOUAjKyuAYwPqAmoU4inMsvMLwDnbx7GGHjiyFyZT9UPxwQU8ufPYbQ/xFIqs6xZjVKaxUSaZ6djnL1+kMu2rwHazw+gAqBLcLKAV0sCAwgFfIxGgyoAOoB4KrvMBwDkqrgeONH4khCJdJaQ34fPl48qG+6zksHmNBu4Is5q/+wNQ2wejbJlTR8PHWivCvgqALoEpxPYhqHVTUCgyWCdQiKdIRJYLgA2DEWIBH0cOL7Y+OOnsis0EC0I5559drju2estoX3ZtjEeema6rfwAKgC6hFwSWF/FFg+aDNYhWBrA8kvU5xO2jQ9woAlF4eLpzDInNFh9gUHLQbhh37E5BsIBNo9ai7LLt49xKpbi51O1+wGMMSwm0hyZWeK56VjV7UIr3y2UjuDo7FLZTmDFTAyEeeS5U004K6UWisNAHbZP9PP4kcaXhCilATgmINUAKrP36Bxnrx/MXZOXbbP8AA8dOMnZ64eq2ud//9fd/HD/CWZjKZKZfDLnXb/9El582qjn/XWUBrCUzORMHcpyjs7G2VghAsjB0QCa3WRc8UY5AXDGeD+HTsYaXhIikc4siwACywkMaDZwBYwx7Ds6z9kb8p33tqyJsmmkryZH8H88fpS1g2Fufuk2PvSas/nA1WcCMFllm9eOEgB/9PU9vOV/PdDq02hLTiwkGB8Iudp27WCEeCrLQiLd4LNSaiGezq64AQNsnxgga+C56VhDj59IZ5flAIAVBgpoNnAFjswsMZ9Ic86G5Sv9y7eP8dAzJ6tafGWyhngqyyvOWceHXnM27/3lM3jTizYDVsRRNXSMAJheSPBvjz3PpCYwlSSWyBANu7Po5ZLB1A/QtmSzhmQ6u8IJDJYJCOAXDXYEWwJg+S0iGvIT8vvUBFSBvAN4uQC4bPsaTi4meXrKuw9nyQ697Q/nfxNR+/lSlWG5HSMAvvrIYVIZ66JoVjXETiKWzBAtYS4oxYSWg2h78oXYVs7ptnFLADQ6FDRRIg9BRBiOBtUEVAGnBtBZ6weXjV+xfQyoLh8glrRW+X2h/EKv336+mOhiAZDNGr708HO519V+2W4lmzUspbxrACoA2pd8P+CVl+hgJMjEYLjhoaCJdHZFFBBoQTg37D02z9Y1UQaKrsnNo31sGqkuH2Apaf0mChd6kaAPEVhKdrEJ6IFfTPPsdIyXnTkOVG/v6lbitkYUDbnTALQgXPvjzGkpDQBg+3g/z5xovgkIrFDQUxoGuir77AigYkSEy7at4cED0579AM7Ct9AEJCJEg34Wk12sAdz+0LOMRoO8+cWWw2M+rgKgkFjSmwAY7gsS9Iv6ANqYeGplLf5Ctk80PheglAkIYDiqGsBqxFMZnjmxyNkbSod6Xr59jOnFJPs9+gGWUitNQM7rWLcKgKm5OPc9OcmbX7yZsX5r5arRK8txVMM+lz4AEWFiQJPB2pnCfsClOGOin1OxFKcWG7cST6RXlqIAGFUBsCpPTy6QNXBOCQ0AyNUF+slBb7k45RZ6/WF/zj/glbYXAHfuOkQ6a3jbpVsZsFsdLiT0x1dI/ofhPq9vYjCsFUHbmLwPoIwJaKLxjuBEurQGMBINMaNO4LLsPWo5gMtpAFtGo4QDPp7xOHeOCahYAERDge51At/x8CFecsYY2ycGcg6VBXUCL8OR/m5NQKDlINodxwRUKg8AYPv4ANDYUFArE3jlb2q4L0g8ldWKoGXYe2yOvqCfrWuiJd/3+YQta6I8d9JbHodjAipe6EVD/tx7XmlrATAft2pdvOOy0wAYdDQA9QEsI2cC8iQAIioA2phKTuDNo30E/dLQSKBEmUS0fD0g1cRLse/oPGetH8TvK1+W5bQ1UZ71mMhXzgQUDfm7UwM4uZhkfCDMK89dB0B/WE1ApfDqBAZLA5heTJDOaHP4diRRwQcQ8Ps4bay/YY7gbNaQzJSOAnIqgqoZaCXGGPYdm+OcDaXt/w5bxywNwEskUKysCcifWwR6pa0FwFw8xa9fvJmQ/SOMBv2IqAZQzGKVJiBjLCGrtB+VooDASgg70KBQUKfQWCkTkJaDKM/UfIJTsVTFYm9b10SJJTOcWHB//ZXz9fWHArl7gFfaWgD4RHjbpVvzr33CQCjAvEYBLSNvAvLgBB7QchDtTCUnMFiO4GenFxuixeX7Aa+8RTimxmpXnd1MzgFcJgLI4bQxyz/gxQ8QS6UJBXwrTEt93aoBnLthiC1FjpSBSEATwYpwVgb9HjUA0N7A7YobAXDG+ACpjOHIzFL9j2/7IEr5ABwBoE7glTx1rHQNoGK2rrGiuJ476V6DiyUyJa/x/nCXagClStv3hwOaB1CEUwjKixM4lw2sxfXakni6sgkoFwraAEewowGU8kE4Y3GtybWC6cUkkaCPYdtPUo7No32I4MkRHEtmSoZ6R0N+4qksmSo6jVUUACKyU0SmROTxgrGPisgREdltP15b8N6HRWS/iDwlIq8uGL/GHtsvIh/yfKY2A+GAZgIXEUum8ftkWfPuSqgG0N5USgQDKxsY4BcNcAQnVtEAHK3E8VMoeRYS6RX1f0oRCfpZPxTxZAJaSqVLLvIc3181FUHd3DH+GbimxPjfGGN22I97AUTkXOCtwHn2Z/5eRPwi4gc+DbwGOBd4m72tZwYjqgEU41QCddMNzCES9DMYCWgoaJsST61syF7Mmv4QI9FgQxzBTjXSUk5gRytRH8BKYom064TMrWuinno6LJYxATnHi1VxX6woAIwx3wfclq67DviyMSZhjHkG2A9caj/2G2MOGGOSwJftbT0zEFYfQDFLyYwn84+DJoO1L/HUym5cpdg+3phQ0JwGUMIJnNMA1AS0gsVkJheuXomta6I860UDKHOdOxpANfWAavEB/I6IPGabiJxmlJuAQwXbHLbHyo17ZiAc0DDQIizboHcBsFYFQNuSSJduB1mMVRSucT6AUgLAGVMT0EoWE2nXwRinjUU5Pp9wrUnFUqW1C2esGkdwtQLgH4AzgB3AUeD/r3I/KxCRW0Rkl4jsOn78+Ir3+8MaBlpMLJnxFALqMDEYYWpeeyy3I/FUdlUHsMP2iX6m5hPMx+sbk58zAZUQQiJCOODLJaspeRaT7vtybB1zIoHcaQGxROmFnlMeumkagDFm0hiTMcZkgc9hmXgAjgBbCjbdbI+VGy+1788aYy42xlw8MTGx4n3HB6ANzfPEkumqNACtCNq+xFOZVR3ADtvt7mD17g2wmgkIrIgzDQNdyWIizUDY3bXo1Ap6dtrd3JXT9JtuAhKRDQUv3wg4EUL3AG8VkbCIbAPOBB4GfgKcKSLbRCSE5Si+p5pjD4QDGFPdl+1WqjUBTQyGWUxm1KfShsRT7k1AUP9Q0PgqJiCwopPUBLQSL07g09Z4SwazFnrlTUDVOIErnqmI3AH8CjAuIoeBW4FfEZEdgAEOAr8FYIx5QkTuBJ4E0sD7jTEZez+/A3wT8AM7jTFPeD5byJWEXkykXTtbup2lZIZ1Q2HPn3NCQU8sJPR/2Wa4NQGdNhbFJ9Q9EihRoRhdJOiruhF5N7OYLB2pU4qRaJDBSMCDAKi/BlDxqjfGvK3E8D+tsv3HgI+VGL8XuNfT2ZXAibGdT6RZW+vOuoRyzqFKOMlgU/MJTrPtkUp7EE9nXMWThwN+No9G6x4JlA8DLaMBBNUEVIwxxtPCVESsSCAXoaDJdJZ01pQRALYG0EQncMvI9QTQSKActYSBgvYGbkfiZWrxl2L7RH/dTUC5KKAyGkA46M9lKysWyYx1k/aiTZ82FuWQCw1gtXpfrQoDbQn5pjAqABycRDCvqABoXxKpjCsTEFhVQQ+6dCS6Pn4FJ3Ak4FMNoAinXLOXmlxb1/Rz6FSsYhkHJ8Sz1L6dVrDVNIbvPAFg+wC0HISFMYalVHVO4NFoCL9PVAC0IW6dwABj/SFiyQzJOq7IE+ksPoFAmUzkSNCvYaBFOItSt2GgYEUCpTKGo7OrF/SLJcvX+/L5hGjI35hM4HZjMGwVWdLIFYt4Kosx3kpBO/h9wlh/SAVAGxJPu3MCAwxGrGuinrkAibRlgipXXqQvqFFAxeSr8nozAUHlSCDHBFTO1xcN+Yk1qBZQW+EkPagJyKKafsCFrB0KazJYG+I2DwBgqM+6KczVUStOVChFEQn6tBREETkzjcs8AMjnAlSqCRRbxQQElmDoCQ3AMQGpALBYTTV0w8RAmEktCd1WGGM8mYCGbA1gbqneGsBqAqD6JiTdimOV8OIE3jAcIeCTijWBKl3n0ZC/N5zA4YCfkN+nPgCbavoBF7JxpI9jc6oBtBOpjCFrVu8FUEjeBFS/ayKeyqwahaRhoCtZLNOzdzUCfh+bR/sqmoDKtYN06BkBANoVrJBaTUAbR/o4uZjU1VwbEa+QhFVM3gRUXw1gNQEUDvo0DLQI557kJn+jkK1j/a5NQOWu8/5woDfyAMCuCKoCAKjsHKrExpEIAM9XiEJQmoezsi4Xg19M40xAq2gAAT/JdJZsFV2oupX8TdqjAFjTV7EeUCVNvy/YQxpAv3YFy1GzCWi4D4DnG9BXVqmOfDtGtyag+odGJ9KZVX0Aji06oVpADicO36sGcNqafubiaWZj5QV4JRNQtX2BO1IADIYDLCTqW/62U3FCv2oxAYEKgHbCTUP4QvpDAXxSZxNQKrt6FFCuJ4CaDh0WE2lE3PtuHLbaoaDPrtIgfim5+r77QtU55TtSAAxoW8gcS7bUryYPAGD9cAQReH5GHcHtghNf71YA+HzCYCTYXBOQdgVbgdWyMeCpNSsUloUu7wdYrND2tT/kzzmhvdCZAiAcqOrLdiM51bCKUhAAQb+PtYNh1QDaiHiFMgylGIzU1yxayQTkCAANHsgTS6Y95QA4bHVRFrpS06e+UIClVMazT6YjBYD6APLUmgcAlhlIncDtg1cTEFiO4HpHAa0uALQtZDELibSnLGCH/nCA8YHwqpFASxWEi5Mg5rVEd0cKAKsrmPoAwFqB+cTbarGYjSN9agJqI/ImIPdzOtQXYG6peXkAYTUBrSCWzBCtQgMAOxJoFR/AYjKTK/pWCqf+kFdHcEcKgIFwgHgqSzqjq49Fu0uQV7tjIZtG+nh+ZknbbLYJ1WgAgw3QAFYTQE6ZCnUC56lWAwA4bayfQyfLa+FLFbr+Ras0yXWsAADUD0D1vQAK2TgcIZHOcnIxWaezUmohJwBc1gICywRUVx9AKrtqHkIuDFRNQDksH0B1AmDrmijPzy7lynB73bdjHvJ6T+xMAeDEPasZqOp+wIVsyIWCqhmoHXAybL2bgOpzPRhjXDiBNQy0mFgiU7UA2LImijFwtMw1GKtgAnIcxEupHjEBgRaEA0cA1NbPd5MtAI5oJFBbkPCYCQyWCWghma5LZm46a9UiWlUABKpzOnYzlgmousXYWH8IgFOx0lp4pYWec9ze0AC0LWSOpVS6Zg1Ak8Hai0Q1GkAkgDFWr+x6Hd9VHoCagHLUshgbjlrlPGbKZANbDuby+873Be4FAZAzAakAqIcJaDQaJBL0qQBoE+KpDCIQ8nsxAdWvHlBeA1ETkFuMMSwm0wxUGQU0Gq2kAaRXzfXJ9wXuARPQYM4JrAJgqYJt0A0iwsbhPo7Oqg+gHXCawXiJ7BqqYz2gvAZQORFMw0AtllIZjPHWDrKQUVsDOFWalA/eAAAgAElEQVRCA3DT9tUJP/XaF7gjBUC/moBy1EMDAMsMpD6A9iCect8O0iFXEbQOoaC5aqSr5QEENBGskMUqGsIXMhQJ4hOYKaEBOG1f3ZiAlnpBA9CuYHkqpYi7ZeNIRE1AbYKXbmAOdTUBufBBiAiRoE8bw9vkWjZWqQH4fMJwX7CkCWjRRc8PxwrQE05gJ9lCy0FYEr9eGsDUfKJsHLLSPKyG8N7mtJ4lod04gUG7ghXiLEZricgbjYZKmoCc5K7VTL1+nyWQe6IUhN8n9If8Pa8BGGOIVbANusWJBJqc1f7ArcYqw9A6E1DOCVzhHCIBv4aB2sSq7AVQyEg0WLIngLPvStpFf8h7p8SOFACgbSEhbxusNRMY8o1h1A/QeqoxATkaQD3qAeU0gAp+iEjQpz4Am5wGUGUUEMBINLSqCajSdR4Ne+8K1rECoD8c6Pkw0FwLuhqjgCDfGvKoVgVtOYkqnMABv49oyM98PTQANQF5JpZzAtemAZTKA1hyWfI9GvTeF7hjBcBgONDzUUC5XgA1qJ0OmgzWPsTT3jUAqF9J6ITLfgThoF8bw9ss5pzA1S/GRstoAG5NQD2lAWhXsHwafj18AJGgn7H+EEe0HlDLcfIAvFKvktBOgbeKGkDApxqAjWOOrkUDGI0GiSUzKwIxYm5NQKFeEgBh9QHU2hC+mI12WWiltVSTBwBWPaB6FEh06wPoC/k1DNTG7Sp9NUbsbOBiM5Db6zzaU07gcH3L33YiuZVBsHYTEMCGYc0FaAeqcQKDlQ1cDw0g7iEKSJ3AFouJNEG/EKqhMVO5chB5AVApCsh7VFYHCwANA11qkAagjWFaS9UCoK9ePgB3TemriTvvVhYT6Zqr8ubKQSwWaQCJyolgYJWErnsimIjsFJEpEXm8YGyNiNwnIk/bf0ftcRGRT4nIfhF5TEReVPCZG+3tnxaRGz2dZQkcH0Av36zqbQLaNNLHYjLDXI9rVq0mns5WNL+Uol5NYRwbdKVidBoFlGcxmakpBwDyFUFnl4o0gFSGoF8IVpiP/pC/IVFA/wxcUzT2IeA7xpgzge/YrwFeA5xpP24B/gEsgQHcClwGXArc6giNahkIB8lkTU+roG6dQ27RSKDWk80akulsVU7gwYjVFKbWRVEinSXk9+HzrV6MTgVAHksDqLUqr2MCWq4BLLksMx21TUBeekJUFADGmO8DJ4uGrwO+YD//AnB9wfi/GIsHgRER2QC8GrjPGHPSGHMKuI+VQsUTWg/IvW3QLU4ugAqA1uHW/FKKob4g6ayp2SyTSGVdZSKHgz4NA7VZrFCv3w3lfABuhUs0bPWE8FKhtVofwDpjzFH7+TFgnf18E3CoYLvD9li58apx6m6rAKivDwBUALSSfEP46kxAUHs9oEQ648oEFQn4SaazdelC1unEEtX3AnDoC/kJB3wro4BS7vp+9+d6AjReAOQwlr5Zt1+AiNwiIrtEZNfx48fLbjcQtn7svZwMtpS0God4rRtTjomBMEG/8Lz2BWgZzuqtGg0gXw6iNkdwIp2tmAMABY3hVQtgoQ5OYLCTwRaXawBLyYyr/AKnKnDMgyO42jvHpG3awf47ZY8fAbYUbLfZHis3vgJjzGeNMRcbYy6emJgoewKOw6WXG8PH7B+Gl8Yhq+HzCes1FLSlOD6tqjSAvvoUhLMEgBsNQLuCOcTq4AQGqxxEsQ9gMZH2pgF4aAxfrQC4B3AieW4E7i4Yf6cdDXQ5MGubir4JvEpERm3n76vssapxVjtew566iaWUux+GFzYOazJYK8mZgKrJBHY0gBq14ngq4yqe3dFSNBTUbtlYh2txNBpa0RSmUjcwB+de4OWe6CYM9A7gx8BZInJYRN4N/CXwShF5GniF/RrgXuAAsB/4HPA+AGPMSeDPgJ/Yjz+1x6om1xi+xzWAetn/HaxcADUBtYq8D6AaE1B9msIkXPYjyDeGVwGwkEjXlAXsMNq/silMzKUJyDm+l1DQins1xrytzFtXl9jWAO8vs5+dwE7XZ1YBbQtpdwOrQyXQQjaORDg2FyeTNfgrhAEq9ccxAVWVB9BXHw0g4bIfQb4xfG/7AJxw9FrqADkM94WYXVqZCOZG03fuBU11AreKXAekHo4CWmqQBpDJGqbmVQtoBbU4gfNRQHXwAbg4flgbwwOF7SDrYQKySkIX5nK4bfpUjQbQsQIgHPAR8EmPawD1iTwoRENBW0uiBh9AJOgn5PfVXA/IvRNYTUCQt7nXKwoonTXLFrYxl4lgLQkDbRUi0vNdwayG8PXVADaNOJ3BVANoBbVEAYFdErpmDcCdCSgXBtrjJqB69AJwGLHLQczY9YDSmSzJdNaTE7gZYaBtQX+ot7uCNcIJvGFYs4FbSS1OYKhPPSArE9iNE9i6ffR6FFA9egE4FGcDxzz0/HC0hMVeMAGB5QfobRNQ/QXAYCRIJOhjekGbw7eCWgWAUw+oFhIui9GpCcjCMQHVKwoI8gJgyUO5F79PCAd8uc+4oaMFwEC4t7uCLTXABwB2a8E61JVXvBNP12oCqr0ktPsoIEcA9LYJqJ5O4OKmMIsuS0E79IcDvaMB9HJbSGOM6+gArwzXqa684p1aEsGgTiYg13kAmgkM+Xpk9ViMjfQt1wAch65bX5/XtpCdLQB6WANIpLMYU79S0IUM9QVXxCIrzSGecleKuRy1moCyWUMy4zIKSMNAgfxNuh6lIIZtAeBoAI5/xa1/IRry944TeCDcuz6AXCXQOieCgd1aUDWAurGUzPBrf/8jdh+aqbhtPOWuEmc5ajUBJTPuGsJb22giGBSYaepgAgr4fQxFArlyEM6+3WsAgZzj2A2dLwB6VANw7I6N8AEM96kPoJ4cmYnx0+dm+K+nyle3dUikq2sH6TAUCRBPWaGD1eCEdLrRAESESNDX843hc3kAdVqMjfaHcgXhvLZ9tTSAHvIBxJIZMj1Yj3zJo23QC2oCqi+OOn9werHitvFUtmoHMOTrAVWbDey0g3SrhUSC3huRdxuxZJpI0EegQstGt4xEQyt8AO5NQAEWe8kHAN7iXruFxTo3gylkuC/IfDyljT7qhDcBkKnaAQy11wNyavu7MQGB5axWJ3C6LjkADk45CPDe9jUa8rPUK1FATj2gXvQD1LsfcCFDkSBZAws9KFgbwYytTR084VIA1GQCqpMG4LLJUCTo63kfQCyZqUsOgMNoCQ3AfRiov3c0gFxF0B70A3hJEPFKbhWpZqC64Dj0TsVSzMZW/5/GXfbjLUe+JHR110Tcgw8AtDE81KchfCHDfYUagG3qdbkoiIYCvZUIBrX3QO1E6t0PuBAnFE0dwfWhUJBWMgPFa3UC50xAtfoA3J1DOOjv+cbwi8n69AJwGI2GWEikSWWyxJJp+oJ+12HB0ZC/dxLBciagntYAGmMCAtQRXCdmvAiAGp3ANZuAnGJ0LjWAvqBPNYBEnU1A/flcAK/lXqKhAMaD666jBYDTGL4XK4I2Mgy0Xr1lFYuZWIr1QxFE4OCJ2KrbJlIZ16vvUuQbw9foBHZ5DpGgv+fDQGPJdK4Ucz3Il4NIWj0/POQXeF0Q1v/u0USc2hs96QT2UCXQK44JSDWA+jCzlGLdUBifuNEAaosC6g8F8EkdTEBufQABDQNdTLir1++W0ahTDiLFYjJNNOh+3z0lAAZtDaAXS0IvJTOIuL9QvTBUp96yisXsUorhaIj+cMCFD6A2E5DPJwzWUA8oHwaqUUBuWUymGahDFrBDYUlorz0/vJqiOtoE1NMaQDJDNOhHpP59ewcjAURq7y2rWMzGkoz0BTl9vL9iKGitYaBQWz2gXCawBxNQr/sAYokM0Tr6AHJNYWwTkJcqo17DwjtaAAT8PvqC3rze3YK1MmiMAufzCQPh2uvKKxYzSylGokFOH4uuGgpqjLEFQG2X5VCk+npA3vMAelsAJNNZkplsXQrBOYzkNADLCdznwQTkNSGtowUAWOUgejMMtL6xx8VY9YBUANRKNmssE1BfkNPH+oHyfoBUxpA11ZeCdrDaQjbHBBQO+no6DDQfjFG/a7E/5CfoF9sE5O0693oeHS8ArKSJZKtPo+k0ohtYIUMRrQdUD+bjaYyxfqenj68uAJyyyrWagKyGPtXNnbOad1sKoi/oJ5nO9mzZkIU6toN0EBFGoiFmbQ3Aiwmo5wTAWH+I6cXeEwBLDWgIX0g9mosr+UiqkWiIrWuiq4aCJmpsCO9QqxPYJxD0u/Mt9XpPgFyxtjqagMCKBDpl+wC8mIC8RiN1vAAYHwj3ZP/a5piAes+0Vm9mlqzFyUhfkEjQz8bhvvIaQMpbFm45ahHeibTVEN5tcEGkx3sC1LMXQCFWRVA7DNSLCcjjeXS8ABgb6E0NwDIBNS6KV01A9cGp6eJEdpw2FuWZMpFAiTqagBYS6arMMgmPDWnyfYF7UwPINYSv87U4Gg0yNRcna7zd1L32JOh8AdAfZiaWIpXprRXIUoP6ATvUo7m4ki8D4STXnT7ez7NlNQBvZRjKMRixygFUkx9jaQAqANyyWMeG8IWMRkM8PxMHvN3UA34fIQ/z1/kCYMAKmTrZY1pAo53Aw31BYslMzwnWejNrBygM2xrAaqGguYbwNZuAqq8H5JiA3JJvDN+bvxMnCqjeGsBINJRrz+lV0/dSlqLjBcC4LQBOdLEf4Pj8yu/m1TnklaGIloSuB7PFGsAqoaA5DaAOJiDwXg9oci7Oz5475SmmPdzjTuCFRGOcwI7JELzb9b0IjI4XAGMDYQCmF2rXAGLJNM9Nx/j55DyPHZ7h4WdOumrk3UgeefYkl/7Ft3nk2VO5MWNM453AUacgnDqCa2EmliIa8udW1dtWCQXNawC1JoJ5Lwm979gc13/6RxyfT/CHrz3H9ef6etwE5PTfrb8JqEAAeLzOvWzf0bWAwAoDBZherE0DyGQNL/v490o6lP/jAy/jnA1DNe2/Wn4xtYgx8NVHDvPi00YBS03PmsZ0A3PQktD1YcZOAnPYYoeClnIE1y0PIGcCcie8f/j0CX77i48QDfu5871XcN7GYdfH6iUfwJGZJdZEQ8uuu8VEGhH3DVvc4mQDA541fS9lKTpeAxgfrI8GML2QYHoxyVtevJm/e/tF/OM7L+Zjb3whAM+dXL2EbyOZnLMcQffuOUrSzrhsZDMYh1xJaBUANTETWy4AnFDQZ6dX/qbyTuB6mYAqz91Xdh3iXZ9/mE2jfXz9fVd6uvmDdx/AnsOzud9xp3Hd3/2Ij9375LKxxWSG/lCg7jW5RgsEgFftwovTuOMFwGA4QMjv40SNAmByztIgXnHuOl5/wUZece46XnnOOgCmStjgm4Vz7NmlFP/18+NAY9LPixnWngB1Yc6uA1TI6eOlQ0HrZQIadGkCuvMnh/iDrz7GFWeMced7r2DjSJ/nYznCyo0GcHw+wXWf/iFf++lhz8dpNQuJNCcWEvz7Y0eXBUY0yhRbiwnIi8Co6ZcmIgdFZI+I7BaRXfbYGhG5T0Setv+O2uMiIp8Skf0i8piIvKiWYxecg5ULUKMT2FlprxuK5MbGBqwa7lP2e61gaj7OtvF+RqNB7t59BMh3A2tUMThQE1C9mFlKMtIXWjZ22ljpUNB6JYI5AmA1E9Deo3P88d2P87Izx9n5rkty8+2VvAmo8qr+8KkYWdNajbpanPvDTCzFj/afyI0v1LkbmMMyE5DH69zL9vXQAK4yxuwwxlxsv/4Q8B1jzJnAd+zXAK8BzrQftwD/UIdjA1YoaK1RQJPzjgAI58b8PmF8IJyb/FYwNZ9g40iE112wgW/vnWQhkc6bgOpsdyxE+wLXh5nYSg1g21h/yVBQpxBbrRpAwO+jP+QvawJaSKR5/+0/ZbgvyN/8xg6C/uqPlzcBVdYAnOvoWAuvp2opvAf8+2NHc89jiXTdHcCwPArIa7exVoeBXgd8wX7+BeD6gvF/MRYPAiMisqEeBxzrD9ecDTw1l0DEKi1RyLqhSGtNQHMJ1g5GuH7HJuKpLN964lheADTgh+cQCfoI+kU1gBowxqxwAoOVDQzwTJEWEE9ZTX5CNdyQHQbLlIQ2xvBHX9/DwelFPvW2i1b83r3ipRaQY2admuu8kG3nnC/aOsI3nziWy9q2SjXUXwMI+n25cFyvwR5etq/1l2aAb4nIIyJyiz22zhjjiMhjwDr7+SbgUMFnD9tjNWOZgGoUAPNxxvpDK1ZD64bCuR9uszHGcHw+wdrBMC/aOsqmkT6+sft5llKN6wfsICI11ZVXLLNIMp3NhdQ6OKGgxWYgpx1kPRyKa4fC3PfkJJ//0TPLVuf/+pND3L37ef77K36Jy7eP1XycsIdaQMc6WANwzvndL93GfDzND35umYEWE5m69gIoZCQaxO8TzwsCL0lptQqAlxpjXoRl3nm/iLy88E1jjMESEq4RkVtEZJeI7Dp+/Lirz4wPhDmxkMA6XHVM2ivtYiYGIxyfb80PdnYpRTKTZWIwjM8nXLdjIz/af4JDJ5eAxjqBQXsC1EquEmiRD6BcKGg8VVs7yEI+/qYLOHv9EH/yb09y1V/dz5ceeo49h2e59Z4neNmZ47zvqhfU5TgiYreFdKEBzFrXUStNqtUyORenP+TnVeeuZ7gvyP/eY61xvRZr88JoNEQ05H1BcMUZ7gV7Tb82Y8wR++8U8HXgUmDSMe3Yf6fszY8AWwo+vtkeK97nZ40xFxtjLp6YmHB1HmP9IRLpLIvJ6mORp+bjy+z/DuuGwpxYSLakJIJjelprO6av27GJTNbwlUcsRarescfFDPZpQbhayFUCLdIAyoWC1qMdpMM5G4a445bL+dJ7LmPDcIQ//Poerv30D3N2f7+vfmGLbruCOX62+Xg6F8nWKUzNJVg3FCEU8HHNeeu578lJ4qkMsUSm7mUgHEaiwaqEy5UvGHe9bdUCQET6RWTQeQ68CngcuAe40d7sRuBu+/k9wDvtaKDLgdkCU1FNjOeygas31ZTTAJyxUuUYGo1jd1xn5zqctX6Qs9cP8viROaBJGoBmAldNrhJo38oIm+JQ0EzWcCqWrJsAcHjJC8a567dfwuffdQm/etZa/v4dL6rZ7l9MJOBOABybjePInWOznaUFTM7FWWsvEF9/4QYWEmnuf+o4i4l0Q6KAwDIVbhj2HprrhVrOfB3wdVs9CQBfMsb8p4j8BLhTRN4NPAv8ur39vcBrgf1ADLiphmMvYyxXDyjJaXatFS+kM1lOLCTKagDgROM0djKKcVTltQWhqdft2MS+/9wHNNYHAFZJgcMdGLLXLjgCYKiEADhtrJ///dhR7t1zlG/vneR7+6Y4FUtx+fY1dT8PEeGqs9dy1dlr675vwDYBVdaQJ+cSnLl2kKcm55mcS7B9YqAh59MIJufjvHirlYl/xfYx1vSH+PfHnmcx2ZgoIIA/fO05uYJwjaLqO4gx5gBwYYnxaeDqEuMGeH+1x1sNZ0VTbSjo9GISY5bfaB2cvIBW2C1zJqDBvGC6dsdGPv6f+xCpPVywEkNqAqqJ2TImIIDt4/3MLqV43+0/ZSQa5Kqz1nL1OWv5lbMac5NuJG5MQAuJNAuJNBdsHrYFQOdoAMYYJm0TEFhhtte8cD1ffeSwVa+/QQuxSNBfd42wmI6vBQR5DaDaSKDcSntwpQbgjLUiFHRq3nI8FaqYm0b6uHTbGh4/Mlv39PNihu2eAMaYhh+rGylsB1nM9RdtIpHOcvFpo7z4tFECdQj9bBXhoL9iY3jnGrtwywhfeeRwR0UCzS6lSKazyxaIr79gA1966DkABhoYjt1oukIArHEKwlWpAThhnutKaACtzAaemk+U1Eo+/JqzefzIbMOPPxQJksoYu/lMV/xUmspMLEXAJyUTc8YHwry/TpE4raYv6CNeIQDDiQDaPtHPQDjQURrAsbmVSaKXbRvLRR928rXRucuOAsIBP4ORQNXJYKXKQDi0Mhv4+FyCiRJayUVbR7nhitMbfnzNBq4NJwms27WnSNBfMRHMuYmuH4qwdqi12fVeKbVA9PuE156/Hqh/L4Bm0hUCAPK5ANUwNe9kAa9U1aF12cBT8/GSZqlmMdTnva68kmc2llqRBNaNuIkCKryJrh+KdFQUUG6BWBQl+Gsv2oxPYPNoc4ND6knXCICx/uqzgafm4oz1h8vaYVuVDTw1Xzo0tVloQbjamF1KlQwB7TbcRAFNzsUZDAfoDwdYPxRpWXZ9NUzlovGWL8Z2bBnhZ//jVbxwk7cS2u1E1wiA8YFw1U1hJudKJ4E5tCIb2Cn6VvyjaybD2hOgJmaWkiUdwN2GmyigY7Nx1g1bi5m1QxGm5uNks9Vn7jeTybkEI9FgyYic4jpPnUbXCACrImiVGsB8oqT936EV2cBTJRxPzcaJX1cNoDpmYr2iAbgwARVk2q8fCpPKGE7Gam/j2gwm5+IrzD/dQhcJgDCnYknSVdykrSzg8jfaVmQD53MAWmkC0sbwtTAbS5VMAus2Im7CQGfjuUXW+uHW5dZUw+R8oqWaeCPpGgEwPhDCGDgV83azSmeyTC+WDrd0KMwGbhar5SY0i1xbSC0H4Zl0Jst8Il0yCazbiAR9JNNZMmVMOtmsYWo+wfqhvAkIOkgAFAivbqNrBMBYv10PyKMf4MSClQW8mqmlFdnAx9tAAwj6fURDfjUBVYEjNHvFBATkauQXM72YJJ01uZX/+tz11P6O4EzWcLxMmZhuoHsEQJXZwPmVdvkbbSuygafmE4QCvlwoZqvQktDVMRNzykD0gBO4Qk+A4mtsYjCMSGcUhJteTJDJmpzQ6ja6RgCM5wrCebtJT7pwtrYiG3hqzsoBaHUS0VBE6wFVw4z9P+uJPIDg6o3hnRu9owEE/T7G+jsjGcypyLuaibiT6RoBkDMBedQAnFX9aja+VmQDT82v7phuFkN9AU0EqwKn32+nhwm6oZIAcPoAFK6i1w93hgBYrUpAN9A1AmC4L0jAJ541gKk5q0b5WP/qqnqzs4FbnQTmYJmA1AnslVwzmJ4QABVMQHYfgMJM+3WDEY51gA8gn8Hc+sVYI+gaAeDzCWuqyAaenEswNlA+C9hh7WBzs4GnChpQtBI1AVWHowH0hA+gQmP4Y3NxxouusXXDkY7RAKwyMa2/FhtB1wgAsGz1XqOAJsu0gixm7VDzsoHjqQxz8XRbqJ1DfdoYvhocH4CTS9HN5ARAmYqgx+YSOfu/w/qhCCcXk2Ujh9qFSVt4BTu4XPdqdNW3Gq8iG3hqLuEqy6+Z2cBOCGipSqDNZqgvyEIi3TFp++3CTCzFYCTQ0XX+3VJJA7ACGpZfY7ncmjY3A1UqE9PpdNWvc6w/5FkDmJp3Z2ppZjZwOySBOQxFAhhjNfJW3DNrl4LuBSr5AI7NxVk/vPy33MpOe16YdLlA7FS6SwAMhD35AFKZLCcWkq6crc3MBm6HMhAOuYJwagbyxOxSqieygMEqBw2lo4DiqQwzsdSKOPp8OYj21gCsBWLrr8NG0WUCIEQsmSGWdLdadSKG3NjanZtxM1Ys5crPtgItCFcdM7EkI33d7wCGwjDQlRpAuTh6Z1Xdzq0hnQWimoA6hHGPuQDO6sONqaXZGkDAJ6xpgwgSLQldHTNLvdEMBgpNQCs1gMJOYIWMRIOEAr6WtFp1y3EXOUKdTncJgEFv2cBekjyamQ08NZ9gfCCMz9f6VoJOUxg1AXljNtZLPoDyTuCcACiKAhIR1g2F21oDmCwjvLqJrhIAXrOB81nAlTWAZmYDT7VR+VmnFpGagNxjjGGmR7qBAYQDPkRKh4FOrbLIavfWkJNtZIptFN0lAJyCcC4jgXJZwC6TPJqVDVwqbK5VaGN47ywmM2SypmecwCJCOOAr2RPg2GycSNBXMh+iVb223VKqGXy30V0CwNYA3OYCOEkefpemlmZlAx9vIw2gPxTAJ6oBeCFXCbRHnMBQvivYsbk464ciJYsarrM1AGPaM8dkci7eNr64RtFVAqAv5Kc/5PfkBPYi3ZuRDZzKZJleTLZFDgBYJTYGI5oN7IWZWO9UAnWIBEoLgKlVrrH1QxGW7Kz3dsTpFNgOvrhG0VUCALyVg7B6Abu/0TYjG9hxYLeLCQi0J4BXHG2pV5zAYEUClQoDPTZXvpuW0yS+XSOBuj0HALpSALgvCDc1F2fCw422GdnAXkJTm8VQX0BNQB6YyRWC6yUBsFIDMMbYWcBlBID9G2/XSKBJ23zVzXSfAOgPuwoDTaYtU4tXDQAamwvQTklgDsN9wbZV09sRR1j2mg9gqUgAzC6lSKaz5U1AtmBo10ggy0TcPtdhI+g6ATAx6K4gnJcsYIdmZAO3UxkIh6GImoC8kOsF0FMagI9EkQno2Nzq3faca68dI4HiqQyzSyk1AXUaY/1hTi4mKlavdNMKspimaADzCbv+ePusHrUngDdmYynCAV8uQaoXiAT9KxLBcq0gy9xEI0E/w33BttQAur0TmEP3CYCBEFmTr8dejryt3f0ENyMb+Ph8nLH+UFuVER6OahSQF2Z6KAvYoVQUkJub6PqhSFv6ALq9E5hD+9xl6oST1DVdwQ/ghHN6sbU3Ixt4aq49WkEWMhQJEE9l2755R7vQS5VAHUpFAeUWWatcY2uHwm0ZBaQaQIMQkWtE5CkR2S8iH6r3/sf7nXpAq/sBJucS+H2SSx5zS6OzF9upDISD22zguXiqbGPwTmQmliRZIru14ueWeqcSqEOpKKBjc3HW9IcIB8qbwuqhARhjyGQNiXSGpeTKRzyVIZ3Jeko46xUB0NR+dSLiBz4NvBI4DPxERO4xxjxZr2M4Tpvf/JddXLB5mB1bRrhwywhnrx9cZlY5OL3I+EDIdRZwbv+DYZ47GePIzFK9TnkZx+binLNhsCH7rhanJPT+qQWSBTkQ0wsJdh+aYfdzM+w+PMOB44v4fcLZ6wdz//cLN48w0AFtEY0xHJuNs/vQDOQVBHsAAA1hSURBVD+zv9ORmSVCAR/nbRxix5YRdmwZ4byNw/SFlt/QTi0meeL5WR4/MseeI7M8fmSWq89Z26Jv0hoiQT9Lycyy6+LQyVjFG+j64QjH5xMsJtLLrsVM1pDOGtKZLJmsIZnJ8tx0jH3H5tl3bI6njs3zi+OLJNIZUhn3N/aATwj6fWwb7+eFm4Z44aZhzts4zJnrBqzjZgypbJaD04tlS1h0E83+dpcC+40xBwBE5MvAdUDdBMAZE/383dsv4sED0+w+NMNnv3+AdBmH8EVbRzzvf+NIH9/ZN8WVf/ndWk+1LBuG+xq272pwtKS3fe7Bku+PD4TZsWWEX7toE0upDI8emuWe3c9z+0PPNfM068amkT52bBnhhitOY3ohwaOHZrnj4ef4/I8Orvq5wXCAczcOceNLTuctF29uzsm2CUORAPOJ9Irr4hXnrFv1c+uHI2QNnHfrN10fa6w/xNkbBnnTizYRDQcI+gS/z0fAL/hEKK46kTWGdCYvUOKpLPuPL/DtvVPcuetw2eNsn+gvWcKim2i2ANgEHCp4fRi4rHADEbkFuAVg69atng8gIrz+go28/oKNgBXO9cTzs/zi+CIUyYFqBMD/ffULOH/z8Ip91QufT3hFm60eL9++htvedhFLRdUeByIBLtg8zKaRvhUXSjZrOHBigSeen1sRHtiujPaHuHDLcEkfTDqT5anJefYdnSdTtKDoDwc4b+MQW9dEu7pswGq868ptbFkTpdjKcvn2sVU/9/oLNrKUXLmK9wkE/D4CPsHvE4J+YeNIH2evH6pbr2xjDEdn4zx+ZJaD04v4RKzj+X0EfcILNw3X5TjtjDSzEJOIvBm4xhjzHvv1DcBlxpjfKbX9xRdfbHbt2tW081MURekGROQRY8zFlbZrthP4CLCl4PVme0xRFEVpMs0WAD8BzhSRbSISAt4K3NPkc1AURVFosg/AGJMWkd8Bvgn4gZ3GmCeaeQ6KoiiKRdNjnIwx9wL3Nvu4iqIoynK6LhNYURRFcYcKAEVRlB5FBYCiKEqPogJAURSlR2lqIphXRGQeeKpoeCvQmTUG3DMMzLb6JBqIzmF30O3z2MlzeJYxpmJRsXYXALuKs9lE5LgxZqJV59QMROSzxphbWn0ejULnsDvo9nns5Dksde8sRSeagGZafQJN4N9afQINRuewO+j2eez6OexEAdCpKplrjDHd/sPTOewOunoee2EO210AfNblmNJZ6Bx2BzqP7YuruWlrH4CiKIrSONpdA+h4RGSniEyJyOMFY58QkX0i8piIfF1ESjYmKNc+0y6m95A9/q92YT2lQegcdj46h6VpuQAo9c91+48VkQ/b2zwlIq9ebZ8t5J+Ba4rG7gNeaIy5APg58OHiDxW0z3wNcC7wNhE5137748DfGGNeAJwC3t2YU3eHzqHOoc5h6+ewKowxLXtgVQT9BbAdCAGPYv2T7wTeam/zGeC3S3z2XHv7MLDN3o+/3D5b/D1PBx4v894bgdtLjF8BfLPg9YfthwAngECp7XQOdQ51DntvDqt9tFoDyPUINsYkAadH8K8CX7W3+QJwfYnPXgd82RiTMMY8A+y391dun+3KzcB/AIjIRhFxKqWWap+5CRgDZowx6aLxVqFzqHOoc9j6OayKVguAcv/ckv9YEblWRP60wmfLjbcdIvJHQBq4HcAY87wx5rWtPSvP6BzqHOocdihN7wdQC8aYe+iSDmIi8i7g9cDVxtYhiyjXPnMaGBGRgH1xdlRbTZ1DncN2olfn0KHVGkC5f+6IiASKxtx+tu37DovINcAHgWuNMbEym5Vsn2n/SL8HvNne7kbg7kaf8yroHOoc6hy2fg6ro5UOCCwN5ACW88hxFJ0HfIXlzqf3lfjseSx3Ph3AcjyV3GcLv+MdwFEghaUGvxvLTnoI2G0/PmNvuxG4t+Czr8WKTvgF8EcF49uBh+39fAUI6xzqHOoc9u4cVv1/afkJlPjnlvvHAtcCf1rw2T+yP/cU8JpKE6YPnUN96BzqI//QTGBFUZQepdU+AEVRFKVFqABQFEXpUVQAKIqi9ChNFwAiskVEviciT4rIEyLyAXv8z+yiTLtF5FsisrHM5++364vsth9vLrVdwfYLjfgevUy5OSx4//dExIjIeJnP6xy2mFWuw4+KyJGCuSmZECUi/ywizxRs97sVjnew3O9BaR2tSARLA79njPmpiAwCj4jIfcAnjDF/DGD/mP4H8N4y+3iHMWZXc05XKUHJOTTGPCkiW4BXUblXrM5hayl3HYJV4OyvXOzjD4wxX628mdKuNF0DMMYcNcb81H4+D+wFNhlj5go26wc8hSeJyP8lIg/bq5H/ZVfxc977G3uV8x0R6doeps2i3Bzab/8NVnKN5/AyncPmUWEOq0ZEXiUiPxaRn4rIV0RkoODtD4rIHnuOX1DrsZTaaakPQEROBy4CHrJff0xEDgHvwNIAynF7geo5JiLnAL8BXGmM2QFk7H2AJUx2GWPOA/4LuLUhX6ZHKZxDEbkOOGKMedTFR3UO24Ti6xD4Hdscu1NERlf56CcK5vB828TzEeAVxpgXAbuA/6dg+1ljzPnA3wF/W/cvoninVQkIwADwCPBrJd77MPAnZT53P3Bx0djvAM+Tz+h7Cvio/V6GfMnW7cDuVidfdMujcA6BKNYNZNh+7yAwrnPY3o/i6xBYh5XJ6wM+Buws87l/Bt5cNPZ6rBLJzhw+CfxTwe9hu/08CEy3+rvrw7SmGJyIBIG7sOpvf63EJrcD9wK3isg3sX6Uu4wx7ym3S+ALxpgVDR1KoJlvdaB4DkXkfKy0/0dFBKzaLz8VkUuxSgnrHLYZpa5DY8xkwfufA/7dfv55LC1htUqZAtxnjHlbmfdNmedKi2hFFJAA/wTsNcb8dcH4mQWbXQfsAzDGvNoYs2OVGwfAd4A3i8hae19rROQ0+z0f+YJNbwd+WJ9v0ruUmkNjzB5jzFpjzOnGmNOx6q28yBhzTOew/VjlOtxQsNkbgccBjDE32XO4WpnkB4ErHfu+iPSLyC8VvP8bBX9/XIevodRIKzSAK4EbgD0istse+0Pg3SJyFpAFnqV8BNAKjBV98hHgWyLiwyr49H57P4vApfb7U+R/hEr1lJxDY8y9q3xmVXQOm0656/BtIrIDa4V+EPgttzs0xhwXq7zyHSIStoc/glUPCGBURB4DEkA5LUFpIloLSFEUpUfRTGBFUZQeRQWAoihKj9JyAbBKSvoaEblPRJ62/47a4++wY5T3iMgDInJhwb6uEavEwH4R+VCrvpOiKEon0HIfgB11sMEUpKQD1wPvAk4aY/7SvpmPGmP+XxF5CVbkwikReQ1WrPhldtboz4FXYkWg/AR4mzHmyVZ8L0VRlHan5RqAKZ+Sfh1W/Dj23+vtbR4wxpyyxx/EijcHuBTYb4w5YIxJAl+296EoiqKUoOUCoJCilPR1xpij9lvHsBKJink38B/2801Y/T0dDlOH2iaKoijdSksygUthF426C/hvxpg5O5sUAGOMERFTtP1VWALgpU09UUVRlC6hLTSAMqUhJp2sRPvvVMH2FwD/CFxnjJm2h48AWwp2u9keUxRFUUrQcgFQLiUduAe40X5+I3C3vf1W4GvADcaYnxds/xPgTBHZJiIh4K32PhRFUZQStEMU0EuBHwB7sMpAgJWS/hBwJ7AVqxzArxtjTorIPwJvsscA0saYi+19vRarzKwfq4rhx5r2RRRFUTqMlgsARVEUpTW03ASkKIqitAYVAIqiKD2KCgBFUZQeRQWAoihKj6ICQFEUpUdRAaB0FSIyIiLvs59vFJGvNvBYO+zQY0XpSFQAKN3GCPA+AGPM88aYN1fYvhZ2ACoAlI5F8wCUrkJEnCqwTwFPA+cYY15o96q9HugHzgT+Cghh9cVNAK+1Ew3PAD4NTAAx4DeNMftE5C3ArUAGmAVeAewH+rBKjvxP4Bngk0AEWAJuMsY85eHY9wOPAr+MVafrZmPMw435TykKYIzRhz665gGcDjxe4vm7sG7Yg1g391ngvfZ7f4NVhBDgO8CZ9vPLgO/az/cAm+znIwX7/LuCYw8BAfv5K4C7PB77fuBz9vOXO+euD3006tE21UAVpQl8z1g9J+ZFZBb4N3t8D3CBXZH2JcBXCqrRhu2/PwL+WUTuxKpFVYph4AsiciZggKDbYxdsdweAMeb7IjIkIiPGmJkqv6+irIoKAKWXSBQ8zxa8zmJdCz5gxhizo/iDxpj3ishlwOuAR0TkxSX2/2dYN/o32r0t7vdw7Nyhig+9yvdRlJpQJ7DSbcxjmVo8Y4yZA56x7f2IxYX28zOMMQ8ZY/4HcByr9HjxsYbJlyB/V3Wnz2/Yx3spMGuMma1yP4pSERUASldhrP4QPxKRx4FPVLGLdwDvFpFHgSfItxX9hIjssff7AJaz9nvAuSKyW0R+A/j/gP8pIj+jeu06bn/+M1gNjxSlYWgUkKK0CXYU0O8bY3a1+lyU3kA1AEVRlB5FNQBFUZQeRTUARVGUHkUFgKIoSo+iAkBRFKVHUQGgKIrSo6gAUBRF6VFUACiKovQo/wcNuVeQKLGlggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 21:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time = hourly.tail(1).index[0]\n",
    "last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 18:00:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_time = last_time - pd.Timedelta('3 hour')\n",
    "cut_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>2286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>2211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 14:00:00  fffaee1fbb9c96703850f64d3262e843          672.0\n",
       "2020-02-25 15:00:00  fffaee1fbb9c96703850f64d3262e843          707.0\n",
       "2020-02-25 16:00:00  fffaee1fbb9c96703850f64d3262e843         2286.0\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843         2211.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843         1663.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = hourly.loc[hourly.index <= cut_time]\n",
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 19:00:00  0001495ce5f079703599a94c32dab2b0          688.0\n",
       "2020-02-25 20:00:00  0001495ce5f079703599a94c32dab2b0          440.0\n",
       "2020-02-25 21:00:00  0001495ce5f079703599a94c32dab2b0          550.0\n",
       "2020-02-25 19:00:00  00134c004e33e830e5dbce3355a485b9          667.0\n",
       "2020-02-25 20:00:00  00134c004e33e830e5dbce3355a485b9          454.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = hourly.loc[hourly.index > cut_time]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = train_set[train_set[\"device_id\"] == sample_device_id]\n",
    "sample_test = test_set[test_set[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1228.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 14:00:00  8e4a851ed2317a249a0903f29d894361          394.0\n",
       "2020-02-25 15:00:00  8e4a851ed2317a249a0903f29d894361         1557.0\n",
       "2020-02-25 16:00:00  8e4a851ed2317a249a0903f29d894361         1869.0\n",
       "2020-02-25 17:00:00  8e4a851ed2317a249a0903f29d894361         1643.0\n",
       "2020-02-25 18:00:00  8e4a851ed2317a249a0903f29d894361         1228.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 22:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 19:00:00  8e4a851ed2317a249a0903f29d894361          465.0\n",
       "2020-02-25 20:00:00  8e4a851ed2317a249a0903f29d894361         1735.0\n",
       "2020-02-25 21:00:00  8e4a851ed2317a249a0903f29d894361         1739.0\n",
       "2020-02-25 22:00:00  8e4a851ed2317a249a0903f29d894361          497.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfe740af60>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "ax = sample_train[\"motor_peak_mA\"].plot(label=\"train\")\n",
    "sample_test[\"motor_peak_mA\"].plot(ax=ax,label=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data from pandas DataFrame to the expected JSON Lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def df_to_tss(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df[\"timeindex\"] = df.index\n",
    "    cats = {}\n",
    "    tss = {}\n",
    "    for index, row in df.iterrows():\n",
    "        target = row[\"motor_peak_mA\"]\n",
    "        if not(math.isnan(target)):\n",
    "            identity = row[\"device_id\"]\n",
    "            cat = cats.get(identity)\n",
    "            if not cat:\n",
    "                cat = len(cats)\n",
    "                start = str(row[\"timeindex\"])\n",
    "                ts = {\n",
    "                    \"start\": start,\n",
    "                    \"cat\": [cat],\n",
    "                    \"target\": [],\n",
    "                }\n",
    "                cats[identity] = cat\n",
    "                tss[cat] = ts\n",
    "            ts = tss.get(cat)\n",
    "            ts[\"target\"].append(target)\n",
    "    return tss\n",
    "\n",
    "def tss_to_jsonl(tss):  \n",
    "    result = \"\"\n",
    "    for key, value in tss.items():\n",
    "        jsonll = json.dumps(value)\n",
    "        result += jsonll\n",
    "        result += \"\\n\"\n",
    "    return result[:-1]\n",
    "\n",
    "def df_to_jsonl(dataframe):\n",
    "    return tss_to_jsonl(df_to_tss(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020414113998413086\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [0], \"target\": [1843.0]}\n",
      "{\"start\": \"2020-02-24 16:00:00\", \"cat\": [1], \"target\": [2171.0, 1949.0, 1769.0, 871.0, 477.0, 529.0, 570.0, 2202.0, 1483.0, 734.0, 10.0, 532.0, 817.0, 519.0, 617.0, 2146.0, 1870.0, 1397.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [2], \"target\": [10.0, 2145.0, 1772.0, 1392.0, 909.0, 556.0, 658.0, 680.0, 2354.0, 1151.0, 21.0, 21.0, 10.0, 21.0, 21.0, 20.0, 10.0, 10.0, 21.0, 9.0, 20.0, 10.0, 681.0, 553.0, 608.0, 2014.0, 1685.0, 1518.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [3], \"target\": [1580.0, 1997.0, 1735.0, 1202.0, 952.0, 436.0, 648.0, 694.0, 2252.0, 1345.0, 621.0, 10.0, 9.0, 10.0, 562.0]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "jsonl = df_to_jsonl(train_set.head(100))\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)\n",
    "print(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.8278374671936\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_tss = df_to_tss(train_set)\n",
    "train_jsonl = tss_to_jsonl(train_tss)\n",
    "\n",
    "test_tss = df_to_tss(test_set)\n",
    "test_jsonl = tss_to_jsonl(test_tss)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mt-motor-maintenance/input/train.json',\n",
       " './mt-motor-maintenance/input/test.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "prefix = \"mt-motor-maintenance\"\n",
    "input_path = \"./{}/input\".format(prefix)\n",
    "\n",
    "train_path = \"{}/train.json\".format(input_path)\n",
    "test_path = \"{}/test.json\".format(input_path)\n",
    "(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(input_path, ignore_errors=True)\n",
    "pathlib.Path(input_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"w\") as text_file:\n",
    "    print(train_jsonl, file=text_file)\n",
    "\n",
    "with open(test_path, \"w\") as text_file:\n",
    "    print(test_jsonl, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.2M\r\n",
      "393221 drwxrwxr-x 2 ec2-user ec2-user 4.0K May 13 17:22 .\r\n",
      "393220 drwxrwxr-x 3 ec2-user ec2-user 4.0K May 13 17:22 ..\r\n",
      "393223 -rw-rw-r-- 1 ec2-user ec2-user 1.4M May 13 17:22 test.json\r\n",
      "393222 -rw-rw-r-- 1 ec2-user ec2-user 3.8M May 13 17:22 train.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls -liah \"{input_path}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: mt-motor-maintenance/input/test.json to s3://mt-ml-workshop-wzejasmw/mt-motor-maintenance/test.json\n",
      "upload: mt-motor-maintenance/input/train.json to s3://mt-ml-workshop-wzejasmw/mt-motor-maintenance/train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync \"{input_path}/\" \"s3://{bucket}/{prefix}/\" --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-13 17:23:18    1373977 test.json\r\n",
      "2020-05-13 17:23:18    3962421 train.json\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls \"s3://{bucket}/{prefix}/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://mt-ml-workshop-wzejasmw/mt-motor-maintenance/train.json',\n",
       " 'test': 's3://mt-ml-workshop-wzejasmw/mt-motor-maintenance/test.json'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_input = {\n",
    "    \"train\": \"s3://{}/{}/train.json\".format(bucket,prefix),\n",
    "    \"test\": \"s3://{}/{}/test.json\".format(bucket,prefix)\n",
    "}\n",
    "dar_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type='ml.c5.2xlarge' #Estimated Training Time: 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'224300973850.dkr.ecr.eu-west-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "dar_image_name = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')\n",
    "dar_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "dar_estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=dar_image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=train_instance_type,\n",
    "    base_job_name=prefix,\n",
    "    output_path=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 'H'\n",
    "prediction_length = 4\n",
    "context_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dar_hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"3\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"20\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"cardinality\": \"auto\",\n",
    "    \"num_dynamic_feat\":\"ignore\"\n",
    "}\n",
    "dar_estimator.set_hyperparameters(**dar_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-13 18:12:10 Starting - Starting the training job...\n",
      "2020-05-13 18:12:11 Starting - Launching requested ML instances......\n",
      "2020-05-13 18:13:37 Starting - Preparing the instances for training...\n",
      "2020-05-13 18:14:11 Downloading - Downloading input data...\n",
      "2020-05-13 18:14:28 Training - Downloading the training image.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'ignore', u'dropout_rate': u'0.05', u'mini_batch_size': u'32', u'learning_rate': u'0.001', u'num_layers': u'3', u'prediction_length': u'4', u'epochs': u'20', u'time_freq': u'H', u'context_length': u'12', u'num_cells': u'40', u'cardinality': u'auto', u'likelihood': u'gaussian', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] Final configuration: {u'dropout_rate': u'0.05', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_layers': u'3', u'epochs': u'20', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'gaussian', u'num_dynamic_feat': u'ignore', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'4', u'time_freq': u'H', u'context_length': u'12', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] [num_dynamic_feat=ignore] Not using any `dynamic_feat` feature that may be in the data.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:46 INFO 140669025912640] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] [cardinality=auto] Inferred value of cardinality=[16946] from dataset.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] Integer time series\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] number of time series: 16946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] number of observations: 419074\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] mean target length: 24\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] min/mean/max target: 9.0/894.217591643/7730.0\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] mean abs(target): 894.217591643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:47 INFO 140669025912640] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Test set statistics:\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Integer time series\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] number of time series: 16804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] number of observations: 51363\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] mean target length: 3\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] min/mean/max target: 9.0/628.066701711/3795.0\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] mean abs(target): 628.066701711\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] nvidia-smi took: 0.0251410007477 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 30.267953872680664, \"sum\": 30.267953872680664, \"min\": 30.267953872680664}}, \"EndTime\": 1589393689.150695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393689.119583}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 98.13594818115234, \"sum\": 98.13594818115234, \"min\": 98.13594818115234}}, \"EndTime\": 1589393689.217836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393689.150778}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch[0] avg_epoch_loss=8.661080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=8.66108036041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch[5] avg_epoch_loss=42.462527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=42.4625271161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch [5]#011Speed: 1439.70 samples/sec#011loss=42.462527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch[10] avg_epoch_loss=74.225507\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=112.341082382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch [10]#011Speed: 984.51 samples/sec#011loss=112.341082\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch[15] avg_epoch_loss=65.818899\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=47.3243627548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch [15]#011Speed: 1662.10 samples/sec#011loss=47.324363\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch[20] avg_epoch_loss=54.714730\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=19.1813901901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch [20]#011Speed: 1022.25 samples/sec#011loss=19.181390\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch[25] avg_epoch_loss=47.597304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=17.7041103363\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:49 INFO 140669025912640] Epoch[0] Batch [25]#011Speed: 1498.93 samples/sec#011loss=17.704110\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[30] avg_epoch_loss=43.425801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=21.7339862823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [30]#011Speed: 1011.99 samples/sec#011loss=21.733986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[35] avg_epoch_loss=42.285841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=35.21808815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [35]#011Speed: 1651.78 samples/sec#011loss=35.218088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[40] avg_epoch_loss=38.919431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=14.6812822342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [40]#011Speed: 1097.52 samples/sec#011loss=14.681282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[45] avg_epoch_loss=37.109336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=22.2665520668\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [45]#011Speed: 1646.36 samples/sec#011loss=22.266552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[50] avg_epoch_loss=34.276249\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=8.21184854507\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [50]#011Speed: 989.02 samples/sec#011loss=8.211849\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[55] avg_epoch_loss=32.374241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=12.9737605095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [55]#011Speed: 1389.82 samples/sec#011loss=12.973761\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch[60] avg_epoch_loss=30.998419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=15.5892131805\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:50 INFO 140669025912640] Epoch[0] Batch [60]#011Speed: 923.24 samples/sec#011loss=15.589213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[65] avg_epoch_loss=29.472254\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=10.8530451775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [65]#011Speed: 1488.50 samples/sec#011loss=10.853045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[70] avg_epoch_loss=28.452457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=14.9911414146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [70]#011Speed: 1020.17 samples/sec#011loss=14.991141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[75] avg_epoch_loss=27.451094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=13.2317335129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [75]#011Speed: 1478.51 samples/sec#011loss=13.231734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[80] avg_epoch_loss=26.551857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=12.8834575653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [80]#011Speed: 1539.62 samples/sec#011loss=12.883458\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[85] avg_epoch_loss=25.419513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=7.07552976608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [85]#011Speed: 1048.77 samples/sec#011loss=7.075530\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[90] avg_epoch_loss=24.613350\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=10.7473516464\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [90]#011Speed: 1506.92 samples/sec#011loss=10.747352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[95] avg_epoch_loss=23.852237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=9.99997730255\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [95]#011Speed: 1047.81 samples/sec#011loss=9.999977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch[100] avg_epoch_loss=23.197720\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=10.6310011864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:51 INFO 140669025912640] Epoch[0] Batch [100]#011Speed: 1553.47 samples/sec#011loss=10.631001\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[105] avg_epoch_loss=22.468188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=7.73164300919\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [105]#011Speed: 1005.09 samples/sec#011loss=7.731643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[110] avg_epoch_loss=21.871224\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=9.21557359695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [110]#011Speed: 1391.12 samples/sec#011loss=9.215574\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[115] avg_epoch_loss=21.316269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=8.99628372192\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [115]#011Speed: 916.01 samples/sec#011loss=8.996284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[120] avg_epoch_loss=20.929827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=11.96435709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [120]#011Speed: 1530.19 samples/sec#011loss=11.964357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[125] avg_epoch_loss=20.447820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=8.78326568604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [125]#011Speed: 983.06 samples/sec#011loss=8.783266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[130] avg_epoch_loss=19.951233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=7.43724412918\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [130]#011Speed: 1572.28 samples/sec#011loss=7.437244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[135] avg_epoch_loss=19.599874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=10.3942502975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [135]#011Speed: 1065.96 samples/sec#011loss=10.394250\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch[140] avg_epoch_loss=19.165168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=7.34117517471\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:52 INFO 140669025912640] Epoch[0] Batch [140]#011Speed: 1675.27 samples/sec#011loss=7.341175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[145] avg_epoch_loss=18.882193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=10.9022830963\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [145]#011Speed: 982.21 samples/sec#011loss=10.902283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[150] avg_epoch_loss=18.529372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=8.22700490952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [150]#011Speed: 1638.78 samples/sec#011loss=8.227005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[155] avg_epoch_loss=18.238266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=9.44687423706\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [155]#011Speed: 912.98 samples/sec#011loss=9.446874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[160] avg_epoch_loss=17.960359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=9.28967018127\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [160]#011Speed: 1643.91 samples/sec#011loss=9.289670\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[165] avg_epoch_loss=17.702284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=9.39224720001\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [165]#011Speed: 1017.85 samples/sec#011loss=9.392247\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[170] avg_epoch_loss=17.439305\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=8.70840682983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [170]#011Speed: 1675.99 samples/sec#011loss=8.708407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch[175] avg_epoch_loss=17.173413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=8.07991933823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:53 INFO 140669025912640] Epoch[0] Batch [175]#011Speed: 1690.02 samples/sec#011loss=8.079919\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[180] avg_epoch_loss=16.941959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=8.79478607178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [180]#011Speed: 1062.49 samples/sec#011loss=8.794786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[185] avg_epoch_loss=16.750925\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=9.83547668457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [185]#011Speed: 1636.01 samples/sec#011loss=9.835477\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[190] avg_epoch_loss=16.549713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=9.06463031769\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [190]#011Speed: 1007.87 samples/sec#011loss=9.064630\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[195] avg_epoch_loss=16.368913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=9.46235055923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [195]#011Speed: 1672.54 samples/sec#011loss=9.462351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[200] avg_epoch_loss=16.177054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=8.65616950989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [200]#011Speed: 1038.44 samples/sec#011loss=8.656170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[205] avg_epoch_loss=16.010265\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=9.3053732872\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [205]#011Speed: 1637.90 samples/sec#011loss=9.305373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[210] avg_epoch_loss=15.820734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=8.01202449799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [210]#011Speed: 960.46 samples/sec#011loss=8.012024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[215] avg_epoch_loss=15.654962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=8.65940723419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [215]#011Speed: 1690.35 samples/sec#011loss=8.659407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch[220] avg_epoch_loss=15.489169\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=8.32690553665\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:54 INFO 140669025912640] Epoch[0] Batch [220]#011Speed: 1626.10 samples/sec#011loss=8.326906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[225] avg_epoch_loss=15.325941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=8.11124992371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [225]#011Speed: 969.86 samples/sec#011loss=8.111250\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[230] avg_epoch_loss=15.187369\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=8.92391223907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [230]#011Speed: 1535.24 samples/sec#011loss=8.923912\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-13 18:14:44 Training - Training image download completed. Training in progress.\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[235] avg_epoch_loss=15.042520\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=8.35049571991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [235]#011Speed: 1035.50 samples/sec#011loss=8.350496\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[240] avg_epoch_loss=14.911769\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=8.74035110474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [240]#011Speed: 1595.12 samples/sec#011loss=8.740351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[245] avg_epoch_loss=14.786632\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=8.75500850677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [245]#011Speed: 991.05 samples/sec#011loss=8.755009\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[250] avg_epoch_loss=14.641961\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=7.52416992188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [250]#011Speed: 1687.73 samples/sec#011loss=7.524170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch[255] avg_epoch_loss=14.520115\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=8.40344419479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:55 INFO 140669025912640] Epoch[0] Batch [255]#011Speed: 1072.64 samples/sec#011loss=8.403444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[260] avg_epoch_loss=14.386052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=7.52199716568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [260]#011Speed: 1651.00 samples/sec#011loss=7.521997\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[265] avg_epoch_loss=14.263396\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=7.86077880859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [265]#011Speed: 982.99 samples/sec#011loss=7.860779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[270] avg_epoch_loss=14.151944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=8.22271518707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [270]#011Speed: 1657.16 samples/sec#011loss=8.222715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[275] avg_epoch_loss=14.045253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=275 train loss <loss>=8.2625834465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [275]#011Speed: 1050.35 samples/sec#011loss=8.262583\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[280] avg_epoch_loss=13.944280\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=280 train loss <loss>=8.37055530548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [280]#011Speed: 1639.34 samples/sec#011loss=8.370555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[285] avg_epoch_loss=13.846604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=285 train loss <loss>=8.3572388649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [285]#011Speed: 1037.69 samples/sec#011loss=8.357239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[290] avg_epoch_loss=13.754950\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=290 train loss <loss>=8.51229400635\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [290]#011Speed: 1460.67 samples/sec#011loss=8.512294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch[295] avg_epoch_loss=13.660209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=295 train loss <loss>=8.14628067017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:56 INFO 140669025912640] Epoch[0] Batch [295]#011Speed: 1073.13 samples/sec#011loss=8.146281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[300] avg_epoch_loss=13.557253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=300 train loss <loss>=7.46229314804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [300]#011Speed: 1637.18 samples/sec#011loss=7.462293\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[305] avg_epoch_loss=13.459956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=305 train loss <loss>=7.60270051956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [305]#011Speed: 1083.73 samples/sec#011loss=7.602701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[310] avg_epoch_loss=13.374865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=310 train loss <loss>=8.16725749969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [310]#011Speed: 1540.55 samples/sec#011loss=8.167257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[315] avg_epoch_loss=13.303452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=315 train loss <loss>=8.86158809662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [315]#011Speed: 1046.78 samples/sec#011loss=8.861588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[320] avg_epoch_loss=13.219627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=320 train loss <loss>=7.92184524536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [320]#011Speed: 1642.58 samples/sec#011loss=7.921845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[325] avg_epoch_loss=13.150311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=325 train loss <loss>=8.70024032593\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [325]#011Speed: 1068.25 samples/sec#011loss=8.700240\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[330] avg_epoch_loss=13.070199\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=330 train loss <loss>=7.84692783356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [330]#011Speed: 1557.62 samples/sec#011loss=7.846928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch[335] avg_epoch_loss=13.001165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=335 train loss <loss>=8.43110847473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:57 INFO 140669025912640] Epoch[0] Batch [335]#011Speed: 1604.20 samples/sec#011loss=8.431108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[340] avg_epoch_loss=12.919537\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=340 train loss <loss>=7.43412389755\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [340]#011Speed: 1076.78 samples/sec#011loss=7.434124\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[345] avg_epoch_loss=12.855240\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=345 train loss <loss>=8.47018213272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [345]#011Speed: 1621.19 samples/sec#011loss=8.470182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[350] avg_epoch_loss=12.793677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=350 train loss <loss>=8.53353719711\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [350]#011Speed: 1112.64 samples/sec#011loss=8.533537\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[355] avg_epoch_loss=12.717942\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=355 train loss <loss>=7.40135231018\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [355]#011Speed: 1503.86 samples/sec#011loss=7.401352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[360] avg_epoch_loss=12.642897\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=360 train loss <loss>=7.29964399338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [360]#011Speed: 1006.33 samples/sec#011loss=7.299644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[365] avg_epoch_loss=12.572535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=365 train loss <loss>=7.49238538742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [365]#011Speed: 1636.28 samples/sec#011loss=7.492385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[370] avg_epoch_loss=12.517394\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=370 train loss <loss>=8.48107328415\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [370]#011Speed: 1122.82 samples/sec#011loss=8.481073\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch[375] avg_epoch_loss=12.453416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=375 train loss <loss>=7.70628108978\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:58 INFO 140669025912640] Epoch[0] Batch [375]#011Speed: 1620.22 samples/sec#011loss=7.706281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[380] avg_epoch_loss=12.394000\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=380 train loss <loss>=7.92590970993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [380]#011Speed: 991.47 samples/sec#011loss=7.925910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[385] avg_epoch_loss=12.341317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=385 train loss <loss>=8.32690839767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [385]#011Speed: 1614.37 samples/sec#011loss=8.326908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[390] avg_epoch_loss=12.289349\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=390 train loss <loss>=8.27741317749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [390]#011Speed: 1017.78 samples/sec#011loss=8.277413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[395] avg_epoch_loss=12.237918\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=395 train loss <loss>=8.21597108841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [395]#011Speed: 1514.47 samples/sec#011loss=8.215971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[400] avg_epoch_loss=12.185929\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=400 train loss <loss>=8.06841058731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [400]#011Speed: 1081.85 samples/sec#011loss=8.068411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[405] avg_epoch_loss=12.136020\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=405 train loss <loss>=8.13330612183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [405]#011Speed: 1677.85 samples/sec#011loss=8.133306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[410] avg_epoch_loss=12.085989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=410 train loss <loss>=8.02353239059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [410]#011Speed: 1101.35 samples/sec#011loss=8.023532\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch[415] avg_epoch_loss=12.030950\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=415 train loss <loss>=7.50668916702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:14:59 INFO 140669025912640] Epoch[0] Batch [415]#011Speed: 1671.86 samples/sec#011loss=7.506689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[420] avg_epoch_loss=11.991837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=420 train loss <loss>=8.73767776489\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [420]#011Speed: 1090.27 samples/sec#011loss=8.737678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[425] avg_epoch_loss=11.945709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=425 train loss <loss>=8.06167879105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [425]#011Speed: 1407.86 samples/sec#011loss=8.061679\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[430] avg_epoch_loss=11.903953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=430 train loss <loss>=8.34640216827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [430]#011Speed: 1103.83 samples/sec#011loss=8.346402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[435] avg_epoch_loss=11.869778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=435 train loss <loss>=8.92386493683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [435]#011Speed: 1657.36 samples/sec#011loss=8.923865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[440] avg_epoch_loss=11.823939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=440 train loss <loss>=7.82675971985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [440]#011Speed: 1116.06 samples/sec#011loss=7.826760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[445] avg_epoch_loss=11.780797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=445 train loss <loss>=7.97571735382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [445]#011Speed: 1668.06 samples/sec#011loss=7.975717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[450] avg_epoch_loss=11.736371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=450 train loss <loss>=7.77354774475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [450]#011Speed: 1117.87 samples/sec#011loss=7.773548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch[455] avg_epoch_loss=11.694713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=455 train loss <loss>=7.93714132309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:00 INFO 140669025912640] Epoch[0] Batch [455]#011Speed: 1664.24 samples/sec#011loss=7.937141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[460] avg_epoch_loss=11.654010\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=460 train loss <loss>=7.94186820984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [460]#011Speed: 1050.85 samples/sec#011loss=7.941868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[465] avg_epoch_loss=11.611143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=465 train loss <loss>=7.65883579254\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [465]#011Speed: 1654.94 samples/sec#011loss=7.658836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[470] avg_epoch_loss=11.573852\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=470 train loss <loss>=8.09829502106\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [470]#011Speed: 958.61 samples/sec#011loss=8.098295\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[475] avg_epoch_loss=11.534941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=475 train loss <loss>=7.86960763931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [475]#011Speed: 1622.97 samples/sec#011loss=7.869608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[480] avg_epoch_loss=11.498057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=480 train loss <loss>=7.98666820526\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [480]#011Speed: 1023.53 samples/sec#011loss=7.986668\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[485] avg_epoch_loss=11.460151\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=485 train loss <loss>=7.81355800629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [485]#011Speed: 1624.22 samples/sec#011loss=7.813558\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[490] avg_epoch_loss=11.427310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=490 train loss <loss>=8.23521966934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [490]#011Speed: 1540.65 samples/sec#011loss=8.235220\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch[495] avg_epoch_loss=11.391525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=495 train loss <loss>=7.8774228096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:01 INFO 140669025912640] Epoch[0] Batch [495]#011Speed: 1020.22 samples/sec#011loss=7.877423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[500] avg_epoch_loss=11.357490\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=500 train loss <loss>=7.98125419617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [500]#011Speed: 1673.92 samples/sec#011loss=7.981254\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[505] avg_epoch_loss=11.324249\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=505 train loss <loss>=7.99347639084\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [505]#011Speed: 1048.53 samples/sec#011loss=7.993476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[510] avg_epoch_loss=11.289835\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=510 train loss <loss>=7.80708866119\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [510]#011Speed: 1667.02 samples/sec#011loss=7.807089\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[515] avg_epoch_loss=11.265999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=515 train loss <loss>=8.83003320694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [515]#011Speed: 983.41 samples/sec#011loss=8.830033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[520] avg_epoch_loss=11.234661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=520 train loss <loss>=8.00053462982\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [520]#011Speed: 1432.54 samples/sec#011loss=8.000535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[525] avg_epoch_loss=11.201134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=525 train loss <loss>=7.7076382637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [525]#011Speed: 1041.29 samples/sec#011loss=7.707638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[530] avg_epoch_loss=11.167316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=530 train loss <loss>=7.60959863663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [530]#011Speed: 1530.88 samples/sec#011loss=7.609599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch[535] avg_epoch_loss=11.133797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=535 train loss <loss>=7.57415237427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:02 INFO 140669025912640] Epoch[0] Batch [535]#011Speed: 1042.16 samples/sec#011loss=7.574152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[540] avg_epoch_loss=11.108953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=540 train loss <loss>=8.44566173553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [540]#011Speed: 1687.48 samples/sec#011loss=8.445662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[545] avg_epoch_loss=11.072896\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=545 train loss <loss>=7.17150297165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [545]#011Speed: 1054.80 samples/sec#011loss=7.171503\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[550] avg_epoch_loss=11.044100\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=550 train loss <loss>=7.89960594177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [550]#011Speed: 1483.35 samples/sec#011loss=7.899606\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[555] avg_epoch_loss=11.016355\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=555 train loss <loss>=7.95879268646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [555]#011Speed: 1052.00 samples/sec#011loss=7.958793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[560] avg_epoch_loss=10.990216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=560 train loss <loss>=8.08360233307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [560]#011Speed: 1642.34 samples/sec#011loss=8.083602\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[565] avg_epoch_loss=10.963689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=565 train loss <loss>=7.98735218048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [565]#011Speed: 1075.50 samples/sec#011loss=7.987352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[570] avg_epoch_loss=10.940904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=570 train loss <loss>=8.36163606644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [570]#011Speed: 1686.00 samples/sec#011loss=8.361636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch[575] avg_epoch_loss=10.912863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=575 train loss <loss>=7.71059675217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:03 INFO 140669025912640] Epoch[0] Batch [575]#011Speed: 1102.60 samples/sec#011loss=7.710597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[0] Batch[580] avg_epoch_loss=10.884486\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, batch=580 train loss <loss>=7.61550378799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[0] Batch [580]#011Speed: 1498.16 samples/sec#011loss=7.615504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] processed a total of 18602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"update.time\": {\"count\": 1, \"max\": 14839.269876480103, \"sum\": 14839.269876480103, \"min\": 14839.269876480103}}, \"EndTime\": 1589393704.057249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393689.217893}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1253.55641324 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=0, train loss <loss>=10.876048134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_1cd78f07-5398-4be7-884b-9534f985abc0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.776996612548828, \"sum\": 10.776996612548828, \"min\": 10.776996612548828}}, \"EndTime\": 1589393704.068516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393704.057326}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[0] avg_epoch_loss=7.069512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=7.06951189041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[5] avg_epoch_loss=7.773181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=7.77318080266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [5]#011Speed: 1649.35 samples/sec#011loss=7.773181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[10] avg_epoch_loss=8.083722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.45637168884\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [10]#011Speed: 1087.77 samples/sec#011loss=8.456372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[15] avg_epoch_loss=7.954235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=7.66936244965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [15]#011Speed: 1603.67 samples/sec#011loss=7.669362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[20] avg_epoch_loss=8.054986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=8.37738876343\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [20]#011Speed: 1085.67 samples/sec#011loss=8.377389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[25] avg_epoch_loss=7.993531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=7.73542175293\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [25]#011Speed: 1678.52 samples/sec#011loss=7.735422\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[30] avg_epoch_loss=7.962460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=7.80088996887\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [30]#011Speed: 1062.30 samples/sec#011loss=7.800890\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch[35] avg_epoch_loss=8.009408\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=8.30048780441\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:04 INFO 140669025912640] Epoch[1] Batch [35]#011Speed: 1672.63 samples/sec#011loss=8.300488\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[40] avg_epoch_loss=8.011078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=8.02310276031\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [40]#011Speed: 992.51 samples/sec#011loss=8.023103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[45] avg_epoch_loss=7.959790\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=7.53922843933\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [45]#011Speed: 1645.67 samples/sec#011loss=7.539228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[50] avg_epoch_loss=7.985634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=8.22340011597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [50]#011Speed: 1006.94 samples/sec#011loss=8.223400\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[55] avg_epoch_loss=7.942330\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=7.50063009262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [55]#011Speed: 1654.16 samples/sec#011loss=7.500630\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[60] avg_epoch_loss=8.001184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=8.66034955978\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [60]#011Speed: 1048.35 samples/sec#011loss=8.660350\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[65] avg_epoch_loss=7.973504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=7.6358048439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [65]#011Speed: 1630.19 samples/sec#011loss=7.635805\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch[70] avg_epoch_loss=7.978351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=8.04232997894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:05 INFO 140669025912640] Epoch[1] Batch [70]#011Speed: 1005.26 samples/sec#011loss=8.042330\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[75] avg_epoch_loss=7.978324\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=7.97793226242\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [75]#011Speed: 1602.02 samples/sec#011loss=7.977932\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[80] avg_epoch_loss=7.943211\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=7.40949611664\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [80]#011Speed: 1038.94 samples/sec#011loss=7.409496\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[85] avg_epoch_loss=7.927107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=7.66623506546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [85]#011Speed: 1578.69 samples/sec#011loss=7.666235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[90] avg_epoch_loss=7.934454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=8.06082315445\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [90]#011Speed: 955.44 samples/sec#011loss=8.060823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[95] avg_epoch_loss=7.949501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=8.2233464241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [95]#011Speed: 1662.04 samples/sec#011loss=8.223346\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[100] avg_epoch_loss=7.918997\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=7.33331699371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [100]#011Speed: 1687.96 samples/sec#011loss=7.333317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[105] avg_epoch_loss=7.916566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=7.86746301651\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [105]#011Speed: 1044.99 samples/sec#011loss=7.867463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch[110] avg_epoch_loss=7.938043\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=8.39335918427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:06 INFO 140669025912640] Epoch[1] Batch [110]#011Speed: 1043.87 samples/sec#011loss=8.393359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[115] avg_epoch_loss=7.916188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=7.43100481033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [115]#011Speed: 1574.48 samples/sec#011loss=7.431005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[120] avg_epoch_loss=7.931842\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=8.29500608444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [120]#011Speed: 1046.65 samples/sec#011loss=8.295006\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[125] avg_epoch_loss=7.926121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=7.78768081665\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [125]#011Speed: 1637.30 samples/sec#011loss=7.787681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[130] avg_epoch_loss=7.912243\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=7.56251535416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [130]#011Speed: 1038.71 samples/sec#011loss=7.562515\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[135] avg_epoch_loss=7.921318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=8.15907459259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [135]#011Speed: 1649.23 samples/sec#011loss=8.159075\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[140] avg_epoch_loss=7.902552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=7.39214076996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [140]#011Speed: 1012.61 samples/sec#011loss=7.392141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[145] avg_epoch_loss=7.910771\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=8.1425201416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [145]#011Speed: 1655.53 samples/sec#011loss=8.142520\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch[150] avg_epoch_loss=7.900231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=7.59247617722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:07 INFO 140669025912640] Epoch[1] Batch [150]#011Speed: 1012.36 samples/sec#011loss=7.592476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[155] avg_epoch_loss=7.891272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=7.62070837021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [155]#011Speed: 1664.20 samples/sec#011loss=7.620708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[160] avg_epoch_loss=7.873348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=7.31411104202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [160]#011Speed: 1067.44 samples/sec#011loss=7.314111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[165] avg_epoch_loss=7.866103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=7.63283185959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [165]#011Speed: 1635.61 samples/sec#011loss=7.632832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[170] avg_epoch_loss=7.862801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=7.75317296982\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [170]#011Speed: 988.03 samples/sec#011loss=7.753173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[175] avg_epoch_loss=7.865263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=7.94945793152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [175]#011Speed: 1651.09 samples/sec#011loss=7.949458\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[180] avg_epoch_loss=7.867217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=7.93599863052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [180]#011Speed: 1016.50 samples/sec#011loss=7.935999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[185] avg_epoch_loss=7.862286\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=7.68379859924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [185]#011Speed: 1669.14 samples/sec#011loss=7.683799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch[190] avg_epoch_loss=7.850837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=7.42492656708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:08 INFO 140669025912640] Epoch[1] Batch [190]#011Speed: 1658.72 samples/sec#011loss=7.424927\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[195] avg_epoch_loss=7.862297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=8.30004463196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [195]#011Speed: 1081.37 samples/sec#011loss=8.300045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[200] avg_epoch_loss=7.844952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=7.16503343582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [200]#011Speed: 1680.95 samples/sec#011loss=7.165033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[205] avg_epoch_loss=7.839572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=7.6233039856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [205]#011Speed: 1042.45 samples/sec#011loss=7.623304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[210] avg_epoch_loss=7.831952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=7.51801729202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [210]#011Speed: 1702.35 samples/sec#011loss=7.518017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[215] avg_epoch_loss=7.816338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=7.15740938187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [215]#011Speed: 963.76 samples/sec#011loss=7.157409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[220] avg_epoch_loss=7.806152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=7.36611337662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [220]#011Speed: 1588.51 samples/sec#011loss=7.366113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[225] avg_epoch_loss=7.804160\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=7.71614732742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [225]#011Speed: 1005.27 samples/sec#011loss=7.716147\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch[230] avg_epoch_loss=7.806632\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=7.91836519241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:09 INFO 140669025912640] Epoch[1] Batch [230]#011Speed: 1682.85 samples/sec#011loss=7.918365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[235] avg_epoch_loss=7.809468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=7.94046058655\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [235]#011Speed: 1055.88 samples/sec#011loss=7.940461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[240] avg_epoch_loss=7.803993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=7.54560909271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [240]#011Speed: 1515.50 samples/sec#011loss=7.545609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[245] avg_epoch_loss=7.794249\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=7.32456274033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [245]#011Speed: 1025.55 samples/sec#011loss=7.324563\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[250] avg_epoch_loss=7.787807\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=7.47085676193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [250]#011Speed: 1474.07 samples/sec#011loss=7.470857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[255] avg_epoch_loss=7.786323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=7.71181545258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [255]#011Speed: 1062.86 samples/sec#011loss=7.711815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[260] avg_epoch_loss=7.775825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=7.23834028244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [260]#011Speed: 1668.53 samples/sec#011loss=7.238340\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[265] avg_epoch_loss=7.772188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=7.58231525421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [265]#011Speed: 1051.06 samples/sec#011loss=7.582315\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch[270] avg_epoch_loss=7.764391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=270 train loss <loss>=7.34960308075\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:10 INFO 140669025912640] Epoch[1] Batch [270]#011Speed: 1650.71 samples/sec#011loss=7.349603\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[275] avg_epoch_loss=7.756215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=275 train loss <loss>=7.3131108284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [275]#011Speed: 993.74 samples/sec#011loss=7.313111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[280] avg_epoch_loss=7.743583\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=280 train loss <loss>=7.04629011154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [280]#011Speed: 1548.28 samples/sec#011loss=7.046290\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[285] avg_epoch_loss=7.737603\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=285 train loss <loss>=7.40153264999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [285]#011Speed: 972.30 samples/sec#011loss=7.401533\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[290] avg_epoch_loss=7.734921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=290 train loss <loss>=7.58150415421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [290]#011Speed: 1599.33 samples/sec#011loss=7.581504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[295] avg_epoch_loss=7.733011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=295 train loss <loss>=7.62181663513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [295]#011Speed: 1040.73 samples/sec#011loss=7.621817\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[300] avg_epoch_loss=7.723168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=300 train loss <loss>=7.1404507637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [300]#011Speed: 1676.48 samples/sec#011loss=7.140451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[305] avg_epoch_loss=7.717507\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=305 train loss <loss>=7.37677364349\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [305]#011Speed: 1030.77 samples/sec#011loss=7.376774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch[310] avg_epoch_loss=7.707997\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=310 train loss <loss>=7.12592363358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:11 INFO 140669025912640] Epoch[1] Batch [310]#011Speed: 1679.59 samples/sec#011loss=7.125924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[315] avg_epoch_loss=7.695034\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=315 train loss <loss>=6.88877573013\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [315]#011Speed: 1006.93 samples/sec#011loss=6.888776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[320] avg_epoch_loss=7.694301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=320 train loss <loss>=7.64796705246\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [320]#011Speed: 1587.95 samples/sec#011loss=7.647967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[325] avg_epoch_loss=7.685306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=325 train loss <loss>=7.10784788132\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [325]#011Speed: 1637.46 samples/sec#011loss=7.107848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[330] avg_epoch_loss=7.680186\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=330 train loss <loss>=7.34635696411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [330]#011Speed: 883.85 samples/sec#011loss=7.346357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[335] avg_epoch_loss=7.668867\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=335 train loss <loss>=6.9195104599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [335]#011Speed: 1437.23 samples/sec#011loss=6.919510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[340] avg_epoch_loss=7.662086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=340 train loss <loss>=7.20642776489\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [340]#011Speed: 949.87 samples/sec#011loss=7.206428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch[345] avg_epoch_loss=7.656140\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=345 train loss <loss>=7.25059709549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:12 INFO 140669025912640] Epoch[1] Batch [345]#011Speed: 1594.05 samples/sec#011loss=7.250597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[350] avg_epoch_loss=7.650954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=350 train loss <loss>=7.29208469391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [350]#011Speed: 985.57 samples/sec#011loss=7.292085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[355] avg_epoch_loss=7.637879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=355 train loss <loss>=6.72005710602\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [355]#011Speed: 1530.25 samples/sec#011loss=6.720057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[360] avg_epoch_loss=7.628657\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=360 train loss <loss>=6.97202854156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [360]#011Speed: 1642.02 samples/sec#011loss=6.972029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[365] avg_epoch_loss=7.615366\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=365 train loss <loss>=6.65574216843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [365]#011Speed: 1027.78 samples/sec#011loss=6.655742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[370] avg_epoch_loss=7.606886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=370 train loss <loss>=6.98616075516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [370]#011Speed: 1669.94 samples/sec#011loss=6.986161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[375] avg_epoch_loss=7.596944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=375 train loss <loss>=6.85924711227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [375]#011Speed: 888.13 samples/sec#011loss=6.859247\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[380] avg_epoch_loss=7.586864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=380 train loss <loss>=6.82882614136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [380]#011Speed: 1698.05 samples/sec#011loss=6.828826\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch[385] avg_epoch_loss=7.583846\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=385 train loss <loss>=7.35388345718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:13 INFO 140669025912640] Epoch[1] Batch [385]#011Speed: 1080.15 samples/sec#011loss=7.353883\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[390] avg_epoch_loss=7.575652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=390 train loss <loss>=6.94311113358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [390]#011Speed: 1676.87 samples/sec#011loss=6.943111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[395] avg_epoch_loss=7.561371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=395 train loss <loss>=6.44457855225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [395]#011Speed: 1039.19 samples/sec#011loss=6.444579\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[400] avg_epoch_loss=7.546668\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=400 train loss <loss>=6.3821603775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [400]#011Speed: 1594.52 samples/sec#011loss=6.382160\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[405] avg_epoch_loss=7.533744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=405 train loss <loss>=6.49723930359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [405]#011Speed: 1027.86 samples/sec#011loss=6.497239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[410] avg_epoch_loss=7.527228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=410 train loss <loss>=6.99815292358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [410]#011Speed: 1634.60 samples/sec#011loss=6.998153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[415] avg_epoch_loss=7.514004\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=415 train loss <loss>=6.42697868347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [415]#011Speed: 1014.04 samples/sec#011loss=6.426979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[420] avg_epoch_loss=7.501144\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=420 train loss <loss>=6.431199646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [420]#011Speed: 1616.42 samples/sec#011loss=6.431200\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch[425] avg_epoch_loss=7.486712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=425 train loss <loss>=6.27155847549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:14 INFO 140669025912640] Epoch[1] Batch [425]#011Speed: 1103.23 samples/sec#011loss=6.271558\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[430] avg_epoch_loss=7.479774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=430 train loss <loss>=6.88862085342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [430]#011Speed: 1668.94 samples/sec#011loss=6.888621\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[435] avg_epoch_loss=7.468513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=435 train loss <loss>=6.4978313446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [435]#011Speed: 1052.76 samples/sec#011loss=6.497831\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[440] avg_epoch_loss=7.452812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=440 train loss <loss>=6.08371906281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [440]#011Speed: 1447.13 samples/sec#011loss=6.083719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[445] avg_epoch_loss=7.444623\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=445 train loss <loss>=6.72230939865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [445]#011Speed: 927.31 samples/sec#011loss=6.722309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[450] avg_epoch_loss=7.431465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=450 train loss <loss>=6.25781097412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [450]#011Speed: 1646.56 samples/sec#011loss=6.257811\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[455] avg_epoch_loss=7.418596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=455 train loss <loss>=6.25780382156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [455]#011Speed: 1032.04 samples/sec#011loss=6.257804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[460] avg_epoch_loss=7.408691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=460 train loss <loss>=6.50532846451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [460]#011Speed: 1664.53 samples/sec#011loss=6.505328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch[465] avg_epoch_loss=7.393673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=465 train loss <loss>=6.00905284882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:15 INFO 140669025912640] Epoch[1] Batch [465]#011Speed: 1054.18 samples/sec#011loss=6.009053\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[470] avg_epoch_loss=7.381786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=470 train loss <loss>=6.27388267517\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [470]#011Speed: 1619.71 samples/sec#011loss=6.273883\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[475] avg_epoch_loss=7.366050\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=475 train loss <loss>=5.88376779556\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [475]#011Speed: 1050.43 samples/sec#011loss=5.883768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[480] avg_epoch_loss=7.358123\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=480 train loss <loss>=6.6034412384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [480]#011Speed: 1459.67 samples/sec#011loss=6.603441\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[485] avg_epoch_loss=7.344349\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=485 train loss <loss>=6.01923704147\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [485]#011Speed: 1061.63 samples/sec#011loss=6.019237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[490] avg_epoch_loss=7.334356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=490 train loss <loss>=6.36309375763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [490]#011Speed: 1591.58 samples/sec#011loss=6.363094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[495] avg_epoch_loss=7.324985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=495 train loss <loss>=6.40469026566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [495]#011Speed: 994.62 samples/sec#011loss=6.404690\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[500] avg_epoch_loss=7.312908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=500 train loss <loss>=6.11490535736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [500]#011Speed: 1482.52 samples/sec#011loss=6.114905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch[505] avg_epoch_loss=7.304376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=505 train loss <loss>=6.44947338104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:16 INFO 140669025912640] Epoch[1] Batch [505]#011Speed: 1032.19 samples/sec#011loss=6.449473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[510] avg_epoch_loss=7.293904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=510 train loss <loss>=6.2341966629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [510]#011Speed: 1651.82 samples/sec#011loss=6.234197\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[515] avg_epoch_loss=7.283179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=515 train loss <loss>=6.18700704575\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [515]#011Speed: 1078.64 samples/sec#011loss=6.187007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[520] avg_epoch_loss=7.269922\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=520 train loss <loss>=5.90179796219\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [520]#011Speed: 1554.41 samples/sec#011loss=5.901798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[525] avg_epoch_loss=7.255793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=525 train loss <loss>=5.78356075287\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [525]#011Speed: 1051.77 samples/sec#011loss=5.783561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[530] avg_epoch_loss=7.244918\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=530 train loss <loss>=6.10083866119\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [530]#011Speed: 1621.80 samples/sec#011loss=6.100839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[535] avg_epoch_loss=7.232421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=535 train loss <loss>=5.90524930954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [535]#011Speed: 1115.29 samples/sec#011loss=5.905249\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[540] avg_epoch_loss=7.222389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=540 train loss <loss>=6.14698019028\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [540]#011Speed: 1625.24 samples/sec#011loss=6.146980\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch[545] avg_epoch_loss=7.209946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=545 train loss <loss>=5.8636048317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:17 INFO 140669025912640] Epoch[1] Batch [545]#011Speed: 1075.11 samples/sec#011loss=5.863605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch[550] avg_epoch_loss=7.202030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=550 train loss <loss>=6.33764677048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch [550]#011Speed: 1640.09 samples/sec#011loss=6.337647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch[555] avg_epoch_loss=7.189688\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=555 train loss <loss>=5.82958803177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch [555]#011Speed: 1129.13 samples/sec#011loss=5.829588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch[560] avg_epoch_loss=7.179580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=560 train loss <loss>=6.05555667877\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch [560]#011Speed: 1585.19 samples/sec#011loss=6.055557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch[565] avg_epoch_loss=7.168037\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=565 train loss <loss>=5.87293453217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch [565]#011Speed: 1093.47 samples/sec#011loss=5.872935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch[570] avg_epoch_loss=7.157780\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, batch=570 train loss <loss>=5.99661483765\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[1] Batch [570]#011Speed: 1590.28 samples/sec#011loss=5.996615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] processed a total of 18321 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14542.67406463623, \"sum\": 14542.67406463623, \"min\": 14542.67406463623}}, \"EndTime\": 1589393718.611306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393704.068575}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1259.8015178 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=1, train loss <loss>=7.15445053806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_2bad8dd2-0c84-426e-9d40-3a5f00362666-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.211944580078125, \"sum\": 10.211944580078125, \"min\": 10.211944580078125}}, \"EndTime\": 1589393718.62194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393718.611369}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[2] Batch[0] avg_epoch_loss=5.801362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=5.80136203766\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[2] Batch[5] avg_epoch_loss=5.763093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=5.76309323311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[2] Batch [5]#011Speed: 1611.78 samples/sec#011loss=5.763093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[2] Batch[10] avg_epoch_loss=5.896877\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=6.05741796494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:18 INFO 140669025912640] Epoch[2] Batch [10]#011Speed: 1039.67 samples/sec#011loss=6.057418\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[15] avg_epoch_loss=5.771187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=5.49467000961\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [15]#011Speed: 1680.16 samples/sec#011loss=5.494670\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[20] avg_epoch_loss=5.855930\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=6.12710733414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [20]#011Speed: 1656.47 samples/sec#011loss=6.127107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[25] avg_epoch_loss=5.848067\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=5.81503925323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [25]#011Speed: 1071.42 samples/sec#011loss=5.815039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[30] avg_epoch_loss=5.944813\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=6.44789514542\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [30]#011Speed: 1598.11 samples/sec#011loss=6.447895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[35] avg_epoch_loss=5.951056\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=5.98976039886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [35]#011Speed: 1010.33 samples/sec#011loss=5.989760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[40] avg_epoch_loss=5.936564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=5.83221921921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [40]#011Speed: 1680.15 samples/sec#011loss=5.832219\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[45] avg_epoch_loss=5.926209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=5.84129905701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [45]#011Speed: 1061.93 samples/sec#011loss=5.841299\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch[50] avg_epoch_loss=5.918956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=5.85223283768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:19 INFO 140669025912640] Epoch[2] Batch [50]#011Speed: 1523.95 samples/sec#011loss=5.852233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[55] avg_epoch_loss=5.918432\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=5.91307992935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [55]#011Speed: 1060.65 samples/sec#011loss=5.913080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[60] avg_epoch_loss=5.906388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=5.77149820328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [60]#011Speed: 1638.40 samples/sec#011loss=5.771498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[65] avg_epoch_loss=5.927424\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=6.18407154083\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [65]#011Speed: 1029.80 samples/sec#011loss=6.184072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[70] avg_epoch_loss=5.951607\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=6.27081022263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [70]#011Speed: 1575.03 samples/sec#011loss=6.270810\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[75] avg_epoch_loss=5.944491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=5.84344940186\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [75]#011Speed: 1019.93 samples/sec#011loss=5.843449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[80] avg_epoch_loss=5.938355\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=5.84509382248\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [80]#011Speed: 1675.99 samples/sec#011loss=5.845094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[85] avg_epoch_loss=5.926377\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=5.73232707977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [85]#011Speed: 982.10 samples/sec#011loss=5.732327\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch[90] avg_epoch_loss=5.922086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=5.84828357697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:20 INFO 140669025912640] Epoch[2] Batch [90]#011Speed: 1478.47 samples/sec#011loss=5.848284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[95] avg_epoch_loss=5.924632\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=5.97096996307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [95]#011Speed: 1061.59 samples/sec#011loss=5.970970\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[100] avg_epoch_loss=5.921736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=5.86613426208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [100]#011Speed: 1646.62 samples/sec#011loss=5.866134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[105] avg_epoch_loss=5.943390\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=6.38080606461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [105]#011Speed: 1071.60 samples/sec#011loss=6.380806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[110] avg_epoch_loss=5.940981\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=5.88989114761\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [110]#011Speed: 1521.68 samples/sec#011loss=5.889891\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[115] avg_epoch_loss=5.932899\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=5.75349025726\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [115]#011Speed: 1025.77 samples/sec#011loss=5.753490\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[120] avg_epoch_loss=5.929055\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=5.83988170624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [120]#011Speed: 1551.65 samples/sec#011loss=5.839882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[125] avg_epoch_loss=5.922764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=5.77050504684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [125]#011Speed: 1085.43 samples/sec#011loss=5.770505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch[130] avg_epoch_loss=5.933071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=6.19281606674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:21 INFO 140669025912640] Epoch[2] Batch [130]#011Speed: 1652.02 samples/sec#011loss=6.192816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[135] avg_epoch_loss=5.938514\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=6.08110818863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [135]#011Speed: 1123.69 samples/sec#011loss=6.081108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[140] avg_epoch_loss=5.935162\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=5.84400730133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [140]#011Speed: 1634.19 samples/sec#011loss=5.844007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[145] avg_epoch_loss=5.929573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=5.77194423676\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [145]#011Speed: 1001.45 samples/sec#011loss=5.771944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[150] avg_epoch_loss=5.929620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=5.93099212646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [150]#011Speed: 1477.94 samples/sec#011loss=5.930992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[155] avg_epoch_loss=5.927747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=5.8712015152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [155]#011Speed: 971.61 samples/sec#011loss=5.871202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[160] avg_epoch_loss=5.928559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=5.95387983322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [160]#011Speed: 1540.83 samples/sec#011loss=5.953880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[165] avg_epoch_loss=5.922867\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=5.73957939148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [165]#011Speed: 1085.64 samples/sec#011loss=5.739579\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch[170] avg_epoch_loss=5.922910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=5.92436380386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:22 INFO 140669025912640] Epoch[2] Batch [170]#011Speed: 1639.63 samples/sec#011loss=5.924364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[175] avg_epoch_loss=5.923352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=5.93846206665\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [175]#011Speed: 1101.66 samples/sec#011loss=5.938462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[180] avg_epoch_loss=5.927255\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=6.06461591721\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [180]#011Speed: 1677.64 samples/sec#011loss=6.064616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[185] avg_epoch_loss=5.919516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=5.63939695358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [185]#011Speed: 963.12 samples/sec#011loss=5.639397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[190] avg_epoch_loss=5.916205\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=5.7930267334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [190]#011Speed: 1571.79 samples/sec#011loss=5.793027\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[195] avg_epoch_loss=5.920317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=6.07740592957\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [195]#011Speed: 1023.42 samples/sec#011loss=6.077406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[200] avg_epoch_loss=5.916344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=5.76058120728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [200]#011Speed: 1565.10 samples/sec#011loss=5.760581\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[205] avg_epoch_loss=5.914705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=5.84882326126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [205]#011Speed: 1039.78 samples/sec#011loss=5.848823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch[210] avg_epoch_loss=5.919876\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=6.13292160034\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:23 INFO 140669025912640] Epoch[2] Batch [210]#011Speed: 1580.56 samples/sec#011loss=6.132922\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[215] avg_epoch_loss=5.918180\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=5.84660482407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [215]#011Speed: 1665.62 samples/sec#011loss=5.846605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[220] avg_epoch_loss=5.914457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=5.75360841751\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [220]#011Speed: 1022.16 samples/sec#011loss=5.753608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[225] avg_epoch_loss=5.907912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=5.61863918304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [225]#011Speed: 1566.49 samples/sec#011loss=5.618639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[230] avg_epoch_loss=5.908653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=5.94213314056\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [230]#011Speed: 1047.08 samples/sec#011loss=5.942133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[235] avg_epoch_loss=5.910188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=5.98111104965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [235]#011Speed: 1673.27 samples/sec#011loss=5.981111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[240] avg_epoch_loss=5.905438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=5.68125667572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [240]#011Speed: 1058.86 samples/sec#011loss=5.681257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[245] avg_epoch_loss=5.904114\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=5.84028959274\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [245]#011Speed: 1588.91 samples/sec#011loss=5.840290\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch[250] avg_epoch_loss=5.899105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=5.65268135071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:24 INFO 140669025912640] Epoch[2] Batch [250]#011Speed: 1086.77 samples/sec#011loss=5.652681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[255] avg_epoch_loss=5.895289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=5.70368852615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [255]#011Speed: 1692.87 samples/sec#011loss=5.703689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[260] avg_epoch_loss=5.898064\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=6.04017324448\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [260]#011Speed: 1022.38 samples/sec#011loss=6.040173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[265] avg_epoch_loss=5.894819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=5.72542886734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [265]#011Speed: 1544.79 samples/sec#011loss=5.725429\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[270] avg_epoch_loss=5.893484\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=270 train loss <loss>=5.82243766785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [270]#011Speed: 1009.34 samples/sec#011loss=5.822438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[275] avg_epoch_loss=5.892082\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=275 train loss <loss>=5.81609487534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [275]#011Speed: 1632.17 samples/sec#011loss=5.816095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[280] avg_epoch_loss=5.892519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=280 train loss <loss>=5.91663103104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [280]#011Speed: 993.07 samples/sec#011loss=5.916631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch[285] avg_epoch_loss=5.888763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=285 train loss <loss>=5.67771377563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:25 INFO 140669025912640] Epoch[2] Batch [285]#011Speed: 1667.21 samples/sec#011loss=5.677714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[290] avg_epoch_loss=5.886926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=290 train loss <loss>=5.78181877136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [290]#011Speed: 991.37 samples/sec#011loss=5.781819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[295] avg_epoch_loss=5.885556\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=295 train loss <loss>=5.80583667755\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [295]#011Speed: 1553.17 samples/sec#011loss=5.805837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[300] avg_epoch_loss=5.881523\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=300 train loss <loss>=5.64276189804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [300]#011Speed: 1038.91 samples/sec#011loss=5.642762\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[305] avg_epoch_loss=5.883403\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=305 train loss <loss>=5.99655981064\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [305]#011Speed: 1580.62 samples/sec#011loss=5.996560\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[310] avg_epoch_loss=5.879625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=310 train loss <loss>=5.64846277237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [310]#011Speed: 1011.18 samples/sec#011loss=5.648463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[315] avg_epoch_loss=5.881611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=315 train loss <loss>=6.00510530472\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [315]#011Speed: 1553.88 samples/sec#011loss=6.005105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[320] avg_epoch_loss=5.880651\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=320 train loss <loss>=5.81998214722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [320]#011Speed: 1059.22 samples/sec#011loss=5.819982\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch[325] avg_epoch_loss=5.880375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=325 train loss <loss>=5.86263427734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:26 INFO 140669025912640] Epoch[2] Batch [325]#011Speed: 1634.14 samples/sec#011loss=5.862634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[330] avg_epoch_loss=5.879873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=330 train loss <loss>=5.84719381332\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [330]#011Speed: 1016.34 samples/sec#011loss=5.847194\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[335] avg_epoch_loss=5.880872\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=335 train loss <loss>=5.94699869156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [335]#011Speed: 1636.24 samples/sec#011loss=5.946999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[340] avg_epoch_loss=5.876815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=340 train loss <loss>=5.60415067673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [340]#011Speed: 1670.90 samples/sec#011loss=5.604151\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[345] avg_epoch_loss=5.870364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=345 train loss <loss>=5.43041763306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [345]#011Speed: 1000.54 samples/sec#011loss=5.430418\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[350] avg_epoch_loss=5.870017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=350 train loss <loss>=5.84601926804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [350]#011Speed: 1599.20 samples/sec#011loss=5.846019\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[355] avg_epoch_loss=5.871451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=355 train loss <loss>=5.97213392258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [355]#011Speed: 1058.53 samples/sec#011loss=5.972134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[360] avg_epoch_loss=5.870118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=360 train loss <loss>=5.7751906395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [360]#011Speed: 1065.52 samples/sec#011loss=5.775191\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch[365] avg_epoch_loss=5.869225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=365 train loss <loss>=5.80477304459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:27 INFO 140669025912640] Epoch[2] Batch [365]#011Speed: 1593.12 samples/sec#011loss=5.804773\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[370] avg_epoch_loss=5.864208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=370 train loss <loss>=5.49691905975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [370]#011Speed: 1055.62 samples/sec#011loss=5.496919\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[375] avg_epoch_loss=5.864236\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=375 train loss <loss>=5.86630153656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [375]#011Speed: 1657.09 samples/sec#011loss=5.866302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[380] avg_epoch_loss=5.860594\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=380 train loss <loss>=5.58676843643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [380]#011Speed: 1114.04 samples/sec#011loss=5.586768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[385] avg_epoch_loss=5.858353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=385 train loss <loss>=5.68756246567\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [385]#011Speed: 1581.48 samples/sec#011loss=5.687562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[390] avg_epoch_loss=5.856096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=390 train loss <loss>=5.68188152313\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [390]#011Speed: 1058.62 samples/sec#011loss=5.681882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[395] avg_epoch_loss=5.854314\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=395 train loss <loss>=5.7149564743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [395]#011Speed: 1660.06 samples/sec#011loss=5.714956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[400] avg_epoch_loss=5.853879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=400 train loss <loss>=5.81939706802\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [400]#011Speed: 1664.27 samples/sec#011loss=5.819397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[405] avg_epoch_loss=5.849329\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=405 train loss <loss>=5.48444442749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [405]#011Speed: 1040.92 samples/sec#011loss=5.484444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch[410] avg_epoch_loss=5.845774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=410 train loss <loss>=5.55708045959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:28 INFO 140669025912640] Epoch[2] Batch [410]#011Speed: 1610.97 samples/sec#011loss=5.557080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[415] avg_epoch_loss=5.848842\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=415 train loss <loss>=6.10107154846\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [415]#011Speed: 984.05 samples/sec#011loss=6.101072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[420] avg_epoch_loss=5.846269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=420 train loss <loss>=5.63215932846\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [420]#011Speed: 1654.31 samples/sec#011loss=5.632159\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[425] avg_epoch_loss=5.842935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=425 train loss <loss>=5.56222639084\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [425]#011Speed: 1005.65 samples/sec#011loss=5.562226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[430] avg_epoch_loss=5.841303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=430 train loss <loss>=5.70227556229\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [430]#011Speed: 1671.30 samples/sec#011loss=5.702276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[435] avg_epoch_loss=5.841827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=435 train loss <loss>=5.88695735931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [435]#011Speed: 1050.66 samples/sec#011loss=5.886957\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[440] avg_epoch_loss=5.842000\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=440 train loss <loss>=5.85708885193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [440]#011Speed: 1451.80 samples/sec#011loss=5.857089\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch[445] avg_epoch_loss=5.844513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=445 train loss <loss>=6.06619987488\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:29 INFO 140669025912640] Epoch[2] Batch [445]#011Speed: 1081.49 samples/sec#011loss=6.066200\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[450] avg_epoch_loss=5.843512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=450 train loss <loss>=5.75423088074\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [450]#011Speed: 1648.17 samples/sec#011loss=5.754231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[455] avg_epoch_loss=5.843519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=455 train loss <loss>=5.84408121109\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [455]#011Speed: 1615.26 samples/sec#011loss=5.844081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[460] avg_epoch_loss=5.841126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=460 train loss <loss>=5.6229265213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [460]#011Speed: 1085.39 samples/sec#011loss=5.622927\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[465] avg_epoch_loss=5.836407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=465 train loss <loss>=5.40131664276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [465]#011Speed: 1438.53 samples/sec#011loss=5.401317\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[470] avg_epoch_loss=5.835665\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=470 train loss <loss>=5.76646385193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [470]#011Speed: 1035.95 samples/sec#011loss=5.766464\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[475] avg_epoch_loss=5.833891\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=475 train loss <loss>=5.66685285568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [475]#011Speed: 1477.19 samples/sec#011loss=5.666853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[480] avg_epoch_loss=5.833164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=480 train loss <loss>=5.76390743256\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [480]#011Speed: 1027.91 samples/sec#011loss=5.763907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch[485] avg_epoch_loss=5.830101\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=485 train loss <loss>=5.53548688889\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:30 INFO 140669025912640] Epoch[2] Batch [485]#011Speed: 1675.50 samples/sec#011loss=5.535487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[490] avg_epoch_loss=5.831930\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=490 train loss <loss>=6.00963029861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [490]#011Speed: 992.11 samples/sec#011loss=6.009630\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[495] avg_epoch_loss=5.830714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=495 train loss <loss>=5.7113535881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [495]#011Speed: 1489.98 samples/sec#011loss=5.711354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[500] avg_epoch_loss=5.828653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=500 train loss <loss>=5.62417879105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [500]#011Speed: 1024.81 samples/sec#011loss=5.624179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[505] avg_epoch_loss=5.828741\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=505 train loss <loss>=5.83752145767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [505]#011Speed: 1538.33 samples/sec#011loss=5.837521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[510] avg_epoch_loss=5.822427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=510 train loss <loss>=5.183502388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [510]#011Speed: 1040.43 samples/sec#011loss=5.183502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[515] avg_epoch_loss=5.821559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=515 train loss <loss>=5.73279867172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [515]#011Speed: 1415.00 samples/sec#011loss=5.732799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[520] avg_epoch_loss=5.818788\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=520 train loss <loss>=5.53285303116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [520]#011Speed: 1051.85 samples/sec#011loss=5.532853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch[525] avg_epoch_loss=5.819171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=525 train loss <loss>=5.85904941559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:31 INFO 140669025912640] Epoch[2] Batch [525]#011Speed: 1596.84 samples/sec#011loss=5.859049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[530] avg_epoch_loss=5.818700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=530 train loss <loss>=5.76923780441\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [530]#011Speed: 1105.18 samples/sec#011loss=5.769238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[535] avg_epoch_loss=5.816849\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=535 train loss <loss>=5.62022066116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [535]#011Speed: 1638.69 samples/sec#011loss=5.620221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[540] avg_epoch_loss=5.816352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=540 train loss <loss>=5.76307668686\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [540]#011Speed: 1076.64 samples/sec#011loss=5.763077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[545] avg_epoch_loss=5.815173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=545 train loss <loss>=5.68761758804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [545]#011Speed: 1514.05 samples/sec#011loss=5.687618\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[550] avg_epoch_loss=5.814087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=550 train loss <loss>=5.69545726776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [550]#011Speed: 1066.78 samples/sec#011loss=5.695457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[555] avg_epoch_loss=5.814622\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=555 train loss <loss>=5.87363882065\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [555]#011Speed: 1627.17 samples/sec#011loss=5.873639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[560] avg_epoch_loss=5.814559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=560 train loss <loss>=5.80753107071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [560]#011Speed: 1088.28 samples/sec#011loss=5.807531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch[565] avg_epoch_loss=5.812733\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=565 train loss <loss>=5.60786800385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:32 INFO 140669025912640] Epoch[2] Batch [565]#011Speed: 1651.15 samples/sec#011loss=5.607868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[2] Batch[570] avg_epoch_loss=5.812076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=570 train loss <loss>=5.73768405914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[2] Batch [570]#011Speed: 1280.84 samples/sec#011loss=5.737684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[2] Batch[575] avg_epoch_loss=5.809967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, batch=575 train loss <loss>=5.56912574768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[2] Batch [575]#011Speed: 1638.24 samples/sec#011loss=5.569126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] processed a total of 18438 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14550.374984741211, \"sum\": 14550.374984741211, \"min\": 14550.374984741211}}, \"EndTime\": 1589393733.172432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393718.622002}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1267.17573899 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=2, train loss <loss>=5.81198859752\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_22f3fc27-4ca4-44f7-a445-d52f61ebc259-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.755922317504883, \"sum\": 8.755922317504883, \"min\": 8.755922317504883}}, \"EndTime\": 1589393733.181689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393733.172495}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[0] avg_epoch_loss=5.555183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=5.55518293381\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[5] avg_epoch_loss=5.477629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=5.4776292642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch [5]#011Speed: 1648.55 samples/sec#011loss=5.477629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[10] avg_epoch_loss=5.659268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=5.87723407745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch [10]#011Speed: 1064.30 samples/sec#011loss=5.877234\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[15] avg_epoch_loss=5.742722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=5.9263215065\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch [15]#011Speed: 1663.16 samples/sec#011loss=5.926322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[20] avg_epoch_loss=5.669561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=5.43544340134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch [20]#011Speed: 1076.53 samples/sec#011loss=5.435443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[25] avg_epoch_loss=5.691883\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=5.78563928604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch [25]#011Speed: 1636.49 samples/sec#011loss=5.785639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch[30] avg_epoch_loss=5.710125\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=5.8049823761\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:33 INFO 140669025912640] Epoch[3] Batch [30]#011Speed: 1659.20 samples/sec#011loss=5.804982\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[35] avg_epoch_loss=5.682244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=5.50938119888\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [35]#011Speed: 1063.86 samples/sec#011loss=5.509381\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[40] avg_epoch_loss=5.682631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=5.68541355133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [40]#011Speed: 1638.60 samples/sec#011loss=5.685414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[45] avg_epoch_loss=5.682757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=5.68379297256\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [45]#011Speed: 1112.78 samples/sec#011loss=5.683793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[50] avg_epoch_loss=5.698283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=5.84111862183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [50]#011Speed: 1605.29 samples/sec#011loss=5.841119\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[55] avg_epoch_loss=5.707796\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=5.80483379364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [55]#011Speed: 1093.93 samples/sec#011loss=5.804834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[60] avg_epoch_loss=5.701354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=5.62920846939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [60]#011Speed: 1658.67 samples/sec#011loss=5.629208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[65] avg_epoch_loss=5.700102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=5.68482217789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [65]#011Speed: 1065.76 samples/sec#011loss=5.684822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch[70] avg_epoch_loss=5.693177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=5.60176448822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:34 INFO 140669025912640] Epoch[3] Batch [70]#011Speed: 1675.41 samples/sec#011loss=5.601764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[75] avg_epoch_loss=5.708670\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=5.92866868973\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [75]#011Speed: 1076.50 samples/sec#011loss=5.928669\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[80] avg_epoch_loss=5.715358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=5.81702136993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [80]#011Speed: 1697.87 samples/sec#011loss=5.817021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[85] avg_epoch_loss=5.707634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=5.58249778748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [85]#011Speed: 1067.16 samples/sec#011loss=5.582498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[90] avg_epoch_loss=5.703048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=5.62416744232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [90]#011Speed: 1568.60 samples/sec#011loss=5.624167\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[95] avg_epoch_loss=5.709798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=5.83265304565\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [95]#011Speed: 987.75 samples/sec#011loss=5.832653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[100] avg_epoch_loss=5.702648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=5.56536407471\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [100]#011Speed: 1628.75 samples/sec#011loss=5.565364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[105] avg_epoch_loss=5.696267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=5.56737966537\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [105]#011Speed: 1054.62 samples/sec#011loss=5.567380\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch[110] avg_epoch_loss=5.696409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=5.69942073822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:35 INFO 140669025912640] Epoch[3] Batch [110]#011Speed: 1619.66 samples/sec#011loss=5.699421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[115] avg_epoch_loss=5.688626\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=5.51584234238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [115]#011Speed: 1035.29 samples/sec#011loss=5.515842\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[120] avg_epoch_loss=5.684791\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=5.59582605362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [120]#011Speed: 1659.39 samples/sec#011loss=5.595826\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[125] avg_epoch_loss=5.679352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=5.54772806168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [125]#011Speed: 1043.50 samples/sec#011loss=5.547728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[130] avg_epoch_loss=5.677670\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=5.63528203964\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [130]#011Speed: 1628.22 samples/sec#011loss=5.635282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[135] avg_epoch_loss=5.683217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=5.82854309082\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [135]#011Speed: 1058.54 samples/sec#011loss=5.828543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[140] avg_epoch_loss=5.672386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=5.37776670456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [140]#011Speed: 1633.22 samples/sec#011loss=5.377767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[145] avg_epoch_loss=5.676901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=5.80423765182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [145]#011Speed: 1079.91 samples/sec#011loss=5.804238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch[150] avg_epoch_loss=5.677067\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=5.68192396164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:36 INFO 140669025912640] Epoch[3] Batch [150]#011Speed: 1627.44 samples/sec#011loss=5.681924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[155] avg_epoch_loss=5.676602\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=5.66255455017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [155]#011Speed: 1093.47 samples/sec#011loss=5.662555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[160] avg_epoch_loss=5.669348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=5.44302892685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [160]#011Speed: 1625.60 samples/sec#011loss=5.443029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[165] avg_epoch_loss=5.671974\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=5.75652971268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [165]#011Speed: 1105.77 samples/sec#011loss=5.756530\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[170] avg_epoch_loss=5.670994\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=5.63845357895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [170]#011Speed: 1569.86 samples/sec#011loss=5.638454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[175] avg_epoch_loss=5.672334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=5.71815958023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [175]#011Speed: 1039.14 samples/sec#011loss=5.718160\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[180] avg_epoch_loss=5.670201\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=5.59511051178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [180]#011Speed: 1643.44 samples/sec#011loss=5.595111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[185] avg_epoch_loss=5.666972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=5.55010614395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [185]#011Speed: 1074.40 samples/sec#011loss=5.550106\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch[190] avg_epoch_loss=5.670454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=5.79995927811\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:37 INFO 140669025912640] Epoch[3] Batch [190]#011Speed: 1647.74 samples/sec#011loss=5.799959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[195] avg_epoch_loss=5.672323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=5.74372243881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [195]#011Speed: 1056.60 samples/sec#011loss=5.743722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[200] avg_epoch_loss=5.675697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=5.8079583168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [200]#011Speed: 1659.72 samples/sec#011loss=5.807958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[205] avg_epoch_loss=5.673804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=5.59771528244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [205]#011Speed: 1083.28 samples/sec#011loss=5.597715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[210] avg_epoch_loss=5.672637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=5.62453594208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [210]#011Speed: 1645.37 samples/sec#011loss=5.624536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[215] avg_epoch_loss=5.676775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=5.85141973495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [215]#011Speed: 1061.18 samples/sec#011loss=5.851420\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[220] avg_epoch_loss=5.675649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=5.626994133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [220]#011Speed: 1603.43 samples/sec#011loss=5.626994\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[225] avg_epoch_loss=5.674339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=5.61645479202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [225]#011Speed: 1108.95 samples/sec#011loss=5.616455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch[230] avg_epoch_loss=5.671363\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=5.53684568405\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:38 INFO 140669025912640] Epoch[3] Batch [230]#011Speed: 1622.74 samples/sec#011loss=5.536846\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[235] avg_epoch_loss=5.669738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=5.5946688652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [235]#011Speed: 1102.08 samples/sec#011loss=5.594669\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[240] avg_epoch_loss=5.672777\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=5.81618518829\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [240]#011Speed: 1656.19 samples/sec#011loss=5.816185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[245] avg_epoch_loss=5.672074\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=5.63821735382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [245]#011Speed: 1015.79 samples/sec#011loss=5.638217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[250] avg_epoch_loss=5.670656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=5.60086746216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [250]#011Speed: 1603.14 samples/sec#011loss=5.600867\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[255] avg_epoch_loss=5.669069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=5.58942775726\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [255]#011Speed: 1478.37 samples/sec#011loss=5.589428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[260] avg_epoch_loss=5.668757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=5.65277776718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [260]#011Speed: 1020.04 samples/sec#011loss=5.652778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[265] avg_epoch_loss=5.673808\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=5.93744478226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [265]#011Speed: 1671.25 samples/sec#011loss=5.937445\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch[270] avg_epoch_loss=5.673503\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=270 train loss <loss>=5.65729894638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:39 INFO 140669025912640] Epoch[3] Batch [270]#011Speed: 1053.48 samples/sec#011loss=5.657299\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[275] avg_epoch_loss=5.672892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=275 train loss <loss>=5.63974876404\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [275]#011Speed: 1674.87 samples/sec#011loss=5.639749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[280] avg_epoch_loss=5.675677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=280 train loss <loss>=5.8294547081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [280]#011Speed: 1004.19 samples/sec#011loss=5.829455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[285] avg_epoch_loss=5.675753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=285 train loss <loss>=5.67997245789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [285]#011Speed: 1683.39 samples/sec#011loss=5.679972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[290] avg_epoch_loss=5.674994\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=290 train loss <loss>=5.63161268234\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [290]#011Speed: 1011.74 samples/sec#011loss=5.631613\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[295] avg_epoch_loss=5.673041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=295 train loss <loss>=5.55937099457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [295]#011Speed: 1448.53 samples/sec#011loss=5.559371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[300] avg_epoch_loss=5.670436\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=300 train loss <loss>=5.51618785858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [300]#011Speed: 1043.07 samples/sec#011loss=5.516188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[305] avg_epoch_loss=5.672020\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=305 train loss <loss>=5.76740598679\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [305]#011Speed: 1680.92 samples/sec#011loss=5.767406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch[310] avg_epoch_loss=5.675951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=310 train loss <loss>=5.9165019989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:40 INFO 140669025912640] Epoch[3] Batch [310]#011Speed: 1070.08 samples/sec#011loss=5.916502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[315] avg_epoch_loss=5.678843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=315 train loss <loss>=5.85877180099\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [315]#011Speed: 1651.10 samples/sec#011loss=5.858772\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[320] avg_epoch_loss=5.679929\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=320 train loss <loss>=5.74851303101\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [320]#011Speed: 1077.14 samples/sec#011loss=5.748513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[325] avg_epoch_loss=5.686002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=325 train loss <loss>=6.07591428757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [325]#011Speed: 1557.38 samples/sec#011loss=6.075914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[330] avg_epoch_loss=5.688551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=330 train loss <loss>=5.85472764969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [330]#011Speed: 1063.35 samples/sec#011loss=5.854728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[335] avg_epoch_loss=5.688956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=335 train loss <loss>=5.7157626152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [335]#011Speed: 1459.87 samples/sec#011loss=5.715763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[340] avg_epoch_loss=5.691217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=340 train loss <loss>=5.84321146011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [340]#011Speed: 1053.81 samples/sec#011loss=5.843211\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[345] avg_epoch_loss=5.687485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=345 train loss <loss>=5.43294506073\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [345]#011Speed: 1478.84 samples/sec#011loss=5.432945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch[350] avg_epoch_loss=5.689208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=350 train loss <loss>=5.80845603943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:41 INFO 140669025912640] Epoch[3] Batch [350]#011Speed: 1034.35 samples/sec#011loss=5.808456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[355] avg_epoch_loss=5.687335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=355 train loss <loss>=5.55579471588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [355]#011Speed: 1461.31 samples/sec#011loss=5.555795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[360] avg_epoch_loss=5.685370\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=360 train loss <loss>=5.54546575546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [360]#011Speed: 1471.72 samples/sec#011loss=5.545466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[365] avg_epoch_loss=5.681644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=365 train loss <loss>=5.41268358231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [365]#011Speed: 1023.21 samples/sec#011loss=5.412684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[370] avg_epoch_loss=5.679701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=370 train loss <loss>=5.53744134903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [370]#011Speed: 1640.88 samples/sec#011loss=5.537441\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[375] avg_epoch_loss=5.678179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=375 train loss <loss>=5.565280056\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [375]#011Speed: 1044.84 samples/sec#011loss=5.565280\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[380] avg_epoch_loss=5.679234\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=380 train loss <loss>=5.75853233337\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [380]#011Speed: 1547.49 samples/sec#011loss=5.758532\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[385] avg_epoch_loss=5.677255\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=385 train loss <loss>=5.526425457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [385]#011Speed: 953.25 samples/sec#011loss=5.526425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch[390] avg_epoch_loss=5.676891\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=390 train loss <loss>=5.64878902435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:42 INFO 140669025912640] Epoch[3] Batch [390]#011Speed: 1606.96 samples/sec#011loss=5.648789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[395] avg_epoch_loss=5.674326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=395 train loss <loss>=5.47380857468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [395]#011Speed: 1035.04 samples/sec#011loss=5.473809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[400] avg_epoch_loss=5.674841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=400 train loss <loss>=5.71558856964\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [400]#011Speed: 1637.23 samples/sec#011loss=5.715589\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[405] avg_epoch_loss=5.675252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=405 train loss <loss>=5.70820684433\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [405]#011Speed: 1075.79 samples/sec#011loss=5.708207\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[410] avg_epoch_loss=5.674584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=410 train loss <loss>=5.62033510208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [410]#011Speed: 1600.40 samples/sec#011loss=5.620335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[415] avg_epoch_loss=5.673700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=415 train loss <loss>=5.60105371475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [415]#011Speed: 1600.29 samples/sec#011loss=5.601054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[420] avg_epoch_loss=5.673172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=420 train loss <loss>=5.62927074432\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [420]#011Speed: 1062.32 samples/sec#011loss=5.629271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[425] avg_epoch_loss=5.671052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=425 train loss <loss>=5.49254217148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [425]#011Speed: 1610.08 samples/sec#011loss=5.492542\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch[430] avg_epoch_loss=5.670552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=430 train loss <loss>=5.62794122696\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:43 INFO 140669025912640] Epoch[3] Batch [430]#011Speed: 1100.78 samples/sec#011loss=5.627941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[435] avg_epoch_loss=5.670840\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=435 train loss <loss>=5.69567089081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [435]#011Speed: 1637.98 samples/sec#011loss=5.695671\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[440] avg_epoch_loss=5.673166\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=440 train loss <loss>=5.87600889206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [440]#011Speed: 1062.92 samples/sec#011loss=5.876009\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[445] avg_epoch_loss=5.671972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=445 train loss <loss>=5.56664915085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [445]#011Speed: 1620.44 samples/sec#011loss=5.566649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[450] avg_epoch_loss=5.667981\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=450 train loss <loss>=5.31198263168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [450]#011Speed: 1088.35 samples/sec#011loss=5.311983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[455] avg_epoch_loss=5.664385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=455 train loss <loss>=5.33999156952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [455]#011Speed: 1625.02 samples/sec#011loss=5.339992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[460] avg_epoch_loss=5.662964\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=460 train loss <loss>=5.53336372375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [460]#011Speed: 1120.84 samples/sec#011loss=5.533364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[465] avg_epoch_loss=5.664488\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=465 train loss <loss>=5.80506868362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [465]#011Speed: 1659.29 samples/sec#011loss=5.805069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch[470] avg_epoch_loss=5.664044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=470 train loss <loss>=5.62257509232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:44 INFO 140669025912640] Epoch[3] Batch [470]#011Speed: 1007.71 samples/sec#011loss=5.622575\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[475] avg_epoch_loss=5.665181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=475 train loss <loss>=5.77232027054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [475]#011Speed: 1596.88 samples/sec#011loss=5.772320\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[480] avg_epoch_loss=5.662570\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=480 train loss <loss>=5.414037323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [480]#011Speed: 1079.41 samples/sec#011loss=5.414037\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[485] avg_epoch_loss=5.661485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=485 train loss <loss>=5.55708837509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [485]#011Speed: 1628.60 samples/sec#011loss=5.557088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[490] avg_epoch_loss=5.660580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=490 train loss <loss>=5.57261018753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [490]#011Speed: 1089.76 samples/sec#011loss=5.572610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[495] avg_epoch_loss=5.660159\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=495 train loss <loss>=5.61877832413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [495]#011Speed: 1496.18 samples/sec#011loss=5.618778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[500] avg_epoch_loss=5.658309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=500 train loss <loss>=5.47481155396\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [500]#011Speed: 1025.40 samples/sec#011loss=5.474812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[505] avg_epoch_loss=5.660244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=505 train loss <loss>=5.85419120789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [505]#011Speed: 1623.34 samples/sec#011loss=5.854191\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch[510] avg_epoch_loss=5.659263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=510 train loss <loss>=5.55993471146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:45 INFO 140669025912640] Epoch[3] Batch [510]#011Speed: 993.93 samples/sec#011loss=5.559935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[515] avg_epoch_loss=5.656702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=515 train loss <loss>=5.39496793747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [515]#011Speed: 1635.93 samples/sec#011loss=5.394968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[520] avg_epoch_loss=5.654923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=520 train loss <loss>=5.47134428024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [520]#011Speed: 1505.51 samples/sec#011loss=5.471344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[525] avg_epoch_loss=5.654973\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=525 train loss <loss>=5.66018924713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [525]#011Speed: 983.94 samples/sec#011loss=5.660189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[530] avg_epoch_loss=5.654412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=530 train loss <loss>=5.59540576935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [530]#011Speed: 994.88 samples/sec#011loss=5.595406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[535] avg_epoch_loss=5.653740\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=535 train loss <loss>=5.58230609894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [535]#011Speed: 1600.88 samples/sec#011loss=5.582306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[540] avg_epoch_loss=5.652464\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=540 train loss <loss>=5.51568231583\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [540]#011Speed: 1066.98 samples/sec#011loss=5.515682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[545] avg_epoch_loss=5.651653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=545 train loss <loss>=5.56389369965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [545]#011Speed: 1643.27 samples/sec#011loss=5.563894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch[550] avg_epoch_loss=5.652651\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=550 train loss <loss>=5.76166343689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:46 INFO 140669025912640] Epoch[3] Batch [550]#011Speed: 1091.65 samples/sec#011loss=5.761663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch[555] avg_epoch_loss=5.651605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=555 train loss <loss>=5.53637933731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch [555]#011Speed: 1641.80 samples/sec#011loss=5.536379\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch[560] avg_epoch_loss=5.650277\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=560 train loss <loss>=5.5025683403\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch [560]#011Speed: 1002.29 samples/sec#011loss=5.502568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch[565] avg_epoch_loss=5.649631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=565 train loss <loss>=5.57716083527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch [565]#011Speed: 1564.36 samples/sec#011loss=5.577161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch[570] avg_epoch_loss=5.649788\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=570 train loss <loss>=5.66760406494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch [570]#011Speed: 1671.19 samples/sec#011loss=5.667604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch[575] avg_epoch_loss=5.648439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, batch=575 train loss <loss>=5.49432058334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[3] Batch [575]#011Speed: 1073.08 samples/sec#011loss=5.494321\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] processed a total of 18550 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14476.006031036377, \"sum\": 14476.006031036377, \"min\": 14476.006031036377}}, \"EndTime\": 1589393747.657809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393733.181744}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1281.42221105 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=3, train loss <loss>=5.64706282945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_3a7ed28f-bfa2-432f-a752-146dfa794716-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.37907600402832, \"sum\": 10.37907600402832, \"min\": 10.37907600402832}}, \"EndTime\": 1589393747.66861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393747.657873}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[4] Batch[0] avg_epoch_loss=5.359934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=5.35993432999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[4] Batch[5] avg_epoch_loss=5.543122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=5.54312157631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[4] Batch [5]#011Speed: 1638.62 samples/sec#011loss=5.543122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[4] Batch[10] avg_epoch_loss=5.524571\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=5.50230922699\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:47 INFO 140669025912640] Epoch[4] Batch [10]#011Speed: 1680.78 samples/sec#011loss=5.502309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[15] avg_epoch_loss=5.571453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=5.67459478378\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [15]#011Speed: 1065.72 samples/sec#011loss=5.674595\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[20] avg_epoch_loss=5.595062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=5.67060947418\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [20]#011Speed: 1672.22 samples/sec#011loss=5.670609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[25] avg_epoch_loss=5.613745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=5.69221515656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [25]#011Speed: 1085.84 samples/sec#011loss=5.692215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[30] avg_epoch_loss=5.621644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=5.66271705627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [30]#011Speed: 1061.89 samples/sec#011loss=5.662717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[35] avg_epoch_loss=5.616530\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=5.58482151031\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [35]#011Speed: 1526.73 samples/sec#011loss=5.584822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[40] avg_epoch_loss=5.589993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=5.3989282608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [40]#011Speed: 1031.05 samples/sec#011loss=5.398928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[45] avg_epoch_loss=5.595611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=5.64167747498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [45]#011Speed: 1655.03 samples/sec#011loss=5.641677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch[50] avg_epoch_loss=5.589180\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=5.53001871109\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:48 INFO 140669025912640] Epoch[4] Batch [50]#011Speed: 1050.83 samples/sec#011loss=5.530019\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[55] avg_epoch_loss=5.590797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=5.60728521347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [55]#011Speed: 1593.37 samples/sec#011loss=5.607285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[60] avg_epoch_loss=5.575453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=5.40359792709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [60]#011Speed: 1064.57 samples/sec#011loss=5.403598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[65] avg_epoch_loss=5.575579\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=5.57712106705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [65]#011Speed: 1646.68 samples/sec#011loss=5.577121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[70] avg_epoch_loss=5.582752\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=5.6774315834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [70]#011Speed: 1081.37 samples/sec#011loss=5.677432\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[75] avg_epoch_loss=5.585086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=5.61824121475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [75]#011Speed: 1562.32 samples/sec#011loss=5.618241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[80] avg_epoch_loss=5.581237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=5.52272491455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [80]#011Speed: 1063.93 samples/sec#011loss=5.522725\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[85] avg_epoch_loss=5.577479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=5.51659097672\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [85]#011Speed: 1641.90 samples/sec#011loss=5.516591\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch[90] avg_epoch_loss=5.557518\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=5.21420326233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:49 INFO 140669025912640] Epoch[4] Batch [90]#011Speed: 1051.59 samples/sec#011loss=5.214203\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[95] avg_epoch_loss=5.555455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=5.51790237427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [95]#011Speed: 1649.45 samples/sec#011loss=5.517902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[100] avg_epoch_loss=5.564206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=5.73222990036\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [100]#011Speed: 1523.11 samples/sec#011loss=5.732230\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[105] avg_epoch_loss=5.570766\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=5.70326890945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [105]#011Speed: 1082.57 samples/sec#011loss=5.703269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[110] avg_epoch_loss=5.562182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=5.3802110672\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [110]#011Speed: 1689.67 samples/sec#011loss=5.380211\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[115] avg_epoch_loss=5.556308\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=5.42589855194\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [115]#011Speed: 1006.33 samples/sec#011loss=5.425899\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[120] avg_epoch_loss=5.568110\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=5.84192304611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [120]#011Speed: 1651.13 samples/sec#011loss=5.841923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[125] avg_epoch_loss=5.562941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=5.43784332275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [125]#011Speed: 1014.14 samples/sec#011loss=5.437843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch[130] avg_epoch_loss=5.565834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=5.63874673843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:50 INFO 140669025912640] Epoch[4] Batch [130]#011Speed: 1411.02 samples/sec#011loss=5.638747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[135] avg_epoch_loss=5.575543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=5.82991189957\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [135]#011Speed: 1031.81 samples/sec#011loss=5.829912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[140] avg_epoch_loss=5.578041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=5.64599428177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [140]#011Speed: 1639.82 samples/sec#011loss=5.645994\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[145] avg_epoch_loss=5.577832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=5.57193555832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [145]#011Speed: 1041.82 samples/sec#011loss=5.571936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[150] avg_epoch_loss=5.577322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=5.56243829727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [150]#011Speed: 1629.58 samples/sec#011loss=5.562438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[155] avg_epoch_loss=5.573393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=5.45471992493\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [155]#011Speed: 1074.19 samples/sec#011loss=5.454720\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[160] avg_epoch_loss=5.579196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=5.76024303436\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [160]#011Speed: 1579.52 samples/sec#011loss=5.760243\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[165] avg_epoch_loss=5.584815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=5.76574554443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [165]#011Speed: 1045.85 samples/sec#011loss=5.765746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch[170] avg_epoch_loss=5.577580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=5.33738431931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:51 INFO 140669025912640] Epoch[4] Batch [170]#011Speed: 1669.43 samples/sec#011loss=5.337384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[175] avg_epoch_loss=5.577743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=5.58331012726\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [175]#011Speed: 1038.51 samples/sec#011loss=5.583310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[180] avg_epoch_loss=5.580553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=5.6794634819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [180]#011Speed: 1686.57 samples/sec#011loss=5.679463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[185] avg_epoch_loss=5.590465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=5.949305439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [185]#011Speed: 1034.72 samples/sec#011loss=5.949305\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[190] avg_epoch_loss=5.590158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=5.57872447968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [190]#011Speed: 1663.29 samples/sec#011loss=5.578724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[195] avg_epoch_loss=5.588753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=5.53508520126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [195]#011Speed: 1043.54 samples/sec#011loss=5.535085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[200] avg_epoch_loss=5.594548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=5.82170419693\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [200]#011Speed: 1655.92 samples/sec#011loss=5.821704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[205] avg_epoch_loss=5.598223\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=5.74595336914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [205]#011Speed: 1074.84 samples/sec#011loss=5.745953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch[210] avg_epoch_loss=5.605395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=5.90088043213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:52 INFO 140669025912640] Epoch[4] Batch [210]#011Speed: 1692.57 samples/sec#011loss=5.900880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[215] avg_epoch_loss=5.604212\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=5.55430021286\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [215]#011Speed: 1013.81 samples/sec#011loss=5.554300\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[220] avg_epoch_loss=5.598259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=5.34107189178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [220]#011Speed: 1638.74 samples/sec#011loss=5.341072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[225] avg_epoch_loss=5.596150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=5.50295877457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [225]#011Speed: 1097.31 samples/sec#011loss=5.502959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[230] avg_epoch_loss=5.596041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=5.59112606049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [230]#011Speed: 1664.91 samples/sec#011loss=5.591126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[235] avg_epoch_loss=5.598042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=5.69046258926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [235]#011Speed: 1027.01 samples/sec#011loss=5.690463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[240] avg_epoch_loss=5.596480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=5.52275543213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [240]#011Speed: 1601.64 samples/sec#011loss=5.522755\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[245] avg_epoch_loss=5.594370\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=5.49265441895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [245]#011Speed: 1043.59 samples/sec#011loss=5.492654\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch[250] avg_epoch_loss=5.590856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=5.41796045303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:53 INFO 140669025912640] Epoch[4] Batch [250]#011Speed: 1650.45 samples/sec#011loss=5.417960\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[255] avg_epoch_loss=5.589799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=5.53676099777\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [255]#011Speed: 1026.31 samples/sec#011loss=5.536761\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[260] avg_epoch_loss=5.591303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=5.66828279495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [260]#011Speed: 1650.44 samples/sec#011loss=5.668283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[265] avg_epoch_loss=5.594911\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=5.78327922821\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [265]#011Speed: 1039.37 samples/sec#011loss=5.783279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[270] avg_epoch_loss=5.600362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=270 train loss <loss>=5.89036540985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [270]#011Speed: 1641.04 samples/sec#011loss=5.890365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[275] avg_epoch_loss=5.599187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=275 train loss <loss>=5.53551177979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [275]#011Speed: 1031.23 samples/sec#011loss=5.535512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[280] avg_epoch_loss=5.597173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=280 train loss <loss>=5.48599758148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [280]#011Speed: 1649.74 samples/sec#011loss=5.485998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[285] avg_epoch_loss=5.596999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=285 train loss <loss>=5.58720569611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [285]#011Speed: 1064.43 samples/sec#011loss=5.587206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch[290] avg_epoch_loss=5.596774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=290 train loss <loss>=5.58391456604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:54 INFO 140669025912640] Epoch[4] Batch [290]#011Speed: 1613.78 samples/sec#011loss=5.583915\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[295] avg_epoch_loss=5.595011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=295 train loss <loss>=5.49236021042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [295]#011Speed: 1060.74 samples/sec#011loss=5.492360\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[300] avg_epoch_loss=5.592560\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=300 train loss <loss>=5.44750146866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [300]#011Speed: 1509.92 samples/sec#011loss=5.447501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[305] avg_epoch_loss=5.589752\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=305 train loss <loss>=5.42067403793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [305]#011Speed: 1012.16 samples/sec#011loss=5.420674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[310] avg_epoch_loss=5.586442\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=310 train loss <loss>=5.3839214325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [310]#011Speed: 1439.22 samples/sec#011loss=5.383921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[315] avg_epoch_loss=5.585965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=315 train loss <loss>=5.55625429153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [315]#011Speed: 1030.32 samples/sec#011loss=5.556254\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[320] avg_epoch_loss=5.586587\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=320 train loss <loss>=5.62594070435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [320]#011Speed: 1689.40 samples/sec#011loss=5.625941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch[325] avg_epoch_loss=5.587096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=325 train loss <loss>=5.61973953247\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:55 INFO 140669025912640] Epoch[4] Batch [325]#011Speed: 1031.45 samples/sec#011loss=5.619740\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[330] avg_epoch_loss=5.586307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=330 train loss <loss>=5.53488769531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [330]#011Speed: 1570.04 samples/sec#011loss=5.534888\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[335] avg_epoch_loss=5.586081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=335 train loss <loss>=5.57111606598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [335]#011Speed: 1012.09 samples/sec#011loss=5.571116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[340] avg_epoch_loss=5.583383\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=340 train loss <loss>=5.40204486847\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [340]#011Speed: 1666.42 samples/sec#011loss=5.402045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[345] avg_epoch_loss=5.581151\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=345 train loss <loss>=5.42892665863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [345]#011Speed: 1653.76 samples/sec#011loss=5.428927\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[350] avg_epoch_loss=5.580578\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=350 train loss <loss>=5.54093084335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [350]#011Speed: 1008.78 samples/sec#011loss=5.540931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[355] avg_epoch_loss=5.578480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=355 train loss <loss>=5.43124504089\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [355]#011Speed: 1584.97 samples/sec#011loss=5.431245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[360] avg_epoch_loss=5.578927\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=360 train loss <loss>=5.61074066162\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [360]#011Speed: 999.84 samples/sec#011loss=5.610741\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch[365] avg_epoch_loss=5.578529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=365 train loss <loss>=5.54980278015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:56 INFO 140669025912640] Epoch[4] Batch [365]#011Speed: 1649.41 samples/sec#011loss=5.549803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[370] avg_epoch_loss=5.575411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=370 train loss <loss>=5.34713487625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [370]#011Speed: 1129.75 samples/sec#011loss=5.347135\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[375] avg_epoch_loss=5.574700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=375 train loss <loss>=5.52196779251\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [375]#011Speed: 1655.73 samples/sec#011loss=5.521968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[380] avg_epoch_loss=5.576770\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=380 train loss <loss>=5.73240299225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [380]#011Speed: 1006.34 samples/sec#011loss=5.732403\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[385] avg_epoch_loss=5.576869\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=385 train loss <loss>=5.58444604874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [385]#011Speed: 1586.92 samples/sec#011loss=5.584446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[390] avg_epoch_loss=5.576239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=390 train loss <loss>=5.52761621475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [390]#011Speed: 1007.44 samples/sec#011loss=5.527616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[395] avg_epoch_loss=5.574353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=395 train loss <loss>=5.42683286667\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [395]#011Speed: 1627.82 samples/sec#011loss=5.426833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[400] avg_epoch_loss=5.572035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=400 train loss <loss>=5.38843374252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [400]#011Speed: 1006.84 samples/sec#011loss=5.388434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch[405] avg_epoch_loss=5.572128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=405 train loss <loss>=5.5796251297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:57 INFO 140669025912640] Epoch[4] Batch [405]#011Speed: 1648.02 samples/sec#011loss=5.579625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[410] avg_epoch_loss=5.572989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=410 train loss <loss>=5.64287757874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [410]#011Speed: 1047.04 samples/sec#011loss=5.642878\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[415] avg_epoch_loss=5.568443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=415 train loss <loss>=5.19480600357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [415]#011Speed: 1681.06 samples/sec#011loss=5.194806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[420] avg_epoch_loss=5.568550\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=420 train loss <loss>=5.57739477158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [420]#011Speed: 1017.74 samples/sec#011loss=5.577395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[425] avg_epoch_loss=5.568962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=425 train loss <loss>=5.60364398956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [425]#011Speed: 1681.45 samples/sec#011loss=5.603644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[430] avg_epoch_loss=5.568221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=430 train loss <loss>=5.5051448822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [430]#011Speed: 977.65 samples/sec#011loss=5.505145\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[435] avg_epoch_loss=5.565904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=435 train loss <loss>=5.3661781311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [435]#011Speed: 1668.62 samples/sec#011loss=5.366178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[440] avg_epoch_loss=5.567427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=440 train loss <loss>=5.70016889572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [440]#011Speed: 1068.38 samples/sec#011loss=5.700169\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch[445] avg_epoch_loss=5.570394\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=445 train loss <loss>=5.83216285706\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:58 INFO 140669025912640] Epoch[4] Batch [445]#011Speed: 1571.60 samples/sec#011loss=5.832163\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[450] avg_epoch_loss=5.573501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=450 train loss <loss>=5.85063581467\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [450]#011Speed: 1001.06 samples/sec#011loss=5.850636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[455] avg_epoch_loss=5.572987\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=455 train loss <loss>=5.52654628754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [455]#011Speed: 1651.30 samples/sec#011loss=5.526546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[460] avg_epoch_loss=5.570354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=460 train loss <loss>=5.33029127121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [460]#011Speed: 1068.52 samples/sec#011loss=5.330291\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[465] avg_epoch_loss=5.568014\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=465 train loss <loss>=5.35221147537\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [465]#011Speed: 1509.49 samples/sec#011loss=5.352211\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[470] avg_epoch_loss=5.568493\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=470 train loss <loss>=5.61319656372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [470]#011Speed: 1044.14 samples/sec#011loss=5.613197\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[475] avg_epoch_loss=5.568417\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=475 train loss <loss>=5.5612660408\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [475]#011Speed: 1699.52 samples/sec#011loss=5.561266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[480] avg_epoch_loss=5.564828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=480 train loss <loss>=5.22312850952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [480]#011Speed: 1045.26 samples/sec#011loss=5.223129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch[485] avg_epoch_loss=5.563268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=485 train loss <loss>=5.41317691803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:15:59 INFO 140669025912640] Epoch[4] Batch [485]#011Speed: 1701.62 samples/sec#011loss=5.413177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[490] avg_epoch_loss=5.561906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=490 train loss <loss>=5.42948436737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [490]#011Speed: 1080.48 samples/sec#011loss=5.429484\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[495] avg_epoch_loss=5.560940\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=495 train loss <loss>=5.46615829468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [495]#011Speed: 1681.38 samples/sec#011loss=5.466158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[500] avg_epoch_loss=5.558484\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=500 train loss <loss>=5.31485900879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [500]#011Speed: 1062.88 samples/sec#011loss=5.314859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[505] avg_epoch_loss=5.555879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=505 train loss <loss>=5.29482879639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [505]#011Speed: 1653.61 samples/sec#011loss=5.294829\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[510] avg_epoch_loss=5.556386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=510 train loss <loss>=5.60768938065\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [510]#011Speed: 1017.17 samples/sec#011loss=5.607689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[515] avg_epoch_loss=5.557000\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=515 train loss <loss>=5.6197558403\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [515]#011Speed: 1532.33 samples/sec#011loss=5.619756\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[520] avg_epoch_loss=5.558225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=520 train loss <loss>=5.68464765549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [520]#011Speed: 1057.78 samples/sec#011loss=5.684648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch[525] avg_epoch_loss=5.556285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=525 train loss <loss>=5.35413627625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:00 INFO 140669025912640] Epoch[4] Batch [525]#011Speed: 1668.49 samples/sec#011loss=5.354136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[530] avg_epoch_loss=5.556595\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=530 train loss <loss>=5.58922386169\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [530]#011Speed: 1006.67 samples/sec#011loss=5.589224\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[535] avg_epoch_loss=5.555310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=535 train loss <loss>=5.41881809235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [535]#011Speed: 1592.63 samples/sec#011loss=5.418818\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[540] avg_epoch_loss=5.554272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=540 train loss <loss>=5.44301300049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [540]#011Speed: 989.34 samples/sec#011loss=5.443013\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[545] avg_epoch_loss=5.556385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=545 train loss <loss>=5.78498373032\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [545]#011Speed: 1599.90 samples/sec#011loss=5.784984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[550] avg_epoch_loss=5.555408\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=550 train loss <loss>=5.44876785278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [550]#011Speed: 1053.77 samples/sec#011loss=5.448768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[555] avg_epoch_loss=5.558103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=555 train loss <loss>=5.85507717133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [555]#011Speed: 1648.75 samples/sec#011loss=5.855077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[560] avg_epoch_loss=5.559760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=560 train loss <loss>=5.74394578934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [560]#011Speed: 1283.86 samples/sec#011loss=5.743946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch[565] avg_epoch_loss=5.559159\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, batch=565 train loss <loss>=5.49174575806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[4] Batch [565]#011Speed: 1625.90 samples/sec#011loss=5.491746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] processed a total of 18127 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14248.455047607422, \"sum\": 14248.455047607422, \"min\": 14248.455047607422}}, \"EndTime\": 1589393761.917183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393747.668672}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1272.19999474 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=4, train loss <loss>=5.55553724778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_6e85ce2a-feb9-433c-9a57-a7517ea7d7bb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.936166763305664, \"sum\": 8.936166763305664, \"min\": 8.936166763305664}}, \"EndTime\": 1589393761.926608, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393761.917246}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] Epoch[5] Batch[0] avg_epoch_loss=5.603380\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=5.60338020325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[5] avg_epoch_loss=5.444380\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=5.4443804423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [5]#011Speed: 1482.47 samples/sec#011loss=5.444380\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[10] avg_epoch_loss=5.495182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=5.55614318848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [10]#011Speed: 1045.92 samples/sec#011loss=5.556143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[15] avg_epoch_loss=5.486022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=5.46587085724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [15]#011Speed: 1655.46 samples/sec#011loss=5.465871\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[20] avg_epoch_loss=5.442395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=5.30278730392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [20]#011Speed: 1688.10 samples/sec#011loss=5.302787\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[25] avg_epoch_loss=5.443809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=5.44974718094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [25]#011Speed: 1006.49 samples/sec#011loss=5.449747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[30] avg_epoch_loss=5.444316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=5.44695415497\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [30]#011Speed: 1084.80 samples/sec#011loss=5.446954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch[35] avg_epoch_loss=5.441277\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=5.4224360466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:02 INFO 140669025912640] Epoch[5] Batch [35]#011Speed: 1641.18 samples/sec#011loss=5.422436\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[40] avg_epoch_loss=5.476007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=5.72606143951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [40]#011Speed: 1069.38 samples/sec#011loss=5.726061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[45] avg_epoch_loss=5.485409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=5.56250238419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [45]#011Speed: 1590.54 samples/sec#011loss=5.562502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[50] avg_epoch_loss=5.516409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=5.80160913467\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [50]#011Speed: 1669.28 samples/sec#011loss=5.801609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[55] avg_epoch_loss=5.520803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=5.56562347412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [55]#011Speed: 994.23 samples/sec#011loss=5.565623\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[60] avg_epoch_loss=5.521812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=5.53311824799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [60]#011Speed: 1661.54 samples/sec#011loss=5.533118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[65] avg_epoch_loss=5.526185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=5.57952795029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [65]#011Speed: 1042.73 samples/sec#011loss=5.579528\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[70] avg_epoch_loss=5.527473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=5.54447984695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [70]#011Speed: 1683.52 samples/sec#011loss=5.544480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[75] avg_epoch_loss=5.514178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=5.32539281845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [75]#011Speed: 1052.92 samples/sec#011loss=5.325393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch[80] avg_epoch_loss=5.514639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=5.52163362503\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:03 INFO 140669025912640] Epoch[5] Batch [80]#011Speed: 1641.47 samples/sec#011loss=5.521634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[85] avg_epoch_loss=5.499613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=5.256199646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [85]#011Speed: 1031.80 samples/sec#011loss=5.256200\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[90] avg_epoch_loss=5.501839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=5.54012594223\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [90]#011Speed: 1678.98 samples/sec#011loss=5.540126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[95] avg_epoch_loss=5.497195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=5.41267299652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [95]#011Speed: 1025.88 samples/sec#011loss=5.412673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[100] avg_epoch_loss=5.508652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=5.72862501144\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [100]#011Speed: 1581.35 samples/sec#011loss=5.728625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[105] avg_epoch_loss=5.502143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=5.37066078186\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [105]#011Speed: 1034.39 samples/sec#011loss=5.370661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[110] avg_epoch_loss=5.488005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=5.18827457428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [110]#011Speed: 1476.82 samples/sec#011loss=5.188275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[115] avg_epoch_loss=5.486029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=5.44216156006\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [115]#011Speed: 1036.31 samples/sec#011loss=5.442162\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch[120] avg_epoch_loss=5.487778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=5.52836732864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:04 INFO 140669025912640] Epoch[5] Batch [120]#011Speed: 1632.45 samples/sec#011loss=5.528367\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[125] avg_epoch_loss=5.493884\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=5.64165525436\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [125]#011Speed: 1638.12 samples/sec#011loss=5.641655\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[130] avg_epoch_loss=5.502731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=5.72567396164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [130]#011Speed: 1087.70 samples/sec#011loss=5.725674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[135] avg_epoch_loss=5.499062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=5.4029168129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [135]#011Speed: 1642.44 samples/sec#011loss=5.402917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[140] avg_epoch_loss=5.496585\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=5.42920732498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [140]#011Speed: 1105.58 samples/sec#011loss=5.429207\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[145] avg_epoch_loss=5.491646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=5.35237064362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [145]#011Speed: 1646.07 samples/sec#011loss=5.352371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[150] avg_epoch_loss=5.490892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=5.46886901855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [150]#011Speed: 1001.09 samples/sec#011loss=5.468869\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[155] avg_epoch_loss=5.491490\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=5.50956630707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [155]#011Speed: 1655.34 samples/sec#011loss=5.509566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch[160] avg_epoch_loss=5.490635\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=5.46395282745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:05 INFO 140669025912640] Epoch[5] Batch [160]#011Speed: 1037.80 samples/sec#011loss=5.463953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[165] avg_epoch_loss=5.489113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=5.44011526108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [165]#011Speed: 1654.30 samples/sec#011loss=5.440115\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[170] avg_epoch_loss=5.489973\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=5.51851100922\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [170]#011Speed: 1027.23 samples/sec#011loss=5.518511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[175] avg_epoch_loss=5.487357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=5.39790306091\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [175]#011Speed: 1658.27 samples/sec#011loss=5.397903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[180] avg_epoch_loss=5.490192\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=5.58995923996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [180]#011Speed: 1012.56 samples/sec#011loss=5.589959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[185] avg_epoch_loss=5.490870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=5.51542100906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [185]#011Speed: 1653.29 samples/sec#011loss=5.515421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[190] avg_epoch_loss=5.496016\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=5.68745737076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [190]#011Speed: 1030.55 samples/sec#011loss=5.687457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[195] avg_epoch_loss=5.496664\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=5.52141990662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [195]#011Speed: 1670.44 samples/sec#011loss=5.521420\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch[200] avg_epoch_loss=5.498102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=5.5544798851\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:06 INFO 140669025912640] Epoch[5] Batch [200]#011Speed: 1062.79 samples/sec#011loss=5.554480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[205] avg_epoch_loss=5.497770\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=5.48440332413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [205]#011Speed: 1678.24 samples/sec#011loss=5.484403\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[210] avg_epoch_loss=5.495824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=5.41566886902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [210]#011Speed: 1041.56 samples/sec#011loss=5.415669\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[215] avg_epoch_loss=5.490757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=5.27690734863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [215]#011Speed: 1659.91 samples/sec#011loss=5.276907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[220] avg_epoch_loss=5.489821\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=5.44941167831\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [220]#011Speed: 1009.99 samples/sec#011loss=5.449412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[225] avg_epoch_loss=5.487997\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=5.40734033585\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [225]#011Speed: 1615.57 samples/sec#011loss=5.407340\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[230] avg_epoch_loss=5.482141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=5.21749353409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [230]#011Speed: 1574.03 samples/sec#011loss=5.217494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[235] avg_epoch_loss=5.477350\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=5.25598497391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [235]#011Speed: 1088.24 samples/sec#011loss=5.255985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch[240] avg_epoch_loss=5.479460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=5.57903909683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:07 INFO 140669025912640] Epoch[5] Batch [240]#011Speed: 1477.62 samples/sec#011loss=5.579039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[245] avg_epoch_loss=5.478783\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=5.44617872238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [245]#011Speed: 1087.39 samples/sec#011loss=5.446179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[250] avg_epoch_loss=5.473076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=5.19225568771\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [250]#011Speed: 1668.75 samples/sec#011loss=5.192256\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[255] avg_epoch_loss=5.476631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=5.65509195328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [255]#011Speed: 1018.95 samples/sec#011loss=5.655092\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[260] avg_epoch_loss=5.478244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=5.56084432602\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [260]#011Speed: 1622.35 samples/sec#011loss=5.560844\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[265] avg_epoch_loss=5.479475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=5.54375982285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [265]#011Speed: 1032.78 samples/sec#011loss=5.543760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[270] avg_epoch_loss=5.487030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=270 train loss <loss>=5.8889336586\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [270]#011Speed: 1625.18 samples/sec#011loss=5.888934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[275] avg_epoch_loss=5.490545\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=275 train loss <loss>=5.68106079102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [275]#011Speed: 1037.68 samples/sec#011loss=5.681061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch[280] avg_epoch_loss=5.492860\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=280 train loss <loss>=5.62062044144\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:08 INFO 140669025912640] Epoch[5] Batch [280]#011Speed: 1675.01 samples/sec#011loss=5.620620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[285] avg_epoch_loss=5.490088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=285 train loss <loss>=5.33430204391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [285]#011Speed: 1034.96 samples/sec#011loss=5.334302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[290] avg_epoch_loss=5.491054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=290 train loss <loss>=5.54630670547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [290]#011Speed: 1683.75 samples/sec#011loss=5.546307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[295] avg_epoch_loss=5.491301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=295 train loss <loss>=5.50571985245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [295]#011Speed: 1020.60 samples/sec#011loss=5.505720\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[300] avg_epoch_loss=5.496384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=300 train loss <loss>=5.79728326797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [300]#011Speed: 1690.62 samples/sec#011loss=5.797283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[305] avg_epoch_loss=5.497044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=305 train loss <loss>=5.53678627014\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [305]#011Speed: 1065.84 samples/sec#011loss=5.536786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[310] avg_epoch_loss=5.493317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=310 train loss <loss>=5.26523065567\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [310]#011Speed: 1646.11 samples/sec#011loss=5.265231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[315] avg_epoch_loss=5.489869\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=315 train loss <loss>=5.27536754608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [315]#011Speed: 1109.50 samples/sec#011loss=5.275368\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch[320] avg_epoch_loss=5.489353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=320 train loss <loss>=5.45678319931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:09 INFO 140669025912640] Epoch[5] Batch [320]#011Speed: 1666.02 samples/sec#011loss=5.456783\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[325] avg_epoch_loss=5.492710\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=325 train loss <loss>=5.70821008682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [325]#011Speed: 1074.68 samples/sec#011loss=5.708210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[330] avg_epoch_loss=5.498209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=330 train loss <loss>=5.8567234993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [330]#011Speed: 1684.23 samples/sec#011loss=5.856723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[335] avg_epoch_loss=5.499807\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=335 train loss <loss>=5.60562362671\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [335]#011Speed: 985.87 samples/sec#011loss=5.605624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[340] avg_epoch_loss=5.500529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=340 train loss <loss>=5.54905366898\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [340]#011Speed: 1662.49 samples/sec#011loss=5.549054\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[345] avg_epoch_loss=5.499592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=345 train loss <loss>=5.4356423378\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [345]#011Speed: 1076.88 samples/sec#011loss=5.435642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[350] avg_epoch_loss=5.501517\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=350 train loss <loss>=5.63472909927\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [350]#011Speed: 1500.74 samples/sec#011loss=5.634729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[355] avg_epoch_loss=5.497892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=355 train loss <loss>=5.24341526031\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [355]#011Speed: 1028.63 samples/sec#011loss=5.243415\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch[360] avg_epoch_loss=5.494726\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=360 train loss <loss>=5.26934785843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:10 INFO 140669025912640] Epoch[5] Batch [360]#011Speed: 1597.99 samples/sec#011loss=5.269348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[365] avg_epoch_loss=5.489278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=365 train loss <loss>=5.09591703415\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [365]#011Speed: 1024.97 samples/sec#011loss=5.095917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[370] avg_epoch_loss=5.489622\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=370 train loss <loss>=5.51480875015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [370]#011Speed: 1650.85 samples/sec#011loss=5.514809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[375] avg_epoch_loss=5.490845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=375 train loss <loss>=5.58159971237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [375]#011Speed: 1078.21 samples/sec#011loss=5.581600\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[380] avg_epoch_loss=5.490681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=380 train loss <loss>=5.47830181122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [380]#011Speed: 1620.36 samples/sec#011loss=5.478302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[385] avg_epoch_loss=5.489737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=385 train loss <loss>=5.41782636642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [385]#011Speed: 1017.16 samples/sec#011loss=5.417826\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[390] avg_epoch_loss=5.490014\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=390 train loss <loss>=5.51142807007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [390]#011Speed: 1508.44 samples/sec#011loss=5.511428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[395] avg_epoch_loss=5.487428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=395 train loss <loss>=5.2852025032\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [395]#011Speed: 1024.77 samples/sec#011loss=5.285203\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch[400] avg_epoch_loss=5.485188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=400 train loss <loss>=5.30772953033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:11 INFO 140669025912640] Epoch[5] Batch [400]#011Speed: 1691.80 samples/sec#011loss=5.307730\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[405] avg_epoch_loss=5.486498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=405 train loss <loss>=5.5915804863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [405]#011Speed: 989.07 samples/sec#011loss=5.591580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[410] avg_epoch_loss=5.482721\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=410 train loss <loss>=5.17606430054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [410]#011Speed: 1611.36 samples/sec#011loss=5.176064\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[415] avg_epoch_loss=5.483803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=415 train loss <loss>=5.57272920609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [415]#011Speed: 1034.13 samples/sec#011loss=5.572729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[420] avg_epoch_loss=5.484895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=420 train loss <loss>=5.57570438385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [420]#011Speed: 1601.63 samples/sec#011loss=5.575704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[425] avg_epoch_loss=5.484373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=425 train loss <loss>=5.44047727585\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [425]#011Speed: 1043.82 samples/sec#011loss=5.440477\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[430] avg_epoch_loss=5.483615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=430 train loss <loss>=5.41899051666\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [430]#011Speed: 1556.63 samples/sec#011loss=5.418991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[435] avg_epoch_loss=5.483221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=435 train loss <loss>=5.44924001694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [435]#011Speed: 974.31 samples/sec#011loss=5.449240\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch[440] avg_epoch_loss=5.485202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=440 train loss <loss>=5.65797929764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:12 INFO 140669025912640] Epoch[5] Batch [440]#011Speed: 1657.68 samples/sec#011loss=5.657979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[445] avg_epoch_loss=5.487522\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=445 train loss <loss>=5.69217195511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [445]#011Speed: 990.64 samples/sec#011loss=5.692172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[450] avg_epoch_loss=5.488701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=450 train loss <loss>=5.59383420944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [450]#011Speed: 1657.72 samples/sec#011loss=5.593834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[455] avg_epoch_loss=5.486940\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=455 train loss <loss>=5.32808551788\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [455]#011Speed: 1048.49 samples/sec#011loss=5.328086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[460] avg_epoch_loss=5.487110\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=460 train loss <loss>=5.50267095566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [460]#011Speed: 1637.11 samples/sec#011loss=5.502671\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[465] avg_epoch_loss=5.483611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=465 train loss <loss>=5.16096153259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [465]#011Speed: 1062.83 samples/sec#011loss=5.160962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[470] avg_epoch_loss=5.482257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=470 train loss <loss>=5.3560880661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [470]#011Speed: 1607.93 samples/sec#011loss=5.356088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch[475] avg_epoch_loss=5.482201\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=475 train loss <loss>=5.47689208984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:13 INFO 140669025912640] Epoch[5] Batch [475]#011Speed: 973.58 samples/sec#011loss=5.476892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[480] avg_epoch_loss=5.481066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=480 train loss <loss>=5.37305746078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [480]#011Speed: 1635.64 samples/sec#011loss=5.373057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[485] avg_epoch_loss=5.481261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=485 train loss <loss>=5.49995861053\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [485]#011Speed: 1098.42 samples/sec#011loss=5.499959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[490] avg_epoch_loss=5.481030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=490 train loss <loss>=5.45865926743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [490]#011Speed: 1659.01 samples/sec#011loss=5.458659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[495] avg_epoch_loss=5.480949\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=495 train loss <loss>=5.47295150757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [495]#011Speed: 1006.92 samples/sec#011loss=5.472952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[500] avg_epoch_loss=5.480440\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=500 train loss <loss>=5.42992286682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [500]#011Speed: 1567.26 samples/sec#011loss=5.429923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[505] avg_epoch_loss=5.481104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=505 train loss <loss>=5.54765977859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [505]#011Speed: 1665.85 samples/sec#011loss=5.547660\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[510] avg_epoch_loss=5.480507\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=510 train loss <loss>=5.42010383606\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [510]#011Speed: 1001.37 samples/sec#011loss=5.420104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch[515] avg_epoch_loss=5.482413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=515 train loss <loss>=5.67715377808\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:14 INFO 140669025912640] Epoch[5] Batch [515]#011Speed: 1696.78 samples/sec#011loss=5.677154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[520] avg_epoch_loss=5.480620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=520 train loss <loss>=5.29563360214\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [520]#011Speed: 1066.74 samples/sec#011loss=5.295634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[525] avg_epoch_loss=5.480519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=525 train loss <loss>=5.4699552536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [525]#011Speed: 1677.36 samples/sec#011loss=5.469955\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[530] avg_epoch_loss=5.480294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=530 train loss <loss>=5.45668535233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [530]#011Speed: 1033.45 samples/sec#011loss=5.456685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[535] avg_epoch_loss=5.479814\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=535 train loss <loss>=5.42881164551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [535]#011Speed: 1624.73 samples/sec#011loss=5.428812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[540] avg_epoch_loss=5.481660\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=540 train loss <loss>=5.67949886322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [540]#011Speed: 1055.80 samples/sec#011loss=5.679499\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[545] avg_epoch_loss=5.482466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=545 train loss <loss>=5.56969232559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [545]#011Speed: 1661.30 samples/sec#011loss=5.569692\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[550] avg_epoch_loss=5.482866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=550 train loss <loss>=5.52653131485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [550]#011Speed: 974.75 samples/sec#011loss=5.526531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch[555] avg_epoch_loss=5.480283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=555 train loss <loss>=5.19565391541\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:15 INFO 140669025912640] Epoch[5] Batch [555]#011Speed: 1690.30 samples/sec#011loss=5.195654\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch[560] avg_epoch_loss=5.481959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=560 train loss <loss>=5.66831502914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch [560]#011Speed: 1064.56 samples/sec#011loss=5.668315\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch[565] avg_epoch_loss=5.480508\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=565 train loss <loss>=5.31777935028\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch [565]#011Speed: 1697.95 samples/sec#011loss=5.317779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch[570] avg_epoch_loss=5.480495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=570 train loss <loss>=5.47897520065\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch [570]#011Speed: 1024.75 samples/sec#011loss=5.478975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch[575] avg_epoch_loss=5.481396\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, batch=575 train loss <loss>=5.58425312042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[5] Batch [575]#011Speed: 1651.65 samples/sec#011loss=5.584253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] processed a total of 18484 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14485.754013061523, \"sum\": 14485.754013061523, \"min\": 14485.754013061523}}, \"EndTime\": 1589393776.412481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393761.926665}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1276.00381599 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=5, train loss <loss>=5.47929949331\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_5d6964e8-da27-44fb-8127-7aed8262261e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.844064712524414, \"sum\": 9.844064712524414, \"min\": 9.844064712524414}}, \"EndTime\": 1589393776.422736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393776.412545}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch[0] avg_epoch_loss=5.103189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=5.10318899155\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch[5] avg_epoch_loss=5.230947\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=5.23094677925\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch [5]#011Speed: 1671.80 samples/sec#011loss=5.230947\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch[10] avg_epoch_loss=5.336504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=5.4631734848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch [10]#011Speed: 1021.15 samples/sec#011loss=5.463173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch[15] avg_epoch_loss=5.372017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=5.45014562607\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:16 INFO 140669025912640] Epoch[6] Batch [15]#011Speed: 1655.59 samples/sec#011loss=5.450146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[20] avg_epoch_loss=5.386749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=5.43388910294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [20]#011Speed: 1042.30 samples/sec#011loss=5.433889\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[25] avg_epoch_loss=5.412970\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=5.52309904099\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [25]#011Speed: 1665.21 samples/sec#011loss=5.523099\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[30] avg_epoch_loss=5.428696\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=5.51046924591\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [30]#011Speed: 1093.21 samples/sec#011loss=5.510469\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[35] avg_epoch_loss=5.432022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=5.45264310837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [35]#011Speed: 1625.72 samples/sec#011loss=5.452643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[40] avg_epoch_loss=5.443552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=5.52656793594\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [40]#011Speed: 1043.54 samples/sec#011loss=5.526568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[45] avg_epoch_loss=5.444716\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=5.45426187515\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [45]#011Speed: 1641.71 samples/sec#011loss=5.454262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[50] avg_epoch_loss=5.434088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=5.33630933762\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [50]#011Speed: 1045.63 samples/sec#011loss=5.336309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[55] avg_epoch_loss=5.412131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=5.18817539215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [55]#011Speed: 1576.08 samples/sec#011loss=5.188175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch[60] avg_epoch_loss=5.432246\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=5.65753355026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:17 INFO 140669025912640] Epoch[6] Batch [60]#011Speed: 1669.78 samples/sec#011loss=5.657534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[65] avg_epoch_loss=5.423422\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=5.31576566696\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [65]#011Speed: 1042.67 samples/sec#011loss=5.315766\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[70] avg_epoch_loss=5.423391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=5.42298555374\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [70]#011Speed: 1659.98 samples/sec#011loss=5.422986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[75] avg_epoch_loss=5.419032\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=5.35713653564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [75]#011Speed: 1077.79 samples/sec#011loss=5.357137\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[80] avg_epoch_loss=5.405841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=5.20533437729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [80]#011Speed: 1669.83 samples/sec#011loss=5.205334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[85] avg_epoch_loss=5.394842\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=5.21665725708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [85]#011Speed: 1024.05 samples/sec#011loss=5.216657\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[90] avg_epoch_loss=5.390646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=5.31847953796\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [90]#011Speed: 1605.60 samples/sec#011loss=5.318480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[95] avg_epoch_loss=5.382952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=5.24291963577\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [95]#011Speed: 1010.60 samples/sec#011loss=5.242920\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch[100] avg_epoch_loss=5.380481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=5.33302555084\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:18 INFO 140669025912640] Epoch[6] Batch [100]#011Speed: 1682.08 samples/sec#011loss=5.333026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[105] avg_epoch_loss=5.388693\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=5.5545876503\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [105]#011Speed: 1049.39 samples/sec#011loss=5.554588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[110] avg_epoch_loss=5.384430\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=5.29404010773\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [110]#011Speed: 1687.23 samples/sec#011loss=5.294040\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[115] avg_epoch_loss=5.401013\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=5.76917304993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [115]#011Speed: 1086.62 samples/sec#011loss=5.769173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[120] avg_epoch_loss=5.394449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=5.24216547012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [120]#011Speed: 1680.83 samples/sec#011loss=5.242165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[125] avg_epoch_loss=5.395429\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=5.41913537979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [125]#011Speed: 1075.80 samples/sec#011loss=5.419135\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[130] avg_epoch_loss=5.392296\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=5.31334915161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [130]#011Speed: 1659.30 samples/sec#011loss=5.313349\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[135] avg_epoch_loss=5.399831\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=5.59723215103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [135]#011Speed: 1058.89 samples/sec#011loss=5.597232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch[140] avg_epoch_loss=5.405392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=5.55665197372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:19 INFO 140669025912640] Epoch[6] Batch [140]#011Speed: 1688.26 samples/sec#011loss=5.556652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[145] avg_epoch_loss=5.407161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=5.45706148148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [145]#011Speed: 1060.24 samples/sec#011loss=5.457061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[150] avg_epoch_loss=5.402516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=5.26687736511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [150]#011Speed: 1669.19 samples/sec#011loss=5.266877\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[155] avg_epoch_loss=5.408217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=5.58037490845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [155]#011Speed: 1086.53 samples/sec#011loss=5.580375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[160] avg_epoch_loss=5.412968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=5.56121711731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [160]#011Speed: 1640.76 samples/sec#011loss=5.561217\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[165] avg_epoch_loss=5.409524\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=5.29861822128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [165]#011Speed: 1063.66 samples/sec#011loss=5.298618\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[170] avg_epoch_loss=5.413589\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=5.54853496552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [170]#011Speed: 1606.97 samples/sec#011loss=5.548535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[175] avg_epoch_loss=5.421214\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=5.68200931549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [175]#011Speed: 1016.90 samples/sec#011loss=5.682009\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch[180] avg_epoch_loss=5.424434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=5.53776521683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:20 INFO 140669025912640] Epoch[6] Batch [180]#011Speed: 1620.94 samples/sec#011loss=5.537765\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[185] avg_epoch_loss=5.419582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=5.24396705627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [185]#011Speed: 1005.49 samples/sec#011loss=5.243967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[190] avg_epoch_loss=5.421395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=5.48882246017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [190]#011Speed: 1471.47 samples/sec#011loss=5.488822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[195] avg_epoch_loss=5.425610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=5.58661251068\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [195]#011Speed: 1044.58 samples/sec#011loss=5.586613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[200] avg_epoch_loss=5.424715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=5.38963747025\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [200]#011Speed: 1651.56 samples/sec#011loss=5.389637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[205] avg_epoch_loss=5.427766\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=5.55040874481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [205]#011Speed: 1113.69 samples/sec#011loss=5.550409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[210] avg_epoch_loss=5.429989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=5.52159347534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [210]#011Speed: 1651.24 samples/sec#011loss=5.521593\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[215] avg_epoch_loss=5.434809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=5.63819656372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [215]#011Speed: 1033.96 samples/sec#011loss=5.638197\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch[220] avg_epoch_loss=5.432161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=5.31779050827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:21 INFO 140669025912640] Epoch[6] Batch [220]#011Speed: 1687.99 samples/sec#011loss=5.317791\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[225] avg_epoch_loss=5.435985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=5.6050034523\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [225]#011Speed: 1090.02 samples/sec#011loss=5.605003\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[230] avg_epoch_loss=5.434375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=5.36156826019\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [230]#011Speed: 1662.63 samples/sec#011loss=5.361568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[235] avg_epoch_loss=5.434691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=5.4493221283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [235]#011Speed: 1097.26 samples/sec#011loss=5.449322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[240] avg_epoch_loss=5.435059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=5.45239868164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [240]#011Speed: 1638.66 samples/sec#011loss=5.452399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[245] avg_epoch_loss=5.435388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=5.45125112534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [245]#011Speed: 1100.71 samples/sec#011loss=5.451251\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[250] avg_epoch_loss=5.432535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=5.29218597412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [250]#011Speed: 1618.94 samples/sec#011loss=5.292186\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[255] avg_epoch_loss=5.430882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=5.34790420532\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [255]#011Speed: 1625.96 samples/sec#011loss=5.347904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch[260] avg_epoch_loss=5.435424\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=5.66795358658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:22 INFO 140669025912640] Epoch[6] Batch [260]#011Speed: 1111.31 samples/sec#011loss=5.667954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[265] avg_epoch_loss=5.434002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=5.35977067947\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [265]#011Speed: 1660.49 samples/sec#011loss=5.359771\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[270] avg_epoch_loss=5.439112\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=270 train loss <loss>=5.71097927094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [270]#011Speed: 1086.85 samples/sec#011loss=5.710979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[275] avg_epoch_loss=5.441690\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=275 train loss <loss>=5.581437397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [275]#011Speed: 1665.14 samples/sec#011loss=5.581437\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[280] avg_epoch_loss=5.435734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=280 train loss <loss>=5.10695734024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [280]#011Speed: 1131.10 samples/sec#011loss=5.106957\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[285] avg_epoch_loss=5.437538\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=285 train loss <loss>=5.53891477585\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [285]#011Speed: 1668.11 samples/sec#011loss=5.538915\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[290] avg_epoch_loss=5.435870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=290 train loss <loss>=5.34044313431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [290]#011Speed: 1103.84 samples/sec#011loss=5.340443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[295] avg_epoch_loss=5.435068\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=295 train loss <loss>=5.38839063644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [295]#011Speed: 1617.70 samples/sec#011loss=5.388391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[300] avg_epoch_loss=5.433988\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=300 train loss <loss>=5.37006912231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [300]#011Speed: 1057.56 samples/sec#011loss=5.370069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch[305] avg_epoch_loss=5.432372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=305 train loss <loss>=5.33508720398\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:23 INFO 140669025912640] Epoch[6] Batch [305]#011Speed: 1656.37 samples/sec#011loss=5.335087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[310] avg_epoch_loss=5.425465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=310 train loss <loss>=5.00278587341\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [310]#011Speed: 1112.49 samples/sec#011loss=5.002786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[315] avg_epoch_loss=5.424584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=315 train loss <loss>=5.36973409653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [315]#011Speed: 1634.00 samples/sec#011loss=5.369734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[320] avg_epoch_loss=5.430852\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=320 train loss <loss>=5.82702207565\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [320]#011Speed: 1101.35 samples/sec#011loss=5.827022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[325] avg_epoch_loss=5.434903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=325 train loss <loss>=5.69494533539\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [325]#011Speed: 1654.38 samples/sec#011loss=5.694945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[330] avg_epoch_loss=5.434555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=330 train loss <loss>=5.41189212799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [330]#011Speed: 1075.86 samples/sec#011loss=5.411892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[335] avg_epoch_loss=5.433983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=335 train loss <loss>=5.39609708786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [335]#011Speed: 1657.81 samples/sec#011loss=5.396097\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[340] avg_epoch_loss=5.437750\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=340 train loss <loss>=5.69089040756\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [340]#011Speed: 1072.21 samples/sec#011loss=5.690890\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch[345] avg_epoch_loss=5.435655\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=345 train loss <loss>=5.29277896881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:24 INFO 140669025912640] Epoch[6] Batch [345]#011Speed: 1653.29 samples/sec#011loss=5.292779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[350] avg_epoch_loss=5.435303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=350 train loss <loss>=5.41098966599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [350]#011Speed: 1128.80 samples/sec#011loss=5.410990\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[355] avg_epoch_loss=5.432164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=355 train loss <loss>=5.21177740097\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [355]#011Speed: 1663.46 samples/sec#011loss=5.211777\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[360] avg_epoch_loss=5.430962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=360 train loss <loss>=5.34537372589\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [360]#011Speed: 1056.29 samples/sec#011loss=5.345374\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[365] avg_epoch_loss=5.430216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=365 train loss <loss>=5.37634305954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [365]#011Speed: 1659.11 samples/sec#011loss=5.376343\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[370] avg_epoch_loss=5.430744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=370 train loss <loss>=5.46942462921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [370]#011Speed: 1644.11 samples/sec#011loss=5.469425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[375] avg_epoch_loss=5.432524\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=375 train loss <loss>=5.56455879211\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [375]#011Speed: 1096.41 samples/sec#011loss=5.564559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[380] avg_epoch_loss=5.431063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=380 train loss <loss>=5.32119922638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [380]#011Speed: 1449.28 samples/sec#011loss=5.321199\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch[385] avg_epoch_loss=5.431666\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=385 train loss <loss>=5.47760066986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:25 INFO 140669025912640] Epoch[6] Batch [385]#011Speed: 1075.18 samples/sec#011loss=5.477601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[390] avg_epoch_loss=5.434318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=390 train loss <loss>=5.63905954361\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [390]#011Speed: 1066.60 samples/sec#011loss=5.639060\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[395] avg_epoch_loss=5.435385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=395 train loss <loss>=5.51884536743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [395]#011Speed: 1573.63 samples/sec#011loss=5.518845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[400] avg_epoch_loss=5.436088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=400 train loss <loss>=5.49180288315\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [400]#011Speed: 1661.08 samples/sec#011loss=5.491803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[405] avg_epoch_loss=5.437687\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=405 train loss <loss>=5.56587314606\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [405]#011Speed: 1074.31 samples/sec#011loss=5.565873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[410] avg_epoch_loss=5.438428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=410 train loss <loss>=5.4986374855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [410]#011Speed: 1670.79 samples/sec#011loss=5.498637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[415] avg_epoch_loss=5.440147\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=415 train loss <loss>=5.58143472672\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [415]#011Speed: 1029.57 samples/sec#011loss=5.581435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[420] avg_epoch_loss=5.440496\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=420 train loss <loss>=5.46955041885\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [420]#011Speed: 1647.81 samples/sec#011loss=5.469550\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch[425] avg_epoch_loss=5.440639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=425 train loss <loss>=5.45269432068\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:26 INFO 140669025912640] Epoch[6] Batch [425]#011Speed: 1035.54 samples/sec#011loss=5.452694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[430] avg_epoch_loss=5.441476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=430 train loss <loss>=5.51277685165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [430]#011Speed: 1697.94 samples/sec#011loss=5.512777\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[435] avg_epoch_loss=5.441662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=435 train loss <loss>=5.45767707825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [435]#011Speed: 1071.57 samples/sec#011loss=5.457677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[440] avg_epoch_loss=5.440936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=440 train loss <loss>=5.37764577866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [440]#011Speed: 1664.15 samples/sec#011loss=5.377646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[445] avg_epoch_loss=5.440817\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=445 train loss <loss>=5.4303399086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [445]#011Speed: 1104.77 samples/sec#011loss=5.430340\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[450] avg_epoch_loss=5.440523\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=450 train loss <loss>=5.414245224\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [450]#011Speed: 1653.61 samples/sec#011loss=5.414245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[455] avg_epoch_loss=5.440316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=455 train loss <loss>=5.42169837952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [455]#011Speed: 1012.72 samples/sec#011loss=5.421698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[460] avg_epoch_loss=5.440895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=460 train loss <loss>=5.4936258316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [460]#011Speed: 1634.00 samples/sec#011loss=5.493626\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch[465] avg_epoch_loss=5.440023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=465 train loss <loss>=5.35964708328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:27 INFO 140669025912640] Epoch[6] Batch [465]#011Speed: 1048.77 samples/sec#011loss=5.359647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[470] avg_epoch_loss=5.438892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=470 train loss <loss>=5.33346319199\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [470]#011Speed: 1646.68 samples/sec#011loss=5.333463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[475] avg_epoch_loss=5.437905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=475 train loss <loss>=5.34499435425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [475]#011Speed: 1050.87 samples/sec#011loss=5.344994\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[480] avg_epoch_loss=5.439181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=480 train loss <loss>=5.5606338501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [480]#011Speed: 1622.98 samples/sec#011loss=5.560634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[485] avg_epoch_loss=5.438125\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=485 train loss <loss>=5.33657197952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [485]#011Speed: 1044.78 samples/sec#011loss=5.336572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[490] avg_epoch_loss=5.436756\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=490 train loss <loss>=5.30360994339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [490]#011Speed: 1523.36 samples/sec#011loss=5.303610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[495] avg_epoch_loss=5.436139\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=495 train loss <loss>=5.37558698654\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [495]#011Speed: 1019.92 samples/sec#011loss=5.375587\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[500] avg_epoch_loss=5.435637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=500 train loss <loss>=5.38579521179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [500]#011Speed: 1668.84 samples/sec#011loss=5.385795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch[505] avg_epoch_loss=5.437461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=505 train loss <loss>=5.62027959824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:28 INFO 140669025912640] Epoch[6] Batch [505]#011Speed: 1087.27 samples/sec#011loss=5.620280\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[510] avg_epoch_loss=5.437437\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=510 train loss <loss>=5.43501186371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [510]#011Speed: 1692.91 samples/sec#011loss=5.435012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[515] avg_epoch_loss=5.436116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=515 train loss <loss>=5.30112075806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [515]#011Speed: 1038.56 samples/sec#011loss=5.301121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[520] avg_epoch_loss=5.436335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=520 train loss <loss>=5.45887908936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [520]#011Speed: 1680.92 samples/sec#011loss=5.458879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[525] avg_epoch_loss=5.437729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=525 train loss <loss>=5.5830075264\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [525]#011Speed: 1054.35 samples/sec#011loss=5.583008\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[530] avg_epoch_loss=5.437776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=530 train loss <loss>=5.44274663925\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [530]#011Speed: 1533.52 samples/sec#011loss=5.442747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[535] avg_epoch_loss=5.438283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=535 train loss <loss>=5.49211807251\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [535]#011Speed: 1043.10 samples/sec#011loss=5.492118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[540] avg_epoch_loss=5.438895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=540 train loss <loss>=5.50451564789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [540]#011Speed: 1586.50 samples/sec#011loss=5.504516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch[545] avg_epoch_loss=5.440204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=545 train loss <loss>=5.58180847168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:29 INFO 140669025912640] Epoch[6] Batch [545]#011Speed: 1027.04 samples/sec#011loss=5.581808\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch[550] avg_epoch_loss=5.439740\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=550 train loss <loss>=5.38911743164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch [550]#011Speed: 1582.07 samples/sec#011loss=5.389117\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch[555] avg_epoch_loss=5.438322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=555 train loss <loss>=5.28202953339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch [555]#011Speed: 1074.80 samples/sec#011loss=5.282030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch[560] avg_epoch_loss=5.438882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=560 train loss <loss>=5.50118732452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch [560]#011Speed: 1621.24 samples/sec#011loss=5.501187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch[565] avg_epoch_loss=5.438455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=565 train loss <loss>=5.39044075012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch [565]#011Speed: 1114.14 samples/sec#011loss=5.390441\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch[570] avg_epoch_loss=5.439244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=570 train loss <loss>=5.52857465744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch [570]#011Speed: 1527.23 samples/sec#011loss=5.528575\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch[575] avg_epoch_loss=5.440173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, batch=575 train loss <loss>=5.5463013649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[6] Batch [575]#011Speed: 1679.03 samples/sec#011loss=5.546301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] processed a total of 18416 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14221.63701057434, \"sum\": 14221.63701057434, \"min\": 14221.63701057434}}, \"EndTime\": 1589393790.644695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393776.423001}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1294.92009914 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=6, train loss <loss>=5.44017299182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_94b0b2c1-4093-40d7-b8c7-3c4aab7e6564-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.175228118896484, \"sum\": 10.175228118896484, \"min\": 10.175228118896484}}, \"EndTime\": 1589393790.655239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393790.644755}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[7] Batch[0] avg_epoch_loss=5.638605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=5.63860464096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[7] Batch[5] avg_epoch_loss=5.424671\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=5.42467125257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:30 INFO 140669025912640] Epoch[7] Batch [5]#011Speed: 1369.81 samples/sec#011loss=5.424671\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[10] avg_epoch_loss=5.292142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=5.13310728073\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [10]#011Speed: 1019.13 samples/sec#011loss=5.133107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[15] avg_epoch_loss=5.357784\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=5.50219497681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [15]#011Speed: 1638.82 samples/sec#011loss=5.502195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[20] avg_epoch_loss=5.361970\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=5.37536621094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [20]#011Speed: 1602.26 samples/sec#011loss=5.375366\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[25] avg_epoch_loss=5.389937\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=5.50739984512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [25]#011Speed: 1019.02 samples/sec#011loss=5.507400\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[30] avg_epoch_loss=5.384989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=5.35925531387\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [30]#011Speed: 1683.48 samples/sec#011loss=5.359255\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[35] avg_epoch_loss=5.399221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=5.48746328354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [35]#011Speed: 1044.27 samples/sec#011loss=5.487463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[40] avg_epoch_loss=5.398066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=5.38974761963\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [40]#011Speed: 1666.98 samples/sec#011loss=5.389748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[45] avg_epoch_loss=5.388621\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=5.31117124557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [45]#011Speed: 1033.60 samples/sec#011loss=5.311171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch[50] avg_epoch_loss=5.394226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=5.44579086304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:31 INFO 140669025912640] Epoch[7] Batch [50]#011Speed: 1655.46 samples/sec#011loss=5.445791\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[55] avg_epoch_loss=5.421534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=5.70008020401\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [55]#011Speed: 1080.19 samples/sec#011loss=5.700080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[60] avg_epoch_loss=5.414971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=5.3414642334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [60]#011Speed: 1621.25 samples/sec#011loss=5.341464\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[65] avg_epoch_loss=5.428316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=5.59112138748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [65]#011Speed: 1045.22 samples/sec#011loss=5.591121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[70] avg_epoch_loss=5.438886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=5.57840633392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [70]#011Speed: 1676.83 samples/sec#011loss=5.578406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[75] avg_epoch_loss=5.435183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=5.38260793686\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [75]#011Speed: 1067.26 samples/sec#011loss=5.382608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[80] avg_epoch_loss=5.414679\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=5.10301523209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [80]#011Speed: 1656.24 samples/sec#011loss=5.103015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[85] avg_epoch_loss=5.412378\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=5.37510375977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [85]#011Speed: 1059.93 samples/sec#011loss=5.375104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch[90] avg_epoch_loss=5.407799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=5.32904872894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:32 INFO 140669025912640] Epoch[7] Batch [90]#011Speed: 1700.43 samples/sec#011loss=5.329049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[95] avg_epoch_loss=5.401921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=5.29493837357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [95]#011Speed: 895.55 samples/sec#011loss=5.294938\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[100] avg_epoch_loss=5.393559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=5.23299798965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [100]#011Speed: 1556.15 samples/sec#011loss=5.232998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[105] avg_epoch_loss=5.389939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=5.31682376862\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [105]#011Speed: 1069.42 samples/sec#011loss=5.316824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[110] avg_epoch_loss=5.401122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=5.63820352554\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [110]#011Speed: 1691.99 samples/sec#011loss=5.638204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[115] avg_epoch_loss=5.406700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=5.53051624298\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [115]#011Speed: 1046.53 samples/sec#011loss=5.530516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[120] avg_epoch_loss=5.416482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=5.64343061447\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [120]#011Speed: 1685.67 samples/sec#011loss=5.643431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[125] avg_epoch_loss=5.407353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=5.18643054962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [125]#011Speed: 1064.62 samples/sec#011loss=5.186431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch[130] avg_epoch_loss=5.415838\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=5.62965593338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:33 INFO 140669025912640] Epoch[7] Batch [130]#011Speed: 1553.92 samples/sec#011loss=5.629656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[135] avg_epoch_loss=5.414841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=5.38871860504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [135]#011Speed: 1028.94 samples/sec#011loss=5.388719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[140] avg_epoch_loss=5.417740\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=5.49661645889\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [140]#011Speed: 1653.93 samples/sec#011loss=5.496616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[145] avg_epoch_loss=5.415748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=5.35955076218\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [145]#011Speed: 1610.04 samples/sec#011loss=5.359551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[150] avg_epoch_loss=5.415106\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=5.39637289047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [150]#011Speed: 1004.60 samples/sec#011loss=5.396373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[155] avg_epoch_loss=5.414486\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=5.39574737549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [155]#011Speed: 1672.19 samples/sec#011loss=5.395747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[160] avg_epoch_loss=5.408528\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=5.22265558243\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [160]#011Speed: 1072.62 samples/sec#011loss=5.222656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[165] avg_epoch_loss=5.404086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=5.26106176376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [165]#011Speed: 1602.34 samples/sec#011loss=5.261062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch[170] avg_epoch_loss=5.407517\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=5.52139701843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:34 INFO 140669025912640] Epoch[7] Batch [170]#011Speed: 1051.91 samples/sec#011loss=5.521397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[175] avg_epoch_loss=5.411305\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=5.54086065292\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [175]#011Speed: 1713.49 samples/sec#011loss=5.540861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[180] avg_epoch_loss=5.415741\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=5.57190437317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [180]#011Speed: 1030.42 samples/sec#011loss=5.571904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[185] avg_epoch_loss=5.415951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=5.42354259491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [185]#011Speed: 1639.02 samples/sec#011loss=5.423543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[190] avg_epoch_loss=5.415010\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=5.38001642227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [190]#011Speed: 1077.67 samples/sec#011loss=5.380016\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[195] avg_epoch_loss=5.416095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=5.45754365921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [195]#011Speed: 1655.61 samples/sec#011loss=5.457544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[200] avg_epoch_loss=5.414129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=5.33706274033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [200]#011Speed: 1021.26 samples/sec#011loss=5.337063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[205] avg_epoch_loss=5.417686\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=5.5606798172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [205]#011Speed: 1478.07 samples/sec#011loss=5.560680\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch[210] avg_epoch_loss=5.415328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=5.31815862656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:35 INFO 140669025912640] Epoch[7] Batch [210]#011Speed: 965.20 samples/sec#011loss=5.318159\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[215] avg_epoch_loss=5.419832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=5.60988531113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [215]#011Speed: 1496.13 samples/sec#011loss=5.609885\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[220] avg_epoch_loss=5.419183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=5.39116783142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [220]#011Speed: 1040.18 samples/sec#011loss=5.391168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[225] avg_epoch_loss=5.418216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=5.37545156479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [225]#011Speed: 1569.54 samples/sec#011loss=5.375452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[230] avg_epoch_loss=5.420592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=5.52798757553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [230]#011Speed: 1071.91 samples/sec#011loss=5.527988\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[235] avg_epoch_loss=5.418743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=5.3333322525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [235]#011Speed: 1658.20 samples/sec#011loss=5.333332\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[240] avg_epoch_loss=5.421212\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=5.53774175644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [240]#011Speed: 1064.55 samples/sec#011loss=5.537742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch[245] avg_epoch_loss=5.418369\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=5.28135433197\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:36 INFO 140669025912640] Epoch[7] Batch [245]#011Speed: 1632.57 samples/sec#011loss=5.281354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[250] avg_epoch_loss=5.417896\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=5.39461650848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [250]#011Speed: 1040.04 samples/sec#011loss=5.394617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[255] avg_epoch_loss=5.418156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=5.43122968674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [255]#011Speed: 1592.07 samples/sec#011loss=5.431230\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[260] avg_epoch_loss=5.419306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=5.47816228867\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [260]#011Speed: 1069.92 samples/sec#011loss=5.478162\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[265] avg_epoch_loss=5.422476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=5.58795814514\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [265]#011Speed: 1660.16 samples/sec#011loss=5.587958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[270] avg_epoch_loss=5.425568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=270 train loss <loss>=5.5900431633\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [270]#011Speed: 1612.41 samples/sec#011loss=5.590043\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[275] avg_epoch_loss=5.427414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=275 train loss <loss>=5.52749557495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [275]#011Speed: 1048.21 samples/sec#011loss=5.527496\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[280] avg_epoch_loss=5.428189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=280 train loss <loss>=5.47095375061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [280]#011Speed: 1638.35 samples/sec#011loss=5.470954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[285] avg_epoch_loss=5.430866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=285 train loss <loss>=5.58134498596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [285]#011Speed: 1040.32 samples/sec#011loss=5.581345\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch[290] avg_epoch_loss=5.426468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=290 train loss <loss>=5.17485971451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:37 INFO 140669025912640] Epoch[7] Batch [290]#011Speed: 1579.12 samples/sec#011loss=5.174860\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[295] avg_epoch_loss=5.427886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=295 train loss <loss>=5.51040391922\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [295]#011Speed: 1045.52 samples/sec#011loss=5.510404\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[300] avg_epoch_loss=5.427206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=300 train loss <loss>=5.38698816299\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [300]#011Speed: 1495.53 samples/sec#011loss=5.386988\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[305] avg_epoch_loss=5.425544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=305 train loss <loss>=5.32550401688\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [305]#011Speed: 1094.97 samples/sec#011loss=5.325504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[310] avg_epoch_loss=5.430444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=310 train loss <loss>=5.7302986145\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [310]#011Speed: 1568.09 samples/sec#011loss=5.730299\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[315] avg_epoch_loss=5.429206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=315 train loss <loss>=5.35218257904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [315]#011Speed: 1096.81 samples/sec#011loss=5.352183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[320] avg_epoch_loss=5.430024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=320 train loss <loss>=5.48174877167\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [320]#011Speed: 1684.99 samples/sec#011loss=5.481749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[325] avg_epoch_loss=5.426909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=325 train loss <loss>=5.22693958282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [325]#011Speed: 1059.48 samples/sec#011loss=5.226940\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch[330] avg_epoch_loss=5.420475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=330 train loss <loss>=5.00092611313\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:38 INFO 140669025912640] Epoch[7] Batch [330]#011Speed: 1634.00 samples/sec#011loss=5.000926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[335] avg_epoch_loss=5.423141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=335 train loss <loss>=5.59968204498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [335]#011Speed: 1016.42 samples/sec#011loss=5.599682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[340] avg_epoch_loss=5.425419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=340 train loss <loss>=5.57847394943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [340]#011Speed: 1663.52 samples/sec#011loss=5.578474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[345] avg_epoch_loss=5.423282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=345 train loss <loss>=5.27757940292\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [345]#011Speed: 1069.55 samples/sec#011loss=5.277579\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[350] avg_epoch_loss=5.422542\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=350 train loss <loss>=5.37130374908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [350]#011Speed: 1662.68 samples/sec#011loss=5.371304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[355] avg_epoch_loss=5.426245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=355 train loss <loss>=5.68617515564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [355]#011Speed: 1068.96 samples/sec#011loss=5.686175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[360] avg_epoch_loss=5.422372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=360 train loss <loss>=5.14664964676\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [360]#011Speed: 1685.20 samples/sec#011loss=5.146650\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[365] avg_epoch_loss=5.421174\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=365 train loss <loss>=5.33465242386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [365]#011Speed: 1034.95 samples/sec#011loss=5.334652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch[370] avg_epoch_loss=5.420981\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=370 train loss <loss>=5.40687026978\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:39 INFO 140669025912640] Epoch[7] Batch [370]#011Speed: 1509.79 samples/sec#011loss=5.406870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[375] avg_epoch_loss=5.422398\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=375 train loss <loss>=5.52753219604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [375]#011Speed: 1039.68 samples/sec#011loss=5.527532\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[380] avg_epoch_loss=5.421781\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=380 train loss <loss>=5.37540960312\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [380]#011Speed: 1656.35 samples/sec#011loss=5.375410\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[385] avg_epoch_loss=5.423225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=385 train loss <loss>=5.53321180344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [385]#011Speed: 1073.03 samples/sec#011loss=5.533212\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[390] avg_epoch_loss=5.424930\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=390 train loss <loss>=5.55659093857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [390]#011Speed: 1654.69 samples/sec#011loss=5.556591\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[395] avg_epoch_loss=5.425269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=395 train loss <loss>=5.45177221298\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [395]#011Speed: 1100.56 samples/sec#011loss=5.451772\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[400] avg_epoch_loss=5.424265\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=400 train loss <loss>=5.34477443695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [400]#011Speed: 1585.84 samples/sec#011loss=5.344774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[405] avg_epoch_loss=5.423712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=405 train loss <loss>=5.3793466568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [405]#011Speed: 1011.88 samples/sec#011loss=5.379347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch[410] avg_epoch_loss=5.422747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=410 train loss <loss>=5.34440574646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:40 INFO 140669025912640] Epoch[7] Batch [410]#011Speed: 1570.72 samples/sec#011loss=5.344406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[415] avg_epoch_loss=5.419634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=415 train loss <loss>=5.16374425888\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [415]#011Speed: 1040.98 samples/sec#011loss=5.163744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[420] avg_epoch_loss=5.419213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=420 train loss <loss>=5.38411598206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [420]#011Speed: 1654.93 samples/sec#011loss=5.384116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[425] avg_epoch_loss=5.416399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=425 train loss <loss>=5.17946910858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [425]#011Speed: 1690.76 samples/sec#011loss=5.179469\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[430] avg_epoch_loss=5.418482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=430 train loss <loss>=5.5960146904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [430]#011Speed: 1027.08 samples/sec#011loss=5.596015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[435] avg_epoch_loss=5.417782\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=435 train loss <loss>=5.35738382339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [435]#011Speed: 1655.37 samples/sec#011loss=5.357384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[440] avg_epoch_loss=5.419580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=440 train loss <loss>=5.5763833046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [440]#011Speed: 1008.67 samples/sec#011loss=5.576383\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[445] avg_epoch_loss=5.418540\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=445 train loss <loss>=5.32682008743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [445]#011Speed: 1691.03 samples/sec#011loss=5.326820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch[450] avg_epoch_loss=5.417345\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=450 train loss <loss>=5.31077060699\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:41 INFO 140669025912640] Epoch[7] Batch [450]#011Speed: 960.40 samples/sec#011loss=5.310771\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[455] avg_epoch_loss=5.418297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=455 train loss <loss>=5.50415773392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [455]#011Speed: 1656.31 samples/sec#011loss=5.504158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[460] avg_epoch_loss=5.418694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=460 train loss <loss>=5.45485048294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [460]#011Speed: 1056.59 samples/sec#011loss=5.454850\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[465] avg_epoch_loss=5.417967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=465 train loss <loss>=5.35100517273\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [465]#011Speed: 1667.12 samples/sec#011loss=5.351005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[470] avg_epoch_loss=5.418898\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=470 train loss <loss>=5.50564632416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [470]#011Speed: 1077.38 samples/sec#011loss=5.505646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[475] avg_epoch_loss=5.417061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=475 train loss <loss>=5.24399709702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [475]#011Speed: 1615.23 samples/sec#011loss=5.243997\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[480] avg_epoch_loss=5.419695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=480 train loss <loss>=5.67045516968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [480]#011Speed: 1001.59 samples/sec#011loss=5.670455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[485] avg_epoch_loss=5.420774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=485 train loss <loss>=5.52455883026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [485]#011Speed: 1675.90 samples/sec#011loss=5.524559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch[490] avg_epoch_loss=5.420523\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=490 train loss <loss>=5.39616994858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:42 INFO 140669025912640] Epoch[7] Batch [490]#011Speed: 1023.93 samples/sec#011loss=5.396170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[495] avg_epoch_loss=5.421719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=495 train loss <loss>=5.53916339874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [495]#011Speed: 1638.55 samples/sec#011loss=5.539163\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[500] avg_epoch_loss=5.420974\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=500 train loss <loss>=5.34709100723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [500]#011Speed: 1668.39 samples/sec#011loss=5.347091\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[505] avg_epoch_loss=5.418425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=505 train loss <loss>=5.16294603348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [505]#011Speed: 1061.30 samples/sec#011loss=5.162946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[510] avg_epoch_loss=5.417918\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=510 train loss <loss>=5.36668395996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [510]#011Speed: 1701.08 samples/sec#011loss=5.366684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[515] avg_epoch_loss=5.417733\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=515 train loss <loss>=5.3988155365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [515]#011Speed: 1046.71 samples/sec#011loss=5.398816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[520] avg_epoch_loss=5.414754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=520 train loss <loss>=5.10731964111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [520]#011Speed: 1675.29 samples/sec#011loss=5.107320\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[525] avg_epoch_loss=5.413938\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=525 train loss <loss>=5.32887029648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [525]#011Speed: 1066.74 samples/sec#011loss=5.328870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch[530] avg_epoch_loss=5.416359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=530 train loss <loss>=5.67102003098\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:43 INFO 140669025912640] Epoch[7] Batch [530]#011Speed: 1606.15 samples/sec#011loss=5.671020\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[535] avg_epoch_loss=5.417169\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=535 train loss <loss>=5.50323162079\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [535]#011Speed: 1068.90 samples/sec#011loss=5.503232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[540] avg_epoch_loss=5.415372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=540 train loss <loss>=5.22275772095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [540]#011Speed: 1078.00 samples/sec#011loss=5.222758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[545] avg_epoch_loss=5.416644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=545 train loss <loss>=5.55419216156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [545]#011Speed: 1694.70 samples/sec#011loss=5.554192\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[550] avg_epoch_loss=5.417627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=550 train loss <loss>=5.52504234314\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [550]#011Speed: 1020.21 samples/sec#011loss=5.525042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[555] avg_epoch_loss=5.418167\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=555 train loss <loss>=5.47762203217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [555]#011Speed: 1639.70 samples/sec#011loss=5.477622\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[560] avg_epoch_loss=5.417950\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=560 train loss <loss>=5.39386825562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [560]#011Speed: 1077.33 samples/sec#011loss=5.393868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[565] avg_epoch_loss=5.417785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=565 train loss <loss>=5.39924230576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [565]#011Speed: 1641.50 samples/sec#011loss=5.399242\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch[570] avg_epoch_loss=5.418081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=570 train loss <loss>=5.4516412735\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:44 INFO 140669025912640] Epoch[7] Batch [570]#011Speed: 1134.25 samples/sec#011loss=5.451641\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[7] Batch[575] avg_epoch_loss=5.418816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, batch=575 train loss <loss>=5.50274991989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[7] Batch [575]#011Speed: 1614.42 samples/sec#011loss=5.502750\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] processed a total of 18466 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14449.885845184326, \"sum\": 14449.885845184326, \"min\": 14449.885845184326}}, \"EndTime\": 1589393805.105253, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393790.655307}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1277.92547369 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=7, train loss <loss>=5.41396344038\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_7dad1d2a-4c2b-4e2e-9f7a-e9b98a17ae22-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.013103485107422, \"sum\": 10.013103485107422, \"min\": 10.013103485107422}}, \"EndTime\": 1589393805.115764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393805.105318}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[0] avg_epoch_loss=5.745610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=5.74561023712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[5] avg_epoch_loss=5.259614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=5.25961359342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch [5]#011Speed: 1680.20 samples/sec#011loss=5.259614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[10] avg_epoch_loss=5.350169\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=5.4588353157\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch [10]#011Speed: 1694.27 samples/sec#011loss=5.458835\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[15] avg_epoch_loss=5.382605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=5.45396299362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch [15]#011Speed: 1065.23 samples/sec#011loss=5.453963\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[20] avg_epoch_loss=5.362598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=5.29857788086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch [20]#011Speed: 1689.65 samples/sec#011loss=5.298578\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[25] avg_epoch_loss=5.359958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=5.34886703491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch [25]#011Speed: 1013.89 samples/sec#011loss=5.348867\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch[30] avg_epoch_loss=5.312153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=5.06357116699\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:45 INFO 140669025912640] Epoch[8] Batch [30]#011Speed: 1459.51 samples/sec#011loss=5.063571\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[35] avg_epoch_loss=5.346567\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=5.55992832184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [35]#011Speed: 1025.21 samples/sec#011loss=5.559928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[40] avg_epoch_loss=5.349706\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=5.37231006622\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [40]#011Speed: 1639.51 samples/sec#011loss=5.372310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[45] avg_epoch_loss=5.327151\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=5.14219579697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [45]#011Speed: 1027.10 samples/sec#011loss=5.142196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[50] avg_epoch_loss=5.311680\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=5.16934614182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [50]#011Speed: 1527.61 samples/sec#011loss=5.169346\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[55] avg_epoch_loss=5.323385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=5.44278030396\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [55]#011Speed: 1081.26 samples/sec#011loss=5.442780\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[60] avg_epoch_loss=5.327307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=5.37123184204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [60]#011Speed: 1572.28 samples/sec#011loss=5.371232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[65] avg_epoch_loss=5.337467\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=5.46142454147\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [65]#011Speed: 997.60 samples/sec#011loss=5.461425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch[70] avg_epoch_loss=5.345993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=5.45852737427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:46 INFO 140669025912640] Epoch[8] Batch [70]#011Speed: 1521.69 samples/sec#011loss=5.458527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[75] avg_epoch_loss=5.362967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=5.60400190353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [75]#011Speed: 1037.29 samples/sec#011loss=5.604002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[80] avg_epoch_loss=5.357759\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=5.2785984993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [80]#011Speed: 1641.65 samples/sec#011loss=5.278598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[85] avg_epoch_loss=5.347047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=5.17351770401\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [85]#011Speed: 1081.17 samples/sec#011loss=5.173518\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[90] avg_epoch_loss=5.344637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=5.30318250656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [90]#011Speed: 1564.61 samples/sec#011loss=5.303183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[95] avg_epoch_loss=5.348468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=5.41818323135\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [95]#011Speed: 971.14 samples/sec#011loss=5.418183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[100] avg_epoch_loss=5.343723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=5.25262651443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [100]#011Speed: 1614.95 samples/sec#011loss=5.252627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[105] avg_epoch_loss=5.356738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=5.61963214874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [105]#011Speed: 1089.63 samples/sec#011loss=5.619632\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch[110] avg_epoch_loss=5.355935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=5.33891639709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:47 INFO 140669025912640] Epoch[8] Batch [110]#011Speed: 1632.77 samples/sec#011loss=5.338916\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[115] avg_epoch_loss=5.356602\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=5.37140741348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [115]#011Speed: 1098.03 samples/sec#011loss=5.371407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[120] avg_epoch_loss=5.360309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=5.44631137848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [120]#011Speed: 1635.05 samples/sec#011loss=5.446311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[125] avg_epoch_loss=5.361574\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=5.3921872139\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [125]#011Speed: 1096.19 samples/sec#011loss=5.392187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[130] avg_epoch_loss=5.356470\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=5.22785816193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [130]#011Speed: 1679.21 samples/sec#011loss=5.227858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[135] avg_epoch_loss=5.362170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=5.51151304245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [135]#011Speed: 1111.28 samples/sec#011loss=5.511513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[140] avg_epoch_loss=5.359177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=5.27776250839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [140]#011Speed: 1643.52 samples/sec#011loss=5.277763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[145] avg_epoch_loss=5.362041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=5.44280900955\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [145]#011Speed: 1093.79 samples/sec#011loss=5.442809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch[150] avg_epoch_loss=5.359095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=5.27305908203\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:48 INFO 140669025912640] Epoch[8] Batch [150]#011Speed: 1650.32 samples/sec#011loss=5.273059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[155] avg_epoch_loss=5.358829\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=5.35079250336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [155]#011Speed: 1587.62 samples/sec#011loss=5.350793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[160] avg_epoch_loss=5.363478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=5.50853748322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [160]#011Speed: 1089.84 samples/sec#011loss=5.508537\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[165] avg_epoch_loss=5.364407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=5.39432649612\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [165]#011Speed: 1638.07 samples/sec#011loss=5.394326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[170] avg_epoch_loss=5.365739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=5.40995340347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [170]#011Speed: 1117.79 samples/sec#011loss=5.409953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[175] avg_epoch_loss=5.366723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=5.40039482117\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [175]#011Speed: 1647.90 samples/sec#011loss=5.400395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[180] avg_epoch_loss=5.371223\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=5.52961978912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [180]#011Speed: 1113.94 samples/sec#011loss=5.529620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[185] avg_epoch_loss=5.369391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=5.30304698944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [185]#011Speed: 1659.58 samples/sec#011loss=5.303047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[190] avg_epoch_loss=5.369506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=5.37379789352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [190]#011Speed: 1077.69 samples/sec#011loss=5.373798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch[195] avg_epoch_loss=5.373491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=5.52572393417\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:49 INFO 140669025912640] Epoch[8] Batch [195]#011Speed: 1494.78 samples/sec#011loss=5.525724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[200] avg_epoch_loss=5.383723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=5.78480291367\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [200]#011Speed: 1056.47 samples/sec#011loss=5.784803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[205] avg_epoch_loss=5.387926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=5.55687904358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [205]#011Speed: 1667.10 samples/sec#011loss=5.556879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[210] avg_epoch_loss=5.389158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=5.43994636536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [210]#011Speed: 1015.84 samples/sec#011loss=5.439946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[215] avg_epoch_loss=5.386769\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=5.28594551086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [215]#011Speed: 1661.09 samples/sec#011loss=5.285946\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[220] avg_epoch_loss=5.391924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=5.61462631226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [220]#011Speed: 1076.89 samples/sec#011loss=5.614626\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[225] avg_epoch_loss=5.389052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=5.26209573746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [225]#011Speed: 1655.15 samples/sec#011loss=5.262096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[230] avg_epoch_loss=5.389046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=5.38875513077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [230]#011Speed: 1067.22 samples/sec#011loss=5.388755\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch[235] avg_epoch_loss=5.386923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=5.28885478973\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:50 INFO 140669025912640] Epoch[8] Batch [235]#011Speed: 1548.45 samples/sec#011loss=5.288855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[240] avg_epoch_loss=5.388139\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=5.44552059174\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [240]#011Speed: 1098.54 samples/sec#011loss=5.445521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[245] avg_epoch_loss=5.388139\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=5.38815441132\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [245]#011Speed: 1655.66 samples/sec#011loss=5.388154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[250] avg_epoch_loss=5.391666\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=5.56520795822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [250]#011Speed: 964.55 samples/sec#011loss=5.565208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[255] avg_epoch_loss=5.392444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=5.43148298264\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [255]#011Speed: 1404.61 samples/sec#011loss=5.431483\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[260] avg_epoch_loss=5.394490\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=5.49926128387\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [260]#011Speed: 1015.69 samples/sec#011loss=5.499261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[265] avg_epoch_loss=5.394039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=265 train loss <loss>=5.37050867081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [265]#011Speed: 1650.79 samples/sec#011loss=5.370509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch[270] avg_epoch_loss=5.396431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=270 train loss <loss>=5.5236579895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:51 INFO 140669025912640] Epoch[8] Batch [270]#011Speed: 1036.76 samples/sec#011loss=5.523658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[275] avg_epoch_loss=5.397598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=275 train loss <loss>=5.46088228226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [275]#011Speed: 1627.87 samples/sec#011loss=5.460882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[280] avg_epoch_loss=5.398705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=280 train loss <loss>=5.45979862213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [280]#011Speed: 1062.67 samples/sec#011loss=5.459799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[285] avg_epoch_loss=5.398955\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=285 train loss <loss>=5.41300535202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [285]#011Speed: 1677.04 samples/sec#011loss=5.413005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[290] avg_epoch_loss=5.398796\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=290 train loss <loss>=5.38969554901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [290]#011Speed: 1037.10 samples/sec#011loss=5.389696\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[295] avg_epoch_loss=5.391846\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=295 train loss <loss>=4.98736658096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [295]#011Speed: 1659.80 samples/sec#011loss=4.987367\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[300] avg_epoch_loss=5.394616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=300 train loss <loss>=5.55856084824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [300]#011Speed: 999.65 samples/sec#011loss=5.558561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[305] avg_epoch_loss=5.395204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=305 train loss <loss>=5.43061943054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [305]#011Speed: 1640.57 samples/sec#011loss=5.430619\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch[310] avg_epoch_loss=5.395210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=310 train loss <loss>=5.39559822083\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:52 INFO 140669025912640] Epoch[8] Batch [310]#011Speed: 996.50 samples/sec#011loss=5.395598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[315] avg_epoch_loss=5.395392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=315 train loss <loss>=5.40669612885\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [315]#011Speed: 1559.10 samples/sec#011loss=5.406696\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[320] avg_epoch_loss=5.396492\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=320 train loss <loss>=5.46603307724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [320]#011Speed: 1072.38 samples/sec#011loss=5.466033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[325] avg_epoch_loss=5.393856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=325 train loss <loss>=5.22462825775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [325]#011Speed: 1687.37 samples/sec#011loss=5.224628\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[330] avg_epoch_loss=5.393606\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=330 train loss <loss>=5.37728872299\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [330]#011Speed: 1072.24 samples/sec#011loss=5.377289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[335] avg_epoch_loss=5.392529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=335 train loss <loss>=5.32125349045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [335]#011Speed: 1590.62 samples/sec#011loss=5.321253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[340] avg_epoch_loss=5.395531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=340 train loss <loss>=5.59722232819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [340]#011Speed: 1565.39 samples/sec#011loss=5.597222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[345] avg_epoch_loss=5.397855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=345 train loss <loss>=5.55636472702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [345]#011Speed: 1106.01 samples/sec#011loss=5.556365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch[350] avg_epoch_loss=5.394621\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=350 train loss <loss>=5.17080097198\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:53 INFO 140669025912640] Epoch[8] Batch [350]#011Speed: 1608.54 samples/sec#011loss=5.170801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[355] avg_epoch_loss=5.395412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=355 train loss <loss>=5.45097579956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [355]#011Speed: 1102.03 samples/sec#011loss=5.450976\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[360] avg_epoch_loss=5.397012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=360 train loss <loss>=5.51092405319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [360]#011Speed: 1521.48 samples/sec#011loss=5.510924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[365] avg_epoch_loss=5.399239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=365 train loss <loss>=5.56003570557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [365]#011Speed: 1093.37 samples/sec#011loss=5.560036\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[370] avg_epoch_loss=5.399682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=370 train loss <loss>=5.43208665848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [370]#011Speed: 1461.66 samples/sec#011loss=5.432087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[375] avg_epoch_loss=5.399046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=375 train loss <loss>=5.35189170837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [375]#011Speed: 1039.91 samples/sec#011loss=5.351892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[380] avg_epoch_loss=5.397528\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=380 train loss <loss>=5.28332633972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [380]#011Speed: 1665.99 samples/sec#011loss=5.283326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[385] avg_epoch_loss=5.398142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=385 train loss <loss>=5.44497909546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [385]#011Speed: 1084.66 samples/sec#011loss=5.444979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch[390] avg_epoch_loss=5.395973\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=390 train loss <loss>=5.22849063873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:54 INFO 140669025912640] Epoch[8] Batch [390]#011Speed: 1644.06 samples/sec#011loss=5.228491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[395] avg_epoch_loss=5.395534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=395 train loss <loss>=5.36122236252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [395]#011Speed: 1089.19 samples/sec#011loss=5.361222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[400] avg_epoch_loss=5.393450\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=400 train loss <loss>=5.22842512131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [400]#011Speed: 1589.51 samples/sec#011loss=5.228425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[405] avg_epoch_loss=5.391374\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=405 train loss <loss>=5.22485609055\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [405]#011Speed: 1097.91 samples/sec#011loss=5.224856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[410] avg_epoch_loss=5.389568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=410 train loss <loss>=5.24287595749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [410]#011Speed: 1642.66 samples/sec#011loss=5.242876\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[415] avg_epoch_loss=5.387547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=415 train loss <loss>=5.22144870758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [415]#011Speed: 1091.16 samples/sec#011loss=5.221449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[420] avg_epoch_loss=5.386297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=420 train loss <loss>=5.28232898712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [420]#011Speed: 1650.70 samples/sec#011loss=5.282329\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[425] avg_epoch_loss=5.383045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=425 train loss <loss>=5.10919408798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [425]#011Speed: 1089.24 samples/sec#011loss=5.109194\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch[430] avg_epoch_loss=5.382222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=430 train loss <loss>=5.31208620071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:55 INFO 140669025912640] Epoch[8] Batch [430]#011Speed: 1688.26 samples/sec#011loss=5.312086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[435] avg_epoch_loss=5.384755\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=435 train loss <loss>=5.60308799744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [435]#011Speed: 1029.42 samples/sec#011loss=5.603088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[440] avg_epoch_loss=5.384541\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=440 train loss <loss>=5.36587362289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [440]#011Speed: 1642.94 samples/sec#011loss=5.365874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[445] avg_epoch_loss=5.385227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=445 train loss <loss>=5.44572782516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [445]#011Speed: 1663.88 samples/sec#011loss=5.445728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[450] avg_epoch_loss=5.384836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=450 train loss <loss>=5.35000934601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [450]#011Speed: 1100.55 samples/sec#011loss=5.350009\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[455] avg_epoch_loss=5.384044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=455 train loss <loss>=5.31264152527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [455]#011Speed: 1638.67 samples/sec#011loss=5.312642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[460] avg_epoch_loss=5.382728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=460 train loss <loss>=5.26266212463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [460]#011Speed: 1094.61 samples/sec#011loss=5.262662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[465] avg_epoch_loss=5.381998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=465 train loss <loss>=5.31470155716\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [465]#011Speed: 1667.22 samples/sec#011loss=5.314702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[470] avg_epoch_loss=5.383188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=470 train loss <loss>=5.49409427643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [470]#011Speed: 1056.16 samples/sec#011loss=5.494094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch[475] avg_epoch_loss=5.385352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=475 train loss <loss>=5.58919305801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:56 INFO 140669025912640] Epoch[8] Batch [475]#011Speed: 1655.46 samples/sec#011loss=5.589193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[480] avg_epoch_loss=5.387437\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=480 train loss <loss>=5.58594408035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [480]#011Speed: 1059.37 samples/sec#011loss=5.585944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[485] avg_epoch_loss=5.386779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=485 train loss <loss>=5.32343091965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [485]#011Speed: 1653.15 samples/sec#011loss=5.323431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[490] avg_epoch_loss=5.387397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=490 train loss <loss>=5.44749927521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [490]#011Speed: 1109.97 samples/sec#011loss=5.447499\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[495] avg_epoch_loss=5.386963\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=495 train loss <loss>=5.34433336258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [495]#011Speed: 1460.44 samples/sec#011loss=5.344333\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[500] avg_epoch_loss=5.387544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=500 train loss <loss>=5.44521560669\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [500]#011Speed: 1083.07 samples/sec#011loss=5.445216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[505] avg_epoch_loss=5.385806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=505 train loss <loss>=5.2116528511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [505]#011Speed: 1556.92 samples/sec#011loss=5.211653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[510] avg_epoch_loss=5.383257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=510 train loss <loss>=5.12528152466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [510]#011Speed: 1017.62 samples/sec#011loss=5.125282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch[515] avg_epoch_loss=5.380238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=515 train loss <loss>=5.07171449661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:57 INFO 140669025912640] Epoch[8] Batch [515]#011Speed: 1657.46 samples/sec#011loss=5.071714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[520] avg_epoch_loss=5.380734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=520 train loss <loss>=5.43191041946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [520]#011Speed: 1033.72 samples/sec#011loss=5.431910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[525] avg_epoch_loss=5.379580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=525 train loss <loss>=5.25928411484\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [525]#011Speed: 1692.59 samples/sec#011loss=5.259284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[530] avg_epoch_loss=5.379741\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=530 train loss <loss>=5.39666929245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [530]#011Speed: 1676.73 samples/sec#011loss=5.396669\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[535] avg_epoch_loss=5.380622\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=535 train loss <loss>=5.47426023483\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [535]#011Speed: 1075.25 samples/sec#011loss=5.474260\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[540] avg_epoch_loss=5.381809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=540 train loss <loss>=5.50907964706\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [540]#011Speed: 1656.32 samples/sec#011loss=5.509080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[545] avg_epoch_loss=5.381905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=545 train loss <loss>=5.39226121902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [545]#011Speed: 1094.86 samples/sec#011loss=5.392261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[550] avg_epoch_loss=5.382239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=550 train loss <loss>=5.41867294312\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [550]#011Speed: 1562.90 samples/sec#011loss=5.418673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch[555] avg_epoch_loss=5.382289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=555 train loss <loss>=5.38784675598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:58 INFO 140669025912640] Epoch[8] Batch [555]#011Speed: 1023.56 samples/sec#011loss=5.387847\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch[560] avg_epoch_loss=5.381731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=560 train loss <loss>=5.31964244843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch [560]#011Speed: 1603.59 samples/sec#011loss=5.319642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch[565] avg_epoch_loss=5.380694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=565 train loss <loss>=5.26439285278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch [565]#011Speed: 1019.19 samples/sec#011loss=5.264393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch[570] avg_epoch_loss=5.379064\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=570 train loss <loss>=5.1945192337\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch [570]#011Speed: 1671.68 samples/sec#011loss=5.194519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch[575] avg_epoch_loss=5.375613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, batch=575 train loss <loss>=4.98150572777\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[8] Batch [575]#011Speed: 1364.49 samples/sec#011loss=4.981506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] processed a total of 18411 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14293.411016464233, \"sum\": 14293.411016464233, \"min\": 14293.411016464233}}, \"EndTime\": 1589393819.409295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393805.115828}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1288.06817963 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=8, train loss <loss>=5.37561306647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_b086d438-545d-405d-8e67-b09ae695b740-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.80687141418457, \"sum\": 9.80687141418457, \"min\": 9.80687141418457}}, \"EndTime\": 1589393819.419492, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393819.409354}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch[0] avg_epoch_loss=5.063944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=5.06394433975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch[5] avg_epoch_loss=5.273336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=5.27333577474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch [5]#011Speed: 1662.75 samples/sec#011loss=5.273336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch[10] avg_epoch_loss=5.248231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=5.21810512543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch [10]#011Speed: 1080.27 samples/sec#011loss=5.218105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch[15] avg_epoch_loss=5.243415\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=5.23281965256\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch [15]#011Speed: 1633.52 samples/sec#011loss=5.232820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch[20] avg_epoch_loss=5.219471\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=5.14285116196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:16:59 INFO 140669025912640] Epoch[9] Batch [20]#011Speed: 1639.60 samples/sec#011loss=5.142851\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[25] avg_epoch_loss=5.226152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=5.25421276093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [25]#011Speed: 1032.84 samples/sec#011loss=5.254213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[30] avg_epoch_loss=5.245474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=5.34594564438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [30]#011Speed: 1589.67 samples/sec#011loss=5.345946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[35] avg_epoch_loss=5.269316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=5.41714010239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [35]#011Speed: 1106.25 samples/sec#011loss=5.417140\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[40] avg_epoch_loss=5.272462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=5.29510717392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [40]#011Speed: 1682.05 samples/sec#011loss=5.295107\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[45] avg_epoch_loss=5.312605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=5.64178352356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [45]#011Speed: 1114.54 samples/sec#011loss=5.641784\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[50] avg_epoch_loss=5.288174\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=5.06340904236\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [50]#011Speed: 1653.56 samples/sec#011loss=5.063409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[55] avg_epoch_loss=5.303615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=5.46111288071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [55]#011Speed: 1101.65 samples/sec#011loss=5.461113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch[60] avg_epoch_loss=5.322691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=5.53633432388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:00 INFO 140669025912640] Epoch[9] Batch [60]#011Speed: 1642.63 samples/sec#011loss=5.536334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[65] avg_epoch_loss=5.318183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=5.26319608688\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [65]#011Speed: 977.68 samples/sec#011loss=5.263196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[70] avg_epoch_loss=5.337154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=5.58756752014\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [70]#011Speed: 1589.64 samples/sec#011loss=5.587568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[75] avg_epoch_loss=5.319427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=5.06769781113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [75]#011Speed: 1047.53 samples/sec#011loss=5.067698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[80] avg_epoch_loss=5.311902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=5.19752607346\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [80]#011Speed: 1641.92 samples/sec#011loss=5.197526\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[85] avg_epoch_loss=5.312745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=5.32639389038\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [85]#011Speed: 1089.79 samples/sec#011loss=5.326394\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[90] avg_epoch_loss=5.299232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=5.06681556702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [90]#011Speed: 1644.01 samples/sec#011loss=5.066816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[95] avg_epoch_loss=5.296975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=5.25589065552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [95]#011Speed: 1102.50 samples/sec#011loss=5.255891\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch[100] avg_epoch_loss=5.291610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=5.18861589432\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:01 INFO 140669025912640] Epoch[9] Batch [100]#011Speed: 1655.12 samples/sec#011loss=5.188616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[105] avg_epoch_loss=5.276227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=4.96549215317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [105]#011Speed: 1027.23 samples/sec#011loss=4.965492\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[110] avg_epoch_loss=5.283087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=5.42850847244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [110]#011Speed: 1589.26 samples/sec#011loss=5.428508\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[115] avg_epoch_loss=5.278160\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=5.16877346039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [115]#011Speed: 1035.40 samples/sec#011loss=5.168773\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[120] avg_epoch_loss=5.283903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=5.41714229584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [120]#011Speed: 1623.69 samples/sec#011loss=5.417142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[125] avg_epoch_loss=5.274673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=5.05131034851\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [125]#011Speed: 1036.01 samples/sec#011loss=5.051310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[130] avg_epoch_loss=5.275488\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=5.29603900909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [130]#011Speed: 1597.54 samples/sec#011loss=5.296039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[135] avg_epoch_loss=5.278847\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=5.36683254242\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [135]#011Speed: 1071.17 samples/sec#011loss=5.366833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch[140] avg_epoch_loss=5.279426\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=5.29518146515\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:02 INFO 140669025912640] Epoch[9] Batch [140]#011Speed: 1644.52 samples/sec#011loss=5.295181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[145] avg_epoch_loss=5.278079\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=5.24009904861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [145]#011Speed: 1080.53 samples/sec#011loss=5.240099\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[150] avg_epoch_loss=5.277993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=5.27547445297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [150]#011Speed: 1441.61 samples/sec#011loss=5.275474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[155] avg_epoch_loss=5.282906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=5.43129434586\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [155]#011Speed: 1119.26 samples/sec#011loss=5.431294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[160] avg_epoch_loss=5.292289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=5.58504037857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [160]#011Speed: 1662.87 samples/sec#011loss=5.585040\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[165] avg_epoch_loss=5.293916\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=5.34629802704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [165]#011Speed: 1126.39 samples/sec#011loss=5.346298\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[170] avg_epoch_loss=5.296271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=5.37446308136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [170]#011Speed: 1679.83 samples/sec#011loss=5.374463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[175] avg_epoch_loss=5.297231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=5.33007144928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [175]#011Speed: 1091.32 samples/sec#011loss=5.330071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch[180] avg_epoch_loss=5.299566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=5.38173599243\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:03 INFO 140669025912640] Epoch[9] Batch [180]#011Speed: 1652.69 samples/sec#011loss=5.381736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[185] avg_epoch_loss=5.302633\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=5.41367874146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [185]#011Speed: 1027.91 samples/sec#011loss=5.413679\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[190] avg_epoch_loss=5.304210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=5.36286830902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [190]#011Speed: 1624.13 samples/sec#011loss=5.362868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[195] avg_epoch_loss=5.305203\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=5.34311752319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [195]#011Speed: 1026.83 samples/sec#011loss=5.343118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[200] avg_epoch_loss=5.306341\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=5.35095815659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [200]#011Speed: 1630.92 samples/sec#011loss=5.350958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[205] avg_epoch_loss=5.307059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=5.33590841293\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [205]#011Speed: 1077.41 samples/sec#011loss=5.335908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[210] avg_epoch_loss=5.318006\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=5.76902112961\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [210]#011Speed: 1651.26 samples/sec#011loss=5.769021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[215] avg_epoch_loss=5.327478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=5.72722072601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [215]#011Speed: 1598.10 samples/sec#011loss=5.727221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[220] avg_epoch_loss=5.327122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=5.31174621582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [220]#011Speed: 1093.76 samples/sec#011loss=5.311746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch[225] avg_epoch_loss=5.325803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=5.26750354767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:04 INFO 140669025912640] Epoch[9] Batch [225]#011Speed: 1676.29 samples/sec#011loss=5.267504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[230] avg_epoch_loss=5.323731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=5.23008308411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [230]#011Speed: 1082.57 samples/sec#011loss=5.230083\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[235] avg_epoch_loss=5.322273\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=5.25490598679\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [235]#011Speed: 1671.77 samples/sec#011loss=5.254906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[240] avg_epoch_loss=5.319725\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=5.19946279526\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [240]#011Speed: 1069.10 samples/sec#011loss=5.199463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[245] avg_epoch_loss=5.321146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=5.38962440491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [245]#011Speed: 1683.80 samples/sec#011loss=5.389624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[250] avg_epoch_loss=5.324434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=5.48622226715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [250]#011Speed: 1032.46 samples/sec#011loss=5.486222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[255] avg_epoch_loss=5.324322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=5.31865959167\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [255]#011Speed: 1668.47 samples/sec#011loss=5.318660\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[260] avg_epoch_loss=5.327701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=5.50071401596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [260]#011Speed: 1041.61 samples/sec#011loss=5.500714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch[265] avg_epoch_loss=5.330316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=5.46685304642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:05 INFO 140669025912640] Epoch[9] Batch [265]#011Speed: 1661.84 samples/sec#011loss=5.466853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[270] avg_epoch_loss=5.326979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=5.14945373535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [270]#011Speed: 954.21 samples/sec#011loss=5.149454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[275] avg_epoch_loss=5.326795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=275 train loss <loss>=5.31677427292\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [275]#011Speed: 1642.39 samples/sec#011loss=5.316774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[280] avg_epoch_loss=5.328067\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=280 train loss <loss>=5.39832773209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [280]#011Speed: 1076.71 samples/sec#011loss=5.398328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[285] avg_epoch_loss=5.327165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=285 train loss <loss>=5.27645139694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [285]#011Speed: 1658.82 samples/sec#011loss=5.276451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[290] avg_epoch_loss=5.328914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=290 train loss <loss>=5.42894191742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [290]#011Speed: 1155.58 samples/sec#011loss=5.428942\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[295] avg_epoch_loss=5.330560\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=295 train loss <loss>=5.42637243271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [295]#011Speed: 1675.97 samples/sec#011loss=5.426372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[300] avg_epoch_loss=5.327939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=300 train loss <loss>=5.17279405594\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [300]#011Speed: 1106.14 samples/sec#011loss=5.172794\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch[305] avg_epoch_loss=5.333879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=305 train loss <loss>=5.69147472382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:06 INFO 140669025912640] Epoch[9] Batch [305]#011Speed: 1645.02 samples/sec#011loss=5.691475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[310] avg_epoch_loss=5.335268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=310 train loss <loss>=5.42026472092\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [310]#011Speed: 1100.52 samples/sec#011loss=5.420265\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[315] avg_epoch_loss=5.337635\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=315 train loss <loss>=5.48485803604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [315]#011Speed: 1655.27 samples/sec#011loss=5.484858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[320] avg_epoch_loss=5.338611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=320 train loss <loss>=5.40026082993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [320]#011Speed: 1110.79 samples/sec#011loss=5.400261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[325] avg_epoch_loss=5.339307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=325 train loss <loss>=5.38399505615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [325]#011Speed: 1526.16 samples/sec#011loss=5.383995\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[330] avg_epoch_loss=5.341935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=330 train loss <loss>=5.51332330704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [330]#011Speed: 1032.54 samples/sec#011loss=5.513323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[335] avg_epoch_loss=5.340100\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=335 train loss <loss>=5.21857223511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [335]#011Speed: 1471.03 samples/sec#011loss=5.218572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[340] avg_epoch_loss=5.341181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=340 train loss <loss>=5.41383113861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [340]#011Speed: 1032.83 samples/sec#011loss=5.413831\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch[345] avg_epoch_loss=5.343700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=345 train loss <loss>=5.5155008316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:07 INFO 140669025912640] Epoch[9] Batch [345]#011Speed: 1628.35 samples/sec#011loss=5.515501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[350] avg_epoch_loss=5.346450\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=350 train loss <loss>=5.53674812317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [350]#011Speed: 1027.62 samples/sec#011loss=5.536748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[355] avg_epoch_loss=5.344254\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=355 train loss <loss>=5.19012784958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [355]#011Speed: 1675.67 samples/sec#011loss=5.190128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[360] avg_epoch_loss=5.342405\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=360 train loss <loss>=5.21075000763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [360]#011Speed: 1682.25 samples/sec#011loss=5.210750\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[365] avg_epoch_loss=5.342910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=365 train loss <loss>=5.37938156128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [365]#011Speed: 1007.12 samples/sec#011loss=5.379382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[370] avg_epoch_loss=5.343171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=370 train loss <loss>=5.36225290298\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [370]#011Speed: 1599.94 samples/sec#011loss=5.362253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[375] avg_epoch_loss=5.341410\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=375 train loss <loss>=5.21074399948\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [375]#011Speed: 1033.33 samples/sec#011loss=5.210744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[380] avg_epoch_loss=5.341876\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=380 train loss <loss>=5.37690830231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [380]#011Speed: 1647.00 samples/sec#011loss=5.376908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch[385] avg_epoch_loss=5.340970\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=385 train loss <loss>=5.27194337845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:08 INFO 140669025912640] Epoch[9] Batch [385]#011Speed: 1060.77 samples/sec#011loss=5.271943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[390] avg_epoch_loss=5.342770\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=390 train loss <loss>=5.48169441223\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [390]#011Speed: 1665.47 samples/sec#011loss=5.481694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[395] avg_epoch_loss=5.339457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=395 train loss <loss>=5.08042802811\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [395]#011Speed: 1031.77 samples/sec#011loss=5.080428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[400] avg_epoch_loss=5.338364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=400 train loss <loss>=5.25179023743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [400]#011Speed: 1685.64 samples/sec#011loss=5.251790\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[405] avg_epoch_loss=5.339435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=405 train loss <loss>=5.42535114288\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [405]#011Speed: 1106.40 samples/sec#011loss=5.425351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[410] avg_epoch_loss=5.340743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=410 train loss <loss>=5.44692487717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [410]#011Speed: 1705.23 samples/sec#011loss=5.446925\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[415] avg_epoch_loss=5.341828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=415 train loss <loss>=5.43097820282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [415]#011Speed: 1065.13 samples/sec#011loss=5.430978\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[420] avg_epoch_loss=5.338847\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=420 train loss <loss>=5.09085464478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [420]#011Speed: 1587.82 samples/sec#011loss=5.090855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch[425] avg_epoch_loss=5.341421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=425 train loss <loss>=5.55815000534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:09 INFO 140669025912640] Epoch[9] Batch [425]#011Speed: 1010.45 samples/sec#011loss=5.558150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[430] avg_epoch_loss=5.338800\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=430 train loss <loss>=5.11550998688\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [430]#011Speed: 1643.40 samples/sec#011loss=5.115510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[435] avg_epoch_loss=5.339150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=435 train loss <loss>=5.36934213638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [435]#011Speed: 1074.40 samples/sec#011loss=5.369342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[440] avg_epoch_loss=5.337631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=440 train loss <loss>=5.20513811111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [440]#011Speed: 1652.93 samples/sec#011loss=5.205138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[445] avg_epoch_loss=5.335615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=445 train loss <loss>=5.15784273148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [445]#011Speed: 1045.52 samples/sec#011loss=5.157843\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[450] avg_epoch_loss=5.336951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=450 train loss <loss>=5.45612239838\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [450]#011Speed: 1669.22 samples/sec#011loss=5.456122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[455] avg_epoch_loss=5.339689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=455 train loss <loss>=5.58666667938\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [455]#011Speed: 1053.25 samples/sec#011loss=5.586667\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[460] avg_epoch_loss=5.340719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=460 train loss <loss>=5.43457279205\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [460]#011Speed: 1652.53 samples/sec#011loss=5.434573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch[465] avg_epoch_loss=5.341887\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=465 train loss <loss>=5.44960050583\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:10 INFO 140669025912640] Epoch[9] Batch [465]#011Speed: 1064.96 samples/sec#011loss=5.449601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[470] avg_epoch_loss=5.341278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=470 train loss <loss>=5.28456382751\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [470]#011Speed: 1505.63 samples/sec#011loss=5.284564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[475] avg_epoch_loss=5.342857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=475 train loss <loss>=5.49160041809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [475]#011Speed: 1663.27 samples/sec#011loss=5.491600\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[480] avg_epoch_loss=5.343408\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=480 train loss <loss>=5.39582252502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [480]#011Speed: 1107.09 samples/sec#011loss=5.395823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[485] avg_epoch_loss=5.344120\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=485 train loss <loss>=5.41263666153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [485]#011Speed: 1654.11 samples/sec#011loss=5.412637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[490] avg_epoch_loss=5.346312\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=490 train loss <loss>=5.55940179825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [490]#011Speed: 1105.43 samples/sec#011loss=5.559402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[495] avg_epoch_loss=5.346148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=495 train loss <loss>=5.32998762131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [495]#011Speed: 1643.47 samples/sec#011loss=5.329988\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[500] avg_epoch_loss=5.344511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=500 train loss <loss>=5.18211364746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [500]#011Speed: 1097.81 samples/sec#011loss=5.182114\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch[505] avg_epoch_loss=5.344454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=505 train loss <loss>=5.33875265121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:11 INFO 140669025912640] Epoch[9] Batch [505]#011Speed: 1617.84 samples/sec#011loss=5.338753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[510] avg_epoch_loss=5.344318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=510 train loss <loss>=5.33055477142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [510]#011Speed: 1096.70 samples/sec#011loss=5.330555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[515] avg_epoch_loss=5.345152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=515 train loss <loss>=5.43038396835\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [515]#011Speed: 1620.11 samples/sec#011loss=5.430384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[520] avg_epoch_loss=5.344573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=520 train loss <loss>=5.28486795425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [520]#011Speed: 1109.72 samples/sec#011loss=5.284868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[525] avg_epoch_loss=5.343582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=525 train loss <loss>=5.24024705887\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [525]#011Speed: 1629.03 samples/sec#011loss=5.240247\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[530] avg_epoch_loss=5.342714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=530 train loss <loss>=5.25149393082\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [530]#011Speed: 1080.29 samples/sec#011loss=5.251494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[535] avg_epoch_loss=5.342837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=535 train loss <loss>=5.35588874817\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [535]#011Speed: 1464.17 samples/sec#011loss=5.355889\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[540] avg_epoch_loss=5.342886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=540 train loss <loss>=5.34810037613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [540]#011Speed: 1049.94 samples/sec#011loss=5.348100\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch[545] avg_epoch_loss=5.344308\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=545 train loss <loss>=5.49815616608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:12 INFO 140669025912640] Epoch[9] Batch [545]#011Speed: 1441.56 samples/sec#011loss=5.498156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch[550] avg_epoch_loss=5.344348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=550 train loss <loss>=5.34868850708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch [550]#011Speed: 1038.56 samples/sec#011loss=5.348689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch[555] avg_epoch_loss=5.345152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=555 train loss <loss>=5.43378410339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch [555]#011Speed: 1617.16 samples/sec#011loss=5.433784\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch[560] avg_epoch_loss=5.345086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=560 train loss <loss>=5.33773021698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch [560]#011Speed: 1096.55 samples/sec#011loss=5.337730\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch[565] avg_epoch_loss=5.346459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=565 train loss <loss>=5.50047750473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch [565]#011Speed: 1548.03 samples/sec#011loss=5.500478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch[570] avg_epoch_loss=5.345950\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, batch=570 train loss <loss>=5.28835916519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[9] Batch [570]#011Speed: 1262.13 samples/sec#011loss=5.288359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] processed a total of 18380 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14205.862998962402, \"sum\": 14205.862998962402, \"min\": 14205.862998962402}}, \"EndTime\": 1589393833.625472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393819.419552}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1293.82332641 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=9, train loss <loss>=5.34624830826\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_96cacb96-a149-452d-8e40-1636093eebe2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.859085083007812, \"sum\": 9.859085083007812, \"min\": 9.859085083007812}}, \"EndTime\": 1589393833.63575, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393833.625537}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[10] Batch[0] avg_epoch_loss=5.025459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=5.02545928955\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[10] Batch[5] avg_epoch_loss=5.234760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=5.23475964864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[10] Batch [5]#011Speed: 1650.08 samples/sec#011loss=5.234760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[10] Batch[10] avg_epoch_loss=5.365756\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=5.52295227051\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:13 INFO 140669025912640] Epoch[10] Batch [10]#011Speed: 1655.32 samples/sec#011loss=5.522952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[15] avg_epoch_loss=5.345983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=5.30248146057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [15]#011Speed: 992.86 samples/sec#011loss=5.302481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[20] avg_epoch_loss=5.371500\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=5.45315322876\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [20]#011Speed: 1617.97 samples/sec#011loss=5.453153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[25] avg_epoch_loss=5.390416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=5.4698638916\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [25]#011Speed: 1035.04 samples/sec#011loss=5.469864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[30] avg_epoch_loss=5.393790\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=5.41133260727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [30]#011Speed: 1636.46 samples/sec#011loss=5.411333\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[35] avg_epoch_loss=5.390158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=5.36763954163\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [35]#011Speed: 1025.17 samples/sec#011loss=5.367640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[40] avg_epoch_loss=5.389986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=5.38875408173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [40]#011Speed: 1689.47 samples/sec#011loss=5.388754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[45] avg_epoch_loss=5.363565\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=5.14690542221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [45]#011Speed: 1037.96 samples/sec#011loss=5.146905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch[50] avg_epoch_loss=5.375770\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=5.48805885315\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:14 INFO 140669025912640] Epoch[10] Batch [50]#011Speed: 1681.34 samples/sec#011loss=5.488059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[55] avg_epoch_loss=5.371280\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=5.32548036575\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [55]#011Speed: 1053.04 samples/sec#011loss=5.325480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[60] avg_epoch_loss=5.367746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=5.32816753387\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [60]#011Speed: 1658.63 samples/sec#011loss=5.328168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[65] avg_epoch_loss=5.373152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=5.43910808563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [65]#011Speed: 1054.38 samples/sec#011loss=5.439108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[70] avg_epoch_loss=5.379905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=5.46903886795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [70]#011Speed: 1656.69 samples/sec#011loss=5.469039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[75] avg_epoch_loss=5.391595\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=5.55759840012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [75]#011Speed: 1079.11 samples/sec#011loss=5.557598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[80] avg_epoch_loss=5.373351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=5.09604597092\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [80]#011Speed: 1659.15 samples/sec#011loss=5.096046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[85] avg_epoch_loss=5.380153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=5.49034175873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [85]#011Speed: 1043.08 samples/sec#011loss=5.490342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch[90] avg_epoch_loss=5.385880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=5.48437662125\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:15 INFO 140669025912640] Epoch[10] Batch [90]#011Speed: 1667.31 samples/sec#011loss=5.484377\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[95] avg_epoch_loss=5.377974\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=5.23408317566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [95]#011Speed: 1066.47 samples/sec#011loss=5.234083\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[100] avg_epoch_loss=5.382797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=5.47540464401\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [100]#011Speed: 1423.41 samples/sec#011loss=5.475405\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[105] avg_epoch_loss=5.372337\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=5.16105422974\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [105]#011Speed: 1067.86 samples/sec#011loss=5.161054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[110] avg_epoch_loss=5.376173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=5.45749731064\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [110]#011Speed: 1651.14 samples/sec#011loss=5.457497\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[115] avg_epoch_loss=5.376627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=5.38670797348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [115]#011Speed: 1121.12 samples/sec#011loss=5.386708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[120] avg_epoch_loss=5.397522\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=5.88226318359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [120]#011Speed: 1651.63 samples/sec#011loss=5.882263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[125] avg_epoch_loss=5.391877\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=5.25527572632\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [125]#011Speed: 1116.67 samples/sec#011loss=5.255276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch[130] avg_epoch_loss=5.402847\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=5.67928991318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:16 INFO 140669025912640] Epoch[10] Batch [130]#011Speed: 1636.71 samples/sec#011loss=5.679290\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[135] avg_epoch_loss=5.400257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=5.332396698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [135]#011Speed: 1047.59 samples/sec#011loss=5.332397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[140] avg_epoch_loss=5.395294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=5.26031064987\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [140]#011Speed: 1568.94 samples/sec#011loss=5.260311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[145] avg_epoch_loss=5.388668\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=5.20182313919\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [145]#011Speed: 1000.54 samples/sec#011loss=5.201823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[150] avg_epoch_loss=5.389288\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=5.4073756218\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [150]#011Speed: 1640.08 samples/sec#011loss=5.407376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[155] avg_epoch_loss=5.388853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=5.37571763992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [155]#011Speed: 1040.46 samples/sec#011loss=5.375718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[160] avg_epoch_loss=5.390538\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=5.443110466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [160]#011Speed: 1650.23 samples/sec#011loss=5.443110\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[165] avg_epoch_loss=5.389414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=5.3532336235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [165]#011Speed: 1054.98 samples/sec#011loss=5.353234\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch[170] avg_epoch_loss=5.386437\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=5.2875957489\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:17 INFO 140669025912640] Epoch[10] Batch [170]#011Speed: 1645.81 samples/sec#011loss=5.287596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[175] avg_epoch_loss=5.387550\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=5.42561359406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [175]#011Speed: 1112.08 samples/sec#011loss=5.425614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[180] avg_epoch_loss=5.383528\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=5.2419629097\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [180]#011Speed: 1591.50 samples/sec#011loss=5.241963\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[185] avg_epoch_loss=5.384209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=5.40886468887\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [185]#011Speed: 1108.51 samples/sec#011loss=5.408865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[190] avg_epoch_loss=5.382385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=5.31452445984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [190]#011Speed: 1647.11 samples/sec#011loss=5.314524\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[195] avg_epoch_loss=5.378678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=5.23707838058\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [195]#011Speed: 1068.68 samples/sec#011loss=5.237078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[200] avg_epoch_loss=5.379043\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=5.39331645966\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [200]#011Speed: 1668.28 samples/sec#011loss=5.393316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[205] avg_epoch_loss=5.382786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=5.5332775116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [205]#011Speed: 1040.84 samples/sec#011loss=5.533278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch[210] avg_epoch_loss=5.387708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=5.59048128128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:18 INFO 140669025912640] Epoch[10] Batch [210]#011Speed: 1615.62 samples/sec#011loss=5.590481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[215] avg_epoch_loss=5.383538\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=5.207584095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [215]#011Speed: 1025.10 samples/sec#011loss=5.207584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[220] avg_epoch_loss=5.382640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=5.34382009506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [220]#011Speed: 1656.43 samples/sec#011loss=5.343820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[225] avg_epoch_loss=5.376327\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=5.09732599258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [225]#011Speed: 1066.21 samples/sec#011loss=5.097326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[230] avg_epoch_loss=5.371649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=5.16018409729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [230]#011Speed: 1684.81 samples/sec#011loss=5.160184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[235] avg_epoch_loss=5.374627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=5.51223325729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [235]#011Speed: 1008.22 samples/sec#011loss=5.512233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[240] avg_epoch_loss=5.373280\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=5.30966110229\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [240]#011Speed: 1551.57 samples/sec#011loss=5.309661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[245] avg_epoch_loss=5.377338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=5.57296686172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [245]#011Speed: 1038.84 samples/sec#011loss=5.572967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch[250] avg_epoch_loss=5.371155\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=5.06696033478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:19 INFO 140669025912640] Epoch[10] Batch [250]#011Speed: 1687.34 samples/sec#011loss=5.066960\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[255] avg_epoch_loss=5.369566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=5.28975362778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [255]#011Speed: 1047.09 samples/sec#011loss=5.289754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[260] avg_epoch_loss=5.368434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=5.3104973793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [260]#011Speed: 1635.24 samples/sec#011loss=5.310497\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[265] avg_epoch_loss=5.364853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=5.17790555954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [265]#011Speed: 1009.06 samples/sec#011loss=5.177906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[270] avg_epoch_loss=5.365299\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=5.38905849457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [270]#011Speed: 1670.16 samples/sec#011loss=5.389058\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[275] avg_epoch_loss=5.367797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=275 train loss <loss>=5.50318927765\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [275]#011Speed: 1059.17 samples/sec#011loss=5.503189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[280] avg_epoch_loss=5.366697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=280 train loss <loss>=5.30597763062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [280]#011Speed: 1682.60 samples/sec#011loss=5.305978\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[285] avg_epoch_loss=5.357498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=285 train loss <loss>=4.84050760269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [285]#011Speed: 1048.52 samples/sec#011loss=4.840508\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch[290] avg_epoch_loss=5.355209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=290 train loss <loss>=5.22427453995\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:20 INFO 140669025912640] Epoch[10] Batch [290]#011Speed: 1614.69 samples/sec#011loss=5.224275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[295] avg_epoch_loss=5.355302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=295 train loss <loss>=5.36070423126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [295]#011Speed: 1065.03 samples/sec#011loss=5.360704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[300] avg_epoch_loss=5.354833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=300 train loss <loss>=5.32707262039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [300]#011Speed: 1459.99 samples/sec#011loss=5.327073\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[305] avg_epoch_loss=5.356175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=305 train loss <loss>=5.43693552017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [305]#011Speed: 1093.85 samples/sec#011loss=5.436936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[310] avg_epoch_loss=5.358910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=310 train loss <loss>=5.52632169724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [310]#011Speed: 1664.17 samples/sec#011loss=5.526322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[315] avg_epoch_loss=5.360261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=315 train loss <loss>=5.44430770874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [315]#011Speed: 1034.57 samples/sec#011loss=5.444308\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[320] avg_epoch_loss=5.357928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=320 train loss <loss>=5.21046552658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [320]#011Speed: 1429.90 samples/sec#011loss=5.210466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[325] avg_epoch_loss=5.358052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=325 train loss <loss>=5.36598520279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [325]#011Speed: 1535.71 samples/sec#011loss=5.365985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch[330] avg_epoch_loss=5.359164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=330 train loss <loss>=5.43171787262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:21 INFO 140669025912640] Epoch[10] Batch [330]#011Speed: 1099.42 samples/sec#011loss=5.431718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[335] avg_epoch_loss=5.360164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=335 train loss <loss>=5.42637052536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [335]#011Speed: 1579.64 samples/sec#011loss=5.426371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[340] avg_epoch_loss=5.358153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=340 train loss <loss>=5.22297487259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [340]#011Speed: 1068.26 samples/sec#011loss=5.222975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[345] avg_epoch_loss=5.359899\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=345 train loss <loss>=5.47898521423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [345]#011Speed: 1573.95 samples/sec#011loss=5.478985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[350] avg_epoch_loss=5.362150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=350 train loss <loss>=5.51789464951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [350]#011Speed: 959.05 samples/sec#011loss=5.517895\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[355] avg_epoch_loss=5.360105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=355 train loss <loss>=5.21659250259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [355]#011Speed: 1459.03 samples/sec#011loss=5.216593\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[360] avg_epoch_loss=5.358608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=360 train loss <loss>=5.25198869705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [360]#011Speed: 1011.17 samples/sec#011loss=5.251989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[365] avg_epoch_loss=5.362260\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=365 train loss <loss>=5.62597370148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [365]#011Speed: 1542.29 samples/sec#011loss=5.625974\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch[370] avg_epoch_loss=5.360405\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=370 train loss <loss>=5.22456846237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:22 INFO 140669025912640] Epoch[10] Batch [370]#011Speed: 1039.03 samples/sec#011loss=5.224568\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[375] avg_epoch_loss=5.361468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=375 train loss <loss>=5.44037704468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [375]#011Speed: 1659.98 samples/sec#011loss=5.440377\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[380] avg_epoch_loss=5.360641\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=380 train loss <loss>=5.29842472076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [380]#011Speed: 985.05 samples/sec#011loss=5.298425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[385] avg_epoch_loss=5.363045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=385 train loss <loss>=5.54621734619\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [385]#011Speed: 1646.23 samples/sec#011loss=5.546217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[390] avg_epoch_loss=5.363723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=390 train loss <loss>=5.41609258652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [390]#011Speed: 1085.79 samples/sec#011loss=5.416093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[395] avg_epoch_loss=5.363598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=395 train loss <loss>=5.35383892059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [395]#011Speed: 1655.20 samples/sec#011loss=5.353839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[400] avg_epoch_loss=5.364009\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=400 train loss <loss>=5.39651241302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [400]#011Speed: 1095.59 samples/sec#011loss=5.396512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[405] avg_epoch_loss=5.365830\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=405 train loss <loss>=5.51190071106\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [405]#011Speed: 1632.20 samples/sec#011loss=5.511901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch[410] avg_epoch_loss=5.364648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=410 train loss <loss>=5.26870508194\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:23 INFO 140669025912640] Epoch[10] Batch [410]#011Speed: 1134.39 samples/sec#011loss=5.268705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[415] avg_epoch_loss=5.361870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=415 train loss <loss>=5.13346443176\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [415]#011Speed: 1567.84 samples/sec#011loss=5.133464\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[420] avg_epoch_loss=5.362725\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=420 train loss <loss>=5.4339056015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [420]#011Speed: 1021.89 samples/sec#011loss=5.433906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[425] avg_epoch_loss=5.363072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=425 train loss <loss>=5.39228916168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [425]#011Speed: 1640.76 samples/sec#011loss=5.392289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[430] avg_epoch_loss=5.364306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=430 train loss <loss>=5.46943902969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [430]#011Speed: 1638.54 samples/sec#011loss=5.469439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[435] avg_epoch_loss=5.364486\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=435 train loss <loss>=5.37997217178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [435]#011Speed: 1081.42 samples/sec#011loss=5.379972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[440] avg_epoch_loss=5.363937\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=440 train loss <loss>=5.31605958939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [440]#011Speed: 1650.11 samples/sec#011loss=5.316060\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[445] avg_epoch_loss=5.363908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=445 train loss <loss>=5.36133003235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [445]#011Speed: 1094.56 samples/sec#011loss=5.361330\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch[450] avg_epoch_loss=5.361339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=450 train loss <loss>=5.13224496841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:24 INFO 140669025912640] Epoch[10] Batch [450]#011Speed: 1651.12 samples/sec#011loss=5.132245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[455] avg_epoch_loss=5.360844\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=455 train loss <loss>=5.3162115097\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [455]#011Speed: 1103.93 samples/sec#011loss=5.316212\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[460] avg_epoch_loss=5.361410\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=460 train loss <loss>=5.41301145554\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [460]#011Speed: 1665.03 samples/sec#011loss=5.413011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[465] avg_epoch_loss=5.359410\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=465 train loss <loss>=5.17496204376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [465]#011Speed: 1060.02 samples/sec#011loss=5.174962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[470] avg_epoch_loss=5.357754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=470 train loss <loss>=5.20344190598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [470]#011Speed: 1619.47 samples/sec#011loss=5.203442\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[475] avg_epoch_loss=5.354802\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=475 train loss <loss>=5.07673740387\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [475]#011Speed: 1114.96 samples/sec#011loss=5.076737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[480] avg_epoch_loss=5.355905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=480 train loss <loss>=5.46089792252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [480]#011Speed: 1659.58 samples/sec#011loss=5.460898\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[485] avg_epoch_loss=5.354768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=485 train loss <loss>=5.24536457062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [485]#011Speed: 1138.27 samples/sec#011loss=5.245365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch[490] avg_epoch_loss=5.356122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=490 train loss <loss>=5.48772115707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:25 INFO 140669025912640] Epoch[10] Batch [490]#011Speed: 1648.23 samples/sec#011loss=5.487721\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[495] avg_epoch_loss=5.357155\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=495 train loss <loss>=5.4585978508\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [495]#011Speed: 1091.95 samples/sec#011loss=5.458598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[500] avg_epoch_loss=5.354734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=500 train loss <loss>=5.11462144852\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [500]#011Speed: 1639.32 samples/sec#011loss=5.114621\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[505] avg_epoch_loss=5.355412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=505 train loss <loss>=5.42332296371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [505]#011Speed: 960.27 samples/sec#011loss=5.423323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[510] avg_epoch_loss=5.353476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=510 train loss <loss>=5.15758371353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [510]#011Speed: 1609.61 samples/sec#011loss=5.157584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[515] avg_epoch_loss=5.351709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=515 train loss <loss>=5.17108507156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [515]#011Speed: 1122.41 samples/sec#011loss=5.171085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[520] avg_epoch_loss=5.351093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=520 train loss <loss>=5.28751497269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [520]#011Speed: 1651.99 samples/sec#011loss=5.287515\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[525] avg_epoch_loss=5.350958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=525 train loss <loss>=5.33694229126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [525]#011Speed: 1107.29 samples/sec#011loss=5.336942\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch[530] avg_epoch_loss=5.351678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=530 train loss <loss>=5.42735977173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:26 INFO 140669025912640] Epoch[10] Batch [530]#011Speed: 1634.81 samples/sec#011loss=5.427360\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[535] avg_epoch_loss=5.351088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=535 train loss <loss>=5.28848543167\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [535]#011Speed: 1094.28 samples/sec#011loss=5.288485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[540] avg_epoch_loss=5.350204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=540 train loss <loss>=5.2554608345\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [540]#011Speed: 1591.20 samples/sec#011loss=5.255461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[545] avg_epoch_loss=5.349414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=545 train loss <loss>=5.26393280029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [545]#011Speed: 1013.65 samples/sec#011loss=5.263933\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[550] avg_epoch_loss=5.348066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=550 train loss <loss>=5.20086336136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [550]#011Speed: 1673.87 samples/sec#011loss=5.200863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[555] avg_epoch_loss=5.347780\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=555 train loss <loss>=5.31622524261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [555]#011Speed: 1051.10 samples/sec#011loss=5.316225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[560] avg_epoch_loss=5.350316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=560 train loss <loss>=5.63230648041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [560]#011Speed: 1683.45 samples/sec#011loss=5.632306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[565] avg_epoch_loss=5.349370\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=565 train loss <loss>=5.24327383041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [565]#011Speed: 998.71 samples/sec#011loss=5.243274\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch[570] avg_epoch_loss=5.348995\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, batch=570 train loss <loss>=5.30654039383\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] Epoch[10] Batch [570]#011Speed: 1680.09 samples/sec#011loss=5.306540\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] processed a total of 18394 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14316.145896911621, \"sum\": 14316.145896911621, \"min\": 14316.145896911621}}, \"EndTime\": 1589393847.952016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393833.635812}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1284.834666 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=10, train loss <loss>=5.34985446764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:27 INFO 140669025912640] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[0] avg_epoch_loss=4.809905\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=4.80990457535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[5] avg_epoch_loss=5.119429\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=5.11942942937\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [5]#011Speed: 1610.11 samples/sec#011loss=5.119429\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[10] avg_epoch_loss=5.031719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=4.926466465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [10]#011Speed: 1658.38 samples/sec#011loss=4.926466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[15] avg_epoch_loss=5.110900\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=5.28509836197\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [15]#011Speed: 1076.78 samples/sec#011loss=5.285098\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[20] avg_epoch_loss=5.137883\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=5.22422780991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [20]#011Speed: 1655.59 samples/sec#011loss=5.224228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[25] avg_epoch_loss=5.225582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=5.59391689301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [25]#011Speed: 1075.21 samples/sec#011loss=5.593917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[30] avg_epoch_loss=5.242383\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=5.32974786758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [30]#011Speed: 1543.22 samples/sec#011loss=5.329748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[35] avg_epoch_loss=5.277903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=5.49813051224\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [35]#011Speed: 1036.19 samples/sec#011loss=5.498131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch[40] avg_epoch_loss=5.274063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=5.2464094162\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:28 INFO 140669025912640] Epoch[11] Batch [40]#011Speed: 1564.76 samples/sec#011loss=5.246409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[45] avg_epoch_loss=5.264609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=5.18708753586\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [45]#011Speed: 1018.16 samples/sec#011loss=5.187088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[50] avg_epoch_loss=5.243980\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=5.05419187546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [50]#011Speed: 1612.19 samples/sec#011loss=5.054192\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[55] avg_epoch_loss=5.268019\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=5.51322536469\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [55]#011Speed: 1053.58 samples/sec#011loss=5.513225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[60] avg_epoch_loss=5.279849\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=5.41233682632\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [60]#011Speed: 1649.33 samples/sec#011loss=5.412337\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[65] avg_epoch_loss=5.287211\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=5.37702503204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [65]#011Speed: 1039.72 samples/sec#011loss=5.377025\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[70] avg_epoch_loss=5.285579\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=5.26404743195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [70]#011Speed: 1509.93 samples/sec#011loss=5.264047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[75] avg_epoch_loss=5.290854\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=5.36576013565\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [75]#011Speed: 1043.40 samples/sec#011loss=5.365760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch[80] avg_epoch_loss=5.281335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=5.13664608002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:29 INFO 140669025912640] Epoch[11] Batch [80]#011Speed: 1689.90 samples/sec#011loss=5.136646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[85] avg_epoch_loss=5.273370\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=5.14432821274\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [85]#011Speed: 1077.07 samples/sec#011loss=5.144328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[90] avg_epoch_loss=5.275292\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=5.30835456848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [90]#011Speed: 1634.00 samples/sec#011loss=5.308355\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[95] avg_epoch_loss=5.276591\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=5.30023326874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [95]#011Speed: 1046.89 samples/sec#011loss=5.300233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[100] avg_epoch_loss=5.285570\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=5.45796661377\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [100]#011Speed: 1639.65 samples/sec#011loss=5.457967\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[105] avg_epoch_loss=5.293285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=5.44913282394\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [105]#011Speed: 1035.15 samples/sec#011loss=5.449133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[110] avg_epoch_loss=5.291201\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=5.24700698853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [110]#011Speed: 1643.47 samples/sec#011loss=5.247007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[115] avg_epoch_loss=5.314130\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=5.82315244675\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [115]#011Speed: 1082.60 samples/sec#011loss=5.823152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch[120] avg_epoch_loss=5.315040\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=5.33615694046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:30 INFO 140669025912640] Epoch[11] Batch [120]#011Speed: 1629.20 samples/sec#011loss=5.336157\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[125] avg_epoch_loss=5.316574\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=5.35370016098\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [125]#011Speed: 1124.96 samples/sec#011loss=5.353700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[130] avg_epoch_loss=5.325063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=5.53898649216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [130]#011Speed: 1492.19 samples/sec#011loss=5.538986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[135] avg_epoch_loss=5.330123\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=5.46269874573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [135]#011Speed: 1051.05 samples/sec#011loss=5.462699\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[140] avg_epoch_loss=5.334758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=5.46082353592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [140]#011Speed: 1682.19 samples/sec#011loss=5.460824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[145] avg_epoch_loss=5.343831\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=5.59969463348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [145]#011Speed: 1043.54 samples/sec#011loss=5.599695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[150] avg_epoch_loss=5.346150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=5.41386060715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [150]#011Speed: 1655.44 samples/sec#011loss=5.413861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[155] avg_epoch_loss=5.337179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=5.06626567841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [155]#011Speed: 1078.17 samples/sec#011loss=5.066266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch[160] avg_epoch_loss=5.337095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=5.33447418213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:31 INFO 140669025912640] Epoch[11] Batch [160]#011Speed: 1681.38 samples/sec#011loss=5.334474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[165] avg_epoch_loss=5.341048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=5.4683142662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [165]#011Speed: 1062.28 samples/sec#011loss=5.468314\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[170] avg_epoch_loss=5.342313\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=5.38433246613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [170]#011Speed: 1614.04 samples/sec#011loss=5.384332\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[175] avg_epoch_loss=5.345799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=5.46502609253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [175]#011Speed: 1076.19 samples/sec#011loss=5.465026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[180] avg_epoch_loss=5.343445\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=5.26056070328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [180]#011Speed: 1651.87 samples/sec#011loss=5.260561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[185] avg_epoch_loss=5.347372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=5.48952674866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [185]#011Speed: 1085.83 samples/sec#011loss=5.489527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[190] avg_epoch_loss=5.351026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=5.48697681427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [190]#011Speed: 1513.09 samples/sec#011loss=5.486977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[195] avg_epoch_loss=5.350738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=5.33973903656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [195]#011Speed: 1037.82 samples/sec#011loss=5.339739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch[200] avg_epoch_loss=5.349858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=5.31534433365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:32 INFO 140669025912640] Epoch[11] Batch [200]#011Speed: 1642.54 samples/sec#011loss=5.315344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[205] avg_epoch_loss=5.351231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=5.40641880035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [205]#011Speed: 1090.90 samples/sec#011loss=5.406419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[210] avg_epoch_loss=5.350177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=5.30676078796\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [210]#011Speed: 1633.18 samples/sec#011loss=5.306761\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[215] avg_epoch_loss=5.353080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=5.47560443878\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [215]#011Speed: 1053.16 samples/sec#011loss=5.475604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[220] avg_epoch_loss=5.349985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=5.21627540588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [220]#011Speed: 1667.47 samples/sec#011loss=5.216275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[225] avg_epoch_loss=5.349640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=5.33436384201\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [225]#011Speed: 1028.17 samples/sec#011loss=5.334364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[230] avg_epoch_loss=5.346769\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=5.2170290947\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [230]#011Speed: 1620.34 samples/sec#011loss=5.217029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[235] avg_epoch_loss=5.342495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=5.14500513077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [235]#011Speed: 1104.87 samples/sec#011loss=5.145005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch[240] avg_epoch_loss=5.342908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=5.36240234375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:33 INFO 140669025912640] Epoch[11] Batch [240]#011Speed: 1691.24 samples/sec#011loss=5.362402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[245] avg_epoch_loss=5.339918\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=5.19580144882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [245]#011Speed: 987.64 samples/sec#011loss=5.195801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[250] avg_epoch_loss=5.337196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=5.20327358246\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [250]#011Speed: 1680.20 samples/sec#011loss=5.203274\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[255] avg_epoch_loss=5.340983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=5.53110961914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [255]#011Speed: 989.88 samples/sec#011loss=5.531110\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[260] avg_epoch_loss=5.344209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=5.50940008163\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [260]#011Speed: 1681.20 samples/sec#011loss=5.509400\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[265] avg_epoch_loss=5.346184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=5.44924659729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [265]#011Speed: 1520.12 samples/sec#011loss=5.449247\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[270] avg_epoch_loss=5.343964\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=270 train loss <loss>=5.22585773468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [270]#011Speed: 1001.15 samples/sec#011loss=5.225858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[275] avg_epoch_loss=5.346490\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=275 train loss <loss>=5.48342981339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [275]#011Speed: 1680.78 samples/sec#011loss=5.483430\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch[280] avg_epoch_loss=5.343794\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=280 train loss <loss>=5.19495162964\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:34 INFO 140669025912640] Epoch[11] Batch [280]#011Speed: 1053.16 samples/sec#011loss=5.194952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[285] avg_epoch_loss=5.340998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=285 train loss <loss>=5.18385152817\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [285]#011Speed: 1636.73 samples/sec#011loss=5.183852\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[290] avg_epoch_loss=5.337109\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=290 train loss <loss>=5.11468505859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [290]#011Speed: 1013.94 samples/sec#011loss=5.114685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[295] avg_epoch_loss=5.333860\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=295 train loss <loss>=5.14477558136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [295]#011Speed: 1591.65 samples/sec#011loss=5.144776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[300] avg_epoch_loss=5.331511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=300 train loss <loss>=5.19243078232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [300]#011Speed: 996.82 samples/sec#011loss=5.192431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[305] avg_epoch_loss=5.328598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=305 train loss <loss>=5.15323457718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [305]#011Speed: 1665.97 samples/sec#011loss=5.153235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[310] avg_epoch_loss=5.327728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=310 train loss <loss>=5.27445640564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [310]#011Speed: 1086.71 samples/sec#011loss=5.274456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[315] avg_epoch_loss=5.323584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=315 train loss <loss>=5.06583614349\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [315]#011Speed: 1631.82 samples/sec#011loss=5.065836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch[320] avg_epoch_loss=5.325880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=320 train loss <loss>=5.4710272789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:35 INFO 140669025912640] Epoch[11] Batch [320]#011Speed: 1116.78 samples/sec#011loss=5.471027\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[325] avg_epoch_loss=5.327058\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=325 train loss <loss>=5.40267801285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [325]#011Speed: 1645.91 samples/sec#011loss=5.402678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[330] avg_epoch_loss=5.327675\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=330 train loss <loss>=5.36788568497\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [330]#011Speed: 1098.52 samples/sec#011loss=5.367886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[335] avg_epoch_loss=5.327914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=335 train loss <loss>=5.34371938705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [335]#011Speed: 1490.06 samples/sec#011loss=5.343719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[340] avg_epoch_loss=5.326828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=340 train loss <loss>=5.2538433075\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [340]#011Speed: 1017.57 samples/sec#011loss=5.253843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[345] avg_epoch_loss=5.328711\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=345 train loss <loss>=5.45712833405\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [345]#011Speed: 1406.36 samples/sec#011loss=5.457128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[350] avg_epoch_loss=5.327107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=350 train loss <loss>=5.21615447998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [350]#011Speed: 826.13 samples/sec#011loss=5.216154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch[355] avg_epoch_loss=5.326473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=355 train loss <loss>=5.28197078705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:36 INFO 140669025912640] Epoch[11] Batch [355]#011Speed: 1565.13 samples/sec#011loss=5.281971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[360] avg_epoch_loss=5.328291\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=360 train loss <loss>=5.45773162842\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [360]#011Speed: 1058.15 samples/sec#011loss=5.457732\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[365] avg_epoch_loss=5.331411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=365 train loss <loss>=5.55666770935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [365]#011Speed: 1574.42 samples/sec#011loss=5.556668\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[370] avg_epoch_loss=5.331673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=370 train loss <loss>=5.3508597374\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [370]#011Speed: 1054.56 samples/sec#011loss=5.350860\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[375] avg_epoch_loss=5.329801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=375 train loss <loss>=5.19086351395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [375]#011Speed: 1644.09 samples/sec#011loss=5.190864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[380] avg_epoch_loss=5.330069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=380 train loss <loss>=5.35022716522\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [380]#011Speed: 888.99 samples/sec#011loss=5.350227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[385] avg_epoch_loss=5.329402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=385 train loss <loss>=5.2786236763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [385]#011Speed: 1634.14 samples/sec#011loss=5.278624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[390] avg_epoch_loss=5.331377\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=390 train loss <loss>=5.48382043839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [390]#011Speed: 1089.61 samples/sec#011loss=5.483820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch[395] avg_epoch_loss=5.331912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=395 train loss <loss>=5.37373342514\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:37 INFO 140669025912640] Epoch[11] Batch [395]#011Speed: 1643.27 samples/sec#011loss=5.373733\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[400] avg_epoch_loss=5.331516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=400 train loss <loss>=5.30017385483\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [400]#011Speed: 1088.81 samples/sec#011loss=5.300174\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[405] avg_epoch_loss=5.329107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=405 train loss <loss>=5.13590278625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [405]#011Speed: 1656.88 samples/sec#011loss=5.135903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[410] avg_epoch_loss=5.326736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=410 train loss <loss>=5.13421220779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [410]#011Speed: 1020.03 samples/sec#011loss=5.134212\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[415] avg_epoch_loss=5.328017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=415 train loss <loss>=5.43325977325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [415]#011Speed: 1519.32 samples/sec#011loss=5.433260\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[420] avg_epoch_loss=5.329372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=420 train loss <loss>=5.44218139648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [420]#011Speed: 1089.28 samples/sec#011loss=5.442181\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[425] avg_epoch_loss=5.329434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=425 train loss <loss>=5.33462781906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [425]#011Speed: 1638.34 samples/sec#011loss=5.334628\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[430] avg_epoch_loss=5.326057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=430 train loss <loss>=5.03832025528\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [430]#011Speed: 1102.80 samples/sec#011loss=5.038320\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch[435] avg_epoch_loss=5.323726\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=435 train loss <loss>=5.12281522751\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:38 INFO 140669025912640] Epoch[11] Batch [435]#011Speed: 1641.60 samples/sec#011loss=5.122815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[440] avg_epoch_loss=5.324414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=440 train loss <loss>=5.3843960762\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [440]#011Speed: 1636.53 samples/sec#011loss=5.384396\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[445] avg_epoch_loss=5.323617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=445 train loss <loss>=5.25333347321\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [445]#011Speed: 1087.09 samples/sec#011loss=5.253333\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[450] avg_epoch_loss=5.321476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=450 train loss <loss>=5.13045320511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [450]#011Speed: 1616.98 samples/sec#011loss=5.130453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[455] avg_epoch_loss=5.318239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=455 train loss <loss>=5.02630090714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [455]#011Speed: 1099.08 samples/sec#011loss=5.026301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[460] avg_epoch_loss=5.317550\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=460 train loss <loss>=5.25471544266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [460]#011Speed: 1510.12 samples/sec#011loss=5.254715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[465] avg_epoch_loss=5.318126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=465 train loss <loss>=5.37118873596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [465]#011Speed: 1054.48 samples/sec#011loss=5.371189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[470] avg_epoch_loss=5.316636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=470 train loss <loss>=5.17783327103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [470]#011Speed: 1667.86 samples/sec#011loss=5.177833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch[475] avg_epoch_loss=5.314337\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=475 train loss <loss>=5.09769992828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:39 INFO 140669025912640] Epoch[11] Batch [475]#011Speed: 1028.65 samples/sec#011loss=5.097700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[480] avg_epoch_loss=5.313998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=480 train loss <loss>=5.28180942535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [480]#011Speed: 1672.97 samples/sec#011loss=5.281809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[485] avg_epoch_loss=5.314137\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=485 train loss <loss>=5.32750482559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [485]#011Speed: 1052.11 samples/sec#011loss=5.327505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[490] avg_epoch_loss=5.315035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=490 train loss <loss>=5.40226869583\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [490]#011Speed: 1617.09 samples/sec#011loss=5.402269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[495] avg_epoch_loss=5.316286\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=495 train loss <loss>=5.43914318085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [495]#011Speed: 1092.45 samples/sec#011loss=5.439143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[500] avg_epoch_loss=5.315511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=500 train loss <loss>=5.23858737946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [500]#011Speed: 1633.65 samples/sec#011loss=5.238587\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[505] avg_epoch_loss=5.317344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=505 train loss <loss>=5.50107593536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [505]#011Speed: 1103.12 samples/sec#011loss=5.501076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[510] avg_epoch_loss=5.315336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=510 train loss <loss>=5.11209974289\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [510]#011Speed: 1586.19 samples/sec#011loss=5.112100\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch[515] avg_epoch_loss=5.314981\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=515 train loss <loss>=5.27866258621\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:40 INFO 140669025912640] Epoch[11] Batch [515]#011Speed: 1630.94 samples/sec#011loss=5.278663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[520] avg_epoch_loss=5.313408\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=520 train loss <loss>=5.15112171173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [520]#011Speed: 1052.12 samples/sec#011loss=5.151122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[525] avg_epoch_loss=5.313150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=525 train loss <loss>=5.28621807098\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [525]#011Speed: 1648.02 samples/sec#011loss=5.286218\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[530] avg_epoch_loss=5.312461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=530 train loss <loss>=5.23998756409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [530]#011Speed: 1040.98 samples/sec#011loss=5.239988\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[535] avg_epoch_loss=5.313238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=535 train loss <loss>=5.39574346542\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [535]#011Speed: 1544.54 samples/sec#011loss=5.395743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[540] avg_epoch_loss=5.311953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=540 train loss <loss>=5.17422761917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [540]#011Speed: 1054.85 samples/sec#011loss=5.174228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[545] avg_epoch_loss=5.312909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=545 train loss <loss>=5.41638870239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [545]#011Speed: 1673.54 samples/sec#011loss=5.416389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[550] avg_epoch_loss=5.311816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=550 train loss <loss>=5.19242172241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [550]#011Speed: 1116.77 samples/sec#011loss=5.192422\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch[555] avg_epoch_loss=5.313896\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=555 train loss <loss>=5.54317865372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:41 INFO 140669025912640] Epoch[11] Batch [555]#011Speed: 1671.28 samples/sec#011loss=5.543179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch[560] avg_epoch_loss=5.314758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=560 train loss <loss>=5.4105837822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch [560]#011Speed: 1045.80 samples/sec#011loss=5.410584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch[565] avg_epoch_loss=5.311987\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=565 train loss <loss>=5.00103797913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch [565]#011Speed: 1651.07 samples/sec#011loss=5.001038\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch[570] avg_epoch_loss=5.315440\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=570 train loss <loss>=5.70636901855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch [570]#011Speed: 1170.80 samples/sec#011loss=5.706369\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch[575] avg_epoch_loss=5.316789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, batch=575 train loss <loss>=5.47078924179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[11] Batch [575]#011Speed: 1573.35 samples/sec#011loss=5.470789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] processed a total of 18415 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14398.574829101562, \"sum\": 14398.574829101562, \"min\": 14398.574829101562}}, \"EndTime\": 1589393862.350964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393847.952078}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1278.93765697 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=11, train loss <loss>=5.31678869741\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_d329e308-8e18-47fe-ba71-db31a3f2fcdd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.329961776733398, \"sum\": 10.329961776733398, \"min\": 10.329961776733398}}, \"EndTime\": 1589393862.361687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393862.351028}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch[0] avg_epoch_loss=5.055240\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=5.05523967743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch[5] avg_epoch_loss=5.397749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=5.39774910609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch [5]#011Speed: 1629.89 samples/sec#011loss=5.397749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch[10] avg_epoch_loss=5.500739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=5.62432785034\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch [10]#011Speed: 1088.76 samples/sec#011loss=5.624328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch[15] avg_epoch_loss=5.457242\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=5.3615486145\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch [15]#011Speed: 1642.71 samples/sec#011loss=5.361549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch[20] avg_epoch_loss=5.442962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=5.39726409912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:42 INFO 140669025912640] Epoch[12] Batch [20]#011Speed: 1616.39 samples/sec#011loss=5.397264\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[25] avg_epoch_loss=5.433168\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=5.39203186035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [25]#011Speed: 1082.90 samples/sec#011loss=5.392032\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[30] avg_epoch_loss=5.396425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=5.20536088943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [30]#011Speed: 1627.62 samples/sec#011loss=5.205361\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[35] avg_epoch_loss=5.412858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=5.51474199295\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [35]#011Speed: 1075.52 samples/sec#011loss=5.514742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[40] avg_epoch_loss=5.383813\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=5.17469148636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [40]#011Speed: 1602.45 samples/sec#011loss=5.174691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[45] avg_epoch_loss=5.384312\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=5.3884062767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [45]#011Speed: 1083.48 samples/sec#011loss=5.388406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[50] avg_epoch_loss=5.385708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=5.39855070114\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [50]#011Speed: 1644.35 samples/sec#011loss=5.398551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[55] avg_epoch_loss=5.361268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=5.11198358536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [55]#011Speed: 1085.14 samples/sec#011loss=5.111984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch[60] avg_epoch_loss=5.345671\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=5.170981884\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:43 INFO 140669025912640] Epoch[12] Batch [60]#011Speed: 1660.42 samples/sec#011loss=5.170982\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[65] avg_epoch_loss=5.358108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=5.50983867645\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [65]#011Speed: 1084.31 samples/sec#011loss=5.509839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[70] avg_epoch_loss=5.357714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=5.35250892639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [70]#011Speed: 1667.00 samples/sec#011loss=5.352509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[75] avg_epoch_loss=5.363102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=5.43961629868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [75]#011Speed: 1095.30 samples/sec#011loss=5.439616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[80] avg_epoch_loss=5.351075\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=5.1682554245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [80]#011Speed: 1534.95 samples/sec#011loss=5.168255\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[85] avg_epoch_loss=5.339225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=5.14725608826\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [85]#011Speed: 1046.53 samples/sec#011loss=5.147256\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[90] avg_epoch_loss=5.346806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=5.47720909119\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [90]#011Speed: 1644.79 samples/sec#011loss=5.477209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[95] avg_epoch_loss=5.341830\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=5.25125846863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [95]#011Speed: 1636.78 samples/sec#011loss=5.251258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[100] avg_epoch_loss=5.347143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=5.44915046692\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [100]#011Speed: 1071.96 samples/sec#011loss=5.449150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch[105] avg_epoch_loss=5.337054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=5.13326234818\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:44 INFO 140669025912640] Epoch[12] Batch [105]#011Speed: 1565.77 samples/sec#011loss=5.133262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[110] avg_epoch_loss=5.332777\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=5.2421046257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [110]#011Speed: 1122.98 samples/sec#011loss=5.242105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[115] avg_epoch_loss=5.339238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=5.48268451691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [115]#011Speed: 1641.61 samples/sec#011loss=5.482685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[120] avg_epoch_loss=5.337967\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=5.30846185684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [120]#011Speed: 1086.97 samples/sec#011loss=5.308462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[125] avg_epoch_loss=5.336361\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=5.29749822617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [125]#011Speed: 1640.23 samples/sec#011loss=5.297498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[130] avg_epoch_loss=5.334617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=5.29066152573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [130]#011Speed: 1094.50 samples/sec#011loss=5.290662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[135] avg_epoch_loss=5.329563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=5.19717082977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [135]#011Speed: 1640.93 samples/sec#011loss=5.197171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[140] avg_epoch_loss=5.326390\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=5.24008493423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [140]#011Speed: 1108.02 samples/sec#011loss=5.240085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch[145] avg_epoch_loss=5.328918\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=5.40020275116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:45 INFO 140669025912640] Epoch[12] Batch [145]#011Speed: 1590.16 samples/sec#011loss=5.400203\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[150] avg_epoch_loss=5.325677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=5.23103914261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [150]#011Speed: 1020.61 samples/sec#011loss=5.231039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[155] avg_epoch_loss=5.318903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=5.11430997849\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [155]#011Speed: 1555.50 samples/sec#011loss=5.114310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[160] avg_epoch_loss=5.319132\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=5.32627391815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [160]#011Speed: 1025.67 samples/sec#011loss=5.326274\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[165] avg_epoch_loss=5.323897\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=5.47736034393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [165]#011Speed: 1522.65 samples/sec#011loss=5.477360\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[170] avg_epoch_loss=5.322647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=5.28111591339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [170]#011Speed: 1048.32 samples/sec#011loss=5.281116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[175] avg_epoch_loss=5.329773\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=5.57351198196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [175]#011Speed: 1539.29 samples/sec#011loss=5.573512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[180] avg_epoch_loss=5.333082\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=5.44955425262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [180]#011Speed: 1037.98 samples/sec#011loss=5.449554\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch[185] avg_epoch_loss=5.328119\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=5.14846220016\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:46 INFO 140669025912640] Epoch[12] Batch [185]#011Speed: 1642.80 samples/sec#011loss=5.148462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[190] avg_epoch_loss=5.328998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=5.36169424057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [190]#011Speed: 1050.41 samples/sec#011loss=5.361694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[195] avg_epoch_loss=5.331295\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=5.41902313232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [195]#011Speed: 1655.68 samples/sec#011loss=5.419023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[200] avg_epoch_loss=5.324219\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=5.04684915543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [200]#011Speed: 970.05 samples/sec#011loss=5.046849\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[205] avg_epoch_loss=5.320439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=5.16847343445\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [205]#011Speed: 1581.59 samples/sec#011loss=5.168473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[210] avg_epoch_loss=5.318040\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=5.2191983223\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [210]#011Speed: 1013.72 samples/sec#011loss=5.219198\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[215] avg_epoch_loss=5.318840\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=5.35260429382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [215]#011Speed: 1654.55 samples/sec#011loss=5.352604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[220] avg_epoch_loss=5.314239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=5.11546363831\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [220]#011Speed: 1068.50 samples/sec#011loss=5.115464\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch[225] avg_epoch_loss=5.311952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=5.21086826324\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:47 INFO 140669025912640] Epoch[12] Batch [225]#011Speed: 1653.93 samples/sec#011loss=5.210868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[230] avg_epoch_loss=5.314864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=5.44651031494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [230]#011Speed: 1094.76 samples/sec#011loss=5.446510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[235] avg_epoch_loss=5.311058\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=5.13520755768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [235]#011Speed: 1625.93 samples/sec#011loss=5.135208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[240] avg_epoch_loss=5.310224\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=5.27084980011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [240]#011Speed: 1018.22 samples/sec#011loss=5.270850\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[245] avg_epoch_loss=5.306172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=5.11088504791\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [245]#011Speed: 1564.78 samples/sec#011loss=5.110885\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[250] avg_epoch_loss=5.302920\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=5.14290399551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [250]#011Speed: 1045.49 samples/sec#011loss=5.142904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[255] avg_epoch_loss=5.305858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=5.45336551666\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [255]#011Speed: 1666.74 samples/sec#011loss=5.453366\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[260] avg_epoch_loss=5.303673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=5.19176998138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [260]#011Speed: 1059.01 samples/sec#011loss=5.191770\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch[265] avg_epoch_loss=5.301688\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=5.19807395935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:48 INFO 140669025912640] Epoch[12] Batch [265]#011Speed: 1703.52 samples/sec#011loss=5.198074\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[270] avg_epoch_loss=5.304645\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=270 train loss <loss>=5.46197748184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [270]#011Speed: 1081.25 samples/sec#011loss=5.461977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[275] avg_epoch_loss=5.308540\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=275 train loss <loss>=5.51965847015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [275]#011Speed: 1665.04 samples/sec#011loss=5.519658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[280] avg_epoch_loss=5.308549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=280 train loss <loss>=5.30902376175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [280]#011Speed: 1080.40 samples/sec#011loss=5.309024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[285] avg_epoch_loss=5.305512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=285 train loss <loss>=5.13482656479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [285]#011Speed: 1653.30 samples/sec#011loss=5.134827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[290] avg_epoch_loss=5.306519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=290 train loss <loss>=5.36413841248\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [290]#011Speed: 1127.78 samples/sec#011loss=5.364138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[295] avg_epoch_loss=5.305676\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=295 train loss <loss>=5.25662584305\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [295]#011Speed: 1635.69 samples/sec#011loss=5.256626\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[300] avg_epoch_loss=5.304931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=300 train loss <loss>=5.26081342697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [300]#011Speed: 1063.69 samples/sec#011loss=5.260813\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch[305] avg_epoch_loss=5.303856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=305 train loss <loss>=5.23915901184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:49 INFO 140669025912640] Epoch[12] Batch [305]#011Speed: 1636.02 samples/sec#011loss=5.239159\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[310] avg_epoch_loss=5.300949\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=310 train loss <loss>=5.12304410934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [310]#011Speed: 1115.79 samples/sec#011loss=5.123044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[315] avg_epoch_loss=5.299804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=315 train loss <loss>=5.22855873108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [315]#011Speed: 1648.79 samples/sec#011loss=5.228559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[320] avg_epoch_loss=5.295440\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=320 train loss <loss>=5.01961355209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [320]#011Speed: 1102.24 samples/sec#011loss=5.019614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[325] avg_epoch_loss=5.294966\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=325 train loss <loss>=5.26457958221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [325]#011Speed: 1632.17 samples/sec#011loss=5.264580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[330] avg_epoch_loss=5.299265\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=330 train loss <loss>=5.57951974869\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [330]#011Speed: 1647.70 samples/sec#011loss=5.579520\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[335] avg_epoch_loss=5.298413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=335 train loss <loss>=5.24203367233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [335]#011Speed: 1091.75 samples/sec#011loss=5.242034\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[340] avg_epoch_loss=5.299403\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=340 train loss <loss>=5.36594820023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [340]#011Speed: 1651.99 samples/sec#011loss=5.365948\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch[345] avg_epoch_loss=5.297972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=345 train loss <loss>=5.2003862381\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:50 INFO 140669025912640] Epoch[12] Batch [345]#011Speed: 1112.65 samples/sec#011loss=5.200386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[350] avg_epoch_loss=5.294504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=350 train loss <loss>=5.05446853638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [350]#011Speed: 1637.88 samples/sec#011loss=5.054469\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[355] avg_epoch_loss=5.291676\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=355 train loss <loss>=5.09319782257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [355]#011Speed: 1092.43 samples/sec#011loss=5.093198\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[360] avg_epoch_loss=5.290772\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=360 train loss <loss>=5.2263876915\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [360]#011Speed: 1633.24 samples/sec#011loss=5.226388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[365] avg_epoch_loss=5.290706\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=365 train loss <loss>=5.28596763611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [365]#011Speed: 1030.48 samples/sec#011loss=5.285968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[370] avg_epoch_loss=5.294339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=370 train loss <loss>=5.56026916504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [370]#011Speed: 1629.03 samples/sec#011loss=5.560269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[375] avg_epoch_loss=5.290629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=375 train loss <loss>=5.01531715393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [375]#011Speed: 1046.65 samples/sec#011loss=5.015317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[380] avg_epoch_loss=5.288338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=380 train loss <loss>=5.11609706879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [380]#011Speed: 1397.76 samples/sec#011loss=5.116097\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch[385] avg_epoch_loss=5.289581\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=385 train loss <loss>=5.38429603577\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:51 INFO 140669025912640] Epoch[12] Batch [385]#011Speed: 977.57 samples/sec#011loss=5.384296\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[390] avg_epoch_loss=5.290277\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=390 train loss <loss>=5.34398517609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [390]#011Speed: 1629.86 samples/sec#011loss=5.343985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[395] avg_epoch_loss=5.292609\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=395 train loss <loss>=5.47494421005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [395]#011Speed: 1106.45 samples/sec#011loss=5.474944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[400] avg_epoch_loss=5.293037\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=400 train loss <loss>=5.32693634033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [400]#011Speed: 1644.30 samples/sec#011loss=5.326936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[405] avg_epoch_loss=5.294612\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=405 train loss <loss>=5.4209230423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [405]#011Speed: 1069.15 samples/sec#011loss=5.420923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[410] avg_epoch_loss=5.294907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=410 train loss <loss>=5.31885242462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [410]#011Speed: 1541.47 samples/sec#011loss=5.318852\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[415] avg_epoch_loss=5.298922\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=415 train loss <loss>=5.6290148735\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [415]#011Speed: 1111.71 samples/sec#011loss=5.629015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[420] avg_epoch_loss=5.291473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=420 train loss <loss>=4.67170057297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [420]#011Speed: 1628.68 samples/sec#011loss=4.671701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch[425] avg_epoch_loss=5.289170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=425 train loss <loss>=5.09521360397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:52 INFO 140669025912640] Epoch[12] Batch [425]#011Speed: 1027.52 samples/sec#011loss=5.095214\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[430] avg_epoch_loss=5.288430\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=430 train loss <loss>=5.22541513443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [430]#011Speed: 1645.91 samples/sec#011loss=5.225415\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[435] avg_epoch_loss=5.289555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=435 train loss <loss>=5.38650875092\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [435]#011Speed: 1108.19 samples/sec#011loss=5.386509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[440] avg_epoch_loss=5.290200\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=440 train loss <loss>=5.34647874832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [440]#011Speed: 1653.07 samples/sec#011loss=5.346479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[445] avg_epoch_loss=5.290515\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=445 train loss <loss>=5.31823167801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [445]#011Speed: 1060.28 samples/sec#011loss=5.318232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[450] avg_epoch_loss=5.291131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=450 train loss <loss>=5.34614524841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [450]#011Speed: 1650.25 samples/sec#011loss=5.346145\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[455] avg_epoch_loss=5.290378\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=455 train loss <loss>=5.22242088318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [455]#011Speed: 1107.10 samples/sec#011loss=5.222421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[460] avg_epoch_loss=5.290734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=460 train loss <loss>=5.32319936752\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [460]#011Speed: 1641.43 samples/sec#011loss=5.323199\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch[465] avg_epoch_loss=5.290148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=465 train loss <loss>=5.23610916138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:53 INFO 140669025912640] Epoch[12] Batch [465]#011Speed: 1104.29 samples/sec#011loss=5.236109\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[470] avg_epoch_loss=5.287429\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=470 train loss <loss>=5.0340464592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [470]#011Speed: 1643.62 samples/sec#011loss=5.034046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[475] avg_epoch_loss=5.289870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=475 train loss <loss>=5.51982679367\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [475]#011Speed: 1105.48 samples/sec#011loss=5.519827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[480] avg_epoch_loss=5.292886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=480 train loss <loss>=5.58002138138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [480]#011Speed: 1643.40 samples/sec#011loss=5.580021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[485] avg_epoch_loss=5.292226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=485 train loss <loss>=5.22874574661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [485]#011Speed: 1089.39 samples/sec#011loss=5.228746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[490] avg_epoch_loss=5.290438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=490 train loss <loss>=5.11657676697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [490]#011Speed: 1575.60 samples/sec#011loss=5.116577\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[495] avg_epoch_loss=5.291489\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=495 train loss <loss>=5.39475746155\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [495]#011Speed: 1038.79 samples/sec#011loss=5.394757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[500] avg_epoch_loss=5.290805\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=500 train loss <loss>=5.22293376923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [500]#011Speed: 1651.30 samples/sec#011loss=5.222934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[505] avg_epoch_loss=5.289497\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=505 train loss <loss>=5.15845108032\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [505]#011Speed: 1095.09 samples/sec#011loss=5.158451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch[510] avg_epoch_loss=5.291015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=510 train loss <loss>=5.44463148117\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:54 INFO 140669025912640] Epoch[12] Batch [510]#011Speed: 1639.40 samples/sec#011loss=5.444631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[515] avg_epoch_loss=5.293062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=515 train loss <loss>=5.50227794647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [515]#011Speed: 1023.44 samples/sec#011loss=5.502278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[520] avg_epoch_loss=5.293177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=520 train loss <loss>=5.3050157547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [520]#011Speed: 1670.70 samples/sec#011loss=5.305016\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[525] avg_epoch_loss=5.293835\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=525 train loss <loss>=5.36242837906\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [525]#011Speed: 1004.67 samples/sec#011loss=5.362428\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[530] avg_epoch_loss=5.293229\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=530 train loss <loss>=5.22939987183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [530]#011Speed: 1583.39 samples/sec#011loss=5.229400\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[535] avg_epoch_loss=5.292506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=535 train loss <loss>=5.21578731537\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [535]#011Speed: 1080.37 samples/sec#011loss=5.215787\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[540] avg_epoch_loss=5.291351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=540 train loss <loss>=5.16753826141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [540]#011Speed: 1667.90 samples/sec#011loss=5.167538\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[545] avg_epoch_loss=5.292734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=545 train loss <loss>=5.44229393005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [545]#011Speed: 1087.51 samples/sec#011loss=5.442294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch[550] avg_epoch_loss=5.291977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=550 train loss <loss>=5.20932636261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:55 INFO 140669025912640] Epoch[12] Batch [550]#011Speed: 1676.20 samples/sec#011loss=5.209326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch[555] avg_epoch_loss=5.291117\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=555 train loss <loss>=5.19639863968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch [555]#011Speed: 1029.96 samples/sec#011loss=5.196399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch[560] avg_epoch_loss=5.290578\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=560 train loss <loss>=5.23067789078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch [560]#011Speed: 1579.98 samples/sec#011loss=5.230678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch[565] avg_epoch_loss=5.288602\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=565 train loss <loss>=5.06685838699\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch [565]#011Speed: 1235.76 samples/sec#011loss=5.066858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch[570] avg_epoch_loss=5.287754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, batch=570 train loss <loss>=5.19180002213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[12] Batch [570]#011Speed: 1533.63 samples/sec#011loss=5.191800\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] processed a total of 18293 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14147.558212280273, \"sum\": 14147.558212280273, \"min\": 14147.558212280273}}, \"EndTime\": 1589393876.50937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393862.361752}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1293.00397073 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=12, train loss <loss>=5.28880293553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_4bae73d5-b84c-40c1-a21c-5b6e87895665-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.01596450805664, \"sum\": 10.01596450805664, \"min\": 10.01596450805664}}, \"EndTime\": 1589393876.519825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393876.509454}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch[0] avg_epoch_loss=4.279951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=4.27995061874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch[5] avg_epoch_loss=5.051878\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=5.05187773705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch [5]#011Speed: 1633.24 samples/sec#011loss=5.051878\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch[10] avg_epoch_loss=5.030508\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=5.00486478806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch [10]#011Speed: 1576.01 samples/sec#011loss=5.004865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch[15] avg_epoch_loss=5.064738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=5.1400434494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:56 INFO 140669025912640] Epoch[13] Batch [15]#011Speed: 1032.34 samples/sec#011loss=5.140043\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[20] avg_epoch_loss=5.053276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=5.01659898758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [20]#011Speed: 1655.95 samples/sec#011loss=5.016599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[25] avg_epoch_loss=5.077822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=5.18091249466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [25]#011Speed: 1105.66 samples/sec#011loss=5.180912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[30] avg_epoch_loss=5.145027\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=5.49449319839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [30]#011Speed: 1681.06 samples/sec#011loss=5.494493\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[35] avg_epoch_loss=5.173939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=5.35319452286\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [35]#011Speed: 1080.58 samples/sec#011loss=5.353195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[40] avg_epoch_loss=5.213679\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=5.49980640411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [40]#011Speed: 1599.34 samples/sec#011loss=5.499806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[45] avg_epoch_loss=5.200688\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=5.09415817261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [45]#011Speed: 1052.37 samples/sec#011loss=5.094158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[50] avg_epoch_loss=5.223170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=5.43000841141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [50]#011Speed: 1708.93 samples/sec#011loss=5.430008\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch[55] avg_epoch_loss=5.219836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=5.18583421707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:57 INFO 140669025912640] Epoch[13] Batch [55]#011Speed: 1063.59 samples/sec#011loss=5.185834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[60] avg_epoch_loss=5.216049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=5.17363100052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [60]#011Speed: 1634.64 samples/sec#011loss=5.173631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[65] avg_epoch_loss=5.228350\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=5.37841730118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [65]#011Speed: 1011.27 samples/sec#011loss=5.378417\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[70] avg_epoch_loss=5.233372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=5.29965934753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [70]#011Speed: 1600.27 samples/sec#011loss=5.299659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[75] avg_epoch_loss=5.235937\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=5.27236795425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [75]#011Speed: 1123.74 samples/sec#011loss=5.272368\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[80] avg_epoch_loss=5.234129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=5.20663833618\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [80]#011Speed: 1675.57 samples/sec#011loss=5.206638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[85] avg_epoch_loss=5.213030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=4.87124185562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [85]#011Speed: 1119.09 samples/sec#011loss=4.871242\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[90] avg_epoch_loss=5.210079\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=5.15932044983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [90]#011Speed: 1680.00 samples/sec#011loss=5.159320\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch[95] avg_epoch_loss=5.206335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=5.13818864822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:58 INFO 140669025912640] Epoch[13] Batch [95]#011Speed: 1040.84 samples/sec#011loss=5.138189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[100] avg_epoch_loss=5.198718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=5.05247440338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [100]#011Speed: 1640.57 samples/sec#011loss=5.052474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[105] avg_epoch_loss=5.199984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=5.22555236816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [105]#011Speed: 1098.19 samples/sec#011loss=5.225552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[110] avg_epoch_loss=5.188799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=4.95167303085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [110]#011Speed: 1679.26 samples/sec#011loss=4.951673\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[115] avg_epoch_loss=5.190683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=5.23252182007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [115]#011Speed: 1144.67 samples/sec#011loss=5.232522\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[120] avg_epoch_loss=5.204237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=5.51868677139\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [120]#011Speed: 1633.24 samples/sec#011loss=5.518687\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[125] avg_epoch_loss=5.206941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=5.27236042023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [125]#011Speed: 1137.72 samples/sec#011loss=5.272360\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[130] avg_epoch_loss=5.207230\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=5.21453065872\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [130]#011Speed: 1683.45 samples/sec#011loss=5.214531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[135] avg_epoch_loss=5.204028\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=5.12012462616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [135]#011Speed: 1103.68 samples/sec#011loss=5.120125\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch[140] avg_epoch_loss=5.205695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=5.25104045868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:17:59 INFO 140669025912640] Epoch[13] Batch [140]#011Speed: 1714.23 samples/sec#011loss=5.251040\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[145] avg_epoch_loss=5.208766\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=5.29537305832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [145]#011Speed: 1088.10 samples/sec#011loss=5.295373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[150] avg_epoch_loss=5.212938\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=5.33475656509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [150]#011Speed: 1697.04 samples/sec#011loss=5.334757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[155] avg_epoch_loss=5.219271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=5.4105266571\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [155]#011Speed: 1072.01 samples/sec#011loss=5.410527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[160] avg_epoch_loss=5.217246\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=5.15405921936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [160]#011Speed: 1605.34 samples/sec#011loss=5.154059\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[165] avg_epoch_loss=5.223616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=5.42872781754\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [165]#011Speed: 1011.31 samples/sec#011loss=5.428728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[170] avg_epoch_loss=5.218146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=5.03655529022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [170]#011Speed: 1509.31 samples/sec#011loss=5.036555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[175] avg_epoch_loss=5.216487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=5.15975799561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [175]#011Speed: 1135.86 samples/sec#011loss=5.159758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch[180] avg_epoch_loss=5.216300\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=5.20971050262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:00 INFO 140669025912640] Epoch[13] Batch [180]#011Speed: 1660.90 samples/sec#011loss=5.209711\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[185] avg_epoch_loss=5.219100\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=5.32045269012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [185]#011Speed: 1070.52 samples/sec#011loss=5.320453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[190] avg_epoch_loss=5.226284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=5.49353809357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [190]#011Speed: 1614.13 samples/sec#011loss=5.493538\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[195] avg_epoch_loss=5.234709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=5.55655117035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [195]#011Speed: 1037.62 samples/sec#011loss=5.556551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[200] avg_epoch_loss=5.237989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=5.36654634476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [200]#011Speed: 1430.24 samples/sec#011loss=5.366546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[205] avg_epoch_loss=5.243787\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=5.47685861588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [205]#011Speed: 982.06 samples/sec#011loss=5.476859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[210] avg_epoch_loss=5.246689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=5.36626062393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [210]#011Speed: 1619.22 samples/sec#011loss=5.366261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[215] avg_epoch_loss=5.251050\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=5.4350818634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [215]#011Speed: 1632.29 samples/sec#011loss=5.435082\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch[220] avg_epoch_loss=5.255432\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=5.44474563599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:01 INFO 140669025912640] Epoch[13] Batch [220]#011Speed: 1071.75 samples/sec#011loss=5.444746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[225] avg_epoch_loss=5.255646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=5.26508493423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [225]#011Speed: 1618.32 samples/sec#011loss=5.265085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[230] avg_epoch_loss=5.254700\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=5.21195421219\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [230]#011Speed: 1105.98 samples/sec#011loss=5.211954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[235] avg_epoch_loss=5.253736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=5.20922231674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [235]#011Speed: 1661.35 samples/sec#011loss=5.209222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[240] avg_epoch_loss=5.249545\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=5.05169439316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [240]#011Speed: 1062.64 samples/sec#011loss=5.051694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[245] avg_epoch_loss=5.248439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=5.19514427185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [245]#011Speed: 1470.59 samples/sec#011loss=5.195144\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[250] avg_epoch_loss=5.245783\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=5.11509084702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [250]#011Speed: 1103.72 samples/sec#011loss=5.115091\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[255] avg_epoch_loss=5.247326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=5.32480278015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [255]#011Speed: 1671.12 samples/sec#011loss=5.324803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch[260] avg_epoch_loss=5.249238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=5.34714622498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:02 INFO 140669025912640] Epoch[13] Batch [260]#011Speed: 1131.31 samples/sec#011loss=5.347146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[265] avg_epoch_loss=5.249485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=5.26238698959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [265]#011Speed: 1477.02 samples/sec#011loss=5.262387\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[270] avg_epoch_loss=5.250198\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=270 train loss <loss>=5.28810815811\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [270]#011Speed: 1037.20 samples/sec#011loss=5.288108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[275] avg_epoch_loss=5.247779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=275 train loss <loss>=5.11664857864\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [275]#011Speed: 1663.86 samples/sec#011loss=5.116649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[280] avg_epoch_loss=5.244968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=280 train loss <loss>=5.08984584808\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [280]#011Speed: 1013.99 samples/sec#011loss=5.089846\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[285] avg_epoch_loss=5.248150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=285 train loss <loss>=5.42695150375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [285]#011Speed: 1612.37 samples/sec#011loss=5.426952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[290] avg_epoch_loss=5.247907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=290 train loss <loss>=5.23400249481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [290]#011Speed: 1089.46 samples/sec#011loss=5.234002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[295] avg_epoch_loss=5.247921\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=295 train loss <loss>=5.24875707626\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [295]#011Speed: 1705.92 samples/sec#011loss=5.248757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch[300] avg_epoch_loss=5.247184\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=300 train loss <loss>=5.20352306366\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:03 INFO 140669025912640] Epoch[13] Batch [300]#011Speed: 1034.05 samples/sec#011loss=5.203523\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[305] avg_epoch_loss=5.274264\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=305 train loss <loss>=6.9044960022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [305]#011Speed: 1594.52 samples/sec#011loss=6.904496\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[310] avg_epoch_loss=5.279134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=310 train loss <loss>=5.57717046738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [310]#011Speed: 1087.78 samples/sec#011loss=5.577170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[315] avg_epoch_loss=5.282012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=315 train loss <loss>=5.46100625992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [315]#011Speed: 1644.55 samples/sec#011loss=5.461006\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[320] avg_epoch_loss=5.284344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=320 train loss <loss>=5.43175640106\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [320]#011Speed: 1052.78 samples/sec#011loss=5.431756\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[325] avg_epoch_loss=5.286985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=325 train loss <loss>=5.45655374527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [325]#011Speed: 1442.61 samples/sec#011loss=5.456554\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[330] avg_epoch_loss=5.287683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=330 train loss <loss>=5.33314208984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [330]#011Speed: 1016.84 samples/sec#011loss=5.333142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[335] avg_epoch_loss=5.290232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=335 train loss <loss>=5.45903177261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [335]#011Speed: 1639.33 samples/sec#011loss=5.459032\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch[340] avg_epoch_loss=5.289872\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=340 train loss <loss>=5.26565361023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:04 INFO 140669025912640] Epoch[13] Batch [340]#011Speed: 1035.04 samples/sec#011loss=5.265654\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[345] avg_epoch_loss=5.291402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=345 train loss <loss>=5.39572458267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [345]#011Speed: 1644.95 samples/sec#011loss=5.395725\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[350] avg_epoch_loss=5.290728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=350 train loss <loss>=5.2440943718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [350]#011Speed: 1091.08 samples/sec#011loss=5.244094\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[355] avg_epoch_loss=5.285444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=355 train loss <loss>=4.91450157166\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [355]#011Speed: 1610.60 samples/sec#011loss=4.914502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[360] avg_epoch_loss=5.286474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=360 train loss <loss>=5.35980682373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [360]#011Speed: 1041.16 samples/sec#011loss=5.359807\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[365] avg_epoch_loss=5.286989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=365 train loss <loss>=5.32419157028\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [365]#011Speed: 1517.77 samples/sec#011loss=5.324192\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[370] avg_epoch_loss=5.289243\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=370 train loss <loss>=5.45422134399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [370]#011Speed: 1063.65 samples/sec#011loss=5.454221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[375] avg_epoch_loss=5.288478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=375 train loss <loss>=5.23172416687\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [375]#011Speed: 1649.75 samples/sec#011loss=5.231724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch[380] avg_epoch_loss=5.287142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=380 train loss <loss>=5.18668088913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:05 INFO 140669025912640] Epoch[13] Batch [380]#011Speed: 1058.49 samples/sec#011loss=5.186681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[385] avg_epoch_loss=5.288859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=385 train loss <loss>=5.41968870163\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [385]#011Speed: 1679.00 samples/sec#011loss=5.419689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[390] avg_epoch_loss=5.292105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=390 train loss <loss>=5.5427406311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [390]#011Speed: 1070.41 samples/sec#011loss=5.542741\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[395] avg_epoch_loss=5.291383\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=395 train loss <loss>=5.23490991592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [395]#011Speed: 1675.44 samples/sec#011loss=5.234910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[400] avg_epoch_loss=5.291930\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=400 train loss <loss>=5.33518800735\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [400]#011Speed: 1004.96 samples/sec#011loss=5.335188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[405] avg_epoch_loss=5.291789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=405 train loss <loss>=5.28051862717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [405]#011Speed: 1432.54 samples/sec#011loss=5.280519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[410] avg_epoch_loss=5.293510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=410 train loss <loss>=5.43326778412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [410]#011Speed: 1005.87 samples/sec#011loss=5.433268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch[415] avg_epoch_loss=5.294332\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=415 train loss <loss>=5.36188592911\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:06 INFO 140669025912640] Epoch[13] Batch [415]#011Speed: 1642.73 samples/sec#011loss=5.361886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[420] avg_epoch_loss=5.296629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=420 train loss <loss>=5.48773479462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [420]#011Speed: 1071.98 samples/sec#011loss=5.487735\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[425] avg_epoch_loss=5.297263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=425 train loss <loss>=5.35067663193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [425]#011Speed: 1670.22 samples/sec#011loss=5.350677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[430] avg_epoch_loss=5.298523\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=430 train loss <loss>=5.40586271286\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [430]#011Speed: 1097.45 samples/sec#011loss=5.405863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[435] avg_epoch_loss=5.298871\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=435 train loss <loss>=5.32890081406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [435]#011Speed: 1697.43 samples/sec#011loss=5.328901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[440] avg_epoch_loss=5.298970\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=440 train loss <loss>=5.30757627487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [440]#011Speed: 990.42 samples/sec#011loss=5.307576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[445] avg_epoch_loss=5.296564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=445 train loss <loss>=5.08438177109\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [445]#011Speed: 1525.46 samples/sec#011loss=5.084382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[450] avg_epoch_loss=5.296714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=450 train loss <loss>=5.31006126404\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [450]#011Speed: 1057.91 samples/sec#011loss=5.310061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch[455] avg_epoch_loss=5.294701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=455 train loss <loss>=5.11314582825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:07 INFO 140669025912640] Epoch[13] Batch [455]#011Speed: 1637.66 samples/sec#011loss=5.113146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[460] avg_epoch_loss=5.293394\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=460 train loss <loss>=5.17414159775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [460]#011Speed: 1058.42 samples/sec#011loss=5.174142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[465] avg_epoch_loss=5.294765\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=465 train loss <loss>=5.42119989395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [465]#011Speed: 1678.01 samples/sec#011loss=5.421200\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[470] avg_epoch_loss=5.294945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=470 train loss <loss>=5.31169757843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [470]#011Speed: 1068.58 samples/sec#011loss=5.311698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[475] avg_epoch_loss=5.292828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=475 train loss <loss>=5.09340686798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [475]#011Speed: 1656.16 samples/sec#011loss=5.093407\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[480] avg_epoch_loss=5.292398\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=480 train loss <loss>=5.25149745941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [480]#011Speed: 1026.50 samples/sec#011loss=5.251497\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[485] avg_epoch_loss=5.291985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=485 train loss <loss>=5.25219278336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [485]#011Speed: 1516.85 samples/sec#011loss=5.252193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[490] avg_epoch_loss=5.290658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=490 train loss <loss>=5.16168937683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [490]#011Speed: 1460.77 samples/sec#011loss=5.161689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[495] avg_epoch_loss=5.294153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=495 train loss <loss>=5.63743467331\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [495]#011Speed: 1095.77 samples/sec#011loss=5.637435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch[500] avg_epoch_loss=5.292980\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=500 train loss <loss>=5.17653646469\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:08 INFO 140669025912640] Epoch[13] Batch [500]#011Speed: 1597.09 samples/sec#011loss=5.176536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[505] avg_epoch_loss=5.290581\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=505 train loss <loss>=5.05023870468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [505]#011Speed: 1030.47 samples/sec#011loss=5.050239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[510] avg_epoch_loss=5.290109\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=510 train loss <loss>=5.24235830307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [510]#011Speed: 1666.20 samples/sec#011loss=5.242358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[515] avg_epoch_loss=5.291800\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=515 train loss <loss>=5.46461982727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [515]#011Speed: 1085.11 samples/sec#011loss=5.464620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[520] avg_epoch_loss=5.291886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=520 train loss <loss>=5.30076341629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [520]#011Speed: 1675.36 samples/sec#011loss=5.300763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[525] avg_epoch_loss=5.292506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=525 train loss <loss>=5.35705728531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [525]#011Speed: 1014.47 samples/sec#011loss=5.357057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[530] avg_epoch_loss=5.293035\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=530 train loss <loss>=5.34876432419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [530]#011Speed: 1637.11 samples/sec#011loss=5.348764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[535] avg_epoch_loss=5.292001\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=535 train loss <loss>=5.18220052719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [535]#011Speed: 1053.33 samples/sec#011loss=5.182201\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch[540] avg_epoch_loss=5.291874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=540 train loss <loss>=5.27816419601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:09 INFO 140669025912640] Epoch[13] Batch [540]#011Speed: 1657.00 samples/sec#011loss=5.278164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch[545] avg_epoch_loss=5.291164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=545 train loss <loss>=5.21436719894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch [545]#011Speed: 1036.62 samples/sec#011loss=5.214367\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch[550] avg_epoch_loss=5.290739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=550 train loss <loss>=5.2443274498\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch [550]#011Speed: 1660.28 samples/sec#011loss=5.244327\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch[555] avg_epoch_loss=5.291524\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=555 train loss <loss>=5.37808589935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch [555]#011Speed: 981.38 samples/sec#011loss=5.378086\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch[560] avg_epoch_loss=5.291262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=560 train loss <loss>=5.26209259033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch [560]#011Speed: 1698.08 samples/sec#011loss=5.262093\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch[565] avg_epoch_loss=5.290393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, batch=565 train loss <loss>=5.19291982651\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[13] Batch [565]#011Speed: 1286.71 samples/sec#011loss=5.192920\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] processed a total of 18171 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14127.385139465332, \"sum\": 14127.385139465332, \"min\": 14127.385139465332}}, \"EndTime\": 1589393890.647331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393876.519888}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1286.21664737 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=13, train loss <loss>=5.29065834636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[14] Batch[0] avg_epoch_loss=4.918164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=4.91816425323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[14] Batch[5] avg_epoch_loss=5.302853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=5.30285334587\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[14] Batch [5]#011Speed: 1660.97 samples/sec#011loss=5.302853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[14] Batch[10] avg_epoch_loss=5.236928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=5.15781774521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:10 INFO 140669025912640] Epoch[14] Batch [10]#011Speed: 1051.35 samples/sec#011loss=5.157818\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[15] avg_epoch_loss=5.281522\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=5.37962932587\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [15]#011Speed: 1634.54 samples/sec#011loss=5.379629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[20] avg_epoch_loss=5.232513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=5.07568426132\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [20]#011Speed: 1670.97 samples/sec#011loss=5.075684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[25] avg_epoch_loss=5.275486\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=5.45596952438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [25]#011Speed: 945.40 samples/sec#011loss=5.455970\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[30] avg_epoch_loss=5.297218\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=5.410227108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [30]#011Speed: 1678.38 samples/sec#011loss=5.410227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[35] avg_epoch_loss=5.309324\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=5.38437900543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [35]#011Speed: 938.66 samples/sec#011loss=5.384379\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[40] avg_epoch_loss=5.298913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=5.2239522934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [40]#011Speed: 1505.87 samples/sec#011loss=5.223952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[45] avg_epoch_loss=5.273057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=5.0610417366\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [45]#011Speed: 1099.47 samples/sec#011loss=5.061042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch[50] avg_epoch_loss=5.265468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=5.19564743042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:11 INFO 140669025912640] Epoch[14] Batch [50]#011Speed: 1645.33 samples/sec#011loss=5.195647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[55] avg_epoch_loss=5.264715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=5.2570306778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [55]#011Speed: 1094.29 samples/sec#011loss=5.257031\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[60] avg_epoch_loss=5.272702\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=5.3621632576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [60]#011Speed: 1642.86 samples/sec#011loss=5.362163\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[65] avg_epoch_loss=5.271039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=5.25075149536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [65]#011Speed: 1098.15 samples/sec#011loss=5.250751\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[70] avg_epoch_loss=5.280875\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=5.4107052803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [70]#011Speed: 1654.93 samples/sec#011loss=5.410705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[75] avg_epoch_loss=5.284728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=5.33943567276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [75]#011Speed: 1089.23 samples/sec#011loss=5.339436\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[80] avg_epoch_loss=5.301599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=5.55804195404\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [80]#011Speed: 1510.95 samples/sec#011loss=5.558042\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[85] avg_epoch_loss=5.285276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=5.0208398819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [85]#011Speed: 1099.08 samples/sec#011loss=5.020840\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch[90] avg_epoch_loss=5.264462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=4.90645961761\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:12 INFO 140669025912640] Epoch[14] Batch [90]#011Speed: 1534.96 samples/sec#011loss=4.906460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[95] avg_epoch_loss=5.260194\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=5.18251886368\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [95]#011Speed: 1036.72 samples/sec#011loss=5.182519\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[100] avg_epoch_loss=5.270034\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=5.45895843506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [100]#011Speed: 1572.03 samples/sec#011loss=5.458958\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[105] avg_epoch_loss=5.268171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=5.23055782318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [105]#011Speed: 1066.74 samples/sec#011loss=5.230558\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[110] avg_epoch_loss=5.283397\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=5.6061715126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [110]#011Speed: 1592.85 samples/sec#011loss=5.606172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[115] avg_epoch_loss=5.278636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=5.17295398712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [115]#011Speed: 1047.96 samples/sec#011loss=5.172954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[120] avg_epoch_loss=5.281252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=5.34192590714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [120]#011Speed: 1692.46 samples/sec#011loss=5.341926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[125] avg_epoch_loss=5.284069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=5.35226268768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [125]#011Speed: 1673.59 samples/sec#011loss=5.352263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch[130] avg_epoch_loss=5.283828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=5.27774429321\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:13 INFO 140669025912640] Epoch[14] Batch [130]#011Speed: 1126.69 samples/sec#011loss=5.277744\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[135] avg_epoch_loss=5.277770\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=5.11903934479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [135]#011Speed: 1682.91 samples/sec#011loss=5.119039\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[140] avg_epoch_loss=5.284618\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=5.4709072113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [140]#011Speed: 1107.41 samples/sec#011loss=5.470907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[145] avg_epoch_loss=5.281076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=5.18119049072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [145]#011Speed: 1693.55 samples/sec#011loss=5.181190\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[150] avg_epoch_loss=5.285419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=5.41221046448\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [150]#011Speed: 1008.29 samples/sec#011loss=5.412210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[155] avg_epoch_loss=5.286657\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=5.324061203\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [155]#011Speed: 1647.47 samples/sec#011loss=5.324061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[160] avg_epoch_loss=5.287954\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=5.32841405869\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [160]#011Speed: 1083.75 samples/sec#011loss=5.328414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[165] avg_epoch_loss=5.282855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=5.11865921021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [165]#011Speed: 1647.89 samples/sec#011loss=5.118659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch[170] avg_epoch_loss=5.281975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=5.252780056\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:14 INFO 140669025912640] Epoch[14] Batch [170]#011Speed: 1130.05 samples/sec#011loss=5.252780\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[175] avg_epoch_loss=5.278467\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=5.15849914551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [175]#011Speed: 1663.25 samples/sec#011loss=5.158499\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[180] avg_epoch_loss=5.280716\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=5.35985040665\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [180]#011Speed: 991.35 samples/sec#011loss=5.359850\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[185] avg_epoch_loss=5.285193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=5.44727144241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [185]#011Speed: 1655.15 samples/sec#011loss=5.447271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[190] avg_epoch_loss=5.282621\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=5.18694200516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [190]#011Speed: 1080.51 samples/sec#011loss=5.186942\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[195] avg_epoch_loss=5.287210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=5.46251649857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [195]#011Speed: 1642.96 samples/sec#011loss=5.462516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[200] avg_epoch_loss=5.283902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=5.1542345047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [200]#011Speed: 1065.74 samples/sec#011loss=5.154235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[205] avg_epoch_loss=5.285371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=5.34443540573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [205]#011Speed: 1659.73 samples/sec#011loss=5.344435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[210] avg_epoch_loss=5.284081\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=5.23092422485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [210]#011Speed: 1107.34 samples/sec#011loss=5.230924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch[215] avg_epoch_loss=5.283608\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=5.2636425972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:15 INFO 140669025912640] Epoch[14] Batch [215]#011Speed: 1667.88 samples/sec#011loss=5.263643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[220] avg_epoch_loss=5.277911\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=5.03178853989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [220]#011Speed: 1677.80 samples/sec#011loss=5.031789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[225] avg_epoch_loss=5.279260\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=5.33887996674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [225]#011Speed: 1091.75 samples/sec#011loss=5.338880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[230] avg_epoch_loss=5.277197\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=5.1839471817\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [230]#011Speed: 1653.44 samples/sec#011loss=5.183947\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[235] avg_epoch_loss=5.275376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=5.19123830795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [235]#011Speed: 1082.70 samples/sec#011loss=5.191238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[240] avg_epoch_loss=5.277207\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=5.36363077164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [240]#011Speed: 1635.47 samples/sec#011loss=5.363631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[245] avg_epoch_loss=5.281210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=5.47418241501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [245]#011Speed: 994.75 samples/sec#011loss=5.474182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[250] avg_epoch_loss=5.279556\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=5.19817399979\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [250]#011Speed: 1676.06 samples/sec#011loss=5.198174\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch[255] avg_epoch_loss=5.282870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=5.44921350479\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:16 INFO 140669025912640] Epoch[14] Batch [255]#011Speed: 1061.50 samples/sec#011loss=5.449214\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[260] avg_epoch_loss=5.279391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=5.10127820969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [260]#011Speed: 1662.63 samples/sec#011loss=5.101278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[265] avg_epoch_loss=5.279268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=5.27287864685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [265]#011Speed: 973.25 samples/sec#011loss=5.272879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[270] avg_epoch_loss=5.278484\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=270 train loss <loss>=5.23677368164\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [270]#011Speed: 1663.42 samples/sec#011loss=5.236774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[275] avg_epoch_loss=5.275620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=275 train loss <loss>=5.12035655975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [275]#011Speed: 1038.26 samples/sec#011loss=5.120357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[280] avg_epoch_loss=5.277188\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=280 train loss <loss>=5.36376714706\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [280]#011Speed: 1605.64 samples/sec#011loss=5.363767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[285] avg_epoch_loss=5.280060\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=285 train loss <loss>=5.44144916534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [285]#011Speed: 1105.29 samples/sec#011loss=5.441449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[290] avg_epoch_loss=5.279443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=290 train loss <loss>=5.24415960312\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [290]#011Speed: 1639.90 samples/sec#011loss=5.244160\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch[295] avg_epoch_loss=5.275269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=295 train loss <loss>=5.03236446381\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:17 INFO 140669025912640] Epoch[14] Batch [295]#011Speed: 1108.47 samples/sec#011loss=5.032364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[300] avg_epoch_loss=5.274825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=300 train loss <loss>=5.24851198196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [300]#011Speed: 1563.37 samples/sec#011loss=5.248512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[305] avg_epoch_loss=5.271910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=305 train loss <loss>=5.09645500183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [305]#011Speed: 1110.06 samples/sec#011loss=5.096455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[310] avg_epoch_loss=5.269556\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=310 train loss <loss>=5.12544898987\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [310]#011Speed: 1610.22 samples/sec#011loss=5.125449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[315] avg_epoch_loss=5.271529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=315 train loss <loss>=5.39428672791\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [315]#011Speed: 1053.01 samples/sec#011loss=5.394287\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[320] avg_epoch_loss=5.275165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=320 train loss <loss>=5.50492601395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [320]#011Speed: 1604.67 samples/sec#011loss=5.504926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[325] avg_epoch_loss=5.273093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=325 train loss <loss>=5.14005746841\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [325]#011Speed: 1442.18 samples/sec#011loss=5.140057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[330] avg_epoch_loss=5.271509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=330 train loss <loss>=5.16826868057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [330]#011Speed: 1083.76 samples/sec#011loss=5.168269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch[335] avg_epoch_loss=5.271722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=335 train loss <loss>=5.28583784103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:18 INFO 140669025912640] Epoch[14] Batch [335]#011Speed: 1642.49 samples/sec#011loss=5.285838\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[340] avg_epoch_loss=5.271093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=340 train loss <loss>=5.22882623672\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [340]#011Speed: 1124.54 samples/sec#011loss=5.228826\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[345] avg_epoch_loss=5.272253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=345 train loss <loss>=5.35133247375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [345]#011Speed: 1676.74 samples/sec#011loss=5.351332\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[350] avg_epoch_loss=5.270964\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=350 train loss <loss>=5.18173742294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [350]#011Speed: 1101.82 samples/sec#011loss=5.181737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[355] avg_epoch_loss=5.266966\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=355 train loss <loss>=4.98631696701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [355]#011Speed: 1450.97 samples/sec#011loss=4.986317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[360] avg_epoch_loss=5.267314\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=360 train loss <loss>=5.29210090637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [360]#011Speed: 1055.25 samples/sec#011loss=5.292101\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[365] avg_epoch_loss=5.261446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=365 train loss <loss>=4.83781805038\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [365]#011Speed: 1637.58 samples/sec#011loss=4.837818\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[370] avg_epoch_loss=5.261414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=370 train loss <loss>=5.25902395248\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [370]#011Speed: 1098.98 samples/sec#011loss=5.259024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch[375] avg_epoch_loss=5.260860\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=375 train loss <loss>=5.21976289749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:19 INFO 140669025912640] Epoch[14] Batch [375]#011Speed: 1677.60 samples/sec#011loss=5.219763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[380] avg_epoch_loss=5.261390\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=380 train loss <loss>=5.30122117996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [380]#011Speed: 971.30 samples/sec#011loss=5.301221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[385] avg_epoch_loss=5.259275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=385 train loss <loss>=5.0981710434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [385]#011Speed: 1651.26 samples/sec#011loss=5.098171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[390] avg_epoch_loss=5.258316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=390 train loss <loss>=5.18427877426\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [390]#011Speed: 1070.74 samples/sec#011loss=5.184279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[395] avg_epoch_loss=5.257828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=395 train loss <loss>=5.21967353821\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [395]#011Speed: 1558.01 samples/sec#011loss=5.219674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[400] avg_epoch_loss=5.256455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=400 train loss <loss>=5.14764375687\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [400]#011Speed: 1575.08 samples/sec#011loss=5.147644\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[405] avg_epoch_loss=5.256066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=405 train loss <loss>=5.22486600876\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [405]#011Speed: 1020.84 samples/sec#011loss=5.224866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[410] avg_epoch_loss=5.256533\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=410 train loss <loss>=5.29452896118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [410]#011Speed: 1684.92 samples/sec#011loss=5.294529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch[415] avg_epoch_loss=5.256442\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=415 train loss <loss>=5.24890756607\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:20 INFO 140669025912640] Epoch[14] Batch [415]#011Speed: 1064.52 samples/sec#011loss=5.248908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[420] avg_epoch_loss=5.253044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=420 train loss <loss>=4.97030677795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [420]#011Speed: 1632.27 samples/sec#011loss=4.970307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[425] avg_epoch_loss=5.253136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=425 train loss <loss>=5.26092023849\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [425]#011Speed: 1051.12 samples/sec#011loss=5.260920\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[430] avg_epoch_loss=5.254334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=430 train loss <loss>=5.35644874573\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [430]#011Speed: 1020.36 samples/sec#011loss=5.356449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[435] avg_epoch_loss=5.256177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=435 train loss <loss>=5.41496200562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [435]#011Speed: 1635.29 samples/sec#011loss=5.414962\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[440] avg_epoch_loss=5.255785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=440 train loss <loss>=5.22163028717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [440]#011Speed: 1070.21 samples/sec#011loss=5.221630\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[445] avg_epoch_loss=5.254694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=445 train loss <loss>=5.15848150253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [445]#011Speed: 1391.62 samples/sec#011loss=5.158482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[450] avg_epoch_loss=5.255281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=450 train loss <loss>=5.30766353607\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [450]#011Speed: 962.79 samples/sec#011loss=5.307664\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch[455] avg_epoch_loss=5.256724\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=455 train loss <loss>=5.38688192368\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:21 INFO 140669025912640] Epoch[14] Batch [455]#011Speed: 1469.02 samples/sec#011loss=5.386882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[460] avg_epoch_loss=5.257205\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=460 train loss <loss>=5.3010134697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [460]#011Speed: 979.41 samples/sec#011loss=5.301013\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[465] avg_epoch_loss=5.255838\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=465 train loss <loss>=5.12985773087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [465]#011Speed: 1655.29 samples/sec#011loss=5.129858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[470] avg_epoch_loss=5.255740\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=470 train loss <loss>=5.24657583237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [470]#011Speed: 1103.76 samples/sec#011loss=5.246576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[475] avg_epoch_loss=5.256617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=475 train loss <loss>=5.339220047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [475]#011Speed: 1644.43 samples/sec#011loss=5.339220\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[480] avg_epoch_loss=5.255764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=480 train loss <loss>=5.17456178665\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [480]#011Speed: 1050.73 samples/sec#011loss=5.174562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[485] avg_epoch_loss=5.255253\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=485 train loss <loss>=5.20612707138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [485]#011Speed: 1667.17 samples/sec#011loss=5.206127\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[490] avg_epoch_loss=5.254089\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=490 train loss <loss>=5.14096813202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [490]#011Speed: 1025.12 samples/sec#011loss=5.140968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch[495] avg_epoch_loss=5.252915\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=495 train loss <loss>=5.13756275177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:22 INFO 140669025912640] Epoch[14] Batch [495]#011Speed: 1628.95 samples/sec#011loss=5.137563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[500] avg_epoch_loss=5.255216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=500 train loss <loss>=5.48345890045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [500]#011Speed: 1609.35 samples/sec#011loss=5.483459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[505] avg_epoch_loss=5.255357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=505 train loss <loss>=5.26953477859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [505]#011Speed: 1046.48 samples/sec#011loss=5.269535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[510] avg_epoch_loss=5.256450\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=510 train loss <loss>=5.36707725525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [510]#011Speed: 1659.44 samples/sec#011loss=5.367077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[515] avg_epoch_loss=5.256047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=515 train loss <loss>=5.2148809433\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [515]#011Speed: 1043.15 samples/sec#011loss=5.214881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[520] avg_epoch_loss=5.256444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=520 train loss <loss>=5.29734840393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [520]#011Speed: 1652.11 samples/sec#011loss=5.297348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[525] avg_epoch_loss=5.256255\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=525 train loss <loss>=5.23656587601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [525]#011Speed: 1006.71 samples/sec#011loss=5.236566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[530] avg_epoch_loss=5.256830\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=530 train loss <loss>=5.31732254028\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [530]#011Speed: 1687.23 samples/sec#011loss=5.317323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch[535] avg_epoch_loss=5.255753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=535 train loss <loss>=5.14138154984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:23 INFO 140669025912640] Epoch[14] Batch [535]#011Speed: 1057.63 samples/sec#011loss=5.141382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[540] avg_epoch_loss=5.255363\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=540 train loss <loss>=5.21359357834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [540]#011Speed: 1651.22 samples/sec#011loss=5.213594\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[545] avg_epoch_loss=5.254696\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=545 train loss <loss>=5.18250026703\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [545]#011Speed: 1067.93 samples/sec#011loss=5.182500\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[550] avg_epoch_loss=5.255027\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=550 train loss <loss>=5.29121007919\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [550]#011Speed: 1612.07 samples/sec#011loss=5.291210\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[555] avg_epoch_loss=5.255010\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=555 train loss <loss>=5.2531255722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [555]#011Speed: 993.66 samples/sec#011loss=5.253126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[560] avg_epoch_loss=5.255088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=560 train loss <loss>=5.26368188858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [560]#011Speed: 1671.61 samples/sec#011loss=5.263682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[565] avg_epoch_loss=5.254257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=565 train loss <loss>=5.16109619141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [565]#011Speed: 1032.01 samples/sec#011loss=5.161096\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[570] avg_epoch_loss=5.252217\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=570 train loss <loss>=5.02126684189\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [570]#011Speed: 1652.57 samples/sec#011loss=5.021267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch[575] avg_epoch_loss=5.251038\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, batch=575 train loss <loss>=5.11642522812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:24 INFO 140669025912640] Epoch[14] Batch [575]#011Speed: 1319.51 samples/sec#011loss=5.116425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] processed a total of 18510 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14385.932922363281, \"sum\": 14385.932922363281, \"min\": 14385.932922363281}}, \"EndTime\": 1589393905.033645, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393890.647394}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1286.66516991 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=14, train loss <loss>=5.25187369661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_4bc1e95f-615e-4368-916e-50cef4107fa4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.003089904785156, \"sum\": 10.003089904785156, \"min\": 10.003089904785156}}, \"EndTime\": 1589393905.044064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393905.033709}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[0] avg_epoch_loss=4.723354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=4.72335386276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[5] avg_epoch_loss=5.284225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=5.28422514598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [5]#011Speed: 1667.10 samples/sec#011loss=5.284225\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[10] avg_epoch_loss=5.298456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=5.31553277969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [10]#011Speed: 1100.10 samples/sec#011loss=5.315533\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[15] avg_epoch_loss=5.295440\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=5.2888053894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [15]#011Speed: 1617.93 samples/sec#011loss=5.288805\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[20] avg_epoch_loss=5.309460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=5.35432510376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [20]#011Speed: 1095.09 samples/sec#011loss=5.354325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[25] avg_epoch_loss=5.301707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=5.26914138794\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [25]#011Speed: 1446.65 samples/sec#011loss=5.269141\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[30] avg_epoch_loss=5.292465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=5.24440956116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [30]#011Speed: 1065.15 samples/sec#011loss=5.244410\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch[35] avg_epoch_loss=5.284991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=5.23865003586\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:25 INFO 140669025912640] Epoch[15] Batch [35]#011Speed: 1666.84 samples/sec#011loss=5.238650\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[40] avg_epoch_loss=5.279191\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=5.23743104935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [40]#011Speed: 1065.28 samples/sec#011loss=5.237431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[45] avg_epoch_loss=5.278029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=5.26849946976\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [45]#011Speed: 1625.06 samples/sec#011loss=5.268499\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[50] avg_epoch_loss=5.272560\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=5.22225141525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [50]#011Speed: 1094.88 samples/sec#011loss=5.222251\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[55] avg_epoch_loss=5.266592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=5.20571126938\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [55]#011Speed: 1645.51 samples/sec#011loss=5.205711\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[60] avg_epoch_loss=5.250098\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=5.06537342072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [60]#011Speed: 1663.82 samples/sec#011loss=5.065373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[65] avg_epoch_loss=5.251851\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=5.27323856354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [65]#011Speed: 991.41 samples/sec#011loss=5.273239\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[70] avg_epoch_loss=5.272765\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=5.54881868362\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [70]#011Speed: 1572.65 samples/sec#011loss=5.548819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch[75] avg_epoch_loss=5.270002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=5.23077545166\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:26 INFO 140669025912640] Epoch[15] Batch [75]#011Speed: 1041.69 samples/sec#011loss=5.230775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[80] avg_epoch_loss=5.261507\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=5.13238582611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [80]#011Speed: 1615.18 samples/sec#011loss=5.132386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[85] avg_epoch_loss=5.253752\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=5.12811555862\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [85]#011Speed: 1135.60 samples/sec#011loss=5.128116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[90] avg_epoch_loss=5.262863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=5.41957244873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [90]#011Speed: 1647.53 samples/sec#011loss=5.419572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[95] avg_epoch_loss=5.264431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=5.29296751022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [95]#011Speed: 1143.75 samples/sec#011loss=5.292968\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[100] avg_epoch_loss=5.248328\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=4.93914852142\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [100]#011Speed: 1111.82 samples/sec#011loss=4.939149\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[105] avg_epoch_loss=5.250640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=5.29733638763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [105]#011Speed: 1634.31 samples/sec#011loss=5.297336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[110] avg_epoch_loss=5.259656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=5.45080623627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [110]#011Speed: 1638.17 samples/sec#011loss=5.450806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch[115] avg_epoch_loss=5.266992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=5.42983951569\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:27 INFO 140669025912640] Epoch[15] Batch [115]#011Speed: 1026.87 samples/sec#011loss=5.429840\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[120] avg_epoch_loss=5.271969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=5.38744649887\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [120]#011Speed: 1639.33 samples/sec#011loss=5.387446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[125] avg_epoch_loss=5.269913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=5.22014322281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [125]#011Speed: 1110.29 samples/sec#011loss=5.220143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[130] avg_epoch_loss=5.268606\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=5.23568944931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [130]#011Speed: 1490.09 samples/sec#011loss=5.235689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[135] avg_epoch_loss=5.275031\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=5.4433716774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [135]#011Speed: 1029.04 samples/sec#011loss=5.443372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[140] avg_epoch_loss=5.269882\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=5.12982473373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [140]#011Speed: 1637.05 samples/sec#011loss=5.129825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[145] avg_epoch_loss=5.266010\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=5.15681648254\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [145]#011Speed: 1038.64 samples/sec#011loss=5.156816\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[150] avg_epoch_loss=5.258620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=5.04282226563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [150]#011Speed: 1684.57 samples/sec#011loss=5.042822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch[155] avg_epoch_loss=5.264885\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=5.45407772064\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:28 INFO 140669025912640] Epoch[15] Batch [155]#011Speed: 1022.67 samples/sec#011loss=5.454078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[160] avg_epoch_loss=5.261074\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=5.14217233658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [160]#011Speed: 1673.83 samples/sec#011loss=5.142172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[165] avg_epoch_loss=5.261266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=5.26745634079\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [165]#011Speed: 1075.53 samples/sec#011loss=5.267456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[170] avg_epoch_loss=5.262441\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=5.30145225525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [170]#011Speed: 1692.87 samples/sec#011loss=5.301452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[175] avg_epoch_loss=5.259423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=5.15622787476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [175]#011Speed: 1019.67 samples/sec#011loss=5.156228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[180] avg_epoch_loss=5.252195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=4.99775342941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [180]#011Speed: 1679.67 samples/sec#011loss=4.997753\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[185] avg_epoch_loss=5.250936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=5.20535821915\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [185]#011Speed: 1051.41 samples/sec#011loss=5.205358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[190] avg_epoch_loss=5.253105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=5.33378639221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [190]#011Speed: 1573.90 samples/sec#011loss=5.333786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch[195] avg_epoch_loss=5.250322\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=5.14401893616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:29 INFO 140669025912640] Epoch[15] Batch [195]#011Speed: 1569.00 samples/sec#011loss=5.144019\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[200] avg_epoch_loss=5.258989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=5.59871435165\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [200]#011Speed: 1019.94 samples/sec#011loss=5.598714\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[205] avg_epoch_loss=5.261303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=5.35433616638\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [205]#011Speed: 1661.23 samples/sec#011loss=5.354336\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[210] avg_epoch_loss=5.261707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=5.27835140228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [210]#011Speed: 1037.64 samples/sec#011loss=5.278351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[215] avg_epoch_loss=5.264228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=5.37063465118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [215]#011Speed: 1690.72 samples/sec#011loss=5.370635\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[220] avg_epoch_loss=5.264306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=5.26767482758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [220]#011Speed: 1016.96 samples/sec#011loss=5.267675\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[225] avg_epoch_loss=5.262382\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=5.177348423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [225]#011Speed: 1593.37 samples/sec#011loss=5.177348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[230] avg_epoch_loss=5.262730\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=5.27845478058\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [230]#011Speed: 1066.25 samples/sec#011loss=5.278455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch[235] avg_epoch_loss=5.258645\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=5.06989955902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:30 INFO 140669025912640] Epoch[15] Batch [235]#011Speed: 1704.46 samples/sec#011loss=5.069900\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[240] avg_epoch_loss=5.249258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=4.806204319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [240]#011Speed: 1076.83 samples/sec#011loss=4.806204\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[245] avg_epoch_loss=5.245727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=5.07551431656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [245]#011Speed: 1707.14 samples/sec#011loss=5.075514\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[250] avg_epoch_loss=5.244923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=5.20538520813\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [250]#011Speed: 1031.51 samples/sec#011loss=5.205385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[255] avg_epoch_loss=5.245133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=5.2556435585\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [255]#011Speed: 1610.51 samples/sec#011loss=5.255644\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[260] avg_epoch_loss=5.245176\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=5.24738893509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [260]#011Speed: 1054.23 samples/sec#011loss=5.247389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[265] avg_epoch_loss=5.242701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=5.11350622177\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [265]#011Speed: 1671.92 samples/sec#011loss=5.113506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[270] avg_epoch_loss=5.242187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=270 train loss <loss>=5.2148557663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [270]#011Speed: 946.96 samples/sec#011loss=5.214856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch[275] avg_epoch_loss=5.244589\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=275 train loss <loss>=5.37475013733\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:31 INFO 140669025912640] Epoch[15] Batch [275]#011Speed: 1705.52 samples/sec#011loss=5.374750\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[280] avg_epoch_loss=5.240595\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=280 train loss <loss>=5.02014446259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [280]#011Speed: 942.70 samples/sec#011loss=5.020144\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[285] avg_epoch_loss=5.237162\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=285 train loss <loss>=5.0442486763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [285]#011Speed: 1648.75 samples/sec#011loss=5.044249\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[290] avg_epoch_loss=5.235057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=290 train loss <loss>=5.11461257935\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [290]#011Speed: 1044.88 samples/sec#011loss=5.114613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[295] avg_epoch_loss=5.232048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=295 train loss <loss>=5.05693006516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [295]#011Speed: 1622.08 samples/sec#011loss=5.056930\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[300] avg_epoch_loss=5.230267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=300 train loss <loss>=5.12484540939\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [300]#011Speed: 1006.94 samples/sec#011loss=5.124845\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[305] avg_epoch_loss=5.230996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=305 train loss <loss>=5.27491197586\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [305]#011Speed: 1591.01 samples/sec#011loss=5.274912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[310] avg_epoch_loss=5.227603\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=310 train loss <loss>=5.01993350983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [310]#011Speed: 1099.61 samples/sec#011loss=5.019934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch[315] avg_epoch_loss=5.226269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=315 train loss <loss>=5.14331884384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:32 INFO 140669025912640] Epoch[15] Batch [315]#011Speed: 1655.35 samples/sec#011loss=5.143319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[320] avg_epoch_loss=5.222548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=320 train loss <loss>=4.98733434677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [320]#011Speed: 1056.71 samples/sec#011loss=4.987334\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[325] avg_epoch_loss=5.224045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=325 train loss <loss>=5.3201376915\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [325]#011Speed: 1639.24 samples/sec#011loss=5.320138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[330] avg_epoch_loss=5.225414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=330 train loss <loss>=5.31473112106\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [330]#011Speed: 1088.06 samples/sec#011loss=5.314731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[335] avg_epoch_loss=5.226898\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=335 train loss <loss>=5.32511091232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [335]#011Speed: 1490.06 samples/sec#011loss=5.325111\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[340] avg_epoch_loss=5.226599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=340 train loss <loss>=5.20650243759\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [340]#011Speed: 971.31 samples/sec#011loss=5.206502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[345] avg_epoch_loss=5.226438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=345 train loss <loss>=5.21547803879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [345]#011Speed: 1642.07 samples/sec#011loss=5.215478\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[350] avg_epoch_loss=5.227527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=350 train loss <loss>=5.30286922455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [350]#011Speed: 1016.07 samples/sec#011loss=5.302869\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch[355] avg_epoch_loss=5.224251\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=355 train loss <loss>=4.99430971146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:33 INFO 140669025912640] Epoch[15] Batch [355]#011Speed: 1652.38 samples/sec#011loss=4.994310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[360] avg_epoch_loss=5.223418\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=360 train loss <loss>=5.16404752731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [360]#011Speed: 1663.15 samples/sec#011loss=5.164048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[365] avg_epoch_loss=5.220834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=365 train loss <loss>=5.03431119919\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [365]#011Speed: 1065.96 samples/sec#011loss=5.034311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[370] avg_epoch_loss=5.218966\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=370 train loss <loss>=5.08221950531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [370]#011Speed: 1590.62 samples/sec#011loss=5.082220\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[375] avg_epoch_loss=5.218855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=375 train loss <loss>=5.21059217453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [375]#011Speed: 1039.70 samples/sec#011loss=5.210592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[380] avg_epoch_loss=5.214852\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=380 train loss <loss>=4.91383333206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [380]#011Speed: 1655.03 samples/sec#011loss=4.913833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[385] avg_epoch_loss=5.217737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=385 train loss <loss>=5.43759336472\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [385]#011Speed: 1018.82 samples/sec#011loss=5.437593\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[390] avg_epoch_loss=5.218789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=390 train loss <loss>=5.29997053146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [390]#011Speed: 1633.19 samples/sec#011loss=5.299971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch[395] avg_epoch_loss=5.218960\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=395 train loss <loss>=5.23238706589\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:34 INFO 140669025912640] Epoch[15] Batch [395]#011Speed: 1094.30 samples/sec#011loss=5.232387\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[400] avg_epoch_loss=5.219054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=400 train loss <loss>=5.22645750046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [400]#011Speed: 1639.31 samples/sec#011loss=5.226458\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[405] avg_epoch_loss=5.218489\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=405 train loss <loss>=5.17322006226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [405]#011Speed: 1120.57 samples/sec#011loss=5.173220\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[410] avg_epoch_loss=5.216412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=410 train loss <loss>=5.0477640152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [410]#011Speed: 1613.73 samples/sec#011loss=5.047764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[415] avg_epoch_loss=5.215570\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=415 train loss <loss>=5.14635658264\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [415]#011Speed: 1110.58 samples/sec#011loss=5.146357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[420] avg_epoch_loss=5.214833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=420 train loss <loss>=5.15343980789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [420]#011Speed: 1597.08 samples/sec#011loss=5.153440\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[425] avg_epoch_loss=5.212899\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=425 train loss <loss>=5.05013637543\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [425]#011Speed: 1123.29 samples/sec#011loss=5.050136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[430] avg_epoch_loss=5.213506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=430 train loss <loss>=5.26521997452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [430]#011Speed: 1485.35 samples/sec#011loss=5.265220\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch[435] avg_epoch_loss=5.214411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=435 train loss <loss>=5.29236402512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:35 INFO 140669025912640] Epoch[15] Batch [435]#011Speed: 1075.05 samples/sec#011loss=5.292364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[440] avg_epoch_loss=5.213729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=440 train loss <loss>=5.15424757004\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [440]#011Speed: 1645.14 samples/sec#011loss=5.154248\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[445] avg_epoch_loss=5.212535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=445 train loss <loss>=5.10725889206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [445]#011Speed: 1098.39 samples/sec#011loss=5.107259\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[450] avg_epoch_loss=5.212487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=450 train loss <loss>=5.20823001862\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [450]#011Speed: 1645.37 samples/sec#011loss=5.208230\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[455] avg_epoch_loss=5.212080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=455 train loss <loss>=5.17529745102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [455]#011Speed: 1077.37 samples/sec#011loss=5.175297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[460] avg_epoch_loss=5.211103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=460 train loss <loss>=5.12199831009\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [460]#011Speed: 1503.01 samples/sec#011loss=5.121998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[465] avg_epoch_loss=5.211246\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=465 train loss <loss>=5.22445430756\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [465]#011Speed: 1040.43 samples/sec#011loss=5.224454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[470] avg_epoch_loss=5.210955\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=470 train loss <loss>=5.18389587402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [470]#011Speed: 1471.60 samples/sec#011loss=5.183896\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch[475] avg_epoch_loss=5.210175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=475 train loss <loss>=5.1366900444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:36 INFO 140669025912640] Epoch[15] Batch [475]#011Speed: 983.94 samples/sec#011loss=5.136690\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[480] avg_epoch_loss=5.212745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=480 train loss <loss>=5.4573841095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [480]#011Speed: 1653.90 samples/sec#011loss=5.457384\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[485] avg_epoch_loss=5.212227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=485 train loss <loss>=5.16237154007\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [485]#011Speed: 1068.44 samples/sec#011loss=5.162372\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[490] avg_epoch_loss=5.213512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=490 train loss <loss>=5.33845996857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [490]#011Speed: 1618.04 samples/sec#011loss=5.338460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[495] avg_epoch_loss=5.213785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=495 train loss <loss>=5.24060983658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [495]#011Speed: 1080.45 samples/sec#011loss=5.240610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[500] avg_epoch_loss=5.217293\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=500 train loss <loss>=5.56521520615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [500]#011Speed: 1636.01 samples/sec#011loss=5.565215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[505] avg_epoch_loss=5.216811\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=505 train loss <loss>=5.16856269836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [505]#011Speed: 1031.57 samples/sec#011loss=5.168563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[510] avg_epoch_loss=5.214049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=510 train loss <loss>=4.93455619812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [510]#011Speed: 1568.49 samples/sec#011loss=4.934556\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch[515] avg_epoch_loss=5.216046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=515 train loss <loss>=5.4201218605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:37 INFO 140669025912640] Epoch[15] Batch [515]#011Speed: 1667.78 samples/sec#011loss=5.420122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[520] avg_epoch_loss=5.215454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=520 train loss <loss>=5.15428791046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [520]#011Speed: 1054.95 samples/sec#011loss=5.154288\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[525] avg_epoch_loss=5.213364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=525 train loss <loss>=4.99562988281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [525]#011Speed: 1636.71 samples/sec#011loss=4.995630\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[530] avg_epoch_loss=5.213187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=530 train loss <loss>=5.19460668564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [530]#011Speed: 1088.74 samples/sec#011loss=5.194607\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[535] avg_epoch_loss=5.216311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=535 train loss <loss>=5.54804983139\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [535]#011Speed: 1519.97 samples/sec#011loss=5.548050\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[540] avg_epoch_loss=5.213654\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=540 train loss <loss>=4.92886095047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [540]#011Speed: 1056.31 samples/sec#011loss=4.928861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[545] avg_epoch_loss=5.212527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=545 train loss <loss>=5.09055080414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [545]#011Speed: 1678.28 samples/sec#011loss=5.090551\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[550] avg_epoch_loss=5.215319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=550 train loss <loss>=5.52015619278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [550]#011Speed: 1077.08 samples/sec#011loss=5.520156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch[555] avg_epoch_loss=5.212486\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=555 train loss <loss>=4.90035581589\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:38 INFO 140669025912640] Epoch[15] Batch [555]#011Speed: 1643.50 samples/sec#011loss=4.900356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch[560] avg_epoch_loss=5.213511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=560 train loss <loss>=5.32747344971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch [560]#011Speed: 1108.55 samples/sec#011loss=5.327473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch[565] avg_epoch_loss=5.212510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=565 train loss <loss>=5.1001534462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch [565]#011Speed: 1658.05 samples/sec#011loss=5.100153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch[570] avg_epoch_loss=5.213108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=570 train loss <loss>=5.2808552742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch [570]#011Speed: 1130.52 samples/sec#011loss=5.280855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch[575] avg_epoch_loss=5.210663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, batch=575 train loss <loss>=4.9314622879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[15] Batch [575]#011Speed: 1640.69 samples/sec#011loss=4.931462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] processed a total of 18430 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14330.47890663147, \"sum\": 14330.47890663147, \"min\": 14330.47890663147}}, \"EndTime\": 1589393919.374666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393905.04413}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1286.0626233 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=15, train loss <loss>=5.21066332195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_b9f0d4f6-3f92-426d-8cb5-b8c6eceb9c4a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.7127685546875, \"sum\": 8.7127685546875, \"min\": 8.7127685546875}}, \"EndTime\": 1589393919.383784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393919.374718}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch[0] avg_epoch_loss=5.215448\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=5.21544790268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch[5] avg_epoch_loss=4.988353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=4.98835277557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch [5]#011Speed: 1658.62 samples/sec#011loss=4.988353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch[10] avg_epoch_loss=5.034944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=5.09085330963\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch [10]#011Speed: 1583.58 samples/sec#011loss=5.090853\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch[15] avg_epoch_loss=5.041778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=5.05681190491\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch [15]#011Speed: 988.73 samples/sec#011loss=5.056812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch[20] avg_epoch_loss=5.084147\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=5.21972961426\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:39 INFO 140669025912640] Epoch[16] Batch [20]#011Speed: 1612.72 samples/sec#011loss=5.219730\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[25] avg_epoch_loss=5.108996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=5.21335935593\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [25]#011Speed: 1065.29 samples/sec#011loss=5.213359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[30] avg_epoch_loss=5.101531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=5.06271324158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [30]#011Speed: 1609.11 samples/sec#011loss=5.062713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[35] avg_epoch_loss=5.082345\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=4.96339302063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [35]#011Speed: 1076.06 samples/sec#011loss=4.963393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[40] avg_epoch_loss=5.095901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=5.19350738525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [40]#011Speed: 1635.81 samples/sec#011loss=5.193507\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[45] avg_epoch_loss=5.099902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=5.1327082634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [45]#011Speed: 1094.22 samples/sec#011loss=5.132708\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[50] avg_epoch_loss=5.111640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=5.21962709427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [50]#011Speed: 1493.61 samples/sec#011loss=5.219627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[55] avg_epoch_loss=5.119304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=5.19747467041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [55]#011Speed: 1089.59 samples/sec#011loss=5.197475\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch[60] avg_epoch_loss=5.138641\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=5.35521354675\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:40 INFO 140669025912640] Epoch[16] Batch [60]#011Speed: 1634.27 samples/sec#011loss=5.355214\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[65] avg_epoch_loss=5.146571\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=5.24331912994\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [65]#011Speed: 1121.72 samples/sec#011loss=5.243319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[70] avg_epoch_loss=5.153235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=5.24119758606\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [70]#011Speed: 1627.67 samples/sec#011loss=5.241198\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[75] avg_epoch_loss=5.163062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=5.30261354446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [75]#011Speed: 1116.31 samples/sec#011loss=5.302614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[80] avg_epoch_loss=5.150636\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=4.96175918579\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [80]#011Speed: 1649.28 samples/sec#011loss=4.961759\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[85] avg_epoch_loss=5.138154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=4.93594522476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [85]#011Speed: 1072.46 samples/sec#011loss=4.935945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[90] avg_epoch_loss=5.137474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=5.12577552795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [90]#011Speed: 1645.38 samples/sec#011loss=5.125776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[95] avg_epoch_loss=5.136873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=5.12593173981\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [95]#011Speed: 1077.01 samples/sec#011loss=5.125932\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch[100] avg_epoch_loss=5.139778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=5.1955616951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:41 INFO 140669025912640] Epoch[16] Batch [100]#011Speed: 1461.33 samples/sec#011loss=5.195562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[105] avg_epoch_loss=5.151618\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=5.39078178406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [105]#011Speed: 1103.46 samples/sec#011loss=5.390782\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[110] avg_epoch_loss=5.158865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=5.31251039505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [110]#011Speed: 1640.30 samples/sec#011loss=5.312510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[115] avg_epoch_loss=5.158977\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=5.1614610672\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [115]#011Speed: 1085.76 samples/sec#011loss=5.161461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[120] avg_epoch_loss=5.163087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=5.25842399597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [120]#011Speed: 1519.71 samples/sec#011loss=5.258424\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[125] avg_epoch_loss=5.162937\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=5.15930595398\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [125]#011Speed: 1455.10 samples/sec#011loss=5.159306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[130] avg_epoch_loss=5.169655\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=5.33895139694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [130]#011Speed: 1062.52 samples/sec#011loss=5.338951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[135] avg_epoch_loss=5.174659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=5.30575942993\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [135]#011Speed: 1608.46 samples/sec#011loss=5.305759\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[140] avg_epoch_loss=5.166076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=4.93263950348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [140]#011Speed: 1110.09 samples/sec#011loss=4.932640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch[145] avg_epoch_loss=5.165574\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=5.15139455795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:42 INFO 140669025912640] Epoch[16] Batch [145]#011Speed: 1597.32 samples/sec#011loss=5.151395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[150] avg_epoch_loss=5.165024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=5.14899110794\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [150]#011Speed: 1124.25 samples/sec#011loss=5.148991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[155] avg_epoch_loss=5.165471\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=5.17894268036\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [155]#011Speed: 1103.49 samples/sec#011loss=5.178943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[160] avg_epoch_loss=5.162822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=5.08020219803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [160]#011Speed: 1651.32 samples/sec#011loss=5.080202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[165] avg_epoch_loss=5.164019\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=5.20255241394\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [165]#011Speed: 1594.15 samples/sec#011loss=5.202552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[170] avg_epoch_loss=5.169001\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=5.33439912796\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [170]#011Speed: 1016.13 samples/sec#011loss=5.334399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[175] avg_epoch_loss=5.171838\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=5.26886711121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [175]#011Speed: 1550.22 samples/sec#011loss=5.268867\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[180] avg_epoch_loss=5.173200\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=5.22113676071\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [180]#011Speed: 1013.43 samples/sec#011loss=5.221137\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch[185] avg_epoch_loss=5.173677\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=5.19095878601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:43 INFO 140669025912640] Epoch[16] Batch [185]#011Speed: 1656.95 samples/sec#011loss=5.190959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[190] avg_epoch_loss=5.170104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=5.03717985153\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [190]#011Speed: 1099.55 samples/sec#011loss=5.037180\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[195] avg_epoch_loss=5.170495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=5.18542470932\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [195]#011Speed: 1640.44 samples/sec#011loss=5.185425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[200] avg_epoch_loss=5.170116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=5.1552819252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [200]#011Speed: 1078.99 samples/sec#011loss=5.155282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[205] avg_epoch_loss=5.168959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=5.12242193222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [205]#011Speed: 1429.04 samples/sec#011loss=5.122422\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[210] avg_epoch_loss=5.169509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=5.19218463898\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [210]#011Speed: 1023.86 samples/sec#011loss=5.192185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[215] avg_epoch_loss=5.175090\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=5.41059370041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [215]#011Speed: 1616.11 samples/sec#011loss=5.410594\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[220] avg_epoch_loss=5.181268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=5.44818000793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [220]#011Speed: 1083.40 samples/sec#011loss=5.448180\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch[225] avg_epoch_loss=5.185731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=5.38298101425\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:44 INFO 140669025912640] Epoch[16] Batch [225]#011Speed: 1648.13 samples/sec#011loss=5.382981\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[230] avg_epoch_loss=5.186957\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=5.24238996506\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [230]#011Speed: 1088.28 samples/sec#011loss=5.242390\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[235] avg_epoch_loss=5.186894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=5.18394031525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [235]#011Speed: 1604.98 samples/sec#011loss=5.183940\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[240] avg_epoch_loss=5.188663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=5.27217102051\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [240]#011Speed: 1018.72 samples/sec#011loss=5.272171\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[245] avg_epoch_loss=5.192033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=5.35445947647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [245]#011Speed: 1677.46 samples/sec#011loss=5.354459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[250] avg_epoch_loss=5.184533\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=4.81554374695\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [250]#011Speed: 1051.80 samples/sec#011loss=4.815544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[255] avg_epoch_loss=5.186303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=5.27518157959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [255]#011Speed: 1543.50 samples/sec#011loss=5.275182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch[260] avg_epoch_loss=5.181850\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=4.95381937027\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:45 INFO 140669025912640] Epoch[16] Batch [260]#011Speed: 1065.55 samples/sec#011loss=4.953819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[265] avg_epoch_loss=5.184680\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=5.33241672516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [265]#011Speed: 1657.34 samples/sec#011loss=5.332417\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[270] avg_epoch_loss=5.186393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=270 train loss <loss>=5.27753343582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [270]#011Speed: 1475.08 samples/sec#011loss=5.277533\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[275] avg_epoch_loss=5.186844\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=275 train loss <loss>=5.21129674911\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [275]#011Speed: 1000.59 samples/sec#011loss=5.211297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[280] avg_epoch_loss=5.188206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=280 train loss <loss>=5.26336479187\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [280]#011Speed: 1531.64 samples/sec#011loss=5.263365\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[285] avg_epoch_loss=5.194373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=285 train loss <loss>=5.54096021652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [285]#011Speed: 994.28 samples/sec#011loss=5.540960\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[290] avg_epoch_loss=5.194824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=290 train loss <loss>=5.22065324783\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [290]#011Speed: 1661.56 samples/sec#011loss=5.220653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[295] avg_epoch_loss=5.195062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=295 train loss <loss>=5.20889148712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [295]#011Speed: 1026.89 samples/sec#011loss=5.208891\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch[300] avg_epoch_loss=5.195990\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=300 train loss <loss>=5.25093307495\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:46 INFO 140669025912640] Epoch[16] Batch [300]#011Speed: 1663.94 samples/sec#011loss=5.250933\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[305] avg_epoch_loss=5.196639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=305 train loss <loss>=5.23570251465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [305]#011Speed: 1049.43 samples/sec#011loss=5.235703\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[310] avg_epoch_loss=5.199768\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=310 train loss <loss>=5.39127197266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [310]#011Speed: 1674.78 samples/sec#011loss=5.391272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[315] avg_epoch_loss=5.202272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=315 train loss <loss>=5.35802850723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [315]#011Speed: 1029.62 samples/sec#011loss=5.358029\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[320] avg_epoch_loss=5.203624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=320 train loss <loss>=5.28909015656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [320]#011Speed: 1670.50 samples/sec#011loss=5.289090\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[325] avg_epoch_loss=5.206301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=325 train loss <loss>=5.37810440063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [325]#011Speed: 1079.99 samples/sec#011loss=5.378104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[330] avg_epoch_loss=5.210326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=330 train loss <loss>=5.47280292511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [330]#011Speed: 1679.05 samples/sec#011loss=5.472803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[335] avg_epoch_loss=5.210991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=335 train loss <loss>=5.25497131348\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [335]#011Speed: 1023.34 samples/sec#011loss=5.254971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch[340] avg_epoch_loss=5.211620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=340 train loss <loss>=5.25390357971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:47 INFO 140669025912640] Epoch[16] Batch [340]#011Speed: 1665.99 samples/sec#011loss=5.253904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[345] avg_epoch_loss=5.210356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=345 train loss <loss>=5.12413291931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [345]#011Speed: 993.79 samples/sec#011loss=5.124133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[350] avg_epoch_loss=5.211398\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=350 train loss <loss>=5.28354463577\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [350]#011Speed: 1668.63 samples/sec#011loss=5.283545\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[355] avg_epoch_loss=5.210058\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=355 train loss <loss>=5.11597595215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [355]#011Speed: 1079.54 samples/sec#011loss=5.115976\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[360] avg_epoch_loss=5.208547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=360 train loss <loss>=5.10094232559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [360]#011Speed: 1681.36 samples/sec#011loss=5.100942\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[365] avg_epoch_loss=5.209944\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=365 train loss <loss>=5.31080274582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [365]#011Speed: 1037.83 samples/sec#011loss=5.310803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[370] avg_epoch_loss=5.209113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=370 train loss <loss>=5.14831552505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [370]#011Speed: 1662.16 samples/sec#011loss=5.148316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[375] avg_epoch_loss=5.209095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=375 train loss <loss>=5.20772886276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [375]#011Speed: 1039.91 samples/sec#011loss=5.207729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch[380] avg_epoch_loss=5.204518\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=380 train loss <loss>=4.86035232544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:48 INFO 140669025912640] Epoch[16] Batch [380]#011Speed: 1421.96 samples/sec#011loss=4.860352\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[385] avg_epoch_loss=5.204684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=385 train loss <loss>=5.21735334396\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [385]#011Speed: 1055.80 samples/sec#011loss=5.217353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[390] avg_epoch_loss=5.204509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=390 train loss <loss>=5.19095039368\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [390]#011Speed: 1649.58 samples/sec#011loss=5.190950\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[395] avg_epoch_loss=5.205487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=395 train loss <loss>=5.28202419281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [395]#011Speed: 1104.85 samples/sec#011loss=5.282024\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[400] avg_epoch_loss=5.205651\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=400 train loss <loss>=5.21864719391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [400]#011Speed: 1637.08 samples/sec#011loss=5.218647\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[405] avg_epoch_loss=5.205482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=405 train loss <loss>=5.19191131592\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [405]#011Speed: 1659.79 samples/sec#011loss=5.191911\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[410] avg_epoch_loss=5.204128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=410 train loss <loss>=5.09419307709\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [410]#011Speed: 1134.53 samples/sec#011loss=5.094193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[415] avg_epoch_loss=5.201717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=415 train loss <loss>=5.00349197388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [415]#011Speed: 1113.28 samples/sec#011loss=5.003492\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch[420] avg_epoch_loss=5.200774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=420 train loss <loss>=5.12235107422\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:49 INFO 140669025912640] Epoch[16] Batch [420]#011Speed: 1472.51 samples/sec#011loss=5.122351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[425] avg_epoch_loss=5.198626\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=425 train loss <loss>=5.01777362823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [425]#011Speed: 1062.67 samples/sec#011loss=5.017774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[430] avg_epoch_loss=5.198729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=430 train loss <loss>=5.2074514389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [430]#011Speed: 1669.24 samples/sec#011loss=5.207451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[435] avg_epoch_loss=5.194871\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=435 train loss <loss>=4.86235866547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [435]#011Speed: 1096.45 samples/sec#011loss=4.862359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[440] avg_epoch_loss=5.196389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=440 train loss <loss>=5.32876882553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [440]#011Speed: 1662.82 samples/sec#011loss=5.328769\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[445] avg_epoch_loss=5.193914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=445 train loss <loss>=4.9756187439\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [445]#011Speed: 1653.36 samples/sec#011loss=4.975619\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[450] avg_epoch_loss=5.194603\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=450 train loss <loss>=5.25604667664\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [450]#011Speed: 1084.84 samples/sec#011loss=5.256047\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[455] avg_epoch_loss=5.193548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=455 train loss <loss>=5.09839935303\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [455]#011Speed: 1598.50 samples/sec#011loss=5.098399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[460] avg_epoch_loss=5.192563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=460 train loss <loss>=5.1027261734\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [460]#011Speed: 1021.41 samples/sec#011loss=5.102726\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch[465] avg_epoch_loss=5.191487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=465 train loss <loss>=5.09226360321\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:50 INFO 140669025912640] Epoch[16] Batch [465]#011Speed: 1648.98 samples/sec#011loss=5.092264\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[470] avg_epoch_loss=5.191355\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=470 train loss <loss>=5.17902584076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [470]#011Speed: 1127.51 samples/sec#011loss=5.179026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[475] avg_epoch_loss=5.188945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=475 train loss <loss>=4.96192522049\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [475]#011Speed: 1668.35 samples/sec#011loss=4.961925\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[480] avg_epoch_loss=5.189760\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=480 train loss <loss>=5.26732597351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [480]#011Speed: 1093.11 samples/sec#011loss=5.267326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[485] avg_epoch_loss=5.192661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=485 train loss <loss>=5.47174730301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [485]#011Speed: 1653.28 samples/sec#011loss=5.471747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[490] avg_epoch_loss=5.192815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=490 train loss <loss>=5.20776176453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [490]#011Speed: 1125.74 samples/sec#011loss=5.207762\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[495] avg_epoch_loss=5.192325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=495 train loss <loss>=5.14427146912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [495]#011Speed: 1677.89 samples/sec#011loss=5.144271\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[500] avg_epoch_loss=5.192257\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=500 train loss <loss>=5.18553409576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [500]#011Speed: 1093.18 samples/sec#011loss=5.185534\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch[505] avg_epoch_loss=5.192207\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=505 train loss <loss>=5.1871427536\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:51 INFO 140669025912640] Epoch[16] Batch [505]#011Speed: 1655.87 samples/sec#011loss=5.187143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[510] avg_epoch_loss=5.189284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=510 train loss <loss>=4.89348716736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [510]#011Speed: 959.47 samples/sec#011loss=4.893487\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[515] avg_epoch_loss=5.189038\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=515 train loss <loss>=5.1639172554\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [515]#011Speed: 1411.92 samples/sec#011loss=5.163917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[520] avg_epoch_loss=5.189351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=520 train loss <loss>=5.22165231705\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [520]#011Speed: 1101.17 samples/sec#011loss=5.221652\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[525] avg_epoch_loss=5.189546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=525 train loss <loss>=5.2098695755\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [525]#011Speed: 1639.19 samples/sec#011loss=5.209870\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[530] avg_epoch_loss=5.189392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=530 train loss <loss>=5.1732211113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [530]#011Speed: 1025.60 samples/sec#011loss=5.173221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[535] avg_epoch_loss=5.188697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=535 train loss <loss>=5.11488275528\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [535]#011Speed: 1606.81 samples/sec#011loss=5.114883\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[540] avg_epoch_loss=5.187976\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=540 train loss <loss>=5.1106803894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [540]#011Speed: 1045.89 samples/sec#011loss=5.110680\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch[545] avg_epoch_loss=5.185613\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=545 train loss <loss>=4.92985925674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:52 INFO 140669025912640] Epoch[16] Batch [545]#011Speed: 1665.19 samples/sec#011loss=4.929859\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[550] avg_epoch_loss=5.185805\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=550 train loss <loss>=5.20682039261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [550]#011Speed: 1002.53 samples/sec#011loss=5.206820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[555] avg_epoch_loss=5.185663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=555 train loss <loss>=5.16996917725\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [555]#011Speed: 1649.89 samples/sec#011loss=5.169969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[560] avg_epoch_loss=5.184275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=560 train loss <loss>=5.02991371155\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [560]#011Speed: 1680.21 samples/sec#011loss=5.029914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[565] avg_epoch_loss=5.181451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=565 train loss <loss>=4.86469936371\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [565]#011Speed: 1094.50 samples/sec#011loss=4.864699\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[570] avg_epoch_loss=5.182747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=570 train loss <loss>=5.32934703827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [570]#011Speed: 1620.15 samples/sec#011loss=5.329347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[575] avg_epoch_loss=5.181324\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=575 train loss <loss>=5.01888122559\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [575]#011Speed: 1214.76 samples/sec#011loss=5.018881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch[580] avg_epoch_loss=5.177326\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, batch=580 train loss <loss>=4.71676368713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[16] Batch [580]#011Speed: 1641.65 samples/sec#011loss=4.716764\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] processed a total of 18563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14398.053884506226, \"sum\": 14398.053884506226, \"min\": 14398.053884506226}}, \"EndTime\": 1589393933.781946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393919.383833}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1289.26341469 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=16, train loss <loss>=5.17732615151\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_7469d908-9e34-4deb-88f3-33c4ab3d4676-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.071039199829102, \"sum\": 10.071039199829102, \"min\": 10.071039199829102}}, \"EndTime\": 1589393933.792384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393933.782005}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[17] Batch[0] avg_epoch_loss=5.026625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=5.02662467957\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[17] Batch[5] avg_epoch_loss=5.107736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=5.10773555438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:53 INFO 140669025912640] Epoch[17] Batch [5]#011Speed: 1661.65 samples/sec#011loss=5.107736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[10] avg_epoch_loss=5.157137\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=5.2164182663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [10]#011Speed: 1570.03 samples/sec#011loss=5.216418\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[15] avg_epoch_loss=5.157311\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=5.15769433975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [15]#011Speed: 1026.53 samples/sec#011loss=5.157694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[20] avg_epoch_loss=5.090740\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=4.87771224976\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [20]#011Speed: 1625.01 samples/sec#011loss=4.877712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[25] avg_epoch_loss=5.083386\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=5.05250005722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [25]#011Speed: 1017.61 samples/sec#011loss=5.052500\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[30] avg_epoch_loss=5.095610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=5.15917482376\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [30]#011Speed: 1662.67 samples/sec#011loss=5.159175\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[35] avg_epoch_loss=5.111739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=5.21173524857\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [35]#011Speed: 976.35 samples/sec#011loss=5.211735\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[40] avg_epoch_loss=5.136594\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=5.3155503273\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [40]#011Speed: 1595.00 samples/sec#011loss=5.315550\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch[45] avg_epoch_loss=5.152183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=5.2800113678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:54 INFO 140669025912640] Epoch[17] Batch [45]#011Speed: 1140.25 samples/sec#011loss=5.280011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[50] avg_epoch_loss=5.153123\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=5.16177511215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [50]#011Speed: 1466.20 samples/sec#011loss=5.161775\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[55] avg_epoch_loss=5.141285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=5.02054195404\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [55]#011Speed: 995.54 samples/sec#011loss=5.020542\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[60] avg_epoch_loss=5.161517\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=5.38810758591\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [60]#011Speed: 1607.46 samples/sec#011loss=5.388108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[65] avg_epoch_loss=5.187278\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=5.50156030655\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [65]#011Speed: 1002.14 samples/sec#011loss=5.501560\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[70] avg_epoch_loss=5.183929\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=5.13972654343\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [70]#011Speed: 1692.40 samples/sec#011loss=5.139727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[75] avg_epoch_loss=5.173825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=5.03034181595\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [75]#011Speed: 1072.80 samples/sec#011loss=5.030342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch[80] avg_epoch_loss=5.179569\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=5.26689291\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:55 INFO 140669025912640] Epoch[17] Batch [80]#011Speed: 1577.10 samples/sec#011loss=5.266893\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[85] avg_epoch_loss=5.178616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=5.16316976547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [85]#011Speed: 1059.86 samples/sec#011loss=5.163170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[90] avg_epoch_loss=5.186736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=5.32640552521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [90]#011Speed: 1659.48 samples/sec#011loss=5.326406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[95] avg_epoch_loss=5.181788\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=5.09173231125\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [95]#011Speed: 1079.66 samples/sec#011loss=5.091732\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[100] avg_epoch_loss=5.178953\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=5.12450895309\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [100]#011Speed: 1642.37 samples/sec#011loss=5.124509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[105] avg_epoch_loss=5.185684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=5.32166166306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [105]#011Speed: 1643.58 samples/sec#011loss=5.321662\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[110] avg_epoch_loss=5.182879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=5.12340631485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [110]#011Speed: 1078.36 samples/sec#011loss=5.123406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[115] avg_epoch_loss=5.188300\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=5.30864887238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [115]#011Speed: 1653.92 samples/sec#011loss=5.308649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[120] avg_epoch_loss=5.191739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=5.27152204514\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [120]#011Speed: 1118.44 samples/sec#011loss=5.271522\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch[125] avg_epoch_loss=5.181283\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=4.92823991776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:56 INFO 140669025912640] Epoch[17] Batch [125]#011Speed: 1640.02 samples/sec#011loss=4.928240\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[130] avg_epoch_loss=5.189238\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=5.38971719742\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [130]#011Speed: 1110.83 samples/sec#011loss=5.389717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[135] avg_epoch_loss=5.194738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=5.33882398605\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [135]#011Speed: 1648.19 samples/sec#011loss=5.338824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[140] avg_epoch_loss=5.190701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=5.08090181351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [140]#011Speed: 1119.21 samples/sec#011loss=5.080902\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[145] avg_epoch_loss=5.196234\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=5.35226860046\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [145]#011Speed: 1631.85 samples/sec#011loss=5.352269\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[150] avg_epoch_loss=5.194312\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=5.13818502426\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [150]#011Speed: 1016.11 samples/sec#011loss=5.138185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[155] avg_epoch_loss=5.194762\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=5.20835590363\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [155]#011Speed: 1650.18 samples/sec#011loss=5.208356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[160] avg_epoch_loss=5.202077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=5.43030996323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [160]#011Speed: 1108.99 samples/sec#011loss=5.430310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch[165] avg_epoch_loss=5.197743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=5.05817899704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:57 INFO 140669025912640] Epoch[17] Batch [165]#011Speed: 1614.60 samples/sec#011loss=5.058179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[170] avg_epoch_loss=5.198952\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=5.23910303116\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [170]#011Speed: 1073.21 samples/sec#011loss=5.239103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[175] avg_epoch_loss=5.199449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=5.21642417908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [175]#011Speed: 1493.39 samples/sec#011loss=5.216424\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[180] avg_epoch_loss=5.197655\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=5.13452148438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [180]#011Speed: 1058.54 samples/sec#011loss=5.134521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[185] avg_epoch_loss=5.197453\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=5.19013080597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [185]#011Speed: 1651.03 samples/sec#011loss=5.190131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[190] avg_epoch_loss=5.202182\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=5.37810192108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [190]#011Speed: 989.12 samples/sec#011loss=5.378102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[195] avg_epoch_loss=5.197468\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=5.01738777161\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [195]#011Speed: 1614.76 samples/sec#011loss=5.017388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[200] avg_epoch_loss=5.200277\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=5.31040887833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [200]#011Speed: 1066.18 samples/sec#011loss=5.310409\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch[205] avg_epoch_loss=5.199157\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=5.15411310196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:58 INFO 140669025912640] Epoch[17] Batch [205]#011Speed: 1649.40 samples/sec#011loss=5.154113\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[210] avg_epoch_loss=5.200874\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=5.27162370682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [210]#011Speed: 1048.53 samples/sec#011loss=5.271624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[215] avg_epoch_loss=5.194540\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=4.92724714279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [215]#011Speed: 1616.93 samples/sec#011loss=4.927247\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[220] avg_epoch_loss=5.193984\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=5.16995573044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [220]#011Speed: 1043.54 samples/sec#011loss=5.169956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[225] avg_epoch_loss=5.191920\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=5.10071659088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [225]#011Speed: 1652.17 samples/sec#011loss=5.100717\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[230] avg_epoch_loss=5.194342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=5.30380430222\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [230]#011Speed: 1136.88 samples/sec#011loss=5.303804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[235] avg_epoch_loss=5.193880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=5.17252902985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [235]#011Speed: 1672.17 samples/sec#011loss=5.172529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[240] avg_epoch_loss=5.192122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=5.10914011002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [240]#011Speed: 1142.42 samples/sec#011loss=5.109140\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch[245] avg_epoch_loss=5.191240\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=5.14873161316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:18:59 INFO 140669025912640] Epoch[17] Batch [245]#011Speed: 1623.36 samples/sec#011loss=5.148732\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[250] avg_epoch_loss=5.187585\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=5.00775156021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [250]#011Speed: 1020.90 samples/sec#011loss=5.007752\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[255] avg_epoch_loss=5.185324\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=5.07185811996\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [255]#011Speed: 1665.71 samples/sec#011loss=5.071858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[260] avg_epoch_loss=5.185072\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=5.1721575737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [260]#011Speed: 1089.81 samples/sec#011loss=5.172158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[265] avg_epoch_loss=5.184406\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=5.14963054657\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [265]#011Speed: 1652.99 samples/sec#011loss=5.149631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[270] avg_epoch_loss=5.183628\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=270 train loss <loss>=5.14223623276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [270]#011Speed: 1000.39 samples/sec#011loss=5.142236\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[275] avg_epoch_loss=5.183456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=275 train loss <loss>=5.17411813736\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [275]#011Speed: 1665.87 samples/sec#011loss=5.174118\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[280] avg_epoch_loss=5.180069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=280 train loss <loss>=4.99311447144\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [280]#011Speed: 1096.29 samples/sec#011loss=4.993114\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch[285] avg_epoch_loss=5.175620\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=285 train loss <loss>=4.92561721802\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:00 INFO 140669025912640] Epoch[17] Batch [285]#011Speed: 1629.51 samples/sec#011loss=4.925617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[290] avg_epoch_loss=5.179231\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=290 train loss <loss>=5.38573188782\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [290]#011Speed: 1100.71 samples/sec#011loss=5.385732\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[295] avg_epoch_loss=5.180393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=295 train loss <loss>=5.248021698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [295]#011Speed: 1671.75 samples/sec#011loss=5.248022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[300] avg_epoch_loss=5.183131\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=300 train loss <loss>=5.34527521133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [300]#011Speed: 1059.27 samples/sec#011loss=5.345275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[305] avg_epoch_loss=5.183268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=305 train loss <loss>=5.1915017128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [305]#011Speed: 1593.31 samples/sec#011loss=5.191502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[310] avg_epoch_loss=5.183335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=310 train loss <loss>=5.18741607666\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [310]#011Speed: 1000.49 samples/sec#011loss=5.187416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[315] avg_epoch_loss=5.183119\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=315 train loss <loss>=5.16966314316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [315]#011Speed: 1612.97 samples/sec#011loss=5.169663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[320] avg_epoch_loss=5.183916\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=320 train loss <loss>=5.2342839241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [320]#011Speed: 1097.58 samples/sec#011loss=5.234284\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch[325] avg_epoch_loss=5.189674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=325 train loss <loss>=5.559349823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:01 INFO 140669025912640] Epoch[17] Batch [325]#011Speed: 1537.91 samples/sec#011loss=5.559350\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[330] avg_epoch_loss=5.192862\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=330 train loss <loss>=5.4007068634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [330]#011Speed: 983.07 samples/sec#011loss=5.400707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[335] avg_epoch_loss=5.191244\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=335 train loss <loss>=5.08414964676\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [335]#011Speed: 1537.16 samples/sec#011loss=5.084150\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[340] avg_epoch_loss=5.191827\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=340 train loss <loss>=5.23099679947\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [340]#011Speed: 1652.99 samples/sec#011loss=5.230997\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[345] avg_epoch_loss=5.189694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=345 train loss <loss>=5.0442278862\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [345]#011Speed: 1051.83 samples/sec#011loss=5.044228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[350] avg_epoch_loss=5.190965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=350 train loss <loss>=5.2789560318\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [350]#011Speed: 1646.46 samples/sec#011loss=5.278956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[355] avg_epoch_loss=5.189381\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=355 train loss <loss>=5.07815237045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [355]#011Speed: 1046.61 samples/sec#011loss=5.078152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[360] avg_epoch_loss=5.189482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=360 train loss <loss>=5.19671316147\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [360]#011Speed: 1613.36 samples/sec#011loss=5.196713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch[365] avg_epoch_loss=5.192639\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=365 train loss <loss>=5.42052412033\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:02 INFO 140669025912640] Epoch[17] Batch [365]#011Speed: 1077.17 samples/sec#011loss=5.420524\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[370] avg_epoch_loss=5.191105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=370 train loss <loss>=5.07880601883\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [370]#011Speed: 1634.60 samples/sec#011loss=5.078806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[375] avg_epoch_loss=5.189235\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=375 train loss <loss>=5.0504942894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [375]#011Speed: 1104.11 samples/sec#011loss=5.050494\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[380] avg_epoch_loss=5.188088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=380 train loss <loss>=5.10186777115\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [380]#011Speed: 1595.99 samples/sec#011loss=5.101868\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[385] avg_epoch_loss=5.187281\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=385 train loss <loss>=5.12579507828\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [385]#011Speed: 1070.45 samples/sec#011loss=5.125795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[390] avg_epoch_loss=5.185798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=390 train loss <loss>=5.07126703262\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [390]#011Speed: 1610.84 samples/sec#011loss=5.071267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[395] avg_epoch_loss=5.185553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=395 train loss <loss>=5.16643371582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [395]#011Speed: 1024.04 samples/sec#011loss=5.166434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[400] avg_epoch_loss=5.186743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=400 train loss <loss>=5.28095636368\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [400]#011Speed: 1632.26 samples/sec#011loss=5.280956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch[405] avg_epoch_loss=5.188985\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=405 train loss <loss>=5.3688243866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:03 INFO 140669025912640] Epoch[17] Batch [405]#011Speed: 1034.47 samples/sec#011loss=5.368824\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[410] avg_epoch_loss=5.186678\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=410 train loss <loss>=4.99929504395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [410]#011Speed: 1595.80 samples/sec#011loss=4.999295\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[415] avg_epoch_loss=5.187986\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=415 train loss <loss>=5.29555530548\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [415]#011Speed: 990.20 samples/sec#011loss=5.295555\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[420] avg_epoch_loss=5.185913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=420 train loss <loss>=5.01339054108\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [420]#011Speed: 1555.24 samples/sec#011loss=5.013391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[425] avg_epoch_loss=5.188338\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=425 train loss <loss>=5.39251623154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [425]#011Speed: 1062.49 samples/sec#011loss=5.392516\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[430] avg_epoch_loss=5.190627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=430 train loss <loss>=5.38566713333\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [430]#011Speed: 1671.94 samples/sec#011loss=5.385667\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[435] avg_epoch_loss=5.190036\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=435 train loss <loss>=5.139128685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [435]#011Speed: 1035.45 samples/sec#011loss=5.139129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[440] avg_epoch_loss=5.187129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=440 train loss <loss>=4.93365936279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [440]#011Speed: 1672.05 samples/sec#011loss=4.933659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch[445] avg_epoch_loss=5.185682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=445 train loss <loss>=5.05801086426\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:04 INFO 140669025912640] Epoch[17] Batch [445]#011Speed: 1058.54 samples/sec#011loss=5.058011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[450] avg_epoch_loss=5.190570\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=450 train loss <loss>=5.62661647797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [450]#011Speed: 1649.40 samples/sec#011loss=5.626616\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[455] avg_epoch_loss=5.187061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=455 train loss <loss>=4.87049245834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [455]#011Speed: 1029.56 samples/sec#011loss=4.870492\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[460] avg_epoch_loss=5.184276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=460 train loss <loss>=4.93029060364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [460]#011Speed: 1685.28 samples/sec#011loss=4.930291\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[465] avg_epoch_loss=5.185170\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=465 train loss <loss>=5.26761684418\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [465]#011Speed: 1058.65 samples/sec#011loss=5.267617\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[470] avg_epoch_loss=5.186745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=470 train loss <loss>=5.33357553482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [470]#011Speed: 1659.84 samples/sec#011loss=5.333576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[475] avg_epoch_loss=5.187090\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=475 train loss <loss>=5.21951065063\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [475]#011Speed: 1026.67 samples/sec#011loss=5.219511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[480] avg_epoch_loss=5.186912\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=480 train loss <loss>=5.16997823715\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [480]#011Speed: 1679.12 samples/sec#011loss=5.169978\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch[485] avg_epoch_loss=5.184380\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=485 train loss <loss>=4.94086580276\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:05 INFO 140669025912640] Epoch[17] Batch [485]#011Speed: 1037.10 samples/sec#011loss=4.940866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[490] avg_epoch_loss=5.187124\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=490 train loss <loss>=5.45382862091\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [490]#011Speed: 1573.27 samples/sec#011loss=5.453829\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[495] avg_epoch_loss=5.184359\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=495 train loss <loss>=4.9128370285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [495]#011Speed: 1022.37 samples/sec#011loss=4.912837\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[500] avg_epoch_loss=5.181873\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=500 train loss <loss>=4.93522357941\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [500]#011Speed: 1689.39 samples/sec#011loss=4.935224\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[505] avg_epoch_loss=5.180148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=505 train loss <loss>=5.00731554031\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [505]#011Speed: 1677.15 samples/sec#011loss=5.007316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[510] avg_epoch_loss=5.182198\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=510 train loss <loss>=5.38969755173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [510]#011Speed: 1011.88 samples/sec#011loss=5.389698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[515] avg_epoch_loss=5.178834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=515 train loss <loss>=4.83502979279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [515]#011Speed: 1613.18 samples/sec#011loss=4.835030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[520] avg_epoch_loss=5.179862\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=520 train loss <loss>=5.28590917587\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [520]#011Speed: 986.80 samples/sec#011loss=5.285909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch[525] avg_epoch_loss=5.178836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=525 train loss <loss>=5.07190341949\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:06 INFO 140669025912640] Epoch[17] Batch [525]#011Speed: 1480.88 samples/sec#011loss=5.071903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[530] avg_epoch_loss=5.179249\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=530 train loss <loss>=5.22271623611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [530]#011Speed: 1012.40 samples/sec#011loss=5.222716\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[535] avg_epoch_loss=5.176711\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=535 train loss <loss>=4.90717763901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [535]#011Speed: 1676.99 samples/sec#011loss=4.907178\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[540] avg_epoch_loss=5.176193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=540 train loss <loss>=5.12072715759\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [540]#011Speed: 1063.99 samples/sec#011loss=5.120727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[545] avg_epoch_loss=5.177206\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=545 train loss <loss>=5.28672218323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [545]#011Speed: 1650.05 samples/sec#011loss=5.286722\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[550] avg_epoch_loss=5.177461\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=550 train loss <loss>=5.20531463623\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [550]#011Speed: 1102.53 samples/sec#011loss=5.205315\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[555] avg_epoch_loss=5.175790\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=555 train loss <loss>=4.99163665771\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [555]#011Speed: 1667.85 samples/sec#011loss=4.991637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[560] avg_epoch_loss=5.174611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=560 train loss <loss>=5.04359722137\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [560]#011Speed: 1102.23 samples/sec#011loss=5.043597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch[565] avg_epoch_loss=5.173593\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=565 train loss <loss>=5.05929718018\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:07 INFO 140669025912640] Epoch[17] Batch [565]#011Speed: 1638.87 samples/sec#011loss=5.059297\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[17] Batch[570] avg_epoch_loss=5.171785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, batch=570 train loss <loss>=4.96714553833\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[17] Batch [570]#011Speed: 1316.55 samples/sec#011loss=4.967146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] processed a total of 18361 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14281.744003295898, \"sum\": 14281.744003295898, \"min\": 14281.744003295898}}, \"EndTime\": 1589393948.074246, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393933.792448}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1285.61946759 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=17, train loss <loss>=5.17061139233\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_6531eb56-a370-4d73-8cdb-6e4fedb126a0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.844852447509766, \"sum\": 8.844852447509766, \"min\": 8.844852447509766}}, \"EndTime\": 1589393948.083566, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393948.074307}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[0] avg_epoch_loss=5.395946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=5.39594554901\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[5] avg_epoch_loss=4.995619\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=4.99561945597\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [5]#011Speed: 1576.68 samples/sec#011loss=4.995619\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[10] avg_epoch_loss=5.025267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=5.06084308624\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [10]#011Speed: 1095.58 samples/sec#011loss=5.060843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[15] avg_epoch_loss=5.042879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=5.08162660599\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [15]#011Speed: 1638.78 samples/sec#011loss=5.081627\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[20] avg_epoch_loss=5.104512\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=5.30173816681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [20]#011Speed: 1619.12 samples/sec#011loss=5.301738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[25] avg_epoch_loss=5.135078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=5.26345205307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [25]#011Speed: 1080.37 samples/sec#011loss=5.263452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[30] avg_epoch_loss=5.156304\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=5.26668214798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [30]#011Speed: 1629.16 samples/sec#011loss=5.266682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch[35] avg_epoch_loss=5.182847\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=5.34741439819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:08 INFO 140669025912640] Epoch[18] Batch [35]#011Speed: 1027.40 samples/sec#011loss=5.347414\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[40] avg_epoch_loss=5.226896\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=5.54404993057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [40]#011Speed: 1669.40 samples/sec#011loss=5.544050\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[45] avg_epoch_loss=5.229237\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=5.24842653275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [45]#011Speed: 1039.26 samples/sec#011loss=5.248427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[50] avg_epoch_loss=5.228349\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=5.22018327713\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [50]#011Speed: 1634.97 samples/sec#011loss=5.220183\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[55] avg_epoch_loss=5.216077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=5.0909072876\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [55]#011Speed: 1114.19 samples/sec#011loss=5.090907\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[60] avg_epoch_loss=5.221634\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=5.28386287689\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [60]#011Speed: 1522.69 samples/sec#011loss=5.283863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[65] avg_epoch_loss=5.212412\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=5.09990930557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [65]#011Speed: 992.72 samples/sec#011loss=5.099909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch[70] avg_epoch_loss=5.218232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=5.29505434036\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:09 INFO 140669025912640] Epoch[18] Batch [70]#011Speed: 1676.98 samples/sec#011loss=5.295054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[75] avg_epoch_loss=5.212871\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=5.13674545288\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [75]#011Speed: 992.12 samples/sec#011loss=5.136745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[80] avg_epoch_loss=5.206914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=5.11636991501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [80]#011Speed: 1513.78 samples/sec#011loss=5.116370\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[85] avg_epoch_loss=5.187610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=4.87487983704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [85]#011Speed: 1032.81 samples/sec#011loss=4.874880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[90] avg_epoch_loss=5.181820\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=5.08223209381\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [90]#011Speed: 1667.92 samples/sec#011loss=5.082232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[95] avg_epoch_loss=5.179653\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=5.14021568298\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [95]#011Speed: 1056.15 samples/sec#011loss=5.140216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[100] avg_epoch_loss=5.180373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=5.19420318604\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [100]#011Speed: 1653.46 samples/sec#011loss=5.194203\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[105] avg_epoch_loss=5.177480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=5.11902751923\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [105]#011Speed: 1666.75 samples/sec#011loss=5.119028\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[110] avg_epoch_loss=5.176308\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=5.15148067474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [110]#011Speed: 1050.95 samples/sec#011loss=5.151481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch[115] avg_epoch_loss=5.177544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=5.20498018265\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:10 INFO 140669025912640] Epoch[18] Batch [115]#011Speed: 1625.31 samples/sec#011loss=5.204980\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[120] avg_epoch_loss=5.179196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=5.21750535965\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [120]#011Speed: 1023.20 samples/sec#011loss=5.217505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[125] avg_epoch_loss=5.176942\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=5.12240056992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [125]#011Speed: 1667.79 samples/sec#011loss=5.122401\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[130] avg_epoch_loss=5.183747\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=5.35524539948\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [130]#011Speed: 1056.04 samples/sec#011loss=5.355245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[135] avg_epoch_loss=5.191732\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=5.40094451904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [135]#011Speed: 1655.48 samples/sec#011loss=5.400945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[140] avg_epoch_loss=5.190588\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=5.15946464539\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [140]#011Speed: 1020.11 samples/sec#011loss=5.159465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[145] avg_epoch_loss=5.194738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=5.31175689697\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [145]#011Speed: 1684.51 samples/sec#011loss=5.311757\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[150] avg_epoch_loss=5.190779\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=5.07517166138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [150]#011Speed: 1038.21 samples/sec#011loss=5.075172\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch[155] avg_epoch_loss=5.184458\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=4.99356575012\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:11 INFO 140669025912640] Epoch[18] Batch [155]#011Speed: 1622.22 samples/sec#011loss=4.993566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[160] avg_epoch_loss=5.188093\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=5.30150909424\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [160]#011Speed: 1133.07 samples/sec#011loss=5.301509\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[165] avg_epoch_loss=5.185546\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=5.10354185104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [165]#011Speed: 1585.43 samples/sec#011loss=5.103542\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[170] avg_epoch_loss=5.183017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=5.09904689789\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [170]#011Speed: 1098.89 samples/sec#011loss=5.099047\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[175] avg_epoch_loss=5.182637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=5.16963329315\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [175]#011Speed: 1613.41 samples/sec#011loss=5.169633\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[180] avg_epoch_loss=5.183959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=5.23049297333\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [180]#011Speed: 1087.10 samples/sec#011loss=5.230493\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[185] avg_epoch_loss=5.182060\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=5.11330966949\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [185]#011Speed: 1579.43 samples/sec#011loss=5.113310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[190] avg_epoch_loss=5.185989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=5.33215789795\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [190]#011Speed: 1065.88 samples/sec#011loss=5.332158\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch[195] avg_epoch_loss=5.186446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=5.20390396118\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:12 INFO 140669025912640] Epoch[18] Batch [195]#011Speed: 1631.16 samples/sec#011loss=5.203904\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[200] avg_epoch_loss=5.183518\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=5.06873474121\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [200]#011Speed: 999.79 samples/sec#011loss=5.068735\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[205] avg_epoch_loss=5.184544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=5.22580327988\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [205]#011Speed: 1643.50 samples/sec#011loss=5.225803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[210] avg_epoch_loss=5.191718\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=5.48729324341\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [210]#011Speed: 1045.01 samples/sec#011loss=5.487293\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[215] avg_epoch_loss=5.193694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=5.27706623077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [215]#011Speed: 1580.26 samples/sec#011loss=5.277066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[220] avg_epoch_loss=5.192785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=5.15352745056\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [220]#011Speed: 1524.89 samples/sec#011loss=5.153527\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[225] avg_epoch_loss=5.188531\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=5.00048017502\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [225]#011Speed: 1110.81 samples/sec#011loss=5.000480\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[230] avg_epoch_loss=5.188099\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=5.16859779358\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [230]#011Speed: 1631.37 samples/sec#011loss=5.168598\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch[235] avg_epoch_loss=5.189085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=5.23464202881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:13 INFO 140669025912640] Epoch[18] Batch [235]#011Speed: 1069.00 samples/sec#011loss=5.234642\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[240] avg_epoch_loss=5.186591\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=5.06885604858\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [240]#011Speed: 1553.96 samples/sec#011loss=5.068856\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[245] avg_epoch_loss=5.184301\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=5.07392616272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [245]#011Speed: 1082.87 samples/sec#011loss=5.073926\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[250] avg_epoch_loss=5.182600\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=5.09893083572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [250]#011Speed: 1661.77 samples/sec#011loss=5.098931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[255] avg_epoch_loss=5.176357\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=4.86294527054\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [255]#011Speed: 1103.96 samples/sec#011loss=4.862945\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[260] avg_epoch_loss=5.175211\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=260 train loss <loss>=5.11652002335\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [260]#011Speed: 1655.30 samples/sec#011loss=5.116520\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[265] avg_epoch_loss=5.174525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=265 train loss <loss>=5.13870420456\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [265]#011Speed: 1098.25 samples/sec#011loss=5.138704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[270] avg_epoch_loss=5.170969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=270 train loss <loss>=4.98183889389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [270]#011Speed: 1653.53 samples/sec#011loss=4.981839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch[275] avg_epoch_loss=5.167342\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=275 train loss <loss>=4.97072467804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:14 INFO 140669025912640] Epoch[18] Batch [275]#011Speed: 1107.44 samples/sec#011loss=4.970725\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[280] avg_epoch_loss=5.169331\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=280 train loss <loss>=5.2791428566\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [280]#011Speed: 1623.03 samples/sec#011loss=5.279143\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[285] avg_epoch_loss=5.171351\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=285 train loss <loss>=5.28488092422\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [285]#011Speed: 1097.10 samples/sec#011loss=5.284881\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[290] avg_epoch_loss=5.170483\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=290 train loss <loss>=5.12079401016\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [290]#011Speed: 1648.93 samples/sec#011loss=5.120794\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[295] avg_epoch_loss=5.171258\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=295 train loss <loss>=5.21639080048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [295]#011Speed: 1107.87 samples/sec#011loss=5.216391\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[300] avg_epoch_loss=5.168774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=300 train loss <loss>=5.02172708511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [300]#011Speed: 1667.85 samples/sec#011loss=5.021727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[305] avg_epoch_loss=5.168729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=305 train loss <loss>=5.16600170135\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [305]#011Speed: 1122.40 samples/sec#011loss=5.166002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[310] avg_epoch_loss=5.165432\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=310 train loss <loss>=4.96368503571\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [310]#011Speed: 1636.31 samples/sec#011loss=4.963685\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch[315] avg_epoch_loss=5.165120\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=315 train loss <loss>=5.14569091797\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:15 INFO 140669025912640] Epoch[18] Batch [315]#011Speed: 1099.76 samples/sec#011loss=5.145691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[320] avg_epoch_loss=5.167455\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=320 train loss <loss>=5.31501131058\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [320]#011Speed: 1546.86 samples/sec#011loss=5.315011\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[325] avg_epoch_loss=5.168274\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=325 train loss <loss>=5.22086343765\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [325]#011Speed: 998.10 samples/sec#011loss=5.220863\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[330] avg_epoch_loss=5.168136\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=330 train loss <loss>=5.15917339325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [330]#011Speed: 1524.27 samples/sec#011loss=5.159173\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[335] avg_epoch_loss=5.168201\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=335 train loss <loss>=5.17245912552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [335]#011Speed: 1089.78 samples/sec#011loss=5.172459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[340] avg_epoch_loss=5.167129\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=340 train loss <loss>=5.09507741928\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [340]#011Speed: 1658.79 samples/sec#011loss=5.095077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[345] avg_epoch_loss=5.165610\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=345 train loss <loss>=5.06207504272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [345]#011Speed: 1097.33 samples/sec#011loss=5.062075\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[350] avg_epoch_loss=5.165481\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=350 train loss <loss>=5.1565574646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [350]#011Speed: 1646.72 samples/sec#011loss=5.156557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch[355] avg_epoch_loss=5.165134\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=355 train loss <loss>=5.14077396393\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:16 INFO 140669025912640] Epoch[18] Batch [355]#011Speed: 1109.18 samples/sec#011loss=5.140774\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[360] avg_epoch_loss=5.164949\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=360 train loss <loss>=5.15175800323\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [360]#011Speed: 1592.51 samples/sec#011loss=5.151758\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[365] avg_epoch_loss=5.164562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=365 train loss <loss>=5.13661088943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [365]#011Speed: 1072.31 samples/sec#011loss=5.136611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[370] avg_epoch_loss=5.163692\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=370 train loss <loss>=5.09997062683\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [370]#011Speed: 1643.45 samples/sec#011loss=5.099971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[375] avg_epoch_loss=5.164454\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=375 train loss <loss>=5.22104063034\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [375]#011Speed: 1111.24 samples/sec#011loss=5.221041\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[380] avg_epoch_loss=5.164933\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=380 train loss <loss>=5.20097208023\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [380]#011Speed: 1602.26 samples/sec#011loss=5.200972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[385] avg_epoch_loss=5.167443\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=385 train loss <loss>=5.35864849091\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [385]#011Speed: 1038.64 samples/sec#011loss=5.358648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[390] avg_epoch_loss=5.167277\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=390 train loss <loss>=5.15450973511\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [390]#011Speed: 1642.14 samples/sec#011loss=5.154510\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[395] avg_epoch_loss=5.167107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=395 train loss <loss>=5.15377979279\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [395]#011Speed: 1100.46 samples/sec#011loss=5.153780\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch[400] avg_epoch_loss=5.166215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=400 train loss <loss>=5.09558181763\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:17 INFO 140669025912640] Epoch[18] Batch [400]#011Speed: 1664.41 samples/sec#011loss=5.095582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[405] avg_epoch_loss=5.166541\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=405 train loss <loss>=5.1926738739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [405]#011Speed: 1596.31 samples/sec#011loss=5.192674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[410] avg_epoch_loss=5.167306\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=410 train loss <loss>=5.22944107056\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [410]#011Speed: 995.00 samples/sec#011loss=5.229441\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[415] avg_epoch_loss=5.164431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=415 train loss <loss>=4.92813844681\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [415]#011Speed: 1695.19 samples/sec#011loss=4.928138\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[420] avg_epoch_loss=5.161738\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=420 train loss <loss>=4.93760004044\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [420]#011Speed: 1044.88 samples/sec#011loss=4.937600\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[425] avg_epoch_loss=5.160375\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=425 train loss <loss>=5.04567403793\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [425]#011Speed: 1648.06 samples/sec#011loss=5.045674\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[430] avg_epoch_loss=5.159582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=430 train loss <loss>=5.09198312759\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [430]#011Speed: 1012.89 samples/sec#011loss=5.091983\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch[435] avg_epoch_loss=5.158564\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=435 train loss <loss>=5.07085456848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:18 INFO 140669025912640] Epoch[18] Batch [435]#011Speed: 1682.95 samples/sec#011loss=5.070855\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[440] avg_epoch_loss=5.158347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=440 train loss <loss>=5.1393995285\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [440]#011Speed: 1008.78 samples/sec#011loss=5.139400\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[445] avg_epoch_loss=5.158087\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=445 train loss <loss>=5.13518610001\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [445]#011Speed: 1558.72 samples/sec#011loss=5.135186\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[450] avg_epoch_loss=5.158482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=450 train loss <loss>=5.19371643066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [450]#011Speed: 1019.71 samples/sec#011loss=5.193716\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[455] avg_epoch_loss=5.158021\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=455 train loss <loss>=5.11640996933\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [455]#011Speed: 1655.08 samples/sec#011loss=5.116410\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[460] avg_epoch_loss=5.154698\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=460 train loss <loss>=4.85164489746\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [460]#011Speed: 1058.53 samples/sec#011loss=4.851645\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[465] avg_epoch_loss=5.153442\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=465 train loss <loss>=5.03764648438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [465]#011Speed: 1596.80 samples/sec#011loss=5.037646\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[470] avg_epoch_loss=5.153625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=470 train loss <loss>=5.17070446014\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [470]#011Speed: 1057.52 samples/sec#011loss=5.170704\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[475] avg_epoch_loss=5.154557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=475 train loss <loss>=5.2422665596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [475]#011Speed: 1659.66 samples/sec#011loss=5.242267\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch[480] avg_epoch_loss=5.155316\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=480 train loss <loss>=5.22758369446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:19 INFO 140669025912640] Epoch[18] Batch [480]#011Speed: 1688.39 samples/sec#011loss=5.227584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[485] avg_epoch_loss=5.155069\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=485 train loss <loss>=5.13131942749\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [485]#011Speed: 983.48 samples/sec#011loss=5.131319\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[490] avg_epoch_loss=5.154557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=490 train loss <loss>=5.10480308533\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [490]#011Speed: 1668.63 samples/sec#011loss=5.104803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[495] avg_epoch_loss=5.153999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=495 train loss <loss>=5.09922733307\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [495]#011Speed: 1015.70 samples/sec#011loss=5.099227\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[500] avg_epoch_loss=5.153434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=500 train loss <loss>=5.09733924866\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [500]#011Speed: 1673.80 samples/sec#011loss=5.097339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[505] avg_epoch_loss=5.154572\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=505 train loss <loss>=5.26862697601\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [505]#011Speed: 1048.36 samples/sec#011loss=5.268627\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[510] avg_epoch_loss=5.156085\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=510 train loss <loss>=5.30920877457\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [510]#011Speed: 1641.08 samples/sec#011loss=5.309209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[515] avg_epoch_loss=5.156292\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=515 train loss <loss>=5.1774020195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [515]#011Speed: 1113.17 samples/sec#011loss=5.177402\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch[520] avg_epoch_loss=5.156435\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=520 train loss <loss>=5.1712562561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:20 INFO 140669025912640] Epoch[18] Batch [520]#011Speed: 1676.02 samples/sec#011loss=5.171256\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[525] avg_epoch_loss=5.156643\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=525 train loss <loss>=5.17834062576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [525]#011Speed: 1067.90 samples/sec#011loss=5.178341\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[530] avg_epoch_loss=5.154325\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=530 train loss <loss>=4.91038475037\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [530]#011Speed: 1609.97 samples/sec#011loss=4.910385\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[535] avg_epoch_loss=5.154460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=535 train loss <loss>=5.1688375473\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [535]#011Speed: 1059.06 samples/sec#011loss=5.168838\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[540] avg_epoch_loss=5.155803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=540 train loss <loss>=5.29979915619\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [540]#011Speed: 1629.63 samples/sec#011loss=5.299799\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[545] avg_epoch_loss=5.154672\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=545 train loss <loss>=5.0323015213\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [545]#011Speed: 968.11 samples/sec#011loss=5.032302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[550] avg_epoch_loss=5.156541\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=550 train loss <loss>=5.36058015823\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [550]#011Speed: 1646.43 samples/sec#011loss=5.360580\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[555] avg_epoch_loss=5.156450\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=555 train loss <loss>=5.14639215469\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [555]#011Speed: 1617.40 samples/sec#011loss=5.146392\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch[560] avg_epoch_loss=5.155107\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=560 train loss <loss>=5.00578594208\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:21 INFO 140669025912640] Epoch[18] Batch [560]#011Speed: 1044.75 samples/sec#011loss=5.005786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch[565] avg_epoch_loss=5.154803\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=565 train loss <loss>=5.12068157196\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch [565]#011Speed: 1617.80 samples/sec#011loss=5.120682\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch[570] avg_epoch_loss=5.153329\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=570 train loss <loss>=4.98655395508\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch [570]#011Speed: 969.14 samples/sec#011loss=4.986554\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch[575] avg_epoch_loss=5.152124\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=575 train loss <loss>=5.01449966431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch [575]#011Speed: 1421.70 samples/sec#011loss=5.014500\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch[580] avg_epoch_loss=5.151423\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, batch=580 train loss <loss>=5.0706407547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[18] Batch [580]#011Speed: 1352.57 samples/sec#011loss=5.070641\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] processed a total of 18583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14388.75699043274, \"sum\": 14388.75699043274, \"min\": 14388.75699043274}}, \"EndTime\": 1589393962.47244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393948.083622}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1291.48622535 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=18, train loss <loss>=5.15142297909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_18780ec1-d79e-4d59-b57a-ea3288a01f34-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.282039642333984, \"sum\": 10.282039642333984, \"min\": 10.282039642333984}}, \"EndTime\": 1589393962.483098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393962.472501}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch[0] avg_epoch_loss=4.873030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=4.87302970886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch[5] avg_epoch_loss=4.929694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=4.92969449361\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch [5]#011Speed: 1570.68 samples/sec#011loss=4.929694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch[10] avg_epoch_loss=5.009501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=5.10526828766\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch [10]#011Speed: 1635.00 samples/sec#011loss=5.105268\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch[15] avg_epoch_loss=5.043449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=5.11813468933\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:22 INFO 140669025912640] Epoch[19] Batch [15]#011Speed: 1073.67 samples/sec#011loss=5.118135\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[20] avg_epoch_loss=5.067076\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=5.14268407822\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [20]#011Speed: 1066.18 samples/sec#011loss=5.142684\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[25] avg_epoch_loss=5.065195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=5.05729398727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [25]#011Speed: 1514.49 samples/sec#011loss=5.057294\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[30] avg_epoch_loss=5.046875\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=4.95161151886\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [30]#011Speed: 1120.08 samples/sec#011loss=4.951612\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[35] avg_epoch_loss=5.063105\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=5.16373243332\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [35]#011Speed: 1676.27 samples/sec#011loss=5.163732\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[40] avg_epoch_loss=5.088911\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=5.27470798492\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [40]#011Speed: 1113.18 samples/sec#011loss=5.274708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[45] avg_epoch_loss=5.101832\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=5.20779056549\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [45]#011Speed: 1627.64 samples/sec#011loss=5.207791\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[50] avg_epoch_loss=5.098801\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=5.07090978622\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [50]#011Speed: 1107.21 samples/sec#011loss=5.070910\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch[55] avg_epoch_loss=5.099806\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=5.11005983353\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:23 INFO 140669025912640] Epoch[19] Batch [55]#011Speed: 1596.10 samples/sec#011loss=5.110060\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[60] avg_epoch_loss=5.104272\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=5.15429048538\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [60]#011Speed: 1051.51 samples/sec#011loss=5.154290\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[65] avg_epoch_loss=5.095658\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=4.99056978226\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [65]#011Speed: 1674.41 samples/sec#011loss=4.990570\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[70] avg_epoch_loss=5.083819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=4.9275396347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [70]#011Speed: 1101.33 samples/sec#011loss=4.927540\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[75] avg_epoch_loss=5.095785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=5.26570129395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [75]#011Speed: 1671.23 samples/sec#011loss=5.265701\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[80] avg_epoch_loss=5.107223\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=5.28107786179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [80]#011Speed: 1026.61 samples/sec#011loss=5.281078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[85] avg_epoch_loss=5.091743\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=4.84097223282\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [85]#011Speed: 1555.53 samples/sec#011loss=4.840972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[90] avg_epoch_loss=5.092505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=5.1056142807\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [90]#011Speed: 1063.40 samples/sec#011loss=5.105614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch[95] avg_epoch_loss=5.090707\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=5.05798940659\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:24 INFO 140669025912640] Epoch[19] Batch [95]#011Speed: 1678.18 samples/sec#011loss=5.057989\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[100] avg_epoch_loss=5.088341\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=5.04291267395\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [100]#011Speed: 1041.68 samples/sec#011loss=5.042913\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[105] avg_epoch_loss=5.095745\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=5.24529008865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [105]#011Speed: 1579.03 samples/sec#011loss=5.245290\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[110] avg_epoch_loss=5.092062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=5.01399793625\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [110]#011Speed: 1677.36 samples/sec#011loss=5.013998\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[115] avg_epoch_loss=5.095005\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=5.16033935547\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [115]#011Speed: 1029.19 samples/sec#011loss=5.160339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[120] avg_epoch_loss=5.087637\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=4.91669387817\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [120]#011Speed: 1663.41 samples/sec#011loss=4.916694\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[125] avg_epoch_loss=5.090557\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=5.16122837067\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [125]#011Speed: 1044.68 samples/sec#011loss=5.161228\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[130] avg_epoch_loss=5.089776\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=5.07007484436\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [130]#011Speed: 1673.97 samples/sec#011loss=5.070075\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[135] avg_epoch_loss=5.091261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=5.13019313812\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [135]#011Speed: 1025.60 samples/sec#011loss=5.130193\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch[140] avg_epoch_loss=5.094088\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=5.17095947266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:25 INFO 140669025912640] Epoch[19] Batch [140]#011Speed: 1656.30 samples/sec#011loss=5.170959\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[145] avg_epoch_loss=5.092877\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=5.05872783661\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [145]#011Speed: 1010.96 samples/sec#011loss=5.058728\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[150] avg_epoch_loss=5.101892\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=5.36512584686\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [150]#011Speed: 1485.20 samples/sec#011loss=5.365126\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[155] avg_epoch_loss=5.102727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=5.12797164917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [155]#011Speed: 1076.98 samples/sec#011loss=5.127972\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[160] avg_epoch_loss=5.097061\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=4.92025184631\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [160]#011Speed: 1622.62 samples/sec#011loss=4.920252\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[165] avg_epoch_loss=5.092241\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=4.93704538345\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [165]#011Speed: 1004.52 samples/sec#011loss=4.937045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[170] avg_epoch_loss=5.092950\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=5.11650362015\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [170]#011Speed: 1599.87 samples/sec#011loss=5.116504\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch[175] avg_epoch_loss=5.087796\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=4.91152515411\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:26 INFO 140669025912640] Epoch[19] Batch [175]#011Speed: 1097.18 samples/sec#011loss=4.911525\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[180] avg_epoch_loss=5.091563\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=5.22416009903\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [180]#011Speed: 1639.04 samples/sec#011loss=5.224160\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[185] avg_epoch_loss=5.094798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=5.2119143486\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [185]#011Speed: 1052.85 samples/sec#011loss=5.211914\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[190] avg_epoch_loss=5.096521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=5.16059608459\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [190]#011Speed: 1548.45 samples/sec#011loss=5.160596\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[195] avg_epoch_loss=5.099582\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=5.2165348053\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [195]#011Speed: 1036.48 samples/sec#011loss=5.216535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[200] avg_epoch_loss=5.102419\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=5.21361522675\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [200]#011Speed: 1616.47 samples/sec#011loss=5.213615\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[205] avg_epoch_loss=5.104552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=5.19028663635\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [205]#011Speed: 1091.03 samples/sec#011loss=5.190287\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[210] avg_epoch_loss=5.110691\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=5.36362924576\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [210]#011Speed: 1634.90 samples/sec#011loss=5.363629\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch[215] avg_epoch_loss=5.115185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=5.30483617783\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:27 INFO 140669025912640] Epoch[19] Batch [215]#011Speed: 1640.45 samples/sec#011loss=5.304836\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[220] avg_epoch_loss=5.114002\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=5.06287984848\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [220]#011Speed: 976.40 samples/sec#011loss=5.062880\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[225] avg_epoch_loss=5.118466\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=5.31580400467\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [225]#011Speed: 1493.82 samples/sec#011loss=5.315804\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[230] avg_epoch_loss=5.118022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=5.09795074463\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [230]#011Speed: 1082.12 samples/sec#011loss=5.097951\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[235] avg_epoch_loss=5.114893\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=4.97030181885\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [235]#011Speed: 1629.09 samples/sec#011loss=4.970302\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[240] avg_epoch_loss=5.117897\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=5.25970830917\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [240]#011Speed: 1081.23 samples/sec#011loss=5.259708\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[245] avg_epoch_loss=5.117553\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=5.10099210739\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [245]#011Speed: 1621.47 samples/sec#011loss=5.100992\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[250] avg_epoch_loss=5.115078\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=4.99327487946\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [250]#011Speed: 1113.95 samples/sec#011loss=4.993275\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch[255] avg_epoch_loss=5.116148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=5.16988353729\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:28 INFO 140669025912640] Epoch[19] Batch [255]#011Speed: 1646.43 samples/sec#011loss=5.169884\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[260] avg_epoch_loss=5.117584\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=5.19109802246\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [260]#011Speed: 1029.47 samples/sec#011loss=5.191098\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[265] avg_epoch_loss=5.116825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=5.07720212936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [265]#011Speed: 1555.07 samples/sec#011loss=5.077202\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[270] avg_epoch_loss=5.122068\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=5.4010181427\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [270]#011Speed: 1015.72 samples/sec#011loss=5.401018\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[275] avg_epoch_loss=5.124973\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=275 train loss <loss>=5.28241577148\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [275]#011Speed: 1675.51 samples/sec#011loss=5.282416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[280] avg_epoch_loss=5.126185\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=280 train loss <loss>=5.19304761887\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [280]#011Speed: 1065.21 samples/sec#011loss=5.193048\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[285] avg_epoch_loss=5.122465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=285 train loss <loss>=4.91345052719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [285]#011Speed: 1661.08 samples/sec#011loss=4.913451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[290] avg_epoch_loss=5.116330\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=290 train loss <loss>=4.76537265778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [290]#011Speed: 1103.36 samples/sec#011loss=4.765373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch[295] avg_epoch_loss=5.117216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=295 train loss <loss>=5.1688085556\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:29 INFO 140669025912640] Epoch[19] Batch [295]#011Speed: 1610.21 samples/sec#011loss=5.168809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[300] avg_epoch_loss=5.118462\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=300 train loss <loss>=5.19221544266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [300]#011Speed: 1104.12 samples/sec#011loss=5.192215\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[305] avg_epoch_loss=5.116484\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=305 train loss <loss>=4.9974155426\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [305]#011Speed: 1593.96 samples/sec#011loss=4.997416\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[310] avg_epoch_loss=5.117209\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=310 train loss <loss>=5.16157112122\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [310]#011Speed: 1086.87 samples/sec#011loss=5.161571\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[315] avg_epoch_loss=5.117133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=315 train loss <loss>=5.11242952347\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [315]#011Speed: 1630.59 samples/sec#011loss=5.112430\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[320] avg_epoch_loss=5.119380\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=320 train loss <loss>=5.26134347916\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [320]#011Speed: 1092.61 samples/sec#011loss=5.261343\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[325] avg_epoch_loss=5.120146\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=325 train loss <loss>=5.16931142807\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [325]#011Speed: 1634.92 samples/sec#011loss=5.169311\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[330] avg_epoch_loss=5.120216\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=330 train loss <loss>=5.12477779388\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [330]#011Speed: 1115.74 samples/sec#011loss=5.124778\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[335] avg_epoch_loss=5.117524\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=335 train loss <loss>=4.93935432434\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [335]#011Speed: 1631.59 samples/sec#011loss=4.939354\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch[340] avg_epoch_loss=5.115809\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=340 train loss <loss>=5.00052051544\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:30 INFO 140669025912640] Epoch[19] Batch [340]#011Speed: 1082.88 samples/sec#011loss=5.000521\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[345] avg_epoch_loss=5.118460\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=345 train loss <loss>=5.29926280975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [345]#011Speed: 1418.68 samples/sec#011loss=5.299263\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[350] avg_epoch_loss=5.116489\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=350 train loss <loss>=4.9801486969\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [350]#011Speed: 957.40 samples/sec#011loss=4.980149\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[355] avg_epoch_loss=5.116242\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=355 train loss <loss>=5.09889678955\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [355]#011Speed: 1596.57 samples/sec#011loss=5.098897\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[360] avg_epoch_loss=5.114445\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=360 train loss <loss>=4.98650112152\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [360]#011Speed: 1068.90 samples/sec#011loss=4.986501\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[365] avg_epoch_loss=5.117648\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=365 train loss <loss>=5.34891624451\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [365]#011Speed: 1613.02 samples/sec#011loss=5.348916\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[370] avg_epoch_loss=5.117452\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=370 train loss <loss>=5.10305223465\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [370]#011Speed: 1057.06 samples/sec#011loss=5.103052\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch[375] avg_epoch_loss=5.116730\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=375 train loss <loss>=5.06317901611\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:31 INFO 140669025912640] Epoch[19] Batch [375]#011Speed: 1668.62 samples/sec#011loss=5.063179\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[380] avg_epoch_loss=5.116128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=380 train loss <loss>=5.07086057663\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [380]#011Speed: 1081.34 samples/sec#011loss=5.070861\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[385] avg_epoch_loss=5.118991\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=385 train loss <loss>=5.33715581894\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [385]#011Speed: 1527.62 samples/sec#011loss=5.337156\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[390] avg_epoch_loss=5.120421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=390 train loss <loss>=5.23082466125\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [390]#011Speed: 1100.44 samples/sec#011loss=5.230825\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[395] avg_epoch_loss=5.123261\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=395 train loss <loss>=5.34533948898\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [395]#011Speed: 1621.90 samples/sec#011loss=5.345339\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[400] avg_epoch_loss=5.122128\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=400 train loss <loss>=5.03241319656\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [400]#011Speed: 1076.19 samples/sec#011loss=5.032413\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[405] avg_epoch_loss=5.122871\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=405 train loss <loss>=5.18245029449\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [405]#011Speed: 1635.22 samples/sec#011loss=5.182450\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[410] avg_epoch_loss=5.120561\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=410 train loss <loss>=4.93293428421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [410]#011Speed: 1616.72 samples/sec#011loss=4.932934\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[415] avg_epoch_loss=5.119280\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=415 train loss <loss>=5.01402206421\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [415]#011Speed: 1020.06 samples/sec#011loss=5.014022\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch[420] avg_epoch_loss=5.118059\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=420 train loss <loss>=5.01643075943\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:32 INFO 140669025912640] Epoch[19] Batch [420]#011Speed: 1623.58 samples/sec#011loss=5.016431\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[425] avg_epoch_loss=5.115062\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=425 train loss <loss>=4.8627117157\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [425]#011Speed: 1054.32 samples/sec#011loss=4.862712\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[430] avg_epoch_loss=5.116245\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=430 train loss <loss>=5.21705694199\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [430]#011Speed: 1656.83 samples/sec#011loss=5.217057\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[435] avg_epoch_loss=5.123194\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=435 train loss <loss>=5.722194767\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [435]#011Speed: 1057.31 samples/sec#011loss=5.722195\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[440] avg_epoch_loss=5.124133\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=440 train loss <loss>=5.20605287552\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [440]#011Speed: 1620.47 samples/sec#011loss=5.206053\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[445] avg_epoch_loss=5.124737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=445 train loss <loss>=5.17800426483\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [445]#011Speed: 1095.59 samples/sec#011loss=5.178004\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[450] avg_epoch_loss=5.128030\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=450 train loss <loss>=5.42172346115\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [450]#011Speed: 1483.85 samples/sec#011loss=5.421723\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[455] avg_epoch_loss=5.128089\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=455 train loss <loss>=5.13347415924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [455]#011Speed: 1049.11 samples/sec#011loss=5.133474\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch[460] avg_epoch_loss=5.128769\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=460 train loss <loss>=5.19079427719\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:33 INFO 140669025912640] Epoch[19] Batch [460]#011Speed: 1643.45 samples/sec#011loss=5.190794\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[465] avg_epoch_loss=5.127053\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=465 train loss <loss>=4.96880779266\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [465]#011Speed: 1036.52 samples/sec#011loss=4.968808\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[470] avg_epoch_loss=5.125373\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=470 train loss <loss>=4.96879777908\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [470]#011Speed: 1602.93 samples/sec#011loss=4.968798\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[475] avg_epoch_loss=5.124780\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=475 train loss <loss>=5.06893587112\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [475]#011Speed: 1048.21 samples/sec#011loss=5.068936\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[480] avg_epoch_loss=5.127879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=480 train loss <loss>=5.42284317017\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [480]#011Speed: 1668.51 samples/sec#011loss=5.422843\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[485] avg_epoch_loss=5.128095\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=485 train loss <loss>=5.14887933731\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [485]#011Speed: 1051.72 samples/sec#011loss=5.148879\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[490] avg_epoch_loss=5.128526\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=490 train loss <loss>=5.17044353485\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [490]#011Speed: 1640.20 samples/sec#011loss=5.170444\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[495] avg_epoch_loss=5.128450\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=495 train loss <loss>=5.12102584839\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [495]#011Speed: 1056.43 samples/sec#011loss=5.121026\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch[500] avg_epoch_loss=5.126389\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=500 train loss <loss>=4.92185077667\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:34 INFO 140669025912640] Epoch[19] Batch [500]#011Speed: 1626.79 samples/sec#011loss=4.921851\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[505] avg_epoch_loss=5.126909\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=505 train loss <loss>=5.17910079956\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [505]#011Speed: 1096.05 samples/sec#011loss=5.179101\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[510] avg_epoch_loss=5.127104\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=510 train loss <loss>=5.14681863785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [510]#011Speed: 1589.59 samples/sec#011loss=5.146819\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[515] avg_epoch_loss=5.125840\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=515 train loss <loss>=4.99659452438\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [515]#011Speed: 1004.34 samples/sec#011loss=4.996595\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[520] avg_epoch_loss=5.124446\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=520 train loss <loss>=4.98064069748\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [520]#011Speed: 1646.84 samples/sec#011loss=4.980641\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[525] avg_epoch_loss=5.124513\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=525 train loss <loss>=5.13152866364\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [525]#011Speed: 1044.76 samples/sec#011loss=5.131529\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[530] avg_epoch_loss=5.124999\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=530 train loss <loss>=5.17607870102\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [530]#011Speed: 1621.35 samples/sec#011loss=5.176079\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[535] avg_epoch_loss=5.125562\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=535 train loss <loss>=5.18532447815\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [535]#011Speed: 1013.18 samples/sec#011loss=5.185324\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch[540] avg_epoch_loss=5.124813\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=540 train loss <loss>=5.04449872971\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:35 INFO 140669025912640] Epoch[19] Batch [540]#011Speed: 1656.21 samples/sec#011loss=5.044499\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[545] avg_epoch_loss=5.124640\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=545 train loss <loss>=5.10592412949\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [545]#011Speed: 1053.72 samples/sec#011loss=5.105924\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[550] avg_epoch_loss=5.122103\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=550 train loss <loss>=4.84515361786\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [550]#011Speed: 1625.95 samples/sec#011loss=4.845154\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[555] avg_epoch_loss=5.120310\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=555 train loss <loss>=4.92270326614\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [555]#011Speed: 1029.58 samples/sec#011loss=4.922703\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[560] avg_epoch_loss=5.120975\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=560 train loss <loss>=5.19493103027\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [560]#011Speed: 1547.12 samples/sec#011loss=5.194931\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[565] avg_epoch_loss=5.121476\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=565 train loss <loss>=5.17764873505\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [565]#011Speed: 1647.17 samples/sec#011loss=5.177649\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[570] avg_epoch_loss=5.119535\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=570 train loss <loss>=4.89986515045\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [570]#011Speed: 987.76 samples/sec#011loss=4.899865\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch[575] avg_epoch_loss=5.120488\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, batch=575 train loss <loss>=5.22922134399\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Epoch[19] Batch [575]#011Speed: 1618.71 samples/sec#011loss=5.229221\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] processed a total of 18456 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 14390.55585861206, \"sum\": 14390.55585861206, \"min\": 14390.55585861206}}, \"EndTime\": 1589393976.873773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393962.483159}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #throughput_metric: host=algo-1, train throughput=1282.49931264 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, epoch=19, train loss <loss>=5.12062115066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/state_40aa354c-6d17-4438-a37b-dbfa512c67bf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.23101806640625, \"sum\": 10.23101806640625, \"min\": 10.23101806640625}}, \"EndTime\": 1589393976.884412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393976.873836}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Final loss: 5.12062115066 (occurred at epoch 19)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] #quality_metric: host=algo-1, train final_loss <loss>=5.12062115066\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 WARNING 140669025912640] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 41.72110557556152, \"sum\": 41.72110557556152, \"min\": 41.72110557556152}}, \"EndTime\": 1589393976.92655, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393976.884477}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 66.48397445678711, \"sum\": 66.48397445678711, \"min\": 66.48397445678711}}, \"EndTime\": 1589393976.951279, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393976.926614}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 4.591941833496094, \"sum\": 4.591941833496094, \"min\": 4.591941833496094}}, \"EndTime\": 1589393976.955983, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393976.951346}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:36 INFO 140669025912640] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03600120544433594, \"sum\": 0.03600120544433594, \"min\": 0.03600120544433594}}, \"EndTime\": 1589393976.956708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393976.956028}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:38 INFO 140669025912640] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:40 INFO 140669025912640] Number of test batches scored: 20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/13/2020 18:19:41 INFO 140669025912640] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:43 INFO 140669025912640] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/numpy/ma/core.py:2785: UserWarning: Warning: converting a masked element to nan.\n",
      "  order=order, subok=True, ndmin=ndmin)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 8737.796068191528, \"sum\": 8737.796068191528, \"min\": 8737.796068191528}}, \"EndTime\": 1589393985.694467, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393976.95676}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, RMSE): 1317.0583727\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, mean_absolute_QuantileLoss): 4666107.511838785\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, mean_wQuantileLoss): 1.5977839431682737\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.1]): 1.7474634116567482\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.2]): 2.0078116612719077\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.3]): 1.9869102514272925\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.4]): 1.8700664540016654\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.5]): 1.792882395562344\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.6]): 1.6748222517254232\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.7]): 1.4570799496326623\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.8]): 1.1394173752046834\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #test_score (algo-1, wQuantileLoss[0.9]): 0.7036017380317356\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=1.59778394317\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:19:45 INFO 140669025912640] #quality_metric: host=algo-1, test RMSE <loss>=1317.0583727\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 299418.9019203186, \"sum\": 299418.9019203186, \"min\": 299418.9019203186}, \"setuptime\": {\"count\": 1, \"max\": 7.251977920532227, \"sum\": 7.251977920532227, \"min\": 7.251977920532227}}, \"EndTime\": 1589393985.702362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589393985.694527}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-13 18:19:55 Uploading - Uploading generated training model\n",
      "2020-05-13 18:19:55 Completed - Training job completed\n",
      "Training seconds: 344\n",
      "Billable seconds: 344\n"
     ]
    }
   ],
   "source": [
    "dar_estimator.fit(inputs=dar_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-motor-maintenance-2020-05-13-18-12-10-591'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_job_name = dar_estimator.latest_training_job.name\n",
    "dar_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Cut Forest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3079934 entries, 2020-02-22 23:59:59 to 2020-02-25 22:03:11\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Dtype\n",
      "---  ------         -----\n",
      " 0   motor_peak_mA  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 47.0 MB\n"
     ]
    }
   ],
   "source": [
    "anomalies = data[[\"motor_peak_mA\"]]\n",
    "anomalies = anomalies[anomalies[\"motor_peak_mA\"] > 0]\n",
    "anomalies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_dataframe = train_test_split(anomalies, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anomaly</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         motor_peak_mA\n",
       "anomaly               \n",
       "0               615677\n",
       "1                  310"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_dataframe.copy()\n",
    "test_data[\"anomaly\"] = test_data[\"motor_peak_mA\"] > 4000\n",
    "test_data[\"anomaly\"] = test_data[\"anomaly\"] | (test_data[\"motor_peak_mA\"] > 50) & (test_data[\"motor_peak_mA\"] < 200)\n",
    "test_data[\"anomaly\"] = test_data[\"anomaly\"].astype(int) \n",
    "test_data.groupby(\"anomaly\").count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615987.000000</td>\n",
       "      <td>615987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>523.652965</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>684.645458</td>\n",
       "      <td>0.022428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>794.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5568.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       motor_peak_mA        anomaly\n",
       "count  615987.000000  615987.000000\n",
       "mean      523.652965       0.000503\n",
       "std       684.645458       0.022428\n",
       "min         9.000000       0.000000\n",
       "25%        10.000000       0.000000\n",
       "50%        21.000000       0.000000\n",
       "75%       794.000000       0.000000\n",
       "max      5568.000000       1.000000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.463947e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.254138e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.861857e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.980000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.730000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       motor_peak_mA\n",
       "count   2.463947e+06\n",
       "mean    5.254138e+02\n",
       "std     6.861857e+02\n",
       "min     9.000000e+00\n",
       "25%     1.000000e+01\n",
       "50%     2.100000e+01\n",
       "75%     7.980000e+02\n",
       "max     7.730000e+03"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9],\n",
       "       [10],\n",
       "       [10],\n",
       "       ...,\n",
       "       [10],\n",
       "       [10],\n",
       "       [ 9]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array = train_data.values\n",
    "train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  10],\n",
       "       [1692],\n",
       "       [ 522],\n",
       "       ...,\n",
       "       [  10],\n",
       "       [  10],\n",
       "       [  10]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = test_data[[\"motor_peak_mA\"]].values\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array = test_data[\"anomaly\"].values\n",
    "labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "import boto3\n",
    "\n",
    "s3bucket = boto3.resource('s3').Bucket(bucket)\n",
    "\n",
    "def upload_records(array,key,labels=None):\n",
    "    result = {} \n",
    "    buf = io.BytesIO()\n",
    "    if (labels is not None):\n",
    "        smac.write_numpy_to_dense_tensor(buf, array, labels)\n",
    "    else:\n",
    "        smac.write_numpy_to_dense_tensor(buf, array)\n",
    "    buf.seek(0)\n",
    "    s3bucket.Object(key).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <sagemaker.inputs.s3_input at 0x7fbfa4c8cef0>,\n",
       " 'test': <sagemaker.inputs.s3_input at 0x7fbfa4c2ef60>}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "prefix = \"mt-motor-anomaly\" \n",
    "\n",
    "cwd = os.getcwd()\n",
    "train_key  = \"{}/input/{}\".format(prefix,\"train.rio\")\n",
    "test_key  = \"{}/input/{}\".format(prefix, \"test.rio\")\n",
    "\n",
    "upload_records(train_array,train_key)\n",
    "upload_records(test_array,test_key,labels_array)\n",
    "\n",
    "train_input = sagemaker.s3_input(\n",
    "       s3_data=\"s3://{}/{}\".format(bucket,train_key),\n",
    "       content_type='application/x-recordio-protobuf',\n",
    "       distribution='ShardedByS3Key')\n",
    "\n",
    "test_input = sagemaker.s3_input(\n",
    "       s3_data=\"s3://{}/{}\".format(bucket,test_key),\n",
    "       content_type='application/x-recordio-protobuf',\n",
    "       distribution='FullyReplicated')\n",
    "\n",
    "rcf_input = {\n",
    "    'train': train_input,\n",
    "    'test': test_input     \n",
    "}\n",
    "\n",
    "rcf_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'438346466558.dkr.ecr.eu-west-1.amazonaws.com/randomcutforest:1'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "rcf_container = get_image_uri(region, 'randomcutforest')\n",
    "rcf_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcf_hparams = {\n",
    "    \"num_samples_per_tree\":512,\n",
    "    \"num_trees\":50,\n",
    "    \"feature_dim\":1,\n",
    "    \"eval_metrics\": \"accuracy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcf_estimator = sagemaker.estimator.Estimator(\n",
    "                      rcf_container,\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.m5.large',\n",
    "                      base_job_name=\"mt-motor-anomaly\",\n",
    "                      output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                      hyperparameters = rcf_hparams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-13 18:52:48 Starting - Starting the training job...\n",
      "2020-05-13 18:52:49 Starting - Launching requested ML instances......\n",
      "2020-05-13 18:53:48 Starting - Preparing the instances for training...\n",
      "2020-05-13 18:54:33 Downloading - Downloading input data...\n",
      "2020-05-13 18:55:10 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/scipy/_lib/_numpy_compat.py:10: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing.nosetester import import_nose\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/scipy/stats/morestats.py:12: DeprecationWarning: Importing from numpy.testing.decorators is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import setastest\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_ftp_port': 8999, u'num_samples_per_tree': 256, u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'_kvstore': u'dist_async', u'force_dense': u'true', u'epochs': 1, u'num_trees': 100, u'eval_metrics': [u'accuracy', u'precision_recall_fscore'], u'_num_kv_servers': u'auto', u'mini_batch_size': 1000}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'eval_metrics': u'accuracy', u'feature_dim': u'1', u'num_samples_per_tree': u'512', u'num_trees': u'50'}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Final configuration: {u'_ftp_port': 8999, u'num_samples_per_tree': u'512', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'_log_level': u'info', u'_kvstore': u'dist_async', u'force_dense': u'true', u'epochs': 1, u'feature_dim': u'1', u'num_trees': u'50', u'eval_metrics': u'accuracy', u'_num_kv_servers': u'auto', u'mini_batch_size': 1000}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 WARNING 139968475498304] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7156db6d-874f-4e39-bef8-583006d2aa2b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2020-05-13-18-52-47-889', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-170-20.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/061256ab-4221-4208-b983-23f2cf6f2073', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:171292125691:training-job/mt-motor-anomaly-2020-05-13-18-52-47-889', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7156db6d-874f-4e39-bef8-583006d2aa2b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.170.20', 'AWS_REGION': 'eu-west-1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2020-05-13-18-52-47-889', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-170-20.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/061256ab-4221-4208-b983-23f2cf6f2073', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:171292125691:training-job/mt-motor-anomaly-2020-05-13-18-52-47-889', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7156db6d-874f-4e39-bef8-583006d2aa2b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'eu-west-1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2020-05-13-18-52-47-889', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-170-20.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/061256ab-4221-4208-b983-23f2cf6f2073', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:171292125691:training-job/mt-motor-anomaly-2020-05-13-18-52-47-889', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7156db6d-874f-4e39-bef8-583006d2aa2b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.170.20', 'AWS_REGION': 'eu-west-1', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2020-05-13-18-52-47-889', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-170-20.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/061256ab-4221-4208-b983-23f2cf6f2073', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:171292125691:training-job/mt-motor-anomaly-2020-05-13-18-52-47-889', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/7156db6d-874f-4e39-bef8-583006d2aa2b', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.0.170.20', 'AWS_REGION': 'eu-west-1', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2020-05-13-18-52-47-889', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '1', 'HOSTNAME': 'ip-10-0-170-20.eu-west-1.compute.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/061256ab-4221-4208-b983-23f2cf6f2073', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:eu-west-1:171292125691:training-job/mt-motor-anomaly-2020-05-13-18-52-47-889', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 31 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 32 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:25 INFO 139968475498304] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[2020-05-13 18:55:25.984] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Verifying hyperparamemters...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Hyperparameters are correct.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Validating that feature_dim agrees with dimensions in training data...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] feature_dim is correct.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Validating memory limits...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Available memory in bytes: 6524846080\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Estimated sample size in bytes: 204800\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Estimated memory needed to build the forest in bytes: 1024000\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Memory limits validated.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Starting cluster sharing facilities...\u001b[0m\n",
      "\u001b[34m[I 20-05-13 18:55:26] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139966608832256] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[34m[I 20-05-13 18:55:26] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139966608832256] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139966608832256] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[34m[I 20-05-13 18:55:26] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[34m[I 20-05-13 18:55:26] passive ports: None\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139966608832256] passive ports: None\u001b[0m\n",
      "\u001b[34m[I 20-05-13 18:55:26] use sendfile(2): False\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139966608832256] use sendfile(2): False\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Create Store: dist_async\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Cluster sharing facilities started.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Verifying all workers are accessible...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] All workers accessible.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Initializing Sampler...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Sampler correctly initialized.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 824.2661952972412, \"sum\": 824.2661952972412, \"min\": 824.2661952972412}}, \"EndTime\": 1589396126.835641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396125.976514}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1589396126.83585, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396126.835802}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-13 18:55:26.836] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 858, \"num_examples\": 1, \"num_bytes\": 28000}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:26 INFO 139968475498304] Sampling training data...\u001b[0m\n",
      "\u001b[34m[2020-05-13 18:55:30.410] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3573, \"num_examples\": 2464, \"num_bytes\": 68990516}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Sampling training data completed.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 3582.1139812469482, \"sum\": 3582.1139812469482, \"min\": 3582.1139812469482}}, \"EndTime\": 1589396130.418634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396126.835735}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 2464, \"sum\": 2464.0, \"min\": 2464}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 2464, \"sum\": 2464.0, \"min\": 2464}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 2463947, \"sum\": 2463947.0, \"min\": 2463947}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2464, \"sum\": 2464.0, \"min\": 2464}, \"Total Records Seen\": {\"count\": 1, \"max\": 2463947, \"sum\": 2463947.0, \"min\": 2463947}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 2463947, \"sum\": 2463947.0, \"min\": 2463947}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1589396130.419089, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\", \"epoch\": 0}, \"StartTime\": 1589396126.836436}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] #throughput_metric: host=algo-1, train throughput=687715.490919 records/second\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Master node: building Random Cut Forest...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Gathering samples...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] 25600 samples gathered\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Building Random Cut Forest...\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Random Cut Forest built: \n",
      "\u001b[0m\n",
      "\u001b[34mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 1, shingle_size: 1, trees_num_nodes: [493, 473, 471, 477, 479, 483, 455, 443, 447, 481, 491, 431, 503, 483, 455, 461, 477, 465, 495, 491, 465, 447, 431, 427, 489, 449, 453, 505, 463, 473, 471, 437, 459, 481, 415, 453, 449, 445, 453, 483, 471, 455, 439, 497, 473, 415, 475, 453, 455, 489, ], trees_depth: [24, 19, 20, 20, 19, 16, 21, 19, 17, 18, 22, 17, 18, 18, 17, 20, 17, 16, 18, 18, 27, 18, 18, 19, 19, 22, 19, 17, 19, 18, 17, 17, 19, 17, 18, 21, 17, 19, 20, 19, 16, 16, 16, 21, 20, 16, 16, 20, 20, 22, ], max_num_nodes: 505, min_num_nodes: 415, avg_num_nodes: 464, max_tree_depth: 27, min_tree_depth: 16, avg_tree_depth: 18, mem_size: 2415744}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 21.435976028442383, \"sum\": 21.435976028442383, \"min\": 21.435976028442383}, \"model.bytes\": {\"count\": 1, \"max\": 2415744, \"sum\": 2415744.0, \"min\": 2415744}, \"fit_model.time\": {\"count\": 1, \"max\": 10.080814361572266, \"sum\": 10.080814361572266, \"min\": 10.080814361572266}}, \"EndTime\": 1589396130.440844, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396130.418703}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Master node: Serializing the RandomCutForest model\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"serialize_model.time\": {\"count\": 1, \"max\": 21.26598358154297, \"sum\": 21.26598358154297, \"min\": 21.26598358154297}}, \"EndTime\": 1589396130.462216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396130.440905}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:30 INFO 139968475498304] Labels shape [DataDesc[out_label,(1000L,),<type 'numpy.int32'>,NCHW]]\u001b[0m\n",
      "\u001b[34m[2020-05-13 18:55:30.464] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 4479, \"num_examples\": 1, \"num_bytes\": 44000}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-13 18:55:44 Uploading - Uploading generated training model\u001b[34m[2020-05-13 18:55:37.589] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 2, \"duration\": 7125, \"num_examples\": 616, \"num_bytes\": 27103428}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"evaluate.time\": {\"count\": 1, \"max\": 7125.711917877197, \"sum\": 7125.711917877197, \"min\": 7125.711917877197}}, \"EndTime\": 1589396137.589835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396130.462271}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-05-13 18:55:38.873] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 4, \"duration\": 1243, \"num_examples\": 616, \"num_bytes\": 27103428}\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #precision_recall_fscore: [('precision', 1.0), ('negative_precision', 0.9817258075256994), ('recall', 0.026814289421330333), ('negative_recall', 1.0), ('f1', 0.05222811894532895), ('negative_f1', 0.990778647376492)]\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #accuracy: [('accuracy', 0.9817350041478148)]\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"score.time\": {\"count\": 1, \"max\": 8695.88017463684, \"sum\": 8695.88017463684, \"min\": 8695.88017463684}}, \"EndTime\": 1589396139.158536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396137.589907}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 616, \"sum\": 616.0, \"min\": 616}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 616, \"sum\": 616.0, \"min\": 616}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 615987, \"sum\": 615987.0, \"min\": 615987}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1233, \"sum\": 1233.0, \"min\": 1233}, \"Total Records Seen\": {\"count\": 1, \"max\": 1232974, \"sum\": 1232974.0, \"min\": 1232974}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 615987, \"sum\": 615987.0, \"min\": 615987}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1589396139.158656, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396130.462622}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('precision', 1.0)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('negative_precision', 0.9817258075256994)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('recall', 0.026814289421330333)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('negative_recall', 1.0)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('f1', 0.05222811894532895)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('negative_f1', 0.990778647376492)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #test_score (algo-1) : ('accuracy', 0.9817350041478148)\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139968475498304] #quality_metric: host=algo-1, test f1 <score>=0.0522281189453\u001b[0m\n",
      "\u001b[34m[I 20-05-13 18:55:39] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[34m[05/13/2020 18:55:39 INFO 139966608832256] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 13437.82901763916, \"sum\": 13437.82901763916, \"min\": 13437.82901763916}, \"setuptime\": {\"count\": 1, \"max\": 183.55703353881836, \"sum\": 183.55703353881836, \"min\": 183.55703353881836}}, \"EndTime\": 1589396139.224833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"RandomCutForest\"}, \"StartTime\": 1589396139.158607}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-13 18:55:50 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 77\n"
     ]
    }
   ],
   "source": [
    "rcf_estimator.fit(rcf_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: mt-motor-anomaly-2020-05-13-18-52-47-889\n"
     ]
    }
   ],
   "source": [
    "print('Training job name: {}'.format(rcf_estimator.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Cut Forest Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "rcf_inference = rcf_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'rcf_inference_endpoint' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-motor-anomaly-2020-05-13-18-52-47-889'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf_inference_endpoint = rcf_inference.endpoint\n",
    "%store rcf_inference_endpoint\n",
    "rcf_inference_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "rcf_inference.content_type = 'text/csv'\n",
    "rcf_inference.serializer = csv_serializer\n",
    "rcf_inference.accept = 'application/json'\n",
    "rcf_inference.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   9],\n",
       "       [  10],\n",
       "       [  10],\n",
       "       [1371],\n",
       "       [   9]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = train_data[:5].values\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': [{'score': 0.7398879019},\n",
       "  {'score': 0.7324709382},\n",
       "  {'score': 0.7324709382},\n",
       "  {'score': 0.9265146281},\n",
       "  {'score': 0.7398879019}]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rcf_inference.predict(sample_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77424646166, 0.9265146281, 0.08520123897173758, 0.8594477006317376)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sigmas = 1\n",
    "\n",
    "scores = results[\"scores\"]\n",
    "scores = [score[\"score\"] for score in scores]\n",
    "series = pd.Series(scores)\n",
    "score_mean = series.mean()\n",
    "score_max = series.max()\n",
    "score_std = series.std()\n",
    "score_cutoff = score_mean + sigmas*score_std\n",
    "(score_mean,score_max,score_std,score_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.926515\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies = series[series > score_cutoff ]  \n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 anomalies detected'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{} anomalies detected\".format(len(anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep AR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-motor-maintenance-2020-05-13-18-12-10-591'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=dar_job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    deployment_image=dar_image_name,\n",
    "    role=role\n",
    ")\n",
    "dar_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16946"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = list(train_tss.values())[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = {\n",
    "    \"instances\": instances,\n",
    "    \"configuration\": {\n",
    "         \"output_types\": [\"mean\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        0\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1843.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        1\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2171.0,\n",
      "        1949.0,\n",
      "        1769.0,\n",
      "        871.0,\n",
      "        477.0,\n",
      "        529.0,\n",
      "        570.0,\n",
      "        2202.0,\n",
      "        1483.0,\n",
      "        734.0,\n",
      "        10.0,\n",
      "        532.0,\n",
      "        817.0,\n",
      "        519.0,\n",
      "        617.0,\n",
      "        2146.0,\n",
      "        1870.0,\n",
      "        1397.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        2\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2145.0,\n",
      "        1772.0,\n",
      "        1392.0,\n",
      "        909.0,\n",
      "        556.0,\n",
      "        658.0,\n",
      "        680.0,\n",
      "        2354.0,\n",
      "        1151.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        681.0,\n",
      "        553.0,\n",
      "        608.0,\n",
      "        2014.0,\n",
      "        1685.0,\n",
      "        1518.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        3\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1580.0,\n",
      "        1997.0,\n",
      "        1735.0,\n",
      "        1202.0,\n",
      "        952.0,\n",
      "        436.0,\n",
      "        648.0,\n",
      "        694.0,\n",
      "        2252.0,\n",
      "        1345.0,\n",
      "        621.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        562.0,\n",
      "        563.0,\n",
      "        10.0,\n",
      "        801.0,\n",
      "        495.0,\n",
      "        1510.0,\n",
      "        1800.0,\n",
      "        1675.0,\n",
      "        1106.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        4\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1830.0,\n",
      "        2195.0,\n",
      "        1846.0,\n",
      "        1503.0,\n",
      "        722.0,\n",
      "        440.0,\n",
      "        575.0,\n",
      "        665.0,\n",
      "        2630.0,\n",
      "        1505.0,\n",
      "        625.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        544.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        563.0,\n",
      "        511.0,\n",
      "        567.0,\n",
      "        2031.0,\n",
      "        1677.0,\n",
      "        1082.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        5\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2324.0,\n",
      "        2592.0,\n",
      "        2225.0,\n",
      "        1298.0,\n",
      "        609.0,\n",
      "        549.0,\n",
      "        863.0,\n",
      "        1103.0,\n",
      "        3073.0,\n",
      "        1784.0,\n",
      "        638.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        880.0,\n",
      "        616.0,\n",
      "        2066.0,\n",
      "        2321.0,\n",
      "        1519.0,\n",
      "        1207.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        6\n",
      "      ],\n",
      "      \"target\": [\n",
      "        88.0,\n",
      "        2173.0,\n",
      "        1697.0,\n",
      "        1427.0,\n",
      "        560.0,\n",
      "        457.0,\n",
      "        538.0,\n",
      "        584.0,\n",
      "        2157.0,\n",
      "        1408.0,\n",
      "        575.0,\n",
      "        617.0,\n",
      "        871.0,\n",
      "        473.0,\n",
      "        1778.0,\n",
      "        2081.0,\n",
      "        1587.0,\n",
      "        1125.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        7\n",
      "      ],\n",
      "      \"target\": [\n",
      "        22.0,\n",
      "        2028.0,\n",
      "        1723.0,\n",
      "        1474.0,\n",
      "        500.0,\n",
      "        537.0,\n",
      "        584.0,\n",
      "        649.0,\n",
      "        2323.0,\n",
      "        1494.0,\n",
      "        674.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        594.0,\n",
      "        515.0,\n",
      "        1513.0,\n",
      "        1938.0,\n",
      "        1901.0,\n",
      "        1033.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        8\n",
      "      ],\n",
      "      \"target\": [\n",
      "        492.0,\n",
      "        2157.0,\n",
      "        1900.0,\n",
      "        1505.0,\n",
      "        908.0,\n",
      "        443.0,\n",
      "        574.0,\n",
      "        642.0,\n",
      "        2446.0,\n",
      "        1514.0,\n",
      "        629.0,\n",
      "        494.0,\n",
      "        827.0,\n",
      "        418.0,\n",
      "        516.0,\n",
      "        1995.0,\n",
      "        1761.0,\n",
      "        1290.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        9\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1704.0,\n",
      "        2060.0,\n",
      "        1764.0,\n",
      "        1498.0,\n",
      "        579.0,\n",
      "        500.0,\n",
      "        586.0,\n",
      "        600.0,\n",
      "        2392.0,\n",
      "        1398.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        547.0,\n",
      "        496.0,\n",
      "        1641.0,\n",
      "        1994.0,\n",
      "        1565.0,\n",
      "        1229.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        10\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2069.0,\n",
      "        1723.0,\n",
      "        1293.0,\n",
      "        1218.0,\n",
      "        563.0,\n",
      "        718.0,\n",
      "        710.0,\n",
      "        2439.0,\n",
      "        2373.0,\n",
      "        676.0,\n",
      "        10.0,\n",
      "        915.0,\n",
      "        447.0,\n",
      "        2004.0,\n",
      "        2183.0,\n",
      "        1802.0,\n",
      "        1258.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        11\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1738.0,\n",
      "        2067.0,\n",
      "        1815.0,\n",
      "        1556.0,\n",
      "        700.0,\n",
      "        397.0,\n",
      "        469.0,\n",
      "        470.0,\n",
      "        2093.0,\n",
      "        1300.0,\n",
      "        693.0,\n",
      "        423.0,\n",
      "        1622.0,\n",
      "        2048.0,\n",
      "        1690.0,\n",
      "        1267.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        12\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1833.0,\n",
      "        2346.0,\n",
      "        1706.0,\n",
      "        1399.0,\n",
      "        908.0,\n",
      "        531.0,\n",
      "        645.0,\n",
      "        644.0,\n",
      "        2198.0,\n",
      "        1436.0,\n",
      "        754.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        32.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        947.0,\n",
      "        518.0,\n",
      "        1846.0,\n",
      "        2182.0,\n",
      "        1684.0,\n",
      "        1021.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        13\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2239.0,\n",
      "        1884.0,\n",
      "        1466.0,\n",
      "        516.0,\n",
      "        528.0,\n",
      "        743.0,\n",
      "        690.0,\n",
      "        2624.0,\n",
      "        1444.0,\n",
      "        660.0,\n",
      "        555.0,\n",
      "        886.0,\n",
      "        480.0,\n",
      "        586.0,\n",
      "        1992.0,\n",
      "        1873.0,\n",
      "        1098.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        14\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2364.0,\n",
      "        2325.0,\n",
      "        1910.0,\n",
      "        1218.0,\n",
      "        1033.0,\n",
      "        627.0,\n",
      "        736.0,\n",
      "        754.0,\n",
      "        2519.0,\n",
      "        1615.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        636.0,\n",
      "        606.0,\n",
      "        628.0,\n",
      "        2134.0,\n",
      "        1793.0,\n",
      "        1253.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        15\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1791.0,\n",
      "        2146.0,\n",
      "        1813.0,\n",
      "        1652.0,\n",
      "        599.0,\n",
      "        494.0,\n",
      "        561.0,\n",
      "        545.0,\n",
      "        2156.0,\n",
      "        1117.0,\n",
      "        705.0,\n",
      "        10.0,\n",
      "        568.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        903.0,\n",
      "        469.0,\n",
      "        492.0,\n",
      "        2158.0,\n",
      "        1586.0,\n",
      "        1037.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        16\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        1999.0,\n",
      "        1753.0,\n",
      "        1336.0,\n",
      "        566.0,\n",
      "        492.0,\n",
      "        637.0,\n",
      "        660.0,\n",
      "        2474.0,\n",
      "        1540.0,\n",
      "        589.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        798.0,\n",
      "        484.0,\n",
      "        492.0,\n",
      "        1919.0,\n",
      "        1713.0,\n",
      "        1012.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        17\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1958.0,\n",
      "        2077.0,\n",
      "        1945.0,\n",
      "        1377.0,\n",
      "        774.0,\n",
      "        488.0,\n",
      "        533.0,\n",
      "        515.0,\n",
      "        1478.0,\n",
      "        1543.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        572.0,\n",
      "        437.0,\n",
      "        1981.0,\n",
      "        1973.0,\n",
      "        1584.0,\n",
      "        1256.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        18\n",
      "      ],\n",
      "      \"target\": [\n",
      "        513.0,\n",
      "        2218.0,\n",
      "        2034.0,\n",
      "        1543.0,\n",
      "        1019.0,\n",
      "        406.0,\n",
      "        476.0,\n",
      "        542.0,\n",
      "        2078.0,\n",
      "        955.0,\n",
      "        781.0,\n",
      "        857.0,\n",
      "        436.0,\n",
      "        2054.0,\n",
      "        2104.0,\n",
      "        1534.0,\n",
      "        1107.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        19\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2265.0,\n",
      "        2159.0,\n",
      "        1533.0,\n",
      "        1027.0,\n",
      "        630.0,\n",
      "        730.0,\n",
      "        741.0,\n",
      "        2426.0,\n",
      "        1551.0,\n",
      "        770.0,\n",
      "        995.0,\n",
      "        557.0,\n",
      "        2044.0,\n",
      "        2077.0,\n",
      "        1688.0,\n",
      "        1168.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        20\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1942.0,\n",
      "        2245.0,\n",
      "        1852.0,\n",
      "        1400.0,\n",
      "        1009.0,\n",
      "        739.0,\n",
      "        1128.0,\n",
      "        1275.0,\n",
      "        2706.0,\n",
      "        1824.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        886.0,\n",
      "        579.0,\n",
      "        630.0,\n",
      "        2199.0,\n",
      "        1753.0,\n",
      "        1429.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        21\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2701.0,\n",
      "        1941.0,\n",
      "        2142.0,\n",
      "        783.0,\n",
      "        641.0,\n",
      "        883.0,\n",
      "        988.0,\n",
      "        3126.0,\n",
      "        1751.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        645.0,\n",
      "        704.0,\n",
      "        738.0,\n",
      "        2523.0,\n",
      "        2063.0,\n",
      "        1423.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        22\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2297.0,\n",
      "        1916.0,\n",
      "        1494.0,\n",
      "        886.0,\n",
      "        596.0,\n",
      "        897.0,\n",
      "        938.0,\n",
      "        2885.0,\n",
      "        1543.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        910.0,\n",
      "        470.0,\n",
      "        2304.0,\n",
      "        2187.0,\n",
      "        1997.0,\n",
      "        1346.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        23\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2000.0,\n",
      "        2446.0,\n",
      "        2075.0,\n",
      "        1662.0,\n",
      "        1253.0,\n",
      "        726.0,\n",
      "        979.0,\n",
      "        1043.0,\n",
      "        2974.0,\n",
      "        1820.0,\n",
      "        728.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        876.0,\n",
      "        568.0,\n",
      "        2264.0,\n",
      "        2361.0,\n",
      "        2253.0,\n",
      "        1432.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        24\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1759.0,\n",
      "        2316.0,\n",
      "        1988.0,\n",
      "        1893.0,\n",
      "        1010.0,\n",
      "        1509.0,\n",
      "        1496.0,\n",
      "        2192.0,\n",
      "        2608.0,\n",
      "        1466.0,\n",
      "        654.0,\n",
      "        979.0,\n",
      "        616.0,\n",
      "        2153.0,\n",
      "        2159.0,\n",
      "        1791.0,\n",
      "        1331.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        25\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2398.0,\n",
      "        2016.0,\n",
      "        1609.0,\n",
      "        845.0,\n",
      "        454.0,\n",
      "        624.0,\n",
      "        838.0,\n",
      "        2365.0,\n",
      "        1355.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        796.0,\n",
      "        561.0,\n",
      "        2096.0,\n",
      "        2195.0,\n",
      "        1794.0,\n",
      "        1462.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        26\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2449.0,\n",
      "        1943.0,\n",
      "        1581.0,\n",
      "        1348.0,\n",
      "        516.0,\n",
      "        607.0,\n",
      "        664.0,\n",
      "        2658.0,\n",
      "        1649.0,\n",
      "        785.0,\n",
      "        1080.0,\n",
      "        572.0,\n",
      "        624.0,\n",
      "        2420.0,\n",
      "        1882.0,\n",
      "        1298.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        27\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        2403.0,\n",
      "        2208.0,\n",
      "        1631.0,\n",
      "        718.0,\n",
      "        665.0,\n",
      "        732.0,\n",
      "        791.0,\n",
      "        3161.0,\n",
      "        1123.0,\n",
      "        667.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1070.0,\n",
      "        585.0,\n",
      "        1742.0,\n",
      "        2400.0,\n",
      "        1687.0,\n",
      "        1276.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        28\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1805.0,\n",
      "        2242.0,\n",
      "        1993.0,\n",
      "        1493.0,\n",
      "        426.0,\n",
      "        522.0,\n",
      "        591.0,\n",
      "        720.0,\n",
      "        21.0,\n",
      "        2404.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        564.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        22.0,\n",
      "        20.0,\n",
      "        943.0,\n",
      "        574.0,\n",
      "        1683.0,\n",
      "        2150.0,\n",
      "        2077.0,\n",
      "        1375.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        29\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1774.0,\n",
      "        2210.0,\n",
      "        1941.0,\n",
      "        1472.0,\n",
      "        700.0,\n",
      "        604.0,\n",
      "        657.0,\n",
      "        753.0,\n",
      "        2579.0,\n",
      "        1053.0,\n",
      "        782.0,\n",
      "        585.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        882.0,\n",
      "        590.0,\n",
      "        1686.0,\n",
      "        2132.0,\n",
      "        1922.0,\n",
      "        1423.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        30\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1627.0,\n",
      "        2077.0,\n",
      "        1755.0,\n",
      "        1431.0,\n",
      "        664.0,\n",
      "        470.0,\n",
      "        503.0,\n",
      "        539.0,\n",
      "        2284.0,\n",
      "        1326.0,\n",
      "        693.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        810.0,\n",
      "        424.0,\n",
      "        487.0,\n",
      "        2028.0,\n",
      "        1824.0,\n",
      "        1304.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        31\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2040.0,\n",
      "        1700.0,\n",
      "        1495.0,\n",
      "        842.0,\n",
      "        460.0,\n",
      "        547.0,\n",
      "        547.0,\n",
      "        2347.0,\n",
      "        1422.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        888.0,\n",
      "        439.0,\n",
      "        2080.0,\n",
      "        1991.0,\n",
      "        1692.0,\n",
      "        1155.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        32\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1883.0,\n",
      "        2385.0,\n",
      "        1931.0,\n",
      "        1652.0,\n",
      "        804.0,\n",
      "        603.0,\n",
      "        677.0,\n",
      "        735.0,\n",
      "        2465.0,\n",
      "        666.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        850.0,\n",
      "        496.0,\n",
      "        1838.0,\n",
      "        2040.0,\n",
      "        1619.0,\n",
      "        1269.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        33\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2157.0,\n",
      "        1646.0,\n",
      "        1326.0,\n",
      "        608.0,\n",
      "        509.0,\n",
      "        546.0,\n",
      "        685.0,\n",
      "        2104.0,\n",
      "        1387.0,\n",
      "        571.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        32.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1008.0,\n",
      "        538.0,\n",
      "        1514.0,\n",
      "        2059.0,\n",
      "        1546.0,\n",
      "        1127.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        34\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1759.0,\n",
      "        2015.0,\n",
      "        2082.0,\n",
      "        1436.0,\n",
      "        1010.0,\n",
      "        502.0,\n",
      "        554.0,\n",
      "        653.0,\n",
      "        2624.0,\n",
      "        1519.0,\n",
      "        704.0,\n",
      "        602.0,\n",
      "        599.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        940.0,\n",
      "        481.0,\n",
      "        1632.0,\n",
      "        2026.0,\n",
      "        1979.0,\n",
      "        1326.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        35\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1779.0,\n",
      "        2091.0,\n",
      "        1934.0,\n",
      "        1722.0,\n",
      "        715.0,\n",
      "        571.0,\n",
      "        622.0,\n",
      "        691.0,\n",
      "        2664.0,\n",
      "        1147.0,\n",
      "        757.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        574.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        989.0,\n",
      "        635.0,\n",
      "        1665.0,\n",
      "        1974.0,\n",
      "        1603.0,\n",
      "        1293.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        36\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2412.0,\n",
      "        2296.0,\n",
      "        1643.0,\n",
      "        1092.0,\n",
      "        547.0,\n",
      "        598.0,\n",
      "        704.0,\n",
      "        2495.0,\n",
      "        1020.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        593.0,\n",
      "        489.0,\n",
      "        2340.0,\n",
      "        2220.0,\n",
      "        2065.0,\n",
      "        1595.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        37\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1660.0,\n",
      "        2242.0,\n",
      "        2062.0,\n",
      "        1644.0,\n",
      "        898.0,\n",
      "        541.0,\n",
      "        666.0,\n",
      "        667.0,\n",
      "        2254.0,\n",
      "        899.0,\n",
      "        720.0,\n",
      "        531.0,\n",
      "        852.0,\n",
      "        496.0,\n",
      "        1753.0,\n",
      "        2153.0,\n",
      "        1765.0,\n",
      "        1583.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        38\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1737.0,\n",
      "        2032.0,\n",
      "        1699.0,\n",
      "        1220.0,\n",
      "        1139.0,\n",
      "        505.0,\n",
      "        534.0,\n",
      "        569.0,\n",
      "        2226.0,\n",
      "        1082.0,\n",
      "        643.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        887.0,\n",
      "        448.0,\n",
      "        1664.0,\n",
      "        1994.0,\n",
      "        1446.0,\n",
      "        1074.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        39\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1816.0,\n",
      "        2361.0,\n",
      "        1916.0,\n",
      "        1372.0,\n",
      "        526.0,\n",
      "        506.0,\n",
      "        685.0,\n",
      "        800.0,\n",
      "        2712.0,\n",
      "        957.0,\n",
      "        775.0,\n",
      "        493.0,\n",
      "        775.0,\n",
      "        509.0,\n",
      "        1701.0,\n",
      "        2209.0,\n",
      "        1709.0,\n",
      "        1212.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        40\n",
      "      ],\n",
      "      \"target\": [\n",
      "        21.0,\n",
      "        2269.0,\n",
      "        1922.0,\n",
      "        1502.0,\n",
      "        1121.0,\n",
      "        487.0,\n",
      "        628.0,\n",
      "        741.0,\n",
      "        2442.0,\n",
      "        1700.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        558.0,\n",
      "        552.0,\n",
      "        644.0,\n",
      "        2222.0,\n",
      "        1972.0,\n",
      "        1350.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        41\n",
      "      ],\n",
      "      \"target\": [\n",
      "        592.0,\n",
      "        2280.0,\n",
      "        2200.0,\n",
      "        1743.0,\n",
      "        1151.0,\n",
      "        537.0,\n",
      "        705.0,\n",
      "        709.0,\n",
      "        2240.0,\n",
      "        1387.0,\n",
      "        677.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        514.0,\n",
      "        531.0,\n",
      "        1669.0,\n",
      "        2273.0,\n",
      "        2180.0,\n",
      "        1526.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        42\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2606.0,\n",
      "        2055.0,\n",
      "        1920.0,\n",
      "        783.0,\n",
      "        730.0,\n",
      "        925.0,\n",
      "        1045.0,\n",
      "        2759.0,\n",
      "        2510.0,\n",
      "        1088.0,\n",
      "        702.0,\n",
      "        2359.0,\n",
      "        2605.0,\n",
      "        2135.0,\n",
      "        1609.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        43\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2236.0,\n",
      "        1858.0,\n",
      "        1624.0,\n",
      "        887.0,\n",
      "        521.0,\n",
      "        598.0,\n",
      "        647.0,\n",
      "        2322.0,\n",
      "        1378.0,\n",
      "        582.0,\n",
      "        558.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        878.0,\n",
      "        468.0,\n",
      "        465.0,\n",
      "        2241.0,\n",
      "        1844.0,\n",
      "        1121.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        44\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1889.0,\n",
      "        2145.0,\n",
      "        1934.0,\n",
      "        1464.0,\n",
      "        763.0,\n",
      "        628.0,\n",
      "        638.0,\n",
      "        716.0,\n",
      "        2394.0,\n",
      "        1575.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        991.0,\n",
      "        481.0,\n",
      "        1699.0,\n",
      "        2085.0,\n",
      "        1620.0,\n",
      "        1402.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        45\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1720.0,\n",
      "        2053.0,\n",
      "        1744.0,\n",
      "        1176.0,\n",
      "        851.0,\n",
      "        417.0,\n",
      "        572.0,\n",
      "        610.0,\n",
      "        2290.0,\n",
      "        1414.0,\n",
      "        524.0,\n",
      "        507.0,\n",
      "        791.0,\n",
      "        421.0,\n",
      "        1665.0,\n",
      "        1975.0,\n",
      "        1625.0,\n",
      "        1013.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        46\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2084.0,\n",
      "        1752.0,\n",
      "        1314.0,\n",
      "        958.0,\n",
      "        453.0,\n",
      "        579.0,\n",
      "        663.0,\n",
      "        2361.0,\n",
      "        1381.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        808.0,\n",
      "        517.0,\n",
      "        2125.0,\n",
      "        2111.0,\n",
      "        1560.0,\n",
      "        1174.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        47\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1875.0,\n",
      "        2467.0,\n",
      "        2198.0,\n",
      "        2058.0,\n",
      "        775.0,\n",
      "        614.0,\n",
      "        811.0,\n",
      "        776.0,\n",
      "        2262.0,\n",
      "        1504.0,\n",
      "        741.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        566.0,\n",
      "        649.0,\n",
      "        656.0,\n",
      "        2326.0,\n",
      "        1776.0,\n",
      "        1207.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        48\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2106.0,\n",
      "        2282.0,\n",
      "        2216.0,\n",
      "        1618.0,\n",
      "        436.0,\n",
      "        553.0,\n",
      "        717.0,\n",
      "        896.0,\n",
      "        2757.0,\n",
      "        1292.0,\n",
      "        555.0,\n",
      "        839.0,\n",
      "        552.0,\n",
      "        1452.0,\n",
      "        2172.0,\n",
      "        1861.0,\n",
      "        1414.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        49\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2267.0,\n",
      "        2228.0,\n",
      "        1887.0,\n",
      "        1448.0,\n",
      "        605.0,\n",
      "        504.0,\n",
      "        608.0,\n",
      "        691.0,\n",
      "        21.0,\n",
      "        2701.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        885.0,\n",
      "        581.0,\n",
      "        10.0,\n",
      "        2176.0,\n",
      "        1882.0,\n",
      "        1282.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        50\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2106.0,\n",
      "        1825.0,\n",
      "        1230.0,\n",
      "        704.0,\n",
      "        534.0,\n",
      "        619.0,\n",
      "        638.0,\n",
      "        2291.0,\n",
      "        2324.0,\n",
      "        511.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        596.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        613.0,\n",
      "        492.0,\n",
      "        1834.0,\n",
      "        1956.0,\n",
      "        1707.0,\n",
      "        1010.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        51\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2177.0,\n",
      "        2199.0,\n",
      "        2108.0,\n",
      "        2003.0,\n",
      "        895.0,\n",
      "        540.0,\n",
      "        756.0,\n",
      "        692.0,\n",
      "        2604.0,\n",
      "        1583.0,\n",
      "        610.0,\n",
      "        10.0,\n",
      "        671.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        960.0,\n",
      "        691.0,\n",
      "        1701.0,\n",
      "        2188.0,\n",
      "        1816.0,\n",
      "        1524.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        52\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2097.0,\n",
      "        2277.0,\n",
      "        1961.0,\n",
      "        1527.0,\n",
      "        671.0,\n",
      "        455.0,\n",
      "        500.0,\n",
      "        590.0,\n",
      "        2634.0,\n",
      "        1160.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        639.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        955.0,\n",
      "        449.0,\n",
      "        2038.0,\n",
      "        2195.0,\n",
      "        1753.0,\n",
      "        1166.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        53\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2274.0,\n",
      "        2001.0,\n",
      "        1652.0,\n",
      "        837.0,\n",
      "        597.0,\n",
      "        820.0,\n",
      "        837.0,\n",
      "        2719.0,\n",
      "        1578.0,\n",
      "        610.0,\n",
      "        594.0,\n",
      "        820.0,\n",
      "        482.0,\n",
      "        608.0,\n",
      "        2157.0,\n",
      "        1810.0,\n",
      "        1305.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        54\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1897.0,\n",
      "        2269.0,\n",
      "        2420.0,\n",
      "        2136.0,\n",
      "        928.0,\n",
      "        569.0,\n",
      "        738.0,\n",
      "        742.0,\n",
      "        2513.0,\n",
      "        1717.0,\n",
      "        562.0,\n",
      "        503.0,\n",
      "        829.0,\n",
      "        594.0,\n",
      "        1699.0,\n",
      "        2234.0,\n",
      "        1713.0,\n",
      "        1382.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        55\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2313.0,\n",
      "        1865.0,\n",
      "        1418.0,\n",
      "        833.0,\n",
      "        509.0,\n",
      "        599.0,\n",
      "        740.0,\n",
      "        2508.0,\n",
      "        1842.0,\n",
      "        741.0,\n",
      "        562.0,\n",
      "        565.0,\n",
      "        895.0,\n",
      "        536.0,\n",
      "        578.0,\n",
      "        2162.0,\n",
      "        2111.0,\n",
      "        1159.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        56\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2003.0,\n",
      "        1840.0,\n",
      "        1486.0,\n",
      "        726.0,\n",
      "        483.0,\n",
      "        599.0,\n",
      "        579.0,\n",
      "        2237.0,\n",
      "        1295.0,\n",
      "        636.0,\n",
      "        518.0,\n",
      "        792.0,\n",
      "        401.0,\n",
      "        806.0,\n",
      "        2003.0,\n",
      "        1470.0,\n",
      "        1007.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        57\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1998.0,\n",
      "        2300.0,\n",
      "        1863.0,\n",
      "        1548.0,\n",
      "        863.0,\n",
      "        605.0,\n",
      "        697.0,\n",
      "        732.0,\n",
      "        2424.0,\n",
      "        1142.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        590.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        605.0,\n",
      "        619.0,\n",
      "        672.0,\n",
      "        2174.0,\n",
      "        1669.0,\n",
      "        1252.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        58\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2088.0,\n",
      "        2866.0,\n",
      "        2390.0,\n",
      "        1745.0,\n",
      "        1101.0,\n",
      "        575.0,\n",
      "        711.0,\n",
      "        871.0,\n",
      "        2709.0,\n",
      "        1361.0,\n",
      "        744.0,\n",
      "        686.0,\n",
      "        651.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        644.0,\n",
      "        918.0,\n",
      "        2103.0,\n",
      "        2503.0,\n",
      "        2089.0,\n",
      "        1428.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        59\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1827.0,\n",
      "        2143.0,\n",
      "        1879.0,\n",
      "        1516.0,\n",
      "        867.0,\n",
      "        443.0,\n",
      "        523.0,\n",
      "        559.0,\n",
      "        2176.0,\n",
      "        1131.0,\n",
      "        699.0,\n",
      "        540.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        876.0,\n",
      "        504.0,\n",
      "        1814.0,\n",
      "        2019.0,\n",
      "        1896.0,\n",
      "        1469.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        60\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1933.0,\n",
      "        2080.0,\n",
      "        1874.0,\n",
      "        1415.0,\n",
      "        569.0,\n",
      "        463.0,\n",
      "        542.0,\n",
      "        626.0,\n",
      "        2357.0,\n",
      "        1493.0,\n",
      "        666.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        596.0,\n",
      "        499.0,\n",
      "        1850.0,\n",
      "        2020.0,\n",
      "        1390.0,\n",
      "        1203.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        61\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1831.0,\n",
      "        2295.0,\n",
      "        2083.0,\n",
      "        1752.0,\n",
      "        1106.0,\n",
      "        495.0,\n",
      "        699.0,\n",
      "        828.0,\n",
      "        3027.0,\n",
      "        1582.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        776.0,\n",
      "        510.0,\n",
      "        591.0,\n",
      "        2352.0,\n",
      "        1789.0,\n",
      "        1414.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        62\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1800.0,\n",
      "        2263.0,\n",
      "        1654.0,\n",
      "        1461.0,\n",
      "        1133.0,\n",
      "        456.0,\n",
      "        561.0,\n",
      "        606.0,\n",
      "        2506.0,\n",
      "        1099.0,\n",
      "        673.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        570.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        897.0,\n",
      "        558.0,\n",
      "        1820.0,\n",
      "        2136.0,\n",
      "        1704.0,\n",
      "        1091.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        63\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        2291.0,\n",
      "        1915.0,\n",
      "        1608.0,\n",
      "        1246.0,\n",
      "        551.0,\n",
      "        591.0,\n",
      "        749.0,\n",
      "        20.0,\n",
      "        2601.0,\n",
      "        828.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        935.0,\n",
      "        543.0,\n",
      "        1763.0,\n",
      "        2193.0,\n",
      "        1898.0,\n",
      "        1189.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        64\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2146.0,\n",
      "        2040.0,\n",
      "        1761.0,\n",
      "        1413.0,\n",
      "        763.0,\n",
      "        478.0,\n",
      "        680.0,\n",
      "        655.0,\n",
      "        2148.0,\n",
      "        1145.0,\n",
      "        926.0,\n",
      "        656.0,\n",
      "        2049.0,\n",
      "        2052.0,\n",
      "        1672.0,\n",
      "        1362.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        65\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2375.0,\n",
      "        2245.0,\n",
      "        1429.0,\n",
      "        1182.0,\n",
      "        485.0,\n",
      "        587.0,\n",
      "        649.0,\n",
      "        2712.0,\n",
      "        1557.0,\n",
      "        556.0,\n",
      "        470.0,\n",
      "        817.0,\n",
      "        459.0,\n",
      "        485.0,\n",
      "        2167.0,\n",
      "        1767.0,\n",
      "        1375.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        66\n",
      "      ],\n",
      "      \"target\": [\n",
      "        41.0,\n",
      "        2383.0,\n",
      "        2145.0,\n",
      "        1516.0,\n",
      "        1380.0,\n",
      "        529.0,\n",
      "        597.0,\n",
      "        672.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        3044.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        673.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        2305.0,\n",
      "        2013.0,\n",
      "        1329.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        67\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2268.0,\n",
      "        2134.0,\n",
      "        1497.0,\n",
      "        863.0,\n",
      "        687.0,\n",
      "        809.0,\n",
      "        814.0,\n",
      "        2613.0,\n",
      "        1694.0,\n",
      "        781.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        1051.0,\n",
      "        565.0,\n",
      "        2104.0,\n",
      "        2313.0,\n",
      "        1872.0,\n",
      "        1291.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        68\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1759.0,\n",
      "        2245.0,\n",
      "        2225.0,\n",
      "        1534.0,\n",
      "        789.0,\n",
      "        527.0,\n",
      "        665.0,\n",
      "        734.0,\n",
      "        2421.0,\n",
      "        1091.0,\n",
      "        730.0,\n",
      "        819.0,\n",
      "        605.0,\n",
      "        1753.0,\n",
      "        2148.0,\n",
      "        2044.0,\n",
      "        1473.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        69\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2268.0,\n",
      "        1947.0,\n",
      "        1248.0,\n",
      "        443.0,\n",
      "        525.0,\n",
      "        690.0,\n",
      "        740.0,\n",
      "        2408.0,\n",
      "        1527.0,\n",
      "        484.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        447.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        744.0,\n",
      "        402.0,\n",
      "        492.0,\n",
      "        2119.0,\n",
      "        1765.0,\n",
      "        1304.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        70\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2207.0,\n",
      "        10.0,\n",
      "        1543.0,\n",
      "        403.0,\n",
      "        525.0,\n",
      "        640.0,\n",
      "        724.0,\n",
      "        2410.0,\n",
      "        960.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        581.0,\n",
      "        550.0,\n",
      "        2160.0,\n",
      "        2026.0,\n",
      "        1815.0,\n",
      "        929.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        71\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1979.0,\n",
      "        2092.0,\n",
      "        1767.0,\n",
      "        1404.0,\n",
      "        591.0,\n",
      "        520.0,\n",
      "        627.0,\n",
      "        782.0,\n",
      "        2627.0,\n",
      "        1642.0,\n",
      "        496.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        836.0,\n",
      "        478.0,\n",
      "        1658.0,\n",
      "        2006.0,\n",
      "        1527.0,\n",
      "        1215.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        72\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1972.0,\n",
      "        2351.0,\n",
      "        1761.0,\n",
      "        1712.0,\n",
      "        853.0,\n",
      "        561.0,\n",
      "        657.0,\n",
      "        791.0,\n",
      "        2742.0,\n",
      "        1738.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        30.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        1031.0,\n",
      "        696.0,\n",
      "        678.0,\n",
      "        2156.0,\n",
      "        1554.0,\n",
      "        1332.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        73\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1843.0,\n",
      "        2216.0,\n",
      "        1910.0,\n",
      "        1549.0,\n",
      "        931.0,\n",
      "        457.0,\n",
      "        593.0,\n",
      "        630.0,\n",
      "        2099.0,\n",
      "        954.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        544.0,\n",
      "        578.0,\n",
      "        568.0,\n",
      "        2143.0,\n",
      "        1701.0,\n",
      "        1067.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        74\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1735.0,\n",
      "        2235.0,\n",
      "        1817.0,\n",
      "        1672.0,\n",
      "        972.0,\n",
      "        442.0,\n",
      "        608.0,\n",
      "        595.0,\n",
      "        2362.0,\n",
      "        1134.0,\n",
      "        742.0,\n",
      "        899.0,\n",
      "        485.0,\n",
      "        1686.0,\n",
      "        2018.0,\n",
      "        1566.0,\n",
      "        1138.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        75\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1872.0,\n",
      "        2106.0,\n",
      "        1763.0,\n",
      "        1724.0,\n",
      "        619.0,\n",
      "        488.0,\n",
      "        553.0,\n",
      "        613.0,\n",
      "        2155.0,\n",
      "        1258.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        870.0,\n",
      "        525.0,\n",
      "        1708.0,\n",
      "        2141.0,\n",
      "        1381.0,\n",
      "        1136.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        76\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2186.0,\n",
      "        2493.0,\n",
      "        2047.0,\n",
      "        1659.0,\n",
      "        1201.0,\n",
      "        561.0,\n",
      "        572.0,\n",
      "        787.0,\n",
      "        2516.0,\n",
      "        1167.0,\n",
      "        805.0,\n",
      "        20.0,\n",
      "        578.0,\n",
      "        591.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        22.0,\n",
      "        585.0,\n",
      "        622.0,\n",
      "        2085.0,\n",
      "        2390.0,\n",
      "        1788.0,\n",
      "        1234.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        77\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2583.0,\n",
      "        2308.0,\n",
      "        2078.0,\n",
      "        1526.0,\n",
      "        810.0,\n",
      "        1001.0,\n",
      "        1200.0,\n",
      "        2812.0,\n",
      "        1837.0,\n",
      "        967.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1140.0,\n",
      "        715.0,\n",
      "        2029.0,\n",
      "        2541.0,\n",
      "        2222.0,\n",
      "        1583.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        78\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1704.0,\n",
      "        2108.0,\n",
      "        2142.0,\n",
      "        1679.0,\n",
      "        1092.0,\n",
      "        538.0,\n",
      "        710.0,\n",
      "        859.0,\n",
      "        2529.0,\n",
      "        1080.0,\n",
      "        760.0,\n",
      "        522.0,\n",
      "        873.0,\n",
      "        559.0,\n",
      "        1747.0,\n",
      "        2082.0,\n",
      "        1673.0,\n",
      "        1258.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        79\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2038.0,\n",
      "        1726.0,\n",
      "        1513.0,\n",
      "        797.0,\n",
      "        517.0,\n",
      "        586.0,\n",
      "        596.0,\n",
      "        2420.0,\n",
      "        1483.0,\n",
      "        651.0,\n",
      "        848.0,\n",
      "        443.0,\n",
      "        1954.0,\n",
      "        1928.0,\n",
      "        1721.0,\n",
      "        1290.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        80\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1738.0,\n",
      "        2341.0,\n",
      "        2074.0,\n",
      "        1785.0,\n",
      "        841.0,\n",
      "        515.0,\n",
      "        647.0,\n",
      "        710.0,\n",
      "        2583.0,\n",
      "        1457.0,\n",
      "        627.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        847.0,\n",
      "        667.0,\n",
      "        1703.0,\n",
      "        2055.0,\n",
      "        1719.0,\n",
      "        1156.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        81\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1730.0,\n",
      "        2071.0,\n",
      "        1840.0,\n",
      "        1275.0,\n",
      "        935.0,\n",
      "        516.0,\n",
      "        616.0,\n",
      "        680.0,\n",
      "        2488.0,\n",
      "        1112.0,\n",
      "        545.0,\n",
      "        546.0,\n",
      "        542.0,\n",
      "        830.0,\n",
      "        399.0,\n",
      "        1576.0,\n",
      "        1904.0,\n",
      "        1520.0,\n",
      "        1045.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        82\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2122.0,\n",
      "        1785.0,\n",
      "        1443.0,\n",
      "        926.0,\n",
      "        489.0,\n",
      "        546.0,\n",
      "        715.0,\n",
      "        2237.0,\n",
      "        1635.0,\n",
      "        719.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        804.0,\n",
      "        455.0,\n",
      "        484.0,\n",
      "        2108.0,\n",
      "        1714.0,\n",
      "        1157.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        83\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        2193.0,\n",
      "        1948.0,\n",
      "        1521.0,\n",
      "        576.0,\n",
      "        542.0,\n",
      "        673.0,\n",
      "        700.0,\n",
      "        2363.0,\n",
      "        1897.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        598.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        556.0,\n",
      "        575.0,\n",
      "        610.0,\n",
      "        2129.0,\n",
      "        1910.0,\n",
      "        1238.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        84\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1656.0,\n",
      "        2202.0,\n",
      "        1846.0,\n",
      "        1479.0,\n",
      "        869.0,\n",
      "        459.0,\n",
      "        661.0,\n",
      "        642.0,\n",
      "        2583.0,\n",
      "        1572.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        536.0,\n",
      "        477.0,\n",
      "        1558.0,\n",
      "        2056.0,\n",
      "        1638.0,\n",
      "        1322.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        85\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1564.0,\n",
      "        2081.0,\n",
      "        1646.0,\n",
      "        1340.0,\n",
      "        834.0,\n",
      "        519.0,\n",
      "        607.0,\n",
      "        624.0,\n",
      "        2285.0,\n",
      "        1067.0,\n",
      "        612.0,\n",
      "        997.0,\n",
      "        493.0,\n",
      "        1555.0,\n",
      "        1999.0,\n",
      "        1502.0,\n",
      "        1267.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        86\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1746.0,\n",
      "        2211.0,\n",
      "        2001.0,\n",
      "        1354.0,\n",
      "        1029.0,\n",
      "        624.0,\n",
      "        755.0,\n",
      "        803.0,\n",
      "        2181.0,\n",
      "        1551.0,\n",
      "        822.0,\n",
      "        725.0,\n",
      "        675.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        688.0,\n",
      "        558.0,\n",
      "        572.0,\n",
      "        2266.0,\n",
      "        1903.0,\n",
      "        1347.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        87\n",
      "      ],\n",
      "      \"target\": [\n",
      "        21.0,\n",
      "        2243.0,\n",
      "        1988.0,\n",
      "        1316.0,\n",
      "        1009.0,\n",
      "        690.0,\n",
      "        781.0,\n",
      "        766.0,\n",
      "        2564.0,\n",
      "        1511.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1020.0,\n",
      "        642.0,\n",
      "        1759.0,\n",
      "        2046.0,\n",
      "        1656.0,\n",
      "        1322.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        88\n",
      "      ],\n",
      "      \"target\": [\n",
      "        596.0,\n",
      "        2250.0,\n",
      "        1813.0,\n",
      "        1303.0,\n",
      "        1343.0,\n",
      "        534.0,\n",
      "        655.0,\n",
      "        742.0,\n",
      "        2268.0,\n",
      "        1605.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        882.0,\n",
      "        520.0,\n",
      "        629.0,\n",
      "        2196.0,\n",
      "        1916.0,\n",
      "        1083.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        89\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2021.0,\n",
      "        1682.0,\n",
      "        1479.0,\n",
      "        959.0,\n",
      "        470.0,\n",
      "        530.0,\n",
      "        561.0,\n",
      "        2051.0,\n",
      "        1365.0,\n",
      "        673.0,\n",
      "        508.0,\n",
      "        507.0,\n",
      "        10.0,\n",
      "        560.0,\n",
      "        422.0,\n",
      "        460.0,\n",
      "        1867.0,\n",
      "        1533.0,\n",
      "        1117.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        90\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2401.0,\n",
      "        2048.0,\n",
      "        1532.0,\n",
      "        713.0,\n",
      "        499.0,\n",
      "        654.0,\n",
      "        749.0,\n",
      "        2536.0,\n",
      "        1623.0,\n",
      "        650.0,\n",
      "        546.0,\n",
      "        911.0,\n",
      "        497.0,\n",
      "        550.0,\n",
      "        2303.0,\n",
      "        1993.0,\n",
      "        1415.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        91\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2245.0,\n",
      "        2177.0,\n",
      "        1964.0,\n",
      "        1688.0,\n",
      "        884.0,\n",
      "        540.0,\n",
      "        706.0,\n",
      "        699.0,\n",
      "        2592.0,\n",
      "        1176.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        926.0,\n",
      "        683.0,\n",
      "        2141.0,\n",
      "        2241.0,\n",
      "        1698.0,\n",
      "        1378.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        92\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1887.0,\n",
      "        1889.0,\n",
      "        1709.0,\n",
      "        1319.0,\n",
      "        486.0,\n",
      "        463.0,\n",
      "        522.0,\n",
      "        505.0,\n",
      "        2054.0,\n",
      "        1022.0,\n",
      "        633.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        820.0,\n",
      "        450.0,\n",
      "        1489.0,\n",
      "        1826.0,\n",
      "        1636.0,\n",
      "        1242.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        93\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2368.0,\n",
      "        2793.0,\n",
      "        2257.0,\n",
      "        1617.0,\n",
      "        1038.0,\n",
      "        933.0,\n",
      "        1069.0,\n",
      "        1069.0,\n",
      "        2897.0,\n",
      "        1254.0,\n",
      "        756.0,\n",
      "        709.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        729.0,\n",
      "        651.0,\n",
      "        2136.0,\n",
      "        2496.0,\n",
      "        1696.0,\n",
      "        1469.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        94\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1970.0,\n",
      "        2417.0,\n",
      "        1877.0,\n",
      "        1597.0,\n",
      "        491.0,\n",
      "        557.0,\n",
      "        767.0,\n",
      "        841.0,\n",
      "        2643.0,\n",
      "        1608.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        606.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        629.0,\n",
      "        656.0,\n",
      "        610.0,\n",
      "        2284.0,\n",
      "        1720.0,\n",
      "        1376.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        95\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1675.0,\n",
      "        2250.0,\n",
      "        1962.0,\n",
      "        1510.0,\n",
      "        708.0,\n",
      "        585.0,\n",
      "        663.0,\n",
      "        733.0,\n",
      "        2640.0,\n",
      "        1484.0,\n",
      "        566.0,\n",
      "        587.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        923.0,\n",
      "        566.0,\n",
      "        1668.0,\n",
      "        2112.0,\n",
      "        1662.0,\n",
      "        1351.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        96\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1722.0,\n",
      "        2080.0,\n",
      "        1841.0,\n",
      "        1549.0,\n",
      "        668.0,\n",
      "        614.0,\n",
      "        772.0,\n",
      "        901.0,\n",
      "        2502.0,\n",
      "        1706.0,\n",
      "        636.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        926.0,\n",
      "        489.0,\n",
      "        1584.0,\n",
      "        1914.0,\n",
      "        1711.0,\n",
      "        1213.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        97\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2002.0,\n",
      "        2200.0,\n",
      "        1996.0,\n",
      "        1557.0,\n",
      "        776.0,\n",
      "        580.0,\n",
      "        722.0,\n",
      "        848.0,\n",
      "        2774.0,\n",
      "        1241.0,\n",
      "        793.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        1046.0,\n",
      "        567.0,\n",
      "        1811.0,\n",
      "        2028.0,\n",
      "        1897.0,\n",
      "        1186.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        98\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2006.0,\n",
      "        1987.0,\n",
      "        1732.0,\n",
      "        1386.0,\n",
      "        491.0,\n",
      "        474.0,\n",
      "        659.0,\n",
      "        773.0,\n",
      "        2424.0,\n",
      "        1548.0,\n",
      "        655.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        505.0,\n",
      "        445.0,\n",
      "        1821.0,\n",
      "        1905.0,\n",
      "        1590.0,\n",
      "        1217.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        99\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2538.0,\n",
      "        2246.0,\n",
      "        1820.0,\n",
      "        1094.0,\n",
      "        725.0,\n",
      "        850.0,\n",
      "        884.0,\n",
      "        2698.0,\n",
      "        1843.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        19.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        1254.0,\n",
      "        759.0,\n",
      "        865.0,\n",
      "        2463.0,\n",
      "        1921.0,\n",
      "        1535.0\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"configuration\": {\n",
      "    \"output_types\": [\n",
      "      \"mean\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "inference_json = json.dumps(inference, indent=2)\n",
    "print(inference_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.RealTimePredictor at 0x7fbfc18a0b38>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = sagemaker.predictor.RealTimePredictor(\n",
    "    dar_endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    content_type=\"application/json\")\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'mean': [2175.9440917969,\n",
       "    1820.5814208984,\n",
       "    1285.3566894531,\n",
       "    610.0578613281]},\n",
       "  {'mean': [1262.0045166016, 1024.5852050781, 962.9938354492, 987.2399902344]},\n",
       "  {'mean': [777.8779907227, 479.3178405762, 517.5393066406, 540.8561401367]},\n",
       "  {'mean': [865.8353271484, 558.0474853516, 383.9394226074, 255.5512542725]},\n",
       "  {'mean': [527.2911987305, 410.6343688965, 472.1435852051, 477.643371582]},\n",
       "  {'mean': [603.2672119141, 618.0535888672, 640.3118896484, 885.4478759766]},\n",
       "  {'mean': [925.0042114258, 878.9406738281, 1026.0784912109, 1284.4594726562]},\n",
       "  {'mean': [530.1256103516, 523.7680053711, 566.1091918945, 728.0111083984]},\n",
       "  {'mean': [1334.8979492188,\n",
       "    1038.6798095703,\n",
       "    936.1234130859,\n",
       "    1070.9415283203]},\n",
       "  {'mean': [592.6786499023, 504.2263183594, 548.6373291016, 624.6314697266]},\n",
       "  {'mean': [958.2547607422, 941.094543457, 1015.2977294922, 1347.2459716797]},\n",
       "  {'mean': [1076.0523681641, 767.4130249023, 752.0357666016, 997.1391601562]},\n",
       "  {'mean': [538.6221313477, 548.2768554688, 567.8700561523, 780.1853027344]},\n",
       "  {'mean': [1170.21875, 1051.875, 1132.0697021484, 1390.1231689453]},\n",
       "  {'mean': [619.2973022461, 510.1078186035, 583.2577514648, 660.7407226562]},\n",
       "  {'mean': [545.7723999023, 441.6937255859, 501.0785827637, 492.4852294922]},\n",
       "  {'mean': [509.4888305664, 438.669921875, 539.1054077148, 603.8639526367]},\n",
       "  {'mean': [623.7866210938, 539.9260253906, 564.3593139648, 595.7732543945]},\n",
       "  {'mean': [1060.2094726562, 836.8649902344, 767.2496948242, 1097.2788085938]},\n",
       "  {'mean': [1050.1812744141, 891.3847045898, 957.9453735352, 1159.2452392578]},\n",
       "  {'mean': [670.9364013672, 524.4324951172, 673.1724853516, 733.388671875]},\n",
       "  {'mean': [621.4100341797, 546.4639892578, 704.8954467773, 726.0563964844]},\n",
       "  {'mean': [692.1575927734, 646.409362793, 654.3258056641, 853.0139770508]},\n",
       "  {'mean': [1119.6453857422, 802.6716918945, 699.4322509766, 521.7825927734]},\n",
       "  {'mean': [1326.3499755859,\n",
       "    1331.3043212891,\n",
       "    1612.6407470703,\n",
       "    1921.4875488281]},\n",
       "  {'mean': [727.649597168, 566.6682128906, 583.0485229492, 615.3775024414]},\n",
       "  {'mean': [1208.5681152344, 949.6701660156, 900.1221313477, 1141.1872558594]},\n",
       "  {'mean': [647.543762207, 533.8308105469, 587.8828735352, 701.4879760742]},\n",
       "  {'mean': [636.7092285156, 539.9804077148, 604.4274291992, 580.8547363281]},\n",
       "  {'mean': [1034.3408203125, 654.0424804688, 514.6051025391, 371.6424255371]},\n",
       "  {'mean': [668.705078125, 428.8751525879, 477.1801452637, 494.9668273926]},\n",
       "  {'mean': [615.6737060547, 544.8475952148, 534.2935791016, 721.2149047852]},\n",
       "  {'mean': [639.9789428711, 556.2438964844, 603.9190063477, 751.1843261719]},\n",
       "  {'mean': [573.5443115234, 443.2826538086, 461.2727050781, 506.5791015625]},\n",
       "  {'mean': [1355.2006835938, 941.4426269531, 648.410949707, 451.8393859863]},\n",
       "  {'mean': [620.2365112305, 501.5899963379, 526.0572509766, 617.2514038086]},\n",
       "  {'mean': [774.221862793, 623.783203125, 650.1885986328, 709.01953125]},\n",
       "  {'mean': [1220.9769287109, 948.3856201172, 985.3884887695, 979.680847168]},\n",
       "  {'mean': [1134.166015625, 769.3872680664, 701.6669311523, 672.7102050781]},\n",
       "  {'mean': [1059.859375, 853.4351806641, 1001.2380371094, 1181.3492431641]},\n",
       "  {'mean': [721.8409423828, 530.811340332, 586.9424438477, 582.299621582]},\n",
       "  {'mean': [783.1974487305, 590.2518310547, 655.0946655273, 660.3970947266]},\n",
       "  {'mean': [1394.7846679688,\n",
       "    1021.639465332,\n",
       "    1097.9332275391,\n",
       "    1199.7375488281]},\n",
       "  {'mean': [615.5321655273, 485.2120361328, 546.602722168, 541.4325561523]},\n",
       "  {'mean': [622.7535400391, 508.4343261719, 566.1021728516, 658.5511474609]},\n",
       "  {'mean': [926.5152587891, 821.4479980469, 941.9573364258, 1183.0009765625]},\n",
       "  {'mean': [637.5950317383, 570.6168823242, 564.3608398438, 849.6391601562]},\n",
       "  {'mean': [580.0323486328, 524.0098876953, 643.8942871094, 641.7706298828]},\n",
       "  {'mean': [1132.0502929688,\n",
       "    1018.5794677734,\n",
       "    1024.1795654297,\n",
       "    1229.1800537109]},\n",
       "  {'mean': [583.7865600586, 463.2682495117, 590.2913818359, 537.9206542969]},\n",
       "  {'mean': [600.3407592773, 517.8703613281, 539.2391357422, 634.8662719727]},\n",
       "  {'mean': [1585.4085693359, 1163.4195556641, 893.0928344727, 775.487121582]},\n",
       "  {'mean': [601.6757202148, 552.7428588867, 581.6768188477, 720.9801025391]},\n",
       "  {'mean': [1263.1553955078,\n",
       "    1069.6121826172,\n",
       "    1015.7429199219,\n",
       "    1110.5305175781]},\n",
       "  {'mean': [1208.8746337891,\n",
       "    1159.3538818359,\n",
       "    1217.1619873047,\n",
       "    1522.1881103516]},\n",
       "  {'mean': [1203.919921875,\n",
       "    1007.1119384766,\n",
       "    1012.5878295898,\n",
       "    1301.2362060547]},\n",
       "  {'mean': [1051.2368164062, 986.4836425781, 955.4893798828, 1167.8626708984]},\n",
       "  {'mean': [594.9423828125, 487.2073364258, 573.7916259766, 575.7953491211]},\n",
       "  {'mean': [715.7496948242, 604.174621582, 627.8819580078, 673.59375]},\n",
       "  {'mean': [719.1688842773, 519.9309082031, 581.0802612305, 597.1795043945]},\n",
       "  {'mean': [587.6634521484, 545.2969360352, 566.6825561523, 829.5154418945]},\n",
       "  {'mean': [693.5036621094, 515.0186157227, 626.7056884766, 663.0778198242]},\n",
       "  {'mean': [609.826965332, 529.9138793945, 520.9645996094, 657.7941894531]},\n",
       "  {'mean': [657.8493041992, 583.1049804688, 632.5769042969, 599.5177001953]},\n",
       "  {'mean': [1092.7010498047, 847.1300048828, 739.3225708008, 818.6809082031]},\n",
       "  {'mean': [1357.8348388672, 1025.9697265625, 898.6127929688, 982.1588134766]},\n",
       "  {'mean': [849.8256835938, 553.2106323242, 643.5454101562, 591.3394165039]},\n",
       "  {'mean': [653.1083374023, 605.4368286133, 642.9984130859, 823.6031494141]},\n",
       "  {'mean': [1095.5009765625, 868.1815795898, 819.9668579102, 1153.1684570312]},\n",
       "  {'mean': [623.2936401367, 467.4204711914, 531.6793212891, 535.137878418]},\n",
       "  {'mean': [569.5855712891, 522.4838867188, 428.3642272949, 693.7894287109]},\n",
       "  {'mean': [1145.6030273438, 709.9845581055, 521.4561157227, 321.3436584473]},\n",
       "  {'mean': [643.174987793, 471.096496582, 536.5841064453, 581.5274047852]},\n",
       "  {'mean': [537.1037597656, 449.3075256348, 545.6654052734, 516.2421264648]},\n",
       "  {'mean': [1049.6612548828, 925.3681030273, 980.8695068359, 1177.2109375]},\n",
       "  {'mean': [587.2133789062, 556.606628418, 565.8974609375, 783.458190918]},\n",
       "  {'mean': [715.3300170898, 563.5186157227, 562.565246582, 735.0720214844]},\n",
       "  {'mean': [780.1881103516, 646.1929931641, 724.9201660156, 755.708190918]},\n",
       "  {'mean': [1192.0607910156,\n",
       "    1061.4066162109,\n",
       "    1181.8861083984,\n",
       "    1399.8917236328]},\n",
       "  {'mean': [1013.2829589844, 819.8655395508, 902.2248535156, 1112.1285400391]},\n",
       "  {'mean': [701.3515014648, 564.5916137695, 534.5288696289, 472.0186462402]},\n",
       "  {'mean': [1066.8645019531, 921.5546264648, 992.8875732422, 1173.9261474609]},\n",
       "  {'mean': [604.8574829102, 474.5319824219, 577.0345458984, 615.8872070312]},\n",
       "  {'mean': [617.7808227539, 499.9634094238, 565.1075439453, 559.6597900391]},\n",
       "  {'mean': [656.4831542969, 548.2699584961, 652.008605957, 770.435546875]},\n",
       "  {'mean': [1103.2474365234, 904.9131469727, 904.6594238281, 1075.03125]},\n",
       "  {'mean': [687.2089233398, 490.871887207, 570.6735229492, 555.5216064453]},\n",
       "  {'mean': [664.4722900391, 584.4643554688, 605.9053955078, 765.0892333984]},\n",
       "  {'mean': [635.1826171875, 483.7046813965, 608.8532104492, 609.7031860352]},\n",
       "  {'mean': [1387.1188964844, 1128.0643310547, 962.4053344727, 837.0657958984]},\n",
       "  {'mean': [1243.8151855469, 962.873046875, 855.5239257812, 1078.5910644531]},\n",
       "  {'mean': [664.9462280273, 592.6884155273, 612.9588012695, 741.6588134766]},\n",
       "  {'mean': [565.245300293, 412.9221496582, 446.020324707, 472.7693481445]},\n",
       "  {'mean': [776.4121704102, 652.8708496094, 644.334777832, 694.9644775391]},\n",
       "  {'mean': [594.3483886719, 497.0307922363, 591.7445678711, 625.5291748047]},\n",
       "  {'mean': [648.7103271484, 496.5751647949, 534.8706054688, 602.6575317383]},\n",
       "  {'mean': [588.6382446289, 530.2620849609, 583.5244750977, 671.9815063477]},\n",
       "  {'mean': [602.2144775391, 531.3082275391, 570.4534912109, 794.1567993164]},\n",
       "  {'mean': [595.7730712891, 502.1516723633, 531.6011962891, 649.0860595703]},\n",
       "  {'mean': [706.5794677734, 526.0172729492, 630.4898681641, 632.2265014648]}]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor.predict(inference_json)\n",
    "prediction = json.loads(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2175.9440917969, 1820.5814208984, 1285.3566894531, 610.0578613281],\n",
       " [1262.0045166016, 1024.5852050781, 962.9938354492, 987.2399902344],\n",
       " [777.8779907227, 479.3178405762, 517.5393066406, 540.8561401367],\n",
       " [865.8353271484, 558.0474853516, 383.9394226074, 255.5512542725],\n",
       " [527.2911987305, 410.6343688965, 472.1435852051, 477.643371582],\n",
       " [603.2672119141, 618.0535888672, 640.3118896484, 885.4478759766],\n",
       " [925.0042114258, 878.9406738281, 1026.0784912109, 1284.4594726562],\n",
       " [530.1256103516, 523.7680053711, 566.1091918945, 728.0111083984],\n",
       " [1334.8979492188, 1038.6798095703, 936.1234130859, 1070.9415283203],\n",
       " [592.6786499023, 504.2263183594, 548.6373291016, 624.6314697266],\n",
       " [958.2547607422, 941.094543457, 1015.2977294922, 1347.2459716797],\n",
       " [1076.0523681641, 767.4130249023, 752.0357666016, 997.1391601562],\n",
       " [538.6221313477, 548.2768554688, 567.8700561523, 780.1853027344],\n",
       " [1170.21875, 1051.875, 1132.0697021484, 1390.1231689453],\n",
       " [619.2973022461, 510.1078186035, 583.2577514648, 660.7407226562],\n",
       " [545.7723999023, 441.6937255859, 501.0785827637, 492.4852294922],\n",
       " [509.4888305664, 438.669921875, 539.1054077148, 603.8639526367],\n",
       " [623.7866210938, 539.9260253906, 564.3593139648, 595.7732543945],\n",
       " [1060.2094726562, 836.8649902344, 767.2496948242, 1097.2788085938],\n",
       " [1050.1812744141, 891.3847045898, 957.9453735352, 1159.2452392578],\n",
       " [670.9364013672, 524.4324951172, 673.1724853516, 733.388671875],\n",
       " [621.4100341797, 546.4639892578, 704.8954467773, 726.0563964844],\n",
       " [692.1575927734, 646.409362793, 654.3258056641, 853.0139770508],\n",
       " [1119.6453857422, 802.6716918945, 699.4322509766, 521.7825927734],\n",
       " [1326.3499755859, 1331.3043212891, 1612.6407470703, 1921.4875488281],\n",
       " [727.649597168, 566.6682128906, 583.0485229492, 615.3775024414],\n",
       " [1208.5681152344, 949.6701660156, 900.1221313477, 1141.1872558594],\n",
       " [647.543762207, 533.8308105469, 587.8828735352, 701.4879760742],\n",
       " [636.7092285156, 539.9804077148, 604.4274291992, 580.8547363281],\n",
       " [1034.3408203125, 654.0424804688, 514.6051025391, 371.6424255371],\n",
       " [668.705078125, 428.8751525879, 477.1801452637, 494.9668273926],\n",
       " [615.6737060547, 544.8475952148, 534.2935791016, 721.2149047852],\n",
       " [639.9789428711, 556.2438964844, 603.9190063477, 751.1843261719],\n",
       " [573.5443115234, 443.2826538086, 461.2727050781, 506.5791015625],\n",
       " [1355.2006835938, 941.4426269531, 648.410949707, 451.8393859863],\n",
       " [620.2365112305, 501.5899963379, 526.0572509766, 617.2514038086],\n",
       " [774.221862793, 623.783203125, 650.1885986328, 709.01953125],\n",
       " [1220.9769287109, 948.3856201172, 985.3884887695, 979.680847168],\n",
       " [1134.166015625, 769.3872680664, 701.6669311523, 672.7102050781],\n",
       " [1059.859375, 853.4351806641, 1001.2380371094, 1181.3492431641],\n",
       " [721.8409423828, 530.811340332, 586.9424438477, 582.299621582],\n",
       " [783.1974487305, 590.2518310547, 655.0946655273, 660.3970947266],\n",
       " [1394.7846679688, 1021.639465332, 1097.9332275391, 1199.7375488281],\n",
       " [615.5321655273, 485.2120361328, 546.602722168, 541.4325561523],\n",
       " [622.7535400391, 508.4343261719, 566.1021728516, 658.5511474609],\n",
       " [926.5152587891, 821.4479980469, 941.9573364258, 1183.0009765625],\n",
       " [637.5950317383, 570.6168823242, 564.3608398438, 849.6391601562],\n",
       " [580.0323486328, 524.0098876953, 643.8942871094, 641.7706298828],\n",
       " [1132.0502929688, 1018.5794677734, 1024.1795654297, 1229.1800537109],\n",
       " [583.7865600586, 463.2682495117, 590.2913818359, 537.9206542969],\n",
       " [600.3407592773, 517.8703613281, 539.2391357422, 634.8662719727],\n",
       " [1585.4085693359, 1163.4195556641, 893.0928344727, 775.487121582],\n",
       " [601.6757202148, 552.7428588867, 581.6768188477, 720.9801025391],\n",
       " [1263.1553955078, 1069.6121826172, 1015.7429199219, 1110.5305175781],\n",
       " [1208.8746337891, 1159.3538818359, 1217.1619873047, 1522.1881103516],\n",
       " [1203.919921875, 1007.1119384766, 1012.5878295898, 1301.2362060547],\n",
       " [1051.2368164062, 986.4836425781, 955.4893798828, 1167.8626708984],\n",
       " [594.9423828125, 487.2073364258, 573.7916259766, 575.7953491211],\n",
       " [715.7496948242, 604.174621582, 627.8819580078, 673.59375],\n",
       " [719.1688842773, 519.9309082031, 581.0802612305, 597.1795043945],\n",
       " [587.6634521484, 545.2969360352, 566.6825561523, 829.5154418945],\n",
       " [693.5036621094, 515.0186157227, 626.7056884766, 663.0778198242],\n",
       " [609.826965332, 529.9138793945, 520.9645996094, 657.7941894531],\n",
       " [657.8493041992, 583.1049804688, 632.5769042969, 599.5177001953],\n",
       " [1092.7010498047, 847.1300048828, 739.3225708008, 818.6809082031],\n",
       " [1357.8348388672, 1025.9697265625, 898.6127929688, 982.1588134766],\n",
       " [849.8256835938, 553.2106323242, 643.5454101562, 591.3394165039],\n",
       " [653.1083374023, 605.4368286133, 642.9984130859, 823.6031494141],\n",
       " [1095.5009765625, 868.1815795898, 819.9668579102, 1153.1684570312],\n",
       " [623.2936401367, 467.4204711914, 531.6793212891, 535.137878418],\n",
       " [569.5855712891, 522.4838867188, 428.3642272949, 693.7894287109],\n",
       " [1145.6030273438, 709.9845581055, 521.4561157227, 321.3436584473],\n",
       " [643.174987793, 471.096496582, 536.5841064453, 581.5274047852],\n",
       " [537.1037597656, 449.3075256348, 545.6654052734, 516.2421264648],\n",
       " [1049.6612548828, 925.3681030273, 980.8695068359, 1177.2109375],\n",
       " [587.2133789062, 556.606628418, 565.8974609375, 783.458190918],\n",
       " [715.3300170898, 563.5186157227, 562.565246582, 735.0720214844],\n",
       " [780.1881103516, 646.1929931641, 724.9201660156, 755.708190918],\n",
       " [1192.0607910156, 1061.4066162109, 1181.8861083984, 1399.8917236328],\n",
       " [1013.2829589844, 819.8655395508, 902.2248535156, 1112.1285400391],\n",
       " [701.3515014648, 564.5916137695, 534.5288696289, 472.0186462402],\n",
       " [1066.8645019531, 921.5546264648, 992.8875732422, 1173.9261474609],\n",
       " [604.8574829102, 474.5319824219, 577.0345458984, 615.8872070312],\n",
       " [617.7808227539, 499.9634094238, 565.1075439453, 559.6597900391],\n",
       " [656.4831542969, 548.2699584961, 652.008605957, 770.435546875],\n",
       " [1103.2474365234, 904.9131469727, 904.6594238281, 1075.03125],\n",
       " [687.2089233398, 490.871887207, 570.6735229492, 555.5216064453],\n",
       " [664.4722900391, 584.4643554688, 605.9053955078, 765.0892333984],\n",
       " [635.1826171875, 483.7046813965, 608.8532104492, 609.7031860352],\n",
       " [1387.1188964844, 1128.0643310547, 962.4053344727, 837.0657958984],\n",
       " [1243.8151855469, 962.873046875, 855.5239257812, 1078.5910644531],\n",
       " [664.9462280273, 592.6884155273, 612.9588012695, 741.6588134766],\n",
       " [565.245300293, 412.9221496582, 446.020324707, 472.7693481445],\n",
       " [776.4121704102, 652.8708496094, 644.334777832, 694.9644775391],\n",
       " [594.3483886719, 497.0307922363, 591.7445678711, 625.5291748047],\n",
       " [648.7103271484, 496.5751647949, 534.8706054688, 602.6575317383],\n",
       " [588.6382446289, 530.2620849609, 583.5244750977, 671.9815063477],\n",
       " [602.2144775391, 531.3082275391, 570.4534912109, 794.1567993164],\n",
       " [595.7730712891, 502.1516723633, 531.6011962891, 649.0860595703],\n",
       " [706.5794677734, 526.0172729492, 630.4898681641, 632.2265014648]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = prediction[\"predictions\"]\n",
    "predictions = [p[\"mean\"] for p in predictions]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Device 0 = 1 anomalies (max = 1.1053402615, cutoff = 1.0993106591990305)\n",
      " Device 1 = 1 anomalies (max = 0.9639777549, cutoff = 0.954780679312745)\n",
      " Device 2 = 1 anomalies (max = 0.8648056072, cutoff = 0.8551110103313542)\n",
      " Device 3 = 1 anomalies (max = 1.6893988419, cutoff = 1.5808581132873647)\n",
      " Device 6 = 1 anomalies (max = 0.9582883867, cutoff = 0.949289234639168)\n",
      " Device 9 = 1 anomalies (max = 0.8344431627, cutoff = 0.8328306872497806)\n",
      " Device 10 = 1 anomalies (max = 0.9238428401, cutoff = 0.9166998465309241)\n",
      " Device 12 = 1 anomalies (max = 0.8677280211, cutoff = 0.8617997295353341)\n",
      " Device 19 = 1 anomalies (max = 0.9156928674, cutoff = 0.9108692524983171)\n",
      " Device 20 = 1 anomalies (max = 0.856404616, cutoff = 0.8527200300061143)\n",
      " Device 21 = 1 anomalies (max = 0.8487471005, cutoff = 0.8485997934632247)\n",
      " Device 23 = 1 anomalies (max = 0.9067978595, cutoff = 0.8954923962213082)\n",
      " Device 25 = 1 anomalies (max = 0.8404044348, cutoff = 0.8381161148424757)\n",
      " Device 28 = 1 anomalies (max = 0.8198827469, cutoff = 0.8196694167276073)\n",
      " Device 32 = 1 anomalies (max = 0.8334299907, cutoff = 0.829190914999787)\n",
      " Device 33 = 1 anomalies (max = 0.8006396907, cutoff = 0.7986468929885258)\n",
      " Device 37 = 1 anomalies (max = 0.9458908855, cutoff = 0.9386717931173146)\n",
      " Device 38 = 1 anomalies (max = 0.9155938604, cutoff = 0.9108472860744434)\n",
      " Device 41 = 1 anomalies (max = 0.8617840831, cutoff = 0.8565331081394711)\n",
      " Device 42 = 1 anomalies (max = 0.9276033924, cutoff = 0.9224265912423173)\n",
      " Device 43 = 1 anomalies (max = 0.8202902122, cutoff = 0.816180610533693)\n",
      " Device 45 = 1 anomalies (max = 0.9196359928, cutoff = 0.916476195480908)\n",
      " Device 48 = 1 anomalies (max = 0.9599103443, cutoff = 0.9557373216731814)\n",
      " Device 50 = 1 anomalies (max = 0.8231229045, cutoff = 0.8185261613176137)\n",
      " Device 52 = 1 anomalies (max = 0.8479654516, cutoff = 0.8447297939144088)\n",
      " Device 53 = 1 anomalies (max = 0.9621719472, cutoff = 0.9609476629414082)\n",
      " Device 59 = 1 anomalies (max = 0.8432548909, cutoff = 0.8392693764595771)\n",
      " Device 61 = 1 anomalies (max = 0.8347984191, cutoff = 0.834494641527483)\n",
      " Device 62 = 1 anomalies (max = 0.817390793, cutoff = 0.8140516324937628)\n",
      " Device 64 = 1 anomalies (max = 0.8962304723, cutoff = 0.8926447938846123)\n",
      " Device 66 = 1 anomalies (max = 0.8288489502, cutoff = 0.8244444222911099)\n",
      " Device 69 = 1 anomalies (max = 0.836644999, cutoff = 0.8321313377632157)\n",
      " Device 71 = 1 anomalies (max = 1.2235415107, cutoff = 1.188147292515322)\n",
      " Device 73 = 1 anomalies (max = 0.7815303685, cutoff = 0.7808128358859864)\n",
      " Device 76 = 1 anomalies (max = 0.8473054914, cutoff = 0.8441546054843823)\n",
      " Device 84 = 1 anomalies (max = 0.8495638614, cutoff = 0.8419204531413351)\n",
      " Device 87 = 1 anomalies (max = 0.8692023909, cutoff = 0.863154304315338)\n",
      " Device 89 = 1 anomalies (max = 0.9232981074, cutoff = 0.9213549645431288)\n",
      " Device 90 = 1 anomalies (max = 0.9677189079, cutoff = 0.9621911299996337)\n",
      " Device 94 = 1 anomalies (max = 0.8342385249, cutoff = 0.8328450065216721)\n"
     ]
    }
   ],
   "source": [
    "sigmas = 1.25\n",
    "maintenance = []\n",
    "\n",
    "for i, preds in enumerate(predictions):\n",
    "    infer_data = [[t] for t in preds]\n",
    "    results = rcf_inference.predict(infer_data)\n",
    "    scores = results[\"scores\"]\n",
    "    scores = [score[\"score\"] for score in scores]\n",
    "    series = pd.Series(scores)\n",
    "    score_mean = series.mean()\n",
    "    score_max = series.max()\n",
    "    score_std = series.std()\n",
    "    score_cutoff = score_mean + sigmas*score_std\n",
    "    anomalies = series[series > score_cutoff ]\n",
    "    if not anomalies.empty:\n",
    "        maintenance.append(i)\n",
    "        print(\" Device {} = {} anomalies (max = {}, cutoff = {})\".format(i, len(anomalies), score_max, score_cutoff ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Requesting maintenance for 40 devices'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Requesting maintenance for {} devices\".format(len(maintenance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

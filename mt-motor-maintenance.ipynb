{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine the cabapilities of forecasting and anomaly detection for predictive maintenance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "      <th>battery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>7517a917b42450470661cec1bd4654f8</td>\n",
       "      <td>1335</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1577</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>572ddf9d82d5675ed2db832081b70103</td>\n",
       "      <td>1585</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>b17bbc29ce61265a6212c689a597d4d8</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22 23:59:59</th>\n",
       "      <td>19d3c55b134ab7780d2b711211b7cf7c</td>\n",
       "      <td>1286</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA  battery\n",
       "timestamp                                                                    \n",
       "2020-02-22 23:59:59  7517a917b42450470661cec1bd4654f8           1335       73\n",
       "2020-02-22 23:59:59  8e4a851ed2317a249a0903f29d894361           1577       73\n",
       "2020-02-22 23:59:59  572ddf9d82d5675ed2db832081b70103           1585       73\n",
       "2020-02-22 23:59:59  b17bbc29ce61265a6212c689a597d4d8              0       73\n",
       "2020-02-22 23:59:59  19d3c55b134ab7780d2b711211b7cf7c           1286       73"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8e4a851ed2317a249a0903f29d894361'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_pos = 1\n",
    "sample_device_id = data.iloc[device_pos][\"device_id\"]\n",
    "sample_device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data[data[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor = sample_data[\"motor_peak_mA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5950245d0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "motor.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = data[data[\"motor_peak_mA\"] > 0]\n",
    "hourly = (hourly.groupby(\"device_id\")\n",
    "          .motor_peak_mA\n",
    "          .resample(\"H\")\n",
    "          .max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id                         timestamp          \n",
       "0001495ce5f079703599a94c32dab2b0  2020-02-24 15:00:00    1843.0\n",
       "                                  2020-02-24 16:00:00    1906.0\n",
       "                                  2020-02-24 17:00:00    1909.0\n",
       "                                  2020-02-24 18:00:00    1540.0\n",
       "                                  2020-02-24 19:00:00     476.0\n",
       "                                                          ...  \n",
       "fffaee1fbb9c96703850f64d3262e843  2020-02-25 17:00:00    2211.0\n",
       "                                  2020-02-25 18:00:00    1663.0\n",
       "                                  2020-02-25 19:00:00     841.0\n",
       "                                  2020-02-25 20:00:00     650.0\n",
       "                                  2020-02-25 21:00:00     741.0\n",
       "Name: motor_peak_mA, Length: 529940, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = hourly.reset_index().set_index(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-24 15:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 16:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 17:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 18:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>1540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>2211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-24 15:00:00  0001495ce5f079703599a94c32dab2b0         1843.0\n",
       "2020-02-24 16:00:00  0001495ce5f079703599a94c32dab2b0         1906.0\n",
       "2020-02-24 17:00:00  0001495ce5f079703599a94c32dab2b0         1909.0\n",
       "2020-02-24 18:00:00  0001495ce5f079703599a94c32dab2b0         1540.0\n",
       "2020-02-24 19:00:00  0001495ce5f079703599a94c32dab2b0          476.0\n",
       "...                                               ...            ...\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843         2211.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843         1663.0\n",
       "2020-02-25 19:00:00  fffaee1fbb9c96703850f64d3262e843          841.0\n",
       "2020-02-25 20:00:00  fffaee1fbb9c96703850f64d3262e843          650.0\n",
       "2020-02-25 21:00:00  fffaee1fbb9c96703850f64d3262e843          741.0\n",
       "\n",
       "[529940 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsample = hourly[hourly[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5953cb790>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.tail(12).plot(style=\"k.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc575ac4890>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hsample.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 21:00:00')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time = hourly.tail(1).index[0]\n",
    "last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-25 18:00:00')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_time = last_time - pd.Timedelta('3 hour')\n",
    "cut_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>2286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>2211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>fffaee1fbb9c96703850f64d3262e843</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 14:00:00  fffaee1fbb9c96703850f64d3262e843          672.0\n",
       "2020-02-25 15:00:00  fffaee1fbb9c96703850f64d3262e843          707.0\n",
       "2020-02-25 16:00:00  fffaee1fbb9c96703850f64d3262e843         2286.0\n",
       "2020-02-25 17:00:00  fffaee1fbb9c96703850f64d3262e843         2211.0\n",
       "2020-02-25 18:00:00  fffaee1fbb9c96703850f64d3262e843         1663.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = hourly.loc[hourly.index <= cut_time]\n",
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>0001495ce5f079703599a94c32dab2b0</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>00134c004e33e830e5dbce3355a485b9</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 19:00:00  0001495ce5f079703599a94c32dab2b0          688.0\n",
       "2020-02-25 20:00:00  0001495ce5f079703599a94c32dab2b0          440.0\n",
       "2020-02-25 21:00:00  0001495ce5f079703599a94c32dab2b0          550.0\n",
       "2020-02-25 19:00:00  00134c004e33e830e5dbce3355a485b9          667.0\n",
       "2020-02-25 20:00:00  00134c004e33e830e5dbce3355a485b9          454.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = hourly.loc[hourly.index > cut_time]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = train_set[train_set[\"device_id\"] == sample_device_id]\n",
    "sample_test = test_set[test_set[\"device_id\"] == sample_device_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 14:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 15:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 16:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 17:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 18:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1228.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 14:00:00  8e4a851ed2317a249a0903f29d894361          394.0\n",
       "2020-02-25 15:00:00  8e4a851ed2317a249a0903f29d894361         1557.0\n",
       "2020-02-25 16:00:00  8e4a851ed2317a249a0903f29d894361         1869.0\n",
       "2020-02-25 17:00:00  8e4a851ed2317a249a0903f29d894361         1643.0\n",
       "2020-02-25 18:00:00  8e4a851ed2317a249a0903f29d894361         1228.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-25 19:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 20:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 21:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>1739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25 22:00:00</th>\n",
       "      <td>8e4a851ed2317a249a0903f29d894361</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            device_id  motor_peak_mA\n",
       "timestamp                                                           \n",
       "2020-02-25 19:00:00  8e4a851ed2317a249a0903f29d894361          465.0\n",
       "2020-02-25 20:00:00  8e4a851ed2317a249a0903f29d894361         1735.0\n",
       "2020-02-25 21:00:00  8e4a851ed2317a249a0903f29d894361         1739.0\n",
       "2020-02-25 22:00:00  8e4a851ed2317a249a0903f29d894361          497.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5953e42d0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "ax = sample_train[\"motor_peak_mA\"].plot(label=\"train\")\n",
    "sample_test[\"motor_peak_mA\"].plot(ax=ax,label=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepAR Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data from pandas DataFrame to the expected JSON Lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "def df_to_tss(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df[\"timeindex\"] = df.index\n",
    "    cats = {}\n",
    "    tss = {}\n",
    "    for index, row in df.iterrows():\n",
    "        target = row[\"motor_peak_mA\"]\n",
    "        if not(math.isnan(target)):\n",
    "            identity = row[\"device_id\"]\n",
    "            cat = cats.get(identity)\n",
    "            if not cat:\n",
    "                cat = len(cats)\n",
    "                start = str(row[\"timeindex\"])\n",
    "                ts = {\n",
    "                    \"start\": start,\n",
    "                    \"cat\": [cat],\n",
    "                    \"target\": [],\n",
    "                }\n",
    "                cats[identity] = cat\n",
    "                tss[cat] = ts\n",
    "            ts = tss.get(cat)\n",
    "            ts[\"target\"].append(target)\n",
    "    return tss\n",
    "\n",
    "def tss_to_jsonl(tss):  \n",
    "    result = \"\"\n",
    "    for key, value in tss.items():\n",
    "        jsonll = json.dumps(value)\n",
    "        result += jsonll\n",
    "        result += \"\\n\"\n",
    "    return result[:-1]\n",
    "\n",
    "def df_to_jsonl(dataframe):\n",
    "    return tss_to_jsonl(df_to_tss(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01434469223022461\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [0], \"target\": [1843.0]}\n",
      "{\"start\": \"2020-02-24 16:00:00\", \"cat\": [1], \"target\": [2171.0, 1949.0, 1769.0, 871.0, 477.0, 529.0, 570.0, 2202.0, 1483.0, 734.0, 10.0, 532.0, 817.0, 519.0, 617.0, 2146.0, 1870.0, 1397.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [2], \"target\": [10.0, 2145.0, 1772.0, 1392.0, 909.0, 556.0, 658.0, 680.0, 2354.0, 1151.0, 21.0, 21.0, 10.0, 21.0, 21.0, 20.0, 10.0, 10.0, 21.0, 9.0, 20.0, 10.0, 681.0, 553.0, 608.0, 2014.0, 1685.0, 1518.0]}\n",
      "{\"start\": \"2020-02-24 15:00:00\", \"cat\": [3], \"target\": [1580.0, 1997.0, 1735.0, 1202.0, 952.0, 436.0, 648.0, 694.0, 2252.0, 1345.0, 621.0, 10.0, 9.0, 10.0, 562.0]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "jsonl = df_to_jsonl(train_set.head(100))\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)\n",
    "print(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.501381397247314\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "train_tss = df_to_tss(train_set)\n",
    "train_jsonl = tss_to_jsonl(train_tss)\n",
    "\n",
    "test_tss = df_to_tss(test_set)\n",
    "test_jsonl = tss_to_jsonl(test_tss)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./mt-motor-maintenance/input/train.json',\n",
       " './mt-motor-maintenance/input/test.json')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "prefix = \"mt-motor-maintenance\"\n",
    "input_path = \"./{}/input\".format(prefix)\n",
    "\n",
    "train_path = \"{}/train.json\".format(input_path)\n",
    "test_path = \"{}/test.json\".format(input_path)\n",
    "(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(input_path, ignore_errors=True)\n",
    "pathlib.Path(input_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"w\") as text_file:\n",
    "    print(train_jsonl, file=text_file)\n",
    "\n",
    "with open(test_path, \"w\") as text_file:\n",
    "    print(test_jsonl, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.2M\n",
      "12050591088959177201 drwxr-xr-x 2 root root 6.0K May 14 10:53 .\n",
      " 9857610803793291351 drwxr-xr-x 3 root root 6.0K May 14 10:53 ..\n",
      " 5764175072212119634 -rw-r--r-- 1 root root 1.4M May 14 10:53 test.json\n",
      " 5480359943514405345 -rw-r--r-- 1 root root 3.8M May 14 10:53 train.json\n"
     ]
    }
   ],
   "source": [
    "! ls -liah \"{input_path}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://mt-ml-workshop-yuixc09t/mt-motor-maintenance/output/mt-motor-maintenance-2021-05-14-09-50-38-590/output/model.tar.gz\n",
      "upload: mt-motor-maintenance/input/test.json to s3://mt-ml-workshop-yuixc09t/mt-motor-maintenance/test.json\n",
      "upload: mt-motor-maintenance/input/train.json to s3://mt-ml-workshop-yuixc09t/mt-motor-maintenance/train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync \"{input_path}/\" \"s3://{bucket}/{prefix}/\" --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 10:53:26    1373977 test.json\n",
      "2021-05-14 10:53:26    3962421 train.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls \"s3://{bucket}/{prefix}/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://mt-ml-workshop-yuixc09t/mt-motor-maintenance/train.json',\n",
       " 'test': 's3://mt-ml-workshop-yuixc09t/mt-motor-maintenance/test.json'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_input = {\n",
    "    \"train\": \"s3://{}/{}/train.json\".format(bucket,prefix),\n",
    "    \"test\": \"s3://{}/{}/test.json\".format(bucket,prefix)\n",
    "}\n",
    "dar_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type='ml.c5.2xlarge' #Estimated Training Time: 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'156387875391.dkr.ecr.us-west-2.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "dar_image_name = sagemaker.image_uris.retrieve('forecasting-deepar', region)\n",
    "dar_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "dar_estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_uri=dar_image_name,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=train_instance_type,\n",
    "    base_job_name=prefix,\n",
    "    output_path=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 'H'\n",
    "prediction_length = 4\n",
    "context_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dar_hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"num_cells\": \"40\",\n",
    "    \"num_layers\": \"3\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"20\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"0.001\",\n",
    "    \"dropout_rate\": \"0.05\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"cardinality\": \"auto\",\n",
    "    \"num_dynamic_feat\":\"ignore\"\n",
    "}\n",
    "dar_estimator.set_hyperparameters(**dar_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 10:53:27 Starting - Starting the training job...\n",
      "2021-05-14 10:53:28 Starting - Launching requested ML instances......\n",
      "2021-05-14 10:54:37 Starting - Preparing the instances for training...\n",
      "2021-05-14 10:55:24 Downloading - Downloading input data...\n",
      "2021-05-14 10:55:30 Training - Downloading the training image.....\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:35 INFO 140667699287680] Reading default configuration from /opt/amazon/lib/python3.6/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:35 INFO 140667699287680] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'prediction_length': '4', 'dropout_rate': '0.05', 'time_freq': 'H', 'context_length': '12', 'cardinality': 'auto', 'early_stopping_patience': '10', 'num_dynamic_feat': 'ignore', 'num_cells': '40', 'likelihood': 'gaussian', 'num_layers': '3', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '32'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:35 INFO 140667699287680] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'gaussian', 'mini_batch_size': '32', 'num_cells': '40', 'num_dynamic_feat': 'ignore', 'num_eval_samples': '100', 'num_layers': '3', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'prediction_length': '4', 'time_freq': 'H', 'context_length': '12', 'epochs': '20'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:35 INFO 140667699287680] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:36 INFO 140667699287680] [num_dynamic_feat=ignore] Not using any `dynamic_feat` feature that may be in the data.\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:36 INFO 140667699287680] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:36 INFO 140667699287680] random_seed is None\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:36 INFO 140667699287680] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] [cardinality=auto] Inferred value of cardinality=[16946] from dataset.\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] Integer time series\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] number of time series: 16946\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] number of observations: 419074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] mean target length: 24.729965773633896\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] min/mean/max target: 9.0/894.2175916425261/7730.0\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] mean abs(target): 894.2175916425261\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:37 INFO 140667699287680] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Test set statistics:\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Integer time series\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] number of time series: 16804\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] number of observations: 51363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] mean target length: 3.0565936681742443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] min/mean/max target: 9.0/628.0667017113486/3795.0\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] mean abs(target): 628.0667017113486\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #memory_usage::<batchbuffer> = 0.26302337646484375 mb\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] nvidia-smi took: 0.02516770362854004 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989799.0993376, \"EndTime\": 1620989799.1365204, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 34.83080863952637, \"count\": 1, \"min\": 34.83080863952637, \"max\": 34.83080863952637}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #memory_usage::<model> = 5 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989799.1365898, \"EndTime\": 1620989799.1935325, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 94.08974647521973, \"count\": 1, \"min\": 94.08974647521973, \"max\": 94.08974647521973}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch[0] avg_epoch_loss=235.614609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=235.61460876464844\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch[5] avg_epoch_loss=221.569368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=221.56936756769815\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch [5]#011Speed: 1883.85 samples/sec#011loss=221.569368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch[10] avg_epoch_loss=159.741922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=85.54898834228516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch [10]#011Speed: 1067.42 samples/sec#011loss=85.548988\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch[15] avg_epoch_loss=124.606115\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=47.307339096069335\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch [15]#011Speed: 1899.78 samples/sec#011loss=47.307339\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch[20] avg_epoch_loss=97.528893\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=10.881781673431396\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch [20]#011Speed: 1049.53 samples/sec#011loss=10.881782\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch[25] avg_epoch_loss=82.525940\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=19.513538646698\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:39 INFO 140667699287680] Epoch[0] Batch [25]#011Speed: 1956.04 samples/sec#011loss=19.513539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[30] avg_epoch_loss=72.848678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=22.526915264129638\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [30]#011Speed: 1141.41 samples/sec#011loss=22.526915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[35] avg_epoch_loss=63.950352\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=8.78073263168335\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [35]#011Speed: 1664.82 samples/sec#011loss=8.780733\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[40] avg_epoch_loss=59.901859\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=30.752707099914552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [40]#011Speed: 1009.77 samples/sec#011loss=30.752707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[45] avg_epoch_loss=55.060113\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=15.357800197601318\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [45]#011Speed: 1853.61 samples/sec#011loss=15.357800\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[50] avg_epoch_loss=51.029891\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=13.951846981048584\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [50]#011Speed: 1115.08 samples/sec#011loss=13.951847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[55] avg_epoch_loss=47.794429\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=14.792714595794678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [55]#011Speed: 1608.88 samples/sec#011loss=14.792715\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[60] avg_epoch_loss=44.421176\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=6.640741920471191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [60]#011Speed: 914.77 samples/sec#011loss=6.640742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch[65] avg_epoch_loss=42.069991\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=13.385530948638916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:40 INFO 140667699287680] Epoch[0] Batch [65]#011Speed: 1550.21 samples/sec#011loss=13.385531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[70] avg_epoch_loss=39.655117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=7.77878770828247\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [70]#011Speed: 817.60 samples/sec#011loss=7.778788\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[75] avg_epoch_loss=38.039158\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=15.092537307739258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [75]#011Speed: 1675.74 samples/sec#011loss=15.092537\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[80] avg_epoch_loss=36.378997\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=11.144541168212891\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [80]#011Speed: 1063.08 samples/sec#011loss=11.144541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[85] avg_epoch_loss=34.991716\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=12.517764568328857\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [85]#011Speed: 1904.28 samples/sec#011loss=12.517765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[90] avg_epoch_loss=33.849149\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=14.197008800506591\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [90]#011Speed: 1099.74 samples/sec#011loss=14.197009\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[95] avg_epoch_loss=32.449264\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=6.971345520019531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [95]#011Speed: 1729.63 samples/sec#011loss=6.971346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[100] avg_epoch_loss=31.321191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=9.662194919586181\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [100]#011Speed: 1127.81 samples/sec#011loss=9.662195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch[105] avg_epoch_loss=30.381438\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=11.398429870605469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:41 INFO 140667699287680] Epoch[0] Batch [105]#011Speed: 1923.84 samples/sec#011loss=11.398430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[110] avg_epoch_loss=29.636588\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=13.845763683319092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [110]#011Speed: 1096.39 samples/sec#011loss=13.845764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[115] avg_epoch_loss=28.686730\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=7.599872493743897\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [115]#011Speed: 1805.15 samples/sec#011loss=7.599872\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[120] avg_epoch_loss=27.957201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=11.032142162322998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [120]#011Speed: 1065.50 samples/sec#011loss=11.032142\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[125] avg_epoch_loss=27.248264\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=10.091974067687989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [125]#011Speed: 1858.14 samples/sec#011loss=10.091974\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[130] avg_epoch_loss=26.610851\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=10.548053550720216\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [130]#011Speed: 1148.31 samples/sec#011loss=10.548054\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[135] avg_epoch_loss=26.088054\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=12.39078598022461\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [135]#011Speed: 1677.11 samples/sec#011loss=12.390786\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[140] avg_epoch_loss=25.446114\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=7.985324192047119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [140]#011Speed: 1021.47 samples/sec#011loss=7.985324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[145] avg_epoch_loss=25.006124\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=12.598419952392579\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [145]#011Speed: 1795.02 samples/sec#011loss=12.598420\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch[150] avg_epoch_loss=24.518122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=10.268455123901367\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:42 INFO 140667699287680] Epoch[0] Batch [150]#011Speed: 1037.83 samples/sec#011loss=10.268455\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[155] avg_epoch_loss=24.029749\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=9.280890560150146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [155]#011Speed: 1867.33 samples/sec#011loss=9.280891\u001b[0m\n",
      "\n",
      "2021-05-14 10:56:33 Training - Training image download completed. Training in progress.\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[160] avg_epoch_loss=23.581288\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=9.589311408996583\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [160]#011Speed: 1069.75 samples/sec#011loss=9.589311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[165] avg_epoch_loss=23.140186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=8.9366774559021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [165]#011Speed: 1767.93 samples/sec#011loss=8.936677\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[170] avg_epoch_loss=22.765202\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=10.315760326385497\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [170]#011Speed: 1049.89 samples/sec#011loss=10.315760\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[175] avg_epoch_loss=22.399079\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=9.877657222747803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [175]#011Speed: 1898.86 samples/sec#011loss=9.877657\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[180] avg_epoch_loss=22.040004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=9.400580883026123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [180]#011Speed: 1099.33 samples/sec#011loss=9.400581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[185] avg_epoch_loss=21.714690\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=9.938298988342286\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [185]#011Speed: 1936.23 samples/sec#011loss=9.938299\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch[190] avg_epoch_loss=21.357861\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=8.083851337432861\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:43 INFO 140667699287680] Epoch[0] Batch [190]#011Speed: 1062.60 samples/sec#011loss=8.083851\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[195] avg_epoch_loss=21.003693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=7.474447631835938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [195]#011Speed: 1784.42 samples/sec#011loss=7.474448\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[200] avg_epoch_loss=20.685242\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=8.20197925567627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [200]#011Speed: 988.79 samples/sec#011loss=8.201979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[205] avg_epoch_loss=20.397093\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=8.813484859466552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [205]#011Speed: 1794.13 samples/sec#011loss=8.813485\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[210] avg_epoch_loss=20.108334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=8.211473846435547\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [210]#011Speed: 1047.84 samples/sec#011loss=8.211474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[215] avg_epoch_loss=19.837073\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=8.38984661102295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [215]#011Speed: 1878.38 samples/sec#011loss=8.389847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[220] avg_epoch_loss=19.556030\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=7.414971256256104\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [220]#011Speed: 1114.74 samples/sec#011loss=7.414971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[225] avg_epoch_loss=19.292935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=7.664140892028809\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [225]#011Speed: 1947.02 samples/sec#011loss=7.664141\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[230] avg_epoch_loss=19.079192\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=9.418037223815919\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [230]#011Speed: 1092.51 samples/sec#011loss=9.418037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch[235] avg_epoch_loss=18.831991\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=7.411290836334229\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:44 INFO 140667699287680] Epoch[0] Batch [235]#011Speed: 1741.43 samples/sec#011loss=7.411291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[240] avg_epoch_loss=18.615059\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=8.375845813751221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [240]#011Speed: 1043.20 samples/sec#011loss=8.375846\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[245] avg_epoch_loss=18.396041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=7.839401912689209\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [245]#011Speed: 1748.25 samples/sec#011loss=7.839402\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[250] avg_epoch_loss=18.214797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=9.297597885131836\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [250]#011Speed: 1069.89 samples/sec#011loss=9.297598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[255] avg_epoch_loss=18.051696\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=9.864029121398925\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [255]#011Speed: 1920.96 samples/sec#011loss=9.864029\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[260] avg_epoch_loss=17.887438\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=9.477406883239746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [260]#011Speed: 1119.00 samples/sec#011loss=9.477407\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[265] avg_epoch_loss=17.698597\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=7.84112434387207\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [265]#011Speed: 1738.68 samples/sec#011loss=7.841124\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[270] avg_epoch_loss=17.520003\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=8.01878776550293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [270]#011Speed: 1119.84 samples/sec#011loss=8.018788\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch[275] avg_epoch_loss=17.372455\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=275 train loss <loss>=9.375334072113038\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:45 INFO 140667699287680] Epoch[0] Batch [275]#011Speed: 1668.10 samples/sec#011loss=9.375334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[280] avg_epoch_loss=17.214881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=280 train loss <loss>=8.51682424545288\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [280]#011Speed: 1058.59 samples/sec#011loss=8.516824\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[285] avg_epoch_loss=17.043324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=285 train loss <loss>=7.401780986785889\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [285]#011Speed: 1789.99 samples/sec#011loss=7.401781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[290] avg_epoch_loss=16.881301\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=290 train loss <loss>=7.6136088371276855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [290]#011Speed: 1081.00 samples/sec#011loss=7.613609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[295] avg_epoch_loss=16.720154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=295 train loss <loss>=7.341393184661865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [295]#011Speed: 1628.01 samples/sec#011loss=7.341393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[300] avg_epoch_loss=16.591710\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=300 train loss <loss>=8.987801933288575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [300]#011Speed: 1045.27 samples/sec#011loss=8.987802\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[305] avg_epoch_loss=16.448316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=305 train loss <loss>=7.816018390655517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [305]#011Speed: 1827.81 samples/sec#011loss=7.816018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[310] avg_epoch_loss=16.312207\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=310 train loss <loss>=7.982364749908447\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [310]#011Speed: 1024.94 samples/sec#011loss=7.982365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch[315] avg_epoch_loss=16.197853\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=315 train loss <loss>=9.084987545013428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:46 INFO 140667699287680] Epoch[0] Batch [315]#011Speed: 1943.48 samples/sec#011loss=9.084988\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[320] avg_epoch_loss=16.068988\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=320 train loss <loss>=7.9247640609741214\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [320]#011Speed: 1122.73 samples/sec#011loss=7.924764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[325] avg_epoch_loss=15.957717\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=325 train loss <loss>=8.814101028442384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [325]#011Speed: 1962.74 samples/sec#011loss=8.814101\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[330] avg_epoch_loss=15.837427\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=330 train loss <loss>=7.994510555267334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [330]#011Speed: 1033.20 samples/sec#011loss=7.994511\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[335] avg_epoch_loss=15.721080\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=335 train loss <loss>=8.018898105621338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [335]#011Speed: 1771.09 samples/sec#011loss=8.018898\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[340] avg_epoch_loss=15.601553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=340 train loss <loss>=7.5693460464477536\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [340]#011Speed: 1072.09 samples/sec#011loss=7.569346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[345] avg_epoch_loss=15.487561\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=345 train loss <loss>=7.713317394256592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [345]#011Speed: 1898.10 samples/sec#011loss=7.713317\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[350] avg_epoch_loss=15.378184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=350 train loss <loss>=7.809263229370117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [350]#011Speed: 1050.90 samples/sec#011loss=7.809263\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[355] avg_epoch_loss=15.287532\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=355 train loss <loss>=8.923793411254882\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [355]#011Speed: 1954.90 samples/sec#011loss=8.923793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch[360] avg_epoch_loss=15.188319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=360 train loss <loss>=8.124333763122559\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:47 INFO 140667699287680] Epoch[0] Batch [360]#011Speed: 1063.46 samples/sec#011loss=8.124334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[365] avg_epoch_loss=15.087552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=365 train loss <loss>=7.812205600738525\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [365]#011Speed: 1788.02 samples/sec#011loss=7.812206\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[370] avg_epoch_loss=14.993457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=370 train loss <loss>=8.105653190612793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [370]#011Speed: 1073.12 samples/sec#011loss=8.105653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[375] avg_epoch_loss=14.912183\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=375 train loss <loss>=8.881713008880615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [375]#011Speed: 1955.66 samples/sec#011loss=8.881713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[380] avg_epoch_loss=14.826329\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=380 train loss <loss>=8.370052146911622\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [380]#011Speed: 1113.10 samples/sec#011loss=8.370052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[385] avg_epoch_loss=14.745984\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=385 train loss <loss>=8.623758888244629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [385]#011Speed: 1923.00 samples/sec#011loss=8.623759\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[390] avg_epoch_loss=14.680611\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=390 train loss <loss>=9.633768844604493\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [390]#011Speed: 1126.11 samples/sec#011loss=9.633769\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[395] avg_epoch_loss=14.600891\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=395 train loss <loss>=8.366784954071045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [395]#011Speed: 1861.62 samples/sec#011loss=8.366785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[400] avg_epoch_loss=14.517131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=400 train loss <loss>=7.883331680297852\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [400]#011Speed: 1099.04 samples/sec#011loss=7.883332\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch[405] avg_epoch_loss=14.435241\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=405 train loss <loss>=7.867715072631836\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:48 INFO 140667699287680] Epoch[0] Batch [405]#011Speed: 1855.56 samples/sec#011loss=7.867715\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[410] avg_epoch_loss=14.350436\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=410 train loss <loss>=7.464200973510742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [410]#011Speed: 1117.00 samples/sec#011loss=7.464201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[415] avg_epoch_loss=14.276565\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=415 train loss <loss>=8.204370021820068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [415]#011Speed: 1413.83 samples/sec#011loss=8.204370\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[420] avg_epoch_loss=14.205101\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=420 train loss <loss>=8.259310913085937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [420]#011Speed: 1094.52 samples/sec#011loss=8.259311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[425] avg_epoch_loss=14.138379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=425 train loss <loss>=8.520384883880615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [425]#011Speed: 1412.11 samples/sec#011loss=8.520385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[430] avg_epoch_loss=14.065178\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=430 train loss <loss>=7.828466415405273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [430]#011Speed: 1043.86 samples/sec#011loss=7.828466\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[435] avg_epoch_loss=14.011624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=435 train loss <loss>=9.395321941375732\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [435]#011Speed: 1573.89 samples/sec#011loss=9.395322\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch[440] avg_epoch_loss=13.957377\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=440 train loss <loss>=9.227038192749024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:49 INFO 140667699287680] Epoch[0] Batch [440]#011Speed: 1022.18 samples/sec#011loss=9.227038\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[445] avg_epoch_loss=13.884062\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=445 train loss <loss>=7.417627334594727\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [445]#011Speed: 1809.93 samples/sec#011loss=7.417627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[450] avg_epoch_loss=13.826089\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=450 train loss <loss>=8.654874992370605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [450]#011Speed: 1105.96 samples/sec#011loss=8.654875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[455] avg_epoch_loss=13.759685\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=455 train loss <loss>=7.770102882385254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [455]#011Speed: 1743.42 samples/sec#011loss=7.770103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[460] avg_epoch_loss=13.698790\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=460 train loss <loss>=8.145144176483154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [460]#011Speed: 1086.25 samples/sec#011loss=8.145144\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[465] avg_epoch_loss=13.639597\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=465 train loss <loss>=8.182020664215088\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [465]#011Speed: 1907.54 samples/sec#011loss=8.182021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[470] avg_epoch_loss=13.577985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=470 train loss <loss>=7.835679912567139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [470]#011Speed: 1141.58 samples/sec#011loss=7.835680\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[475] avg_epoch_loss=13.519547\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=475 train loss <loss>=8.014729976654053\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [475]#011Speed: 1743.29 samples/sec#011loss=8.014730\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[480] avg_epoch_loss=13.460214\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=480 train loss <loss>=7.811702060699463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [480]#011Speed: 1096.15 samples/sec#011loss=7.811702\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch[485] avg_epoch_loss=13.399531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=485 train loss <loss>=7.5618483543396\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:50 INFO 140667699287680] Epoch[0] Batch [485]#011Speed: 2014.48 samples/sec#011loss=7.561848\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[490] avg_epoch_loss=13.349310\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=490 train loss <loss>=8.4678560256958\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [490]#011Speed: 1084.16 samples/sec#011loss=8.467856\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[495] avg_epoch_loss=13.291368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=495 train loss <loss>=7.601467514038086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [495]#011Speed: 1805.98 samples/sec#011loss=7.601468\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[500] avg_epoch_loss=13.235215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=500 train loss <loss>=7.664820861816406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [500]#011Speed: 1036.80 samples/sec#011loss=7.664821\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[505] avg_epoch_loss=13.189152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=505 train loss <loss>=8.573599529266357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [505]#011Speed: 1940.68 samples/sec#011loss=8.573600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[510] avg_epoch_loss=13.140538\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=510 train loss <loss>=8.220820999145507\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [510]#011Speed: 1079.67 samples/sec#011loss=8.220821\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[515] avg_epoch_loss=13.088967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=515 train loss <loss>=7.818422889709472\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [515]#011Speed: 1787.26 samples/sec#011loss=7.818423\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[520] avg_epoch_loss=13.037503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=520 train loss <loss>=7.726394557952881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [520]#011Speed: 1044.36 samples/sec#011loss=7.726395\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch[525] avg_epoch_loss=12.989724\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=525 train loss <loss>=8.01116304397583\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:51 INFO 140667699287680] Epoch[0] Batch [525]#011Speed: 1912.00 samples/sec#011loss=8.011163\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch[530] avg_epoch_loss=12.939978\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=530 train loss <loss>=7.706737327575683\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch [530]#011Speed: 1111.62 samples/sec#011loss=7.706737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch[535] avg_epoch_loss=12.893400\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=535 train loss <loss>=7.946780109405518\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch [535]#011Speed: 1904.23 samples/sec#011loss=7.946780\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch[540] avg_epoch_loss=12.850971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=540 train loss <loss>=8.30257806777954\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch [540]#011Speed: 1125.45 samples/sec#011loss=8.302578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch[545] avg_epoch_loss=12.808532\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=545 train loss <loss>=8.216583347320556\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch [545]#011Speed: 1872.33 samples/sec#011loss=8.216583\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch[550] avg_epoch_loss=12.766532\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, batch=550 train loss <loss>=8.180209350585937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[0] Batch [550]#011Speed: 1814.95 samples/sec#011loss=8.180209\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.6/lib/python3.6/contextlib.py:99: DeprecationWarning: generator 'local_timer' raised StopIteration\n",
      "  self.gen.throw(type, value, traceback)\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] processed a total of 17634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989799.1935885, \"EndTime\": 1620989812.4382777, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 13244.611501693726, \"count\": 1, \"min\": 13244.611501693726, \"max\": 13244.611501693726}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1331.3991950511834 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=0, train loss <loss>=12.760306843812915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_2120295a-8a7d-4702-a3ca-42a7820e2b66-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989812.438347, \"EndTime\": 1620989812.447333, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.541107177734375, \"count\": 1, \"min\": 8.541107177734375, \"max\": 8.541107177734375}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch[0] avg_epoch_loss=7.270623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=7.270623207092285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch[5] avg_epoch_loss=7.564087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=7.564086834589641\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch [5]#011Speed: 1882.02 samples/sec#011loss=7.564087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch[10] avg_epoch_loss=7.707529\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=7.879658985137939\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch [10]#011Speed: 1158.27 samples/sec#011loss=7.879659\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch[15] avg_epoch_loss=7.831945\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=8.105659294128419\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch [15]#011Speed: 1879.42 samples/sec#011loss=8.105659\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch[20] avg_epoch_loss=7.953363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=8.341904163360596\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:52 INFO 140667699287680] Epoch[1] Batch [20]#011Speed: 1133.93 samples/sec#011loss=8.341904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[25] avg_epoch_loss=8.050925\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=8.460682392120361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [25]#011Speed: 1871.37 samples/sec#011loss=8.460682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[30] avg_epoch_loss=8.045669\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=8.018336868286132\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [30]#011Speed: 1052.60 samples/sec#011loss=8.018337\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[35] avg_epoch_loss=8.007505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=7.770893573760986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [35]#011Speed: 1751.38 samples/sec#011loss=7.770894\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[40] avg_epoch_loss=7.966024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=7.667354583740234\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [40]#011Speed: 1102.82 samples/sec#011loss=7.667355\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[45] avg_epoch_loss=7.936019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=7.689982795715332\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [45]#011Speed: 1913.77 samples/sec#011loss=7.689983\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[50] avg_epoch_loss=7.964999\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=8.231617259979249\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [50]#011Speed: 1113.06 samples/sec#011loss=8.231617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[55] avg_epoch_loss=7.945066\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=7.741741371154785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [55]#011Speed: 1977.37 samples/sec#011loss=7.741741\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[60] avg_epoch_loss=7.937845\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=7.856972599029541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [60]#011Speed: 1115.76 samples/sec#011loss=7.856973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch[65] avg_epoch_loss=7.947447\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=8.064591884613037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:53 INFO 140667699287680] Epoch[1] Batch [65]#011Speed: 1954.44 samples/sec#011loss=8.064592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[70] avg_epoch_loss=7.939999\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=7.84167890548706\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [70]#011Speed: 1129.39 samples/sec#011loss=7.841679\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[75] avg_epoch_loss=7.957824\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=8.210947132110595\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [75]#011Speed: 1944.75 samples/sec#011loss=8.210947\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[80] avg_epoch_loss=7.937829\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=7.633910465240478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [80]#011Speed: 929.73 samples/sec#011loss=7.633910\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[85] avg_epoch_loss=7.927763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=7.764694690704346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [85]#011Speed: 1872.50 samples/sec#011loss=7.764695\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[90] avg_epoch_loss=7.932993\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=8.022935581207275\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [90]#011Speed: 1056.40 samples/sec#011loss=8.022936\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[95] avg_epoch_loss=7.930024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=7.875995731353759\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [95]#011Speed: 1776.75 samples/sec#011loss=7.875996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[100] avg_epoch_loss=7.943273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=8.197647857666016\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [100]#011Speed: 1126.34 samples/sec#011loss=8.197648\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch[105] avg_epoch_loss=7.924430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=7.543808650970459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:54 INFO 140667699287680] Epoch[1] Batch [105]#011Speed: 1950.30 samples/sec#011loss=7.543809\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[110] avg_epoch_loss=7.921541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=7.860287380218506\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [110]#011Speed: 1093.89 samples/sec#011loss=7.860287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[115] avg_epoch_loss=7.893917\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=7.280665874481201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [115]#011Speed: 1825.91 samples/sec#011loss=7.280666\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[120] avg_epoch_loss=7.895123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=7.923111343383789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [120]#011Speed: 1068.65 samples/sec#011loss=7.923111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[125] avg_epoch_loss=7.870004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=7.262123107910156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [125]#011Speed: 1870.32 samples/sec#011loss=7.262123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[130] avg_epoch_loss=7.857503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=7.542476749420166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [130]#011Speed: 1124.94 samples/sec#011loss=7.542477\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[135] avg_epoch_loss=7.849594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=7.642373561859131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [135]#011Speed: 1876.98 samples/sec#011loss=7.642374\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[140] avg_epoch_loss=7.852639\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=7.935457801818847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [140]#011Speed: 1115.41 samples/sec#011loss=7.935458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch[145] avg_epoch_loss=7.840754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=7.505610942840576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:55 INFO 140667699287680] Epoch[1] Batch [145]#011Speed: 1614.95 samples/sec#011loss=7.505611\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[150] avg_epoch_loss=7.823023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=7.305261421203613\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [150]#011Speed: 960.23 samples/sec#011loss=7.305261\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[155] avg_epoch_loss=7.808207\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=7.36077184677124\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [155]#011Speed: 1778.32 samples/sec#011loss=7.360772\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[160] avg_epoch_loss=7.791973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=7.285465145111084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [160]#011Speed: 1077.44 samples/sec#011loss=7.285465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[165] avg_epoch_loss=7.794341\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=7.870590782165527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [165]#011Speed: 1802.26 samples/sec#011loss=7.870591\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[170] avg_epoch_loss=7.804489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=8.141412544250489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [170]#011Speed: 1010.02 samples/sec#011loss=8.141413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[175] avg_epoch_loss=7.791862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=7.360021781921387\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [175]#011Speed: 1826.15 samples/sec#011loss=7.360022\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[180] avg_epoch_loss=7.785494\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=7.561318969726562\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [180]#011Speed: 1068.18 samples/sec#011loss=7.561319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[185] avg_epoch_loss=7.781318\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=7.630171298980713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [185]#011Speed: 1851.43 samples/sec#011loss=7.630171\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch[190] avg_epoch_loss=7.790389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=8.12780475616455\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:56 INFO 140667699287680] Epoch[1] Batch [190]#011Speed: 1117.73 samples/sec#011loss=8.127805\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[195] avg_epoch_loss=7.788310\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=7.708894729614258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [195]#011Speed: 1834.71 samples/sec#011loss=7.708895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[200] avg_epoch_loss=7.780891\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=7.490088748931885\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [200]#011Speed: 1106.54 samples/sec#011loss=7.490089\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[205] avg_epoch_loss=7.774157\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=7.503446197509765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [205]#011Speed: 1809.81 samples/sec#011loss=7.503446\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[210] avg_epoch_loss=7.772642\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=7.710219383239746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [210]#011Speed: 1118.64 samples/sec#011loss=7.710219\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[215] avg_epoch_loss=7.772506\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=7.76675968170166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [215]#011Speed: 1775.86 samples/sec#011loss=7.766760\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[220] avg_epoch_loss=7.770696\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=7.6925124168396\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [220]#011Speed: 1111.27 samples/sec#011loss=7.692512\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[225] avg_epoch_loss=7.760430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=7.306660842895508\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [225]#011Speed: 1806.91 samples/sec#011loss=7.306661\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch[230] avg_epoch_loss=7.766787\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=8.054111289978028\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:57 INFO 140667699287680] Epoch[1] Batch [230]#011Speed: 1072.42 samples/sec#011loss=8.054111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[235] avg_epoch_loss=7.758989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=7.398748779296875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [235]#011Speed: 1796.61 samples/sec#011loss=7.398749\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[240] avg_epoch_loss=7.748452\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=7.251110649108886\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [240]#011Speed: 1103.59 samples/sec#011loss=7.251111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[245] avg_epoch_loss=7.750177\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=7.8333251953125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [245]#011Speed: 1887.81 samples/sec#011loss=7.833325\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[250] avg_epoch_loss=7.744892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=7.484838390350342\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [250]#011Speed: 1047.27 samples/sec#011loss=7.484838\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[255] avg_epoch_loss=7.733711\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=7.172429370880127\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [255]#011Speed: 1869.80 samples/sec#011loss=7.172429\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[260] avg_epoch_loss=7.716910\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=6.856725406646729\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [260]#011Speed: 1144.35 samples/sec#011loss=6.856725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[265] avg_epoch_loss=7.702387\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=6.944289207458496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [265]#011Speed: 1865.38 samples/sec#011loss=6.944289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[270] avg_epoch_loss=7.682457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=270 train loss <loss>=6.622172451019287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [270]#011Speed: 1163.07 samples/sec#011loss=6.622172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch[275] avg_epoch_loss=7.667652\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=275 train loss <loss>=6.865188217163086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:58 INFO 140667699287680] Epoch[1] Batch [275]#011Speed: 1832.21 samples/sec#011loss=6.865188\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[280] avg_epoch_loss=7.653215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=280 train loss <loss>=6.85632963180542\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [280]#011Speed: 1055.34 samples/sec#011loss=6.856330\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[285] avg_epoch_loss=7.643948\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=285 train loss <loss>=7.123114395141601\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [285]#011Speed: 1822.48 samples/sec#011loss=7.123114\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[290] avg_epoch_loss=7.630338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=290 train loss <loss>=6.851860046386719\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [290]#011Speed: 979.35 samples/sec#011loss=6.851860\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[295] avg_epoch_loss=7.614975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=295 train loss <loss>=6.720870590209961\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [295]#011Speed: 1588.69 samples/sec#011loss=6.720871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[300] avg_epoch_loss=7.606752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=300 train loss <loss>=7.119911479949951\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [300]#011Speed: 1034.47 samples/sec#011loss=7.119911\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[305] avg_epoch_loss=7.601239\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=305 train loss <loss>=7.269388675689697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [305]#011Speed: 1768.01 samples/sec#011loss=7.269389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[310] avg_epoch_loss=7.584957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=310 train loss <loss>=6.588456821441651\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [310]#011Speed: 1072.84 samples/sec#011loss=6.588457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch[315] avg_epoch_loss=7.572832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=315 train loss <loss>=6.818658065795899\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:56:59 INFO 140667699287680] Epoch[1] Batch [315]#011Speed: 1814.31 samples/sec#011loss=6.818658\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[320] avg_epoch_loss=7.553224\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=320 train loss <loss>=6.314046096801758\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [320]#011Speed: 1135.76 samples/sec#011loss=6.314046\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[325] avg_epoch_loss=7.534411\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=325 train loss <loss>=6.326611614227295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [325]#011Speed: 1966.28 samples/sec#011loss=6.326612\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[330] avg_epoch_loss=7.515424\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=330 train loss <loss>=6.277449035644532\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [330]#011Speed: 1079.59 samples/sec#011loss=6.277449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[335] avg_epoch_loss=7.498139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=335 train loss <loss>=6.353850650787353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [335]#011Speed: 1670.36 samples/sec#011loss=6.353851\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[340] avg_epoch_loss=7.488041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=340 train loss <loss>=6.809477615356445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [340]#011Speed: 1002.81 samples/sec#011loss=6.809478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[345] avg_epoch_loss=7.475048\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=345 train loss <loss>=6.588932704925537\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [345]#011Speed: 1977.77 samples/sec#011loss=6.588933\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[350] avg_epoch_loss=7.467500\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=350 train loss <loss>=6.945184803009033\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [350]#011Speed: 1059.46 samples/sec#011loss=6.945185\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch[355] avg_epoch_loss=7.458307\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=355 train loss <loss>=6.812919235229492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:00 INFO 140667699287680] Epoch[1] Batch [355]#011Speed: 1862.29 samples/sec#011loss=6.812919\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[360] avg_epoch_loss=7.445474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=360 train loss <loss>=6.531818866729736\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [360]#011Speed: 1157.38 samples/sec#011loss=6.531819\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[365] avg_epoch_loss=7.429861\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=365 train loss <loss>=6.302567100524902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [365]#011Speed: 1732.09 samples/sec#011loss=6.302567\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[370] avg_epoch_loss=7.422471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=370 train loss <loss>=6.88152322769165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [370]#011Speed: 1122.73 samples/sec#011loss=6.881523\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[375] avg_epoch_loss=7.413451\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=375 train loss <loss>=6.744171905517578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [375]#011Speed: 1856.46 samples/sec#011loss=6.744172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[380] avg_epoch_loss=7.402570\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=380 train loss <loss>=6.584354305267334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [380]#011Speed: 1019.40 samples/sec#011loss=6.584354\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[385] avg_epoch_loss=7.392240\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=385 train loss <loss>=6.605099201202393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [385]#011Speed: 1856.08 samples/sec#011loss=6.605099\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[390] avg_epoch_loss=7.383865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=390 train loss <loss>=6.737308025360107\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [390]#011Speed: 1121.73 samples/sec#011loss=6.737308\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[395] avg_epoch_loss=7.370482\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=395 train loss <loss>=6.323906707763672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [395]#011Speed: 1858.78 samples/sec#011loss=6.323907\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch[400] avg_epoch_loss=7.360306\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=400 train loss <loss>=6.554377937316895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:01 INFO 140667699287680] Epoch[1] Batch [400]#011Speed: 1006.51 samples/sec#011loss=6.554378\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[405] avg_epoch_loss=7.346743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=405 train loss <loss>=6.2589850425720215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [405]#011Speed: 1553.12 samples/sec#011loss=6.258985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[410] avg_epoch_loss=7.334141\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=410 train loss <loss>=6.310864067077636\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [410]#011Speed: 969.46 samples/sec#011loss=6.310864\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[415] avg_epoch_loss=7.318775\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=415 train loss <loss>=6.055709266662598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [415]#011Speed: 1792.72 samples/sec#011loss=6.055709\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[420] avg_epoch_loss=7.304625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=420 train loss <loss>=6.12734842300415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [420]#011Speed: 1030.28 samples/sec#011loss=6.127348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[425] avg_epoch_loss=7.307851\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=425 train loss <loss>=7.579429054260254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [425]#011Speed: 1852.23 samples/sec#011loss=7.579429\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[430] avg_epoch_loss=7.294155\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=430 train loss <loss>=6.1272358894348145\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [430]#011Speed: 1143.28 samples/sec#011loss=6.127236\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[435] avg_epoch_loss=7.281589\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=435 train loss <loss>=6.198406505584717\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [435]#011Speed: 1633.96 samples/sec#011loss=6.198407\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch[440] avg_epoch_loss=7.265646\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=440 train loss <loss>=5.875401496887207\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:02 INFO 140667699287680] Epoch[1] Batch [440]#011Speed: 1149.79 samples/sec#011loss=5.875401\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[445] avg_epoch_loss=7.255600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=445 train loss <loss>=6.3696002006530765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [445]#011Speed: 1949.82 samples/sec#011loss=6.369600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[450] avg_epoch_loss=7.252490\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=450 train loss <loss>=6.975098419189453\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [450]#011Speed: 1124.40 samples/sec#011loss=6.975098\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[455] avg_epoch_loss=7.238460\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=455 train loss <loss>=5.972900676727295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [455]#011Speed: 1697.66 samples/sec#011loss=5.972901\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[460] avg_epoch_loss=7.227314\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=460 train loss <loss>=6.210816478729248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [460]#011Speed: 991.19 samples/sec#011loss=6.210816\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[465] avg_epoch_loss=7.214035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=465 train loss <loss>=5.989725875854492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [465]#011Speed: 1892.90 samples/sec#011loss=5.989726\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[470] avg_epoch_loss=7.207930\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=470 train loss <loss>=6.6389388084411625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [470]#011Speed: 1075.18 samples/sec#011loss=6.638939\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[475] avg_epoch_loss=7.197773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=475 train loss <loss>=6.240931034088135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [475]#011Speed: 1621.50 samples/sec#011loss=6.240931\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch[480] avg_epoch_loss=7.186442\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=480 train loss <loss>=6.107812976837158\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:03 INFO 140667699287680] Epoch[1] Batch [480]#011Speed: 906.82 samples/sec#011loss=6.107813\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[485] avg_epoch_loss=7.175888\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=485 train loss <loss>=6.160577487945557\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [485]#011Speed: 1612.75 samples/sec#011loss=6.160577\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[490] avg_epoch_loss=7.169552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=490 train loss <loss>=6.5537008285522464\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [490]#011Speed: 930.85 samples/sec#011loss=6.553701\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[495] avg_epoch_loss=7.159980\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=495 train loss <loss>=6.219981861114502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [495]#011Speed: 1668.78 samples/sec#011loss=6.219982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[500] avg_epoch_loss=7.152277\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=500 train loss <loss>=6.388125228881836\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [500]#011Speed: 1005.65 samples/sec#011loss=6.388125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[505] avg_epoch_loss=7.141248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=505 train loss <loss>=6.03611192703247\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [505]#011Speed: 1553.11 samples/sec#011loss=6.036112\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[510] avg_epoch_loss=7.130583\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=510 train loss <loss>=6.051307106018067\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [510]#011Speed: 968.18 samples/sec#011loss=6.051307\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[515] avg_epoch_loss=7.118945\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=515 train loss <loss>=5.929589748382568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [515]#011Speed: 1634.22 samples/sec#011loss=5.929590\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch[520] avg_epoch_loss=7.110572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=520 train loss <loss>=6.246496200561523\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:04 INFO 140667699287680] Epoch[1] Batch [520]#011Speed: 891.78 samples/sec#011loss=6.246496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[525] avg_epoch_loss=7.103498\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=525 train loss <loss>=6.36634578704834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [525]#011Speed: 1567.36 samples/sec#011loss=6.366346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[530] avg_epoch_loss=7.093907\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=530 train loss <loss>=6.08491096496582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [530]#011Speed: 910.07 samples/sec#011loss=6.084911\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[535] avg_epoch_loss=7.086981\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=535 train loss <loss>=6.35142297744751\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [535]#011Speed: 1551.69 samples/sec#011loss=6.351423\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[540] avg_epoch_loss=7.073972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=540 train loss <loss>=5.679415035247803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [540]#011Speed: 865.43 samples/sec#011loss=5.679415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[545] avg_epoch_loss=7.063531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=545 train loss <loss>=5.933832168579102\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [545]#011Speed: 1557.33 samples/sec#011loss=5.933832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[550] avg_epoch_loss=7.058530\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=550 train loss <loss>=6.512470531463623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [550]#011Speed: 897.74 samples/sec#011loss=6.512471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch[555] avg_epoch_loss=7.046743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, batch=555 train loss <loss>=5.7477882385253904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:05 INFO 140667699287680] Epoch[1] Batch [555]#011Speed: 1511.87 samples/sec#011loss=5.747788\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] processed a total of 17905 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989812.447384, \"EndTime\": 1620989826.030901, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13583.463191986084, \"count\": 1, \"min\": 13583.463191986084, \"max\": 13583.463191986084}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1318.139180055404 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=1, train loss <loss>=7.038242493356977\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_5e6fd805-a2cf-4be5-a132-0bfd44b28ac1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989826.0309525, \"EndTime\": 1620989826.0395622, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.289337158203125, \"count\": 1, \"min\": 8.289337158203125, \"max\": 8.289337158203125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[0] avg_epoch_loss=6.091578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=6.091578483581543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[5] avg_epoch_loss=5.865063\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=5.865063031514485\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [5]#011Speed: 1665.83 samples/sec#011loss=5.865063\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[10] avg_epoch_loss=6.088316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=6.356219291687012\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [10]#011Speed: 1063.56 samples/sec#011loss=6.356219\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[15] avg_epoch_loss=6.074896\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=6.0453706741333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [15]#011Speed: 1990.05 samples/sec#011loss=6.045371\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[20] avg_epoch_loss=6.102565\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=6.191105937957763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [20]#011Speed: 1017.04 samples/sec#011loss=6.191106\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[25] avg_epoch_loss=5.992117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=5.528237438201904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [25]#011Speed: 1926.92 samples/sec#011loss=5.528237\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[30] avg_epoch_loss=6.010829\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=6.108132839202881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [30]#011Speed: 1090.28 samples/sec#011loss=6.108133\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch[35] avg_epoch_loss=5.984539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=5.821539306640625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:06 INFO 140667699287680] Epoch[2] Batch [35]#011Speed: 1655.56 samples/sec#011loss=5.821539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[40] avg_epoch_loss=5.939303\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=5.613603496551514\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [40]#011Speed: 1051.27 samples/sec#011loss=5.613603\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[45] avg_epoch_loss=5.958915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=6.119729328155517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [45]#011Speed: 1784.18 samples/sec#011loss=6.119729\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[50] avg_epoch_loss=5.959609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=5.965994834899902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [50]#011Speed: 1086.80 samples/sec#011loss=5.965995\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[55] avg_epoch_loss=5.968236\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=6.056231307983398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [55]#011Speed: 1746.75 samples/sec#011loss=6.056231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[60] avg_epoch_loss=5.973670\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=6.034538745880127\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [60]#011Speed: 1065.75 samples/sec#011loss=6.034539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[65] avg_epoch_loss=5.965363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=5.864007472991943\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [65]#011Speed: 1866.41 samples/sec#011loss=5.864007\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[70] avg_epoch_loss=5.967744\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=5.9991758346557615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [70]#011Speed: 1051.01 samples/sec#011loss=5.999176\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch[75] avg_epoch_loss=5.984273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=6.218985080718994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:07 INFO 140667699287680] Epoch[2] Batch [75]#011Speed: 1751.85 samples/sec#011loss=6.218985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[80] avg_epoch_loss=5.976966\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=5.865905284881592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [80]#011Speed: 1105.31 samples/sec#011loss=5.865905\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[85] avg_epoch_loss=6.003499\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=6.433333492279052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [85]#011Speed: 1931.65 samples/sec#011loss=6.433333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[90] avg_epoch_loss=5.979374\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=5.564427757263184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [90]#011Speed: 1035.14 samples/sec#011loss=5.564428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[95] avg_epoch_loss=5.976233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=5.919055366516114\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [95]#011Speed: 1928.11 samples/sec#011loss=5.919055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[100] avg_epoch_loss=5.969260\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=5.8353852272033695\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [100]#011Speed: 1057.05 samples/sec#011loss=5.835385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[105] avg_epoch_loss=5.975117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=6.093424510955811\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [105]#011Speed: 1955.96 samples/sec#011loss=6.093425\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[110] avg_epoch_loss=5.976192\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=5.998979949951172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [110]#011Speed: 1032.24 samples/sec#011loss=5.998980\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch[115] avg_epoch_loss=5.969805\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=5.8280257225036625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:08 INFO 140667699287680] Epoch[2] Batch [115]#011Speed: 1925.77 samples/sec#011loss=5.828026\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[120] avg_epoch_loss=5.969410\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=5.960231971740723\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [120]#011Speed: 1061.73 samples/sec#011loss=5.960232\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[125] avg_epoch_loss=5.978628\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=6.201711654663086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [125]#011Speed: 1960.41 samples/sec#011loss=6.201712\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[130] avg_epoch_loss=5.974964\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=5.882617092132568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [130]#011Speed: 1100.37 samples/sec#011loss=5.882617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[135] avg_epoch_loss=5.974661\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=5.966738319396972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [135]#011Speed: 1751.03 samples/sec#011loss=5.966738\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[140] avg_epoch_loss=5.967764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=5.780148220062256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [140]#011Speed: 987.20 samples/sec#011loss=5.780148\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[145] avg_epoch_loss=5.968698\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=5.995044994354248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [145]#011Speed: 1718.11 samples/sec#011loss=5.995045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[150] avg_epoch_loss=5.972198\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=6.074387741088867\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [150]#011Speed: 1052.07 samples/sec#011loss=6.074388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[155] avg_epoch_loss=5.974381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=6.040324020385742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [155]#011Speed: 1828.61 samples/sec#011loss=6.040324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch[160] avg_epoch_loss=5.972316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=5.907898902893066\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:09 INFO 140667699287680] Epoch[2] Batch [160]#011Speed: 1063.33 samples/sec#011loss=5.907899\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[165] avg_epoch_loss=5.974033\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=6.0292926788330075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [165]#011Speed: 1926.38 samples/sec#011loss=6.029293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[170] avg_epoch_loss=5.971024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=5.871145343780517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [170]#011Speed: 1089.48 samples/sec#011loss=5.871145\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[175] avg_epoch_loss=5.958615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=5.5342333793640135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [175]#011Speed: 1904.48 samples/sec#011loss=5.534233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[180] avg_epoch_loss=5.954271\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=5.801359081268311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [180]#011Speed: 1070.28 samples/sec#011loss=5.801359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[185] avg_epoch_loss=5.957355\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=6.068994045257568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [185]#011Speed: 1824.25 samples/sec#011loss=6.068994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[190] avg_epoch_loss=5.959080\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=6.02324333190918\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [190]#011Speed: 1128.24 samples/sec#011loss=6.023243\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[195] avg_epoch_loss=5.963433\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=6.129736995697021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [195]#011Speed: 1869.55 samples/sec#011loss=6.129737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[200] avg_epoch_loss=5.957895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=5.740774345397949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [200]#011Speed: 1135.66 samples/sec#011loss=5.740774\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch[205] avg_epoch_loss=5.961570\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=6.109310913085937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:10 INFO 140667699287680] Epoch[2] Batch [205]#011Speed: 1883.92 samples/sec#011loss=6.109311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[210] avg_epoch_loss=5.948393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=5.405503463745117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [210]#011Speed: 1168.66 samples/sec#011loss=5.405503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[215] avg_epoch_loss=5.955439\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=6.252783107757568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [215]#011Speed: 1881.98 samples/sec#011loss=6.252783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[220] avg_epoch_loss=5.948052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=5.628955268859864\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [220]#011Speed: 1102.03 samples/sec#011loss=5.628955\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[225] avg_epoch_loss=5.941930\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=5.671301174163818\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [225]#011Speed: 1785.83 samples/sec#011loss=5.671301\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[230] avg_epoch_loss=5.931672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=5.468011951446533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [230]#011Speed: 977.39 samples/sec#011loss=5.468012\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[235] avg_epoch_loss=5.929517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=5.829989719390869\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [235]#011Speed: 1891.39 samples/sec#011loss=5.829990\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[240] avg_epoch_loss=5.924913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=5.707566165924073\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [240]#011Speed: 935.58 samples/sec#011loss=5.707566\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch[245] avg_epoch_loss=5.928757\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=6.1140800476074215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:11 INFO 140667699287680] Epoch[2] Batch [245]#011Speed: 1820.90 samples/sec#011loss=6.114080\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[250] avg_epoch_loss=5.924989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=5.739556312561035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [250]#011Speed: 1040.25 samples/sec#011loss=5.739556\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[255] avg_epoch_loss=5.922816\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=5.813762283325195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [255]#011Speed: 1957.46 samples/sec#011loss=5.813762\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[260] avg_epoch_loss=5.917420\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=5.641131401062012\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [260]#011Speed: 1080.77 samples/sec#011loss=5.641131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[265] avg_epoch_loss=5.918027\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=5.949721050262451\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [265]#011Speed: 1936.70 samples/sec#011loss=5.949721\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[270] avg_epoch_loss=5.912719\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=270 train loss <loss>=5.630342674255371\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [270]#011Speed: 1086.63 samples/sec#011loss=5.630343\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[275] avg_epoch_loss=5.910996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=275 train loss <loss>=5.817586231231689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [275]#011Speed: 1910.06 samples/sec#011loss=5.817586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[280] avg_epoch_loss=5.907669\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=280 train loss <loss>=5.724018478393555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [280]#011Speed: 1102.43 samples/sec#011loss=5.724018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch[285] avg_epoch_loss=5.900051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=285 train loss <loss>=5.471949100494385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:12 INFO 140667699287680] Epoch[2] Batch [285]#011Speed: 1898.31 samples/sec#011loss=5.471949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[290] avg_epoch_loss=5.900316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=290 train loss <loss>=5.9154582023620605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [290]#011Speed: 1105.65 samples/sec#011loss=5.915458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[295] avg_epoch_loss=5.897333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=295 train loss <loss>=5.723725128173828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [295]#011Speed: 1902.57 samples/sec#011loss=5.723725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[300] avg_epoch_loss=5.892321\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=300 train loss <loss>=5.595600223541259\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [300]#011Speed: 1123.74 samples/sec#011loss=5.595600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[305] avg_epoch_loss=5.892250\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=305 train loss <loss>=5.887985897064209\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [305]#011Speed: 1805.63 samples/sec#011loss=5.887986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[310] avg_epoch_loss=5.891122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=310 train loss <loss>=5.822074890136719\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [310]#011Speed: 1108.27 samples/sec#011loss=5.822075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[315] avg_epoch_loss=5.895743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=315 train loss <loss>=6.1831512451171875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [315]#011Speed: 1632.53 samples/sec#011loss=6.183151\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[320] avg_epoch_loss=5.898325\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=320 train loss <loss>=6.061538028717041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [320]#011Speed: 1058.71 samples/sec#011loss=6.061538\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[325] avg_epoch_loss=5.894612\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=325 train loss <loss>=5.656256580352784\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [325]#011Speed: 1840.44 samples/sec#011loss=5.656257\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch[330] avg_epoch_loss=5.893312\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=330 train loss <loss>=5.808560943603515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:13 INFO 140667699287680] Epoch[2] Batch [330]#011Speed: 1128.61 samples/sec#011loss=5.808561\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[335] avg_epoch_loss=5.893214\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=335 train loss <loss>=5.8867112159729\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [335]#011Speed: 1911.00 samples/sec#011loss=5.886711\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[340] avg_epoch_loss=5.889290\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=340 train loss <loss>=5.6256085395812985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [340]#011Speed: 1120.59 samples/sec#011loss=5.625609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[345] avg_epoch_loss=5.890651\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=345 train loss <loss>=5.983443927764893\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [345]#011Speed: 1771.13 samples/sec#011loss=5.983444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[350] avg_epoch_loss=5.886843\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=350 train loss <loss>=5.623335266113282\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [350]#011Speed: 1085.73 samples/sec#011loss=5.623335\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[355] avg_epoch_loss=5.890540\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=355 train loss <loss>=6.150032806396484\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [355]#011Speed: 1805.75 samples/sec#011loss=6.150033\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[360] avg_epoch_loss=5.886001\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=360 train loss <loss>=5.56286506652832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [360]#011Speed: 983.70 samples/sec#011loss=5.562865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[365] avg_epoch_loss=5.882021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=365 train loss <loss>=5.594623947143555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [365]#011Speed: 1851.92 samples/sec#011loss=5.594624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[370] avg_epoch_loss=5.886686\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=370 train loss <loss>=6.228190231323242\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [370]#011Speed: 1024.86 samples/sec#011loss=6.228190\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch[375] avg_epoch_loss=5.884415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=375 train loss <loss>=5.715923595428467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:14 INFO 140667699287680] Epoch[2] Batch [375]#011Speed: 1824.41 samples/sec#011loss=5.715924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[380] avg_epoch_loss=5.880019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=380 train loss <loss>=5.549428462982178\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [380]#011Speed: 1037.85 samples/sec#011loss=5.549428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[385] avg_epoch_loss=5.878278\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=385 train loss <loss>=5.74563684463501\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [385]#011Speed: 1897.49 samples/sec#011loss=5.745637\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[390] avg_epoch_loss=5.874646\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=390 train loss <loss>=5.594237995147705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [390]#011Speed: 1060.44 samples/sec#011loss=5.594238\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[395] avg_epoch_loss=5.874286\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=395 train loss <loss>=5.846118545532226\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [395]#011Speed: 1915.46 samples/sec#011loss=5.846119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[400] avg_epoch_loss=5.876155\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=400 train loss <loss>=6.024221420288086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [400]#011Speed: 1010.40 samples/sec#011loss=6.024221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[405] avg_epoch_loss=5.876246\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=405 train loss <loss>=5.883502960205078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [405]#011Speed: 1938.50 samples/sec#011loss=5.883503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[410] avg_epoch_loss=5.874074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=410 train loss <loss>=5.697718811035156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [410]#011Speed: 1061.49 samples/sec#011loss=5.697719\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch[415] avg_epoch_loss=5.870935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=415 train loss <loss>=5.612899684906006\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:15 INFO 140667699287680] Epoch[2] Batch [415]#011Speed: 1910.92 samples/sec#011loss=5.612900\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[420] avg_epoch_loss=5.873757\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=420 train loss <loss>=6.108588790893554\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [420]#011Speed: 1084.26 samples/sec#011loss=6.108589\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[425] avg_epoch_loss=5.872459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=425 train loss <loss>=5.763164615631103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [425]#011Speed: 1670.53 samples/sec#011loss=5.763165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[430] avg_epoch_loss=5.869218\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=430 train loss <loss>=5.593055152893067\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [430]#011Speed: 1049.57 samples/sec#011loss=5.593055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[435] avg_epoch_loss=5.870474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=435 train loss <loss>=5.978699684143066\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [435]#011Speed: 1867.40 samples/sec#011loss=5.978700\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[440] avg_epoch_loss=5.867268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=440 train loss <loss>=5.587720108032227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [440]#011Speed: 1038.73 samples/sec#011loss=5.587720\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[445] avg_epoch_loss=5.866880\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=445 train loss <loss>=5.832686805725098\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [445]#011Speed: 1849.51 samples/sec#011loss=5.832687\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[450] avg_epoch_loss=5.865740\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=450 train loss <loss>=5.7640073776245115\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [450]#011Speed: 1162.74 samples/sec#011loss=5.764007\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch[455] avg_epoch_loss=5.863446\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=455 train loss <loss>=5.656590747833252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:16 INFO 140667699287680] Epoch[2] Batch [455]#011Speed: 1846.42 samples/sec#011loss=5.656591\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[460] avg_epoch_loss=5.866118\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=460 train loss <loss>=6.10975284576416\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [460]#011Speed: 1031.83 samples/sec#011loss=6.109753\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[465] avg_epoch_loss=5.866716\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=465 train loss <loss>=5.921905899047852\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [465]#011Speed: 1860.14 samples/sec#011loss=5.921906\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[470] avg_epoch_loss=5.865221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=470 train loss <loss>=5.725901699066162\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [470]#011Speed: 1096.73 samples/sec#011loss=5.725902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[475] avg_epoch_loss=5.863447\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=475 train loss <loss>=5.696326732635498\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [475]#011Speed: 1902.94 samples/sec#011loss=5.696327\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[480] avg_epoch_loss=5.863610\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=480 train loss <loss>=5.879122161865235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [480]#011Speed: 1014.07 samples/sec#011loss=5.879122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[485] avg_epoch_loss=5.863074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=485 train loss <loss>=5.8114745140075685\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [485]#011Speed: 1724.88 samples/sec#011loss=5.811475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[490] avg_epoch_loss=5.861985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=490 train loss <loss>=5.75615234375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [490]#011Speed: 1078.44 samples/sec#011loss=5.756152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[495] avg_epoch_loss=5.860265\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=495 train loss <loss>=5.691310882568359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [495]#011Speed: 1938.95 samples/sec#011loss=5.691311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch[500] avg_epoch_loss=5.858221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=500 train loss <loss>=5.6555100440979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:17 INFO 140667699287680] Epoch[2] Batch [500]#011Speed: 1039.94 samples/sec#011loss=5.655510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[505] avg_epoch_loss=5.858550\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=505 train loss <loss>=5.891468620300293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [505]#011Speed: 1771.74 samples/sec#011loss=5.891469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[510] avg_epoch_loss=5.859937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=510 train loss <loss>=6.000361633300781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [510]#011Speed: 1058.03 samples/sec#011loss=6.000362\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[515] avg_epoch_loss=5.857489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=515 train loss <loss>=5.607228374481201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [515]#011Speed: 1947.80 samples/sec#011loss=5.607228\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[520] avg_epoch_loss=5.855977\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=520 train loss <loss>=5.69995346069336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [520]#011Speed: 1090.13 samples/sec#011loss=5.699953\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[525] avg_epoch_loss=5.854303\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=525 train loss <loss>=5.679902172088623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [525]#011Speed: 1885.68 samples/sec#011loss=5.679902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[530] avg_epoch_loss=5.853636\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=530 train loss <loss>=5.783440399169922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [530]#011Speed: 1122.11 samples/sec#011loss=5.783440\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[535] avg_epoch_loss=5.853996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=535 train loss <loss>=5.8923016548156735\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [535]#011Speed: 1955.40 samples/sec#011loss=5.892302\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch[540] avg_epoch_loss=5.854213\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=540 train loss <loss>=5.877422142028808\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:18 INFO 140667699287680] Epoch[2] Batch [540]#011Speed: 1134.12 samples/sec#011loss=5.877422\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch[545] avg_epoch_loss=5.852624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=545 train loss <loss>=5.680696964263916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch [545]#011Speed: 1828.72 samples/sec#011loss=5.680697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch[550] avg_epoch_loss=5.852525\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=550 train loss <loss>=5.841678237915039\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch [550]#011Speed: 1065.57 samples/sec#011loss=5.841678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch[555] avg_epoch_loss=5.848016\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=555 train loss <loss>=5.351187896728516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch [555]#011Speed: 1912.37 samples/sec#011loss=5.351188\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch[560] avg_epoch_loss=5.846499\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, batch=560 train loss <loss>=5.677819061279297\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[2] Batch [560]#011Speed: 1570.60 samples/sec#011loss=5.677819\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] processed a total of 18033 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989826.039607, \"EndTime\": 1620989839.389902, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13350.240468978882, \"count\": 1, \"min\": 13350.240468978882, \"max\": 13350.240468978882}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1350.7522957118406 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=2, train loss <loss>=5.848446137516211\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_b17b56c6-fea5-4ba8-b3ce-0a1eb83a87ff-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989839.3899658, \"EndTime\": 1620989839.3993394, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.879661560058594, \"count\": 1, \"min\": 8.879661560058594, \"max\": 8.879661560058594}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch[0] avg_epoch_loss=5.929477\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=5.929476737976074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch[5] avg_epoch_loss=5.764872\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=5.76487151781718\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch [5]#011Speed: 1881.68 samples/sec#011loss=5.764872\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch[10] avg_epoch_loss=5.687677\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=5.595044231414795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch [10]#011Speed: 1015.22 samples/sec#011loss=5.595044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch[15] avg_epoch_loss=5.811139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=6.082753849029541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch [15]#011Speed: 1651.05 samples/sec#011loss=6.082754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch[20] avg_epoch_loss=5.761902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=5.604346370697021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:19 INFO 140667699287680] Epoch[3] Batch [20]#011Speed: 1147.99 samples/sec#011loss=5.604346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[25] avg_epoch_loss=5.769723\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=5.802571487426758\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [25]#011Speed: 1938.90 samples/sec#011loss=5.802571\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[30] avg_epoch_loss=5.728763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=5.515767002105713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [30]#011Speed: 1113.07 samples/sec#011loss=5.515767\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[35] avg_epoch_loss=5.790273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=6.171637535095215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [35]#011Speed: 1925.79 samples/sec#011loss=6.171638\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[40] avg_epoch_loss=5.776363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=5.676210594177246\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [40]#011Speed: 1150.52 samples/sec#011loss=5.676211\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[45] avg_epoch_loss=5.762849\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=5.65203104019165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [45]#011Speed: 1743.93 samples/sec#011loss=5.652031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[50] avg_epoch_loss=5.739069\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=5.52029447555542\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [50]#011Speed: 1093.18 samples/sec#011loss=5.520294\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[55] avg_epoch_loss=5.727021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=5.60413007736206\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [55]#011Speed: 1862.29 samples/sec#011loss=5.604130\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[60] avg_epoch_loss=5.754262\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=6.059368515014649\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [60]#011Speed: 1046.13 samples/sec#011loss=6.059369\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch[65] avg_epoch_loss=5.754095\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=5.752049541473388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:20 INFO 140667699287680] Epoch[3] Batch [65]#011Speed: 1882.86 samples/sec#011loss=5.752050\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[70] avg_epoch_loss=5.758336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=5.814316749572754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [70]#011Speed: 1074.77 samples/sec#011loss=5.814317\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[75] avg_epoch_loss=5.747206\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=5.5891642570495605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [75]#011Speed: 1890.31 samples/sec#011loss=5.589164\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[80] avg_epoch_loss=5.753291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=5.845790100097656\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [80]#011Speed: 1124.86 samples/sec#011loss=5.845790\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[85] avg_epoch_loss=5.764895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=5.952880764007569\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [85]#011Speed: 1885.40 samples/sec#011loss=5.952881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[90] avg_epoch_loss=5.766715\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=5.798013973236084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [90]#011Speed: 1066.91 samples/sec#011loss=5.798014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[95] avg_epoch_loss=5.741222\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=5.277248191833496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [95]#011Speed: 1936.06 samples/sec#011loss=5.277248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[100] avg_epoch_loss=5.742973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=5.7765936851501465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [100]#011Speed: 1021.62 samples/sec#011loss=5.776594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch[105] avg_epoch_loss=5.742142\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=5.725347328186035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:21 INFO 140667699287680] Epoch[3] Batch [105]#011Speed: 1950.49 samples/sec#011loss=5.725347\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[110] avg_epoch_loss=5.732296\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=5.523576164245606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [110]#011Speed: 976.32 samples/sec#011loss=5.523576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[115] avg_epoch_loss=5.732886\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=5.7459718704223635\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [115]#011Speed: 1972.23 samples/sec#011loss=5.745972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[120] avg_epoch_loss=5.728529\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=5.627450942993164\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [120]#011Speed: 1088.04 samples/sec#011loss=5.627451\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[125] avg_epoch_loss=5.722510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=5.576855278015136\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [125]#011Speed: 1939.24 samples/sec#011loss=5.576855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[130] avg_epoch_loss=5.727682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=5.857997035980224\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [130]#011Speed: 1065.85 samples/sec#011loss=5.857997\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[135] avg_epoch_loss=5.723920\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=5.625366687774658\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [135]#011Speed: 1864.44 samples/sec#011loss=5.625367\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[140] avg_epoch_loss=5.727501\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=5.824917030334473\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [140]#011Speed: 1022.35 samples/sec#011loss=5.824917\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch[145] avg_epoch_loss=5.730228\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=5.807106018066406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:22 INFO 140667699287680] Epoch[3] Batch [145]#011Speed: 1873.78 samples/sec#011loss=5.807106\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[150] avg_epoch_loss=5.734471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=5.858373832702637\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [150]#011Speed: 1068.99 samples/sec#011loss=5.858374\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[155] avg_epoch_loss=5.738797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=5.86944351196289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [155]#011Speed: 1918.85 samples/sec#011loss=5.869444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[160] avg_epoch_loss=5.737732\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=5.704508209228516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [160]#011Speed: 1117.57 samples/sec#011loss=5.704508\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[165] avg_epoch_loss=5.733862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=5.6092558860778805\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [165]#011Speed: 1669.49 samples/sec#011loss=5.609256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[170] avg_epoch_loss=5.734608\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=5.759353256225586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [170]#011Speed: 1053.34 samples/sec#011loss=5.759353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[175] avg_epoch_loss=5.735043\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=5.749940872192383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [175]#011Speed: 1856.98 samples/sec#011loss=5.749941\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[180] avg_epoch_loss=5.733316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=5.672510719299316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [180]#011Speed: 1141.61 samples/sec#011loss=5.672511\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[185] avg_epoch_loss=5.731032\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=5.6483758926391605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [185]#011Speed: 1675.14 samples/sec#011loss=5.648376\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch[190] avg_epoch_loss=5.731461\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=5.74739818572998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:23 INFO 140667699287680] Epoch[3] Batch [190]#011Speed: 1137.64 samples/sec#011loss=5.747398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[195] avg_epoch_loss=5.734050\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=5.832942199707031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [195]#011Speed: 1893.40 samples/sec#011loss=5.832942\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[200] avg_epoch_loss=5.729766\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=5.561839771270752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [200]#011Speed: 1118.87 samples/sec#011loss=5.561840\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[205] avg_epoch_loss=5.728023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=5.657971954345703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [205]#011Speed: 1946.82 samples/sec#011loss=5.657972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[210] avg_epoch_loss=5.727932\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=5.7241902351379395\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [210]#011Speed: 1023.94 samples/sec#011loss=5.724190\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[215] avg_epoch_loss=5.731434\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=5.879202175140381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [215]#011Speed: 1824.33 samples/sec#011loss=5.879202\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[220] avg_epoch_loss=5.725333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=5.461759471893311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [220]#011Speed: 959.41 samples/sec#011loss=5.461759\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[225] avg_epoch_loss=5.725342\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=5.7257240295410154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [225]#011Speed: 2007.43 samples/sec#011loss=5.725724\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[230] avg_epoch_loss=5.720796\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=5.515345764160156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [230]#011Speed: 963.33 samples/sec#011loss=5.515346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch[235] avg_epoch_loss=5.721543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=5.7560652732849125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:24 INFO 140667699287680] Epoch[3] Batch [235]#011Speed: 1983.06 samples/sec#011loss=5.756065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[240] avg_epoch_loss=5.715380\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=5.424480152130127\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [240]#011Speed: 1054.33 samples/sec#011loss=5.424480\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[245] avg_epoch_loss=5.720892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=5.986580276489258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [245]#011Speed: 1701.84 samples/sec#011loss=5.986580\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[250] avg_epoch_loss=5.722595\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=5.806358337402344\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [250]#011Speed: 1055.18 samples/sec#011loss=5.806358\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[255] avg_epoch_loss=5.725040\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=5.847793006896973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [255]#011Speed: 1949.81 samples/sec#011loss=5.847793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[260] avg_epoch_loss=5.721973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=5.564935779571533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [260]#011Speed: 1090.42 samples/sec#011loss=5.564936\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[265] avg_epoch_loss=5.720915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=5.665703582763672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [265]#011Speed: 1795.41 samples/sec#011loss=5.665704\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[270] avg_epoch_loss=5.720002\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=270 train loss <loss>=5.671404075622559\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [270]#011Speed: 1099.18 samples/sec#011loss=5.671404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch[275] avg_epoch_loss=5.718725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=275 train loss <loss>=5.649504089355469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:25 INFO 140667699287680] Epoch[3] Batch [275]#011Speed: 1920.25 samples/sec#011loss=5.649504\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[280] avg_epoch_loss=5.717000\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=280 train loss <loss>=5.621788692474365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [280]#011Speed: 1050.02 samples/sec#011loss=5.621789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[285] avg_epoch_loss=5.716049\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=285 train loss <loss>=5.662596321105957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [285]#011Speed: 1894.37 samples/sec#011loss=5.662596\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[290] avg_epoch_loss=5.711851\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=290 train loss <loss>=5.471749973297119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [290]#011Speed: 1130.05 samples/sec#011loss=5.471750\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[295] avg_epoch_loss=5.709649\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=295 train loss <loss>=5.5814868927001955\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [295]#011Speed: 1683.06 samples/sec#011loss=5.581487\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[300] avg_epoch_loss=5.708424\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=300 train loss <loss>=5.635881328582764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [300]#011Speed: 1115.90 samples/sec#011loss=5.635881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[305] avg_epoch_loss=5.715120\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=305 train loss <loss>=6.118242359161377\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [305]#011Speed: 1606.32 samples/sec#011loss=6.118242\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[310] avg_epoch_loss=5.716743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=310 train loss <loss>=5.816084194183349\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [310]#011Speed: 1097.86 samples/sec#011loss=5.816084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch[315] avg_epoch_loss=5.714129\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=315 train loss <loss>=5.551543712615967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:26 INFO 140667699287680] Epoch[3] Batch [315]#011Speed: 1861.21 samples/sec#011loss=5.551544\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[320] avg_epoch_loss=5.717134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=320 train loss <loss>=5.9070289611816404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [320]#011Speed: 1091.68 samples/sec#011loss=5.907029\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[325] avg_epoch_loss=5.712583\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=325 train loss <loss>=5.420406150817871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [325]#011Speed: 1873.12 samples/sec#011loss=5.420406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[330] avg_epoch_loss=5.710982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=330 train loss <loss>=5.60661506652832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [330]#011Speed: 1122.03 samples/sec#011loss=5.606615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[335] avg_epoch_loss=5.705927\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=335 train loss <loss>=5.37126407623291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [335]#011Speed: 1899.66 samples/sec#011loss=5.371264\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[340] avg_epoch_loss=5.705655\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=340 train loss <loss>=5.687348175048828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [340]#011Speed: 1090.00 samples/sec#011loss=5.687348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[345] avg_epoch_loss=5.702383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=345 train loss <loss>=5.479240417480469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [345]#011Speed: 1827.62 samples/sec#011loss=5.479240\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[350] avg_epoch_loss=5.701806\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=350 train loss <loss>=5.661896514892578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [350]#011Speed: 1020.68 samples/sec#011loss=5.661897\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[355] avg_epoch_loss=5.700018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=355 train loss <loss>=5.57450532913208\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [355]#011Speed: 1807.77 samples/sec#011loss=5.574505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch[360] avg_epoch_loss=5.701468\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=360 train loss <loss>=5.804678821563721\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:27 INFO 140667699287680] Epoch[3] Batch [360]#011Speed: 1021.01 samples/sec#011loss=5.804679\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[365] avg_epoch_loss=5.700263\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=365 train loss <loss>=5.613255405426026\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [365]#011Speed: 1692.51 samples/sec#011loss=5.613255\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[370] avg_epoch_loss=5.703066\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=370 train loss <loss>=5.908241939544678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [370]#011Speed: 1107.83 samples/sec#011loss=5.908242\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[375] avg_epoch_loss=5.701099\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=375 train loss <loss>=5.555177879333496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [375]#011Speed: 1939.55 samples/sec#011loss=5.555178\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[380] avg_epoch_loss=5.699598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=380 train loss <loss>=5.5867541313171385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [380]#011Speed: 1122.59 samples/sec#011loss=5.586754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[385] avg_epoch_loss=5.697226\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=385 train loss <loss>=5.516474342346191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [385]#011Speed: 1956.09 samples/sec#011loss=5.516474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[390] avg_epoch_loss=5.695019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=390 train loss <loss>=5.52465591430664\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [390]#011Speed: 1058.06 samples/sec#011loss=5.524656\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[395] avg_epoch_loss=5.694022\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=395 train loss <loss>=5.6160533905029295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [395]#011Speed: 1956.11 samples/sec#011loss=5.616053\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[400] avg_epoch_loss=5.690176\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=400 train loss <loss>=5.3855668067932125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [400]#011Speed: 1150.03 samples/sec#011loss=5.385567\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch[405] avg_epoch_loss=5.687384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=405 train loss <loss>=5.463400554656983\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:28 INFO 140667699287680] Epoch[3] Batch [405]#011Speed: 1942.82 samples/sec#011loss=5.463401\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[410] avg_epoch_loss=5.688967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=410 train loss <loss>=5.817546081542969\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [410]#011Speed: 1144.69 samples/sec#011loss=5.817546\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[415] avg_epoch_loss=5.692461\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=415 train loss <loss>=5.979666519165039\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [415]#011Speed: 1855.38 samples/sec#011loss=5.979667\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[420] avg_epoch_loss=5.695047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=420 train loss <loss>=5.910235214233398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [420]#011Speed: 1142.54 samples/sec#011loss=5.910235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[425] avg_epoch_loss=5.696267\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=425 train loss <loss>=5.7989301681518555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [425]#011Speed: 1916.83 samples/sec#011loss=5.798930\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[430] avg_epoch_loss=5.699316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=430 train loss <loss>=5.959077930450439\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [430]#011Speed: 1040.74 samples/sec#011loss=5.959078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[435] avg_epoch_loss=5.702907\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=435 train loss <loss>=6.012487697601318\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [435]#011Speed: 1721.77 samples/sec#011loss=6.012488\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[440] avg_epoch_loss=5.702680\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=440 train loss <loss>=5.682909297943115\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [440]#011Speed: 1149.68 samples/sec#011loss=5.682909\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch[445] avg_epoch_loss=5.703005\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=445 train loss <loss>=5.731633281707763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:29 INFO 140667699287680] Epoch[3] Batch [445]#011Speed: 1600.25 samples/sec#011loss=5.731633\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[450] avg_epoch_loss=5.701602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=450 train loss <loss>=5.576492881774902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [450]#011Speed: 1017.18 samples/sec#011loss=5.576493\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[455] avg_epoch_loss=5.705531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=455 train loss <loss>=6.059895992279053\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [455]#011Speed: 1874.40 samples/sec#011loss=6.059896\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[460] avg_epoch_loss=5.704469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=460 train loss <loss>=5.607651805877685\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [460]#011Speed: 1073.88 samples/sec#011loss=5.607652\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[465] avg_epoch_loss=5.703626\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=465 train loss <loss>=5.625843334197998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [465]#011Speed: 1922.20 samples/sec#011loss=5.625843\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[470] avg_epoch_loss=5.703288\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=470 train loss <loss>=5.67182559967041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [470]#011Speed: 1069.74 samples/sec#011loss=5.671826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[475] avg_epoch_loss=5.702385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=475 train loss <loss>=5.617269611358642\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [475]#011Speed: 1957.42 samples/sec#011loss=5.617270\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[480] avg_epoch_loss=5.701279\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=480 train loss <loss>=5.596018981933594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [480]#011Speed: 1046.76 samples/sec#011loss=5.596019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch[485] avg_epoch_loss=5.701952\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=485 train loss <loss>=5.766745376586914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:30 INFO 140667699287680] Epoch[3] Batch [485]#011Speed: 1849.29 samples/sec#011loss=5.766745\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[490] avg_epoch_loss=5.701580\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=490 train loss <loss>=5.665392208099365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [490]#011Speed: 1078.97 samples/sec#011loss=5.665392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[495] avg_epoch_loss=5.701465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=495 train loss <loss>=5.690115642547608\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [495]#011Speed: 1929.38 samples/sec#011loss=5.690116\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[500] avg_epoch_loss=5.700248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=500 train loss <loss>=5.579578399658203\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [500]#011Speed: 1112.39 samples/sec#011loss=5.579578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[505] avg_epoch_loss=5.700635\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=505 train loss <loss>=5.739428329467773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [505]#011Speed: 1695.71 samples/sec#011loss=5.739428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[510] avg_epoch_loss=5.700862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=510 train loss <loss>=5.7237653732299805\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [510]#011Speed: 1111.83 samples/sec#011loss=5.723765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[515] avg_epoch_loss=5.699183\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=515 train loss <loss>=5.527599143981933\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [515]#011Speed: 1959.08 samples/sec#011loss=5.527599\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[520] avg_epoch_loss=5.696996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=520 train loss <loss>=5.471330070495606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [520]#011Speed: 1059.69 samples/sec#011loss=5.471330\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[525] avg_epoch_loss=5.694572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=525 train loss <loss>=5.442042541503906\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [525]#011Speed: 1871.81 samples/sec#011loss=5.442043\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch[530] avg_epoch_loss=5.692970\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=530 train loss <loss>=5.524367618560791\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:31 INFO 140667699287680] Epoch[3] Batch [530]#011Speed: 945.73 samples/sec#011loss=5.524368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[3] Batch[535] avg_epoch_loss=5.694557\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=535 train loss <loss>=5.863164806365967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[3] Batch [535]#011Speed: 1921.66 samples/sec#011loss=5.863165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[3] Batch[540] avg_epoch_loss=5.695491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=540 train loss <loss>=5.795598030090332\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[3] Batch [540]#011Speed: 1184.34 samples/sec#011loss=5.795598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[3] Batch[545] avg_epoch_loss=5.692955\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, batch=545 train loss <loss>=5.418545055389404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[3] Batch [545]#011Speed: 1714.72 samples/sec#011loss=5.418545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] processed a total of 17544 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989839.3994038, \"EndTime\": 1620989852.3236752, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12924.205780029297, \"count\": 1, \"min\": 12924.205780029297, \"max\": 12924.205780029297}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1357.4428858558315 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=3, train loss <loss>=5.692730022041307\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_cea3e386-52b8-4226-89e6-0f64e239eed8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989852.3237386, \"EndTime\": 1620989852.3334854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.393692016601562, \"count\": 1, \"min\": 9.393692016601562, \"max\": 9.393692016601562}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch[0] avg_epoch_loss=5.901640\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=5.90164041519165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch[5] avg_epoch_loss=5.459306\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=5.459305763244629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch [5]#011Speed: 1831.31 samples/sec#011loss=5.459306\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch[10] avg_epoch_loss=5.509229\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=5.56913652420044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch [10]#011Speed: 1090.71 samples/sec#011loss=5.569137\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch[15] avg_epoch_loss=5.541746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=5.61328535079956\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch [15]#011Speed: 1799.13 samples/sec#011loss=5.613285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch[20] avg_epoch_loss=5.536140\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=5.518199634552002\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch [20]#011Speed: 1093.87 samples/sec#011loss=5.518200\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch[25] avg_epoch_loss=5.533510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=5.5224651336669925\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:32 INFO 140667699287680] Epoch[4] Batch [25]#011Speed: 1800.86 samples/sec#011loss=5.522465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[30] avg_epoch_loss=5.593139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=5.903209114074707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [30]#011Speed: 1102.61 samples/sec#011loss=5.903209\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[35] avg_epoch_loss=5.608751\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=5.705544185638428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [35]#011Speed: 1902.60 samples/sec#011loss=5.705544\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[40] avg_epoch_loss=5.610780\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=5.625388431549072\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [40]#011Speed: 1029.06 samples/sec#011loss=5.625388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[45] avg_epoch_loss=5.619084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=5.68717737197876\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [45]#011Speed: 1908.88 samples/sec#011loss=5.687177\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[50] avg_epoch_loss=5.619728\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=5.625656986236573\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [50]#011Speed: 1059.66 samples/sec#011loss=5.625657\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[55] avg_epoch_loss=5.631611\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=5.752807998657227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [55]#011Speed: 1886.45 samples/sec#011loss=5.752808\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[60] avg_epoch_loss=5.627704\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=5.583953762054444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [60]#011Speed: 1061.15 samples/sec#011loss=5.583954\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch[65] avg_epoch_loss=5.635085\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=5.725135421752929\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:33 INFO 140667699287680] Epoch[4] Batch [65]#011Speed: 1875.56 samples/sec#011loss=5.725135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[70] avg_epoch_loss=5.652095\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=5.876629066467285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [70]#011Speed: 1059.26 samples/sec#011loss=5.876629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[75] avg_epoch_loss=5.653347\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=5.671113109588623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [75]#011Speed: 1928.93 samples/sec#011loss=5.671113\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[80] avg_epoch_loss=5.663847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=5.8234460830688475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [80]#011Speed: 1123.13 samples/sec#011loss=5.823446\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[85] avg_epoch_loss=5.676093\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=5.874478912353515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [85]#011Speed: 1920.88 samples/sec#011loss=5.874479\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[90] avg_epoch_loss=5.666492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=5.501367664337158\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [90]#011Speed: 1136.30 samples/sec#011loss=5.501368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[95] avg_epoch_loss=5.655739\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=5.460032653808594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [95]#011Speed: 1938.59 samples/sec#011loss=5.460033\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[100] avg_epoch_loss=5.646043\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=5.459865951538086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [100]#011Speed: 1009.29 samples/sec#011loss=5.459866\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch[105] avg_epoch_loss=5.639357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=5.50429859161377\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:34 INFO 140667699287680] Epoch[4] Batch [105]#011Speed: 1733.49 samples/sec#011loss=5.504299\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[110] avg_epoch_loss=5.644040\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=5.743332004547119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [110]#011Speed: 988.28 samples/sec#011loss=5.743332\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[115] avg_epoch_loss=5.654635\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=5.889845371246338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [115]#011Speed: 1591.33 samples/sec#011loss=5.889845\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[120] avg_epoch_loss=5.659492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=5.772165966033936\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [120]#011Speed: 970.95 samples/sec#011loss=5.772166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[125] avg_epoch_loss=5.653589\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=5.51073694229126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [125]#011Speed: 1617.56 samples/sec#011loss=5.510737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[130] avg_epoch_loss=5.651410\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=5.59650239944458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [130]#011Speed: 983.98 samples/sec#011loss=5.596502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[135] avg_epoch_loss=5.647440\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=5.5434175491333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [135]#011Speed: 1679.78 samples/sec#011loss=5.543418\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[140] avg_epoch_loss=5.643107\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=5.525252151489258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [140]#011Speed: 1038.59 samples/sec#011loss=5.525252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch[145] avg_epoch_loss=5.634536\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=5.392830848693848\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:35 INFO 140667699287680] Epoch[4] Batch [145]#011Speed: 1906.44 samples/sec#011loss=5.392831\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[150] avg_epoch_loss=5.640393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=5.81142406463623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [150]#011Speed: 1074.70 samples/sec#011loss=5.811424\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[155] avg_epoch_loss=5.640414\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=5.641036605834961\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [155]#011Speed: 1697.98 samples/sec#011loss=5.641037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[160] avg_epoch_loss=5.646295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=5.829793167114258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [160]#011Speed: 1092.49 samples/sec#011loss=5.829793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[165] avg_epoch_loss=5.643921\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=5.5674903869628904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [165]#011Speed: 1736.49 samples/sec#011loss=5.567490\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[170] avg_epoch_loss=5.641330\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=5.555308723449707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [170]#011Speed: 1006.71 samples/sec#011loss=5.555309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[175] avg_epoch_loss=5.641392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=5.643498706817627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [175]#011Speed: 1755.30 samples/sec#011loss=5.643499\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[180] avg_epoch_loss=5.642516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=5.682075786590576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [180]#011Speed: 1035.79 samples/sec#011loss=5.682076\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch[185] avg_epoch_loss=5.645653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=5.759220886230469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:36 INFO 140667699287680] Epoch[4] Batch [185]#011Speed: 1712.84 samples/sec#011loss=5.759221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[190] avg_epoch_loss=5.643736\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=5.572405910491943\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [190]#011Speed: 1064.61 samples/sec#011loss=5.572406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[195] avg_epoch_loss=5.646764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=5.762443542480469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [195]#011Speed: 1856.33 samples/sec#011loss=5.762444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[200] avg_epoch_loss=5.649682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=5.764058303833008\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [200]#011Speed: 1150.29 samples/sec#011loss=5.764058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[205] avg_epoch_loss=5.647068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=5.5420208930969235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [205]#011Speed: 1952.84 samples/sec#011loss=5.542021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[210] avg_epoch_loss=5.648736\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=5.717420291900635\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [210]#011Speed: 1105.42 samples/sec#011loss=5.717420\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[215] avg_epoch_loss=5.646989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=5.573267078399658\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [215]#011Speed: 1922.36 samples/sec#011loss=5.573267\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[220] avg_epoch_loss=5.644500\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=5.536989498138428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [220]#011Speed: 1088.26 samples/sec#011loss=5.536989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[225] avg_epoch_loss=5.646466\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=5.733366680145264\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [225]#011Speed: 1850.75 samples/sec#011loss=5.733367\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch[230] avg_epoch_loss=5.639995\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=5.347525978088379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:37 INFO 140667699287680] Epoch[4] Batch [230]#011Speed: 1098.37 samples/sec#011loss=5.347526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[235] avg_epoch_loss=5.639348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=5.609449291229248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [235]#011Speed: 1902.49 samples/sec#011loss=5.609449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[240] avg_epoch_loss=5.634987\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=5.429154586791992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [240]#011Speed: 1091.40 samples/sec#011loss=5.429155\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[245] avg_epoch_loss=5.637574\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=5.762238311767578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [245]#011Speed: 1740.47 samples/sec#011loss=5.762238\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[250] avg_epoch_loss=5.636384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=5.577851581573486\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [250]#011Speed: 1106.50 samples/sec#011loss=5.577852\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[255] avg_epoch_loss=5.636483\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=5.641440582275391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [255]#011Speed: 1678.00 samples/sec#011loss=5.641441\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[260] avg_epoch_loss=5.639196\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=5.778102970123291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [260]#011Speed: 1122.14 samples/sec#011loss=5.778103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[265] avg_epoch_loss=5.636491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=5.495299434661865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [265]#011Speed: 1944.87 samples/sec#011loss=5.495299\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[270] avg_epoch_loss=5.632881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=270 train loss <loss>=5.4408472061157225\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [270]#011Speed: 1017.42 samples/sec#011loss=5.440847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch[275] avg_epoch_loss=5.630025\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=275 train loss <loss>=5.475200176239014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:38 INFO 140667699287680] Epoch[4] Batch [275]#011Speed: 1873.36 samples/sec#011loss=5.475200\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[280] avg_epoch_loss=5.627795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=280 train loss <loss>=5.50468168258667\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [280]#011Speed: 1060.84 samples/sec#011loss=5.504682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[285] avg_epoch_loss=5.618319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=285 train loss <loss>=5.085807228088379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [285]#011Speed: 1849.59 samples/sec#011loss=5.085807\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[290] avg_epoch_loss=5.613161\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=290 train loss <loss>=5.318115711212158\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [290]#011Speed: 1153.61 samples/sec#011loss=5.318116\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[295] avg_epoch_loss=5.610082\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=295 train loss <loss>=5.430859565734863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [295]#011Speed: 1867.35 samples/sec#011loss=5.430860\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[300] avg_epoch_loss=5.607779\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=300 train loss <loss>=5.47143325805664\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [300]#011Speed: 1142.76 samples/sec#011loss=5.471433\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[305] avg_epoch_loss=5.610044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=305 train loss <loss>=5.74645299911499\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [305]#011Speed: 1897.93 samples/sec#011loss=5.746453\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[310] avg_epoch_loss=5.609188\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=310 train loss <loss>=5.5567545890808105\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [310]#011Speed: 1120.62 samples/sec#011loss=5.556755\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch[315] avg_epoch_loss=5.610158\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=315 train loss <loss>=5.670480537414551\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:39 INFO 140667699287680] Epoch[4] Batch [315]#011Speed: 1863.31 samples/sec#011loss=5.670481\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[320] avg_epoch_loss=5.613148\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=320 train loss <loss>=5.802135562896728\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [320]#011Speed: 1044.02 samples/sec#011loss=5.802136\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[325] avg_epoch_loss=5.611095\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=325 train loss <loss>=5.479302406311035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [325]#011Speed: 1814.80 samples/sec#011loss=5.479302\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[330] avg_epoch_loss=5.608817\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=330 train loss <loss>=5.460316371917725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [330]#011Speed: 951.45 samples/sec#011loss=5.460316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[335] avg_epoch_loss=5.611415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=335 train loss <loss>=5.783371639251709\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [335]#011Speed: 1906.10 samples/sec#011loss=5.783372\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[340] avg_epoch_loss=5.609837\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=340 train loss <loss>=5.503772640228272\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [340]#011Speed: 1099.17 samples/sec#011loss=5.503773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[345] avg_epoch_loss=5.609010\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=345 train loss <loss>=5.552622318267822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [345]#011Speed: 1853.33 samples/sec#011loss=5.552622\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[350] avg_epoch_loss=5.607253\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=350 train loss <loss>=5.485698890686035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [350]#011Speed: 997.37 samples/sec#011loss=5.485699\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[355] avg_epoch_loss=5.605378\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=355 train loss <loss>=5.473737335205078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [355]#011Speed: 1813.23 samples/sec#011loss=5.473737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch[360] avg_epoch_loss=5.605640\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=360 train loss <loss>=5.624284076690674\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:40 INFO 140667699287680] Epoch[4] Batch [360]#011Speed: 1029.51 samples/sec#011loss=5.624284\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[365] avg_epoch_loss=5.605586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=365 train loss <loss>=5.601667690277099\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [365]#011Speed: 1993.45 samples/sec#011loss=5.601668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[370] avg_epoch_loss=5.606031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=370 train loss <loss>=5.638615512847901\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [370]#011Speed: 1093.99 samples/sec#011loss=5.638616\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[375] avg_epoch_loss=5.610859\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=375 train loss <loss>=5.969089317321777\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [375]#011Speed: 1933.43 samples/sec#011loss=5.969089\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[380] avg_epoch_loss=5.609729\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=380 train loss <loss>=5.524789237976075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [380]#011Speed: 1067.73 samples/sec#011loss=5.524789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[385] avg_epoch_loss=5.614606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=385 train loss <loss>=5.986226654052734\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [385]#011Speed: 1795.05 samples/sec#011loss=5.986227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[390] avg_epoch_loss=5.613431\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=390 train loss <loss>=5.522707176208496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [390]#011Speed: 1106.19 samples/sec#011loss=5.522707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[395] avg_epoch_loss=5.613180\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=395 train loss <loss>=5.593561458587646\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [395]#011Speed: 1804.30 samples/sec#011loss=5.593561\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch[400] avg_epoch_loss=5.613387\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=400 train loss <loss>=5.629767513275146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:41 INFO 140667699287680] Epoch[4] Batch [400]#011Speed: 1096.84 samples/sec#011loss=5.629768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[405] avg_epoch_loss=5.615163\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=405 train loss <loss>=5.757586097717285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [405]#011Speed: 1867.96 samples/sec#011loss=5.757586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[410] avg_epoch_loss=5.614922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=410 train loss <loss>=5.595352554321289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [410]#011Speed: 1144.48 samples/sec#011loss=5.595353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[415] avg_epoch_loss=5.616336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=415 train loss <loss>=5.732559776306152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [415]#011Speed: 1921.34 samples/sec#011loss=5.732560\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[420] avg_epoch_loss=5.612507\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=420 train loss <loss>=5.293975162506103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [420]#011Speed: 1112.36 samples/sec#011loss=5.293975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[425] avg_epoch_loss=5.611834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=425 train loss <loss>=5.555171203613281\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [425]#011Speed: 1759.14 samples/sec#011loss=5.555171\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[430] avg_epoch_loss=5.610997\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=430 train loss <loss>=5.539633464813233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [430]#011Speed: 1044.22 samples/sec#011loss=5.539633\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[435] avg_epoch_loss=5.608872\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=435 train loss <loss>=5.425750255584717\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [435]#011Speed: 1792.94 samples/sec#011loss=5.425750\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[440] avg_epoch_loss=5.608760\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=440 train loss <loss>=5.598994445800781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [440]#011Speed: 1079.00 samples/sec#011loss=5.598994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch[445] avg_epoch_loss=5.611944\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=445 train loss <loss>=5.8927967071533205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:42 INFO 140667699287680] Epoch[4] Batch [445]#011Speed: 1769.73 samples/sec#011loss=5.892797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[450] avg_epoch_loss=5.610169\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=450 train loss <loss>=5.451831340789795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [450]#011Speed: 1123.44 samples/sec#011loss=5.451831\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[455] avg_epoch_loss=5.608845\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=455 train loss <loss>=5.489345550537109\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [455]#011Speed: 1938.05 samples/sec#011loss=5.489346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[460] avg_epoch_loss=5.608713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=460 train loss <loss>=5.596748638153076\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [460]#011Speed: 1116.38 samples/sec#011loss=5.596749\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[465] avg_epoch_loss=5.609313\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=465 train loss <loss>=5.66461820602417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [465]#011Speed: 1871.77 samples/sec#011loss=5.664618\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[470] avg_epoch_loss=5.608927\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=470 train loss <loss>=5.5729094505310055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [470]#011Speed: 1048.71 samples/sec#011loss=5.572909\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[475] avg_epoch_loss=5.607475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=475 train loss <loss>=5.470732402801514\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [475]#011Speed: 1818.68 samples/sec#011loss=5.470732\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[480] avg_epoch_loss=5.606152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=480 train loss <loss>=5.480215358734131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [480]#011Speed: 1067.04 samples/sec#011loss=5.480215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch[485] avg_epoch_loss=5.607003\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=485 train loss <loss>=5.6888175964355465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:43 INFO 140667699287680] Epoch[4] Batch [485]#011Speed: 1846.47 samples/sec#011loss=5.688818\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[490] avg_epoch_loss=5.607059\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=490 train loss <loss>=5.612539768218994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [490]#011Speed: 1021.08 samples/sec#011loss=5.612540\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[495] avg_epoch_loss=5.605252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=495 train loss <loss>=5.4277756690979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [495]#011Speed: 1888.82 samples/sec#011loss=5.427776\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[500] avg_epoch_loss=5.602813\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=500 train loss <loss>=5.3609050750732425\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [500]#011Speed: 1138.46 samples/sec#011loss=5.360905\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[505] avg_epoch_loss=5.601184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=505 train loss <loss>=5.4379504203796385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [505]#011Speed: 1961.03 samples/sec#011loss=5.437950\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[510] avg_epoch_loss=5.598778\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=510 train loss <loss>=5.3552347183227536\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [510]#011Speed: 1142.84 samples/sec#011loss=5.355235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[515] avg_epoch_loss=5.599790\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=515 train loss <loss>=5.703239250183105\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [515]#011Speed: 1849.70 samples/sec#011loss=5.703239\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[520] avg_epoch_loss=5.598544\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=520 train loss <loss>=5.470013046264649\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [520]#011Speed: 1042.13 samples/sec#011loss=5.470013\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[525] avg_epoch_loss=5.597641\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=525 train loss <loss>=5.503559494018555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [525]#011Speed: 1699.19 samples/sec#011loss=5.503559\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch[530] avg_epoch_loss=5.597258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=530 train loss <loss>=5.556970310211182\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:44 INFO 140667699287680] Epoch[4] Batch [530]#011Speed: 1085.58 samples/sec#011loss=5.556970\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[4] Batch[535] avg_epoch_loss=5.596925\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=535 train loss <loss>=5.56149320602417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[4] Batch [535]#011Speed: 1760.07 samples/sec#011loss=5.561493\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[4] Batch[540] avg_epoch_loss=5.595725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, batch=540 train loss <loss>=5.467106628417969\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[4] Batch [540]#011Speed: 1449.81 samples/sec#011loss=5.467107\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] processed a total of 17406 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989852.333542, \"EndTime\": 1620989865.2295635, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 12895.959854125977, \"count\": 1, \"min\": 12895.959854125977, \"max\": 12895.959854125977}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1349.7146648496455 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=4, train loss <loss>=5.595561363241252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_f88a1d07-3c3b-430c-991d-5fc16961c2c0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989865.2296267, \"EndTime\": 1620989865.2405357, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 10.447978973388672, \"count\": 1, \"min\": 10.447978973388672, \"max\": 10.447978973388672}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch[0] avg_epoch_loss=5.420516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=5.420516014099121\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch[5] avg_epoch_loss=5.573119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=5.573119481404622\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch [5]#011Speed: 1823.40 samples/sec#011loss=5.573119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch[10] avg_epoch_loss=5.526766\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=5.471141242980957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch [10]#011Speed: 1103.49 samples/sec#011loss=5.471141\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch[15] avg_epoch_loss=5.557278\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=5.624403762817383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch [15]#011Speed: 1793.06 samples/sec#011loss=5.624404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch[20] avg_epoch_loss=5.589603\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=5.693045234680175\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch [20]#011Speed: 1117.82 samples/sec#011loss=5.693045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch[25] avg_epoch_loss=5.611254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=5.702186203002929\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:45 INFO 140667699287680] Epoch[5] Batch [25]#011Speed: 1856.44 samples/sec#011loss=5.702186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[30] avg_epoch_loss=5.612057\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=5.616231060028076\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [30]#011Speed: 1156.62 samples/sec#011loss=5.616231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[35] avg_epoch_loss=5.601329\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=5.534814548492432\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [35]#011Speed: 1593.89 samples/sec#011loss=5.534815\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[40] avg_epoch_loss=5.604892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=5.630552101135254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [40]#011Speed: 1014.03 samples/sec#011loss=5.630552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[45] avg_epoch_loss=5.604912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=5.605070495605469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [45]#011Speed: 1814.49 samples/sec#011loss=5.605070\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[50] avg_epoch_loss=5.593541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=5.4889294624328615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [50]#011Speed: 1098.42 samples/sec#011loss=5.488929\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[55] avg_epoch_loss=5.583401\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=5.4799751281738285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [55]#011Speed: 1859.24 samples/sec#011loss=5.479975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[60] avg_epoch_loss=5.573331\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=5.460550689697266\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [60]#011Speed: 1048.87 samples/sec#011loss=5.460551\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[65] avg_epoch_loss=5.567087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=5.490909194946289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [65]#011Speed: 1765.97 samples/sec#011loss=5.490909\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch[70] avg_epoch_loss=5.577040\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=5.708413124084473\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:46 INFO 140667699287680] Epoch[5] Batch [70]#011Speed: 1090.44 samples/sec#011loss=5.708413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[75] avg_epoch_loss=5.559391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=5.308777141571045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [75]#011Speed: 1864.62 samples/sec#011loss=5.308777\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[80] avg_epoch_loss=5.565866\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=5.664289474487305\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [80]#011Speed: 1101.44 samples/sec#011loss=5.664289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[85] avg_epoch_loss=5.556609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=5.406642246246338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [85]#011Speed: 1945.71 samples/sec#011loss=5.406642\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[90] avg_epoch_loss=5.550460\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=5.444694900512696\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [90]#011Speed: 1115.69 samples/sec#011loss=5.444695\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[95] avg_epoch_loss=5.559172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=5.717737007141113\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [95]#011Speed: 1953.94 samples/sec#011loss=5.717737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[100] avg_epoch_loss=5.546855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=5.310356616973877\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [100]#011Speed: 1123.36 samples/sec#011loss=5.310357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[105] avg_epoch_loss=5.535296\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=5.301806449890137\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [105]#011Speed: 1858.90 samples/sec#011loss=5.301806\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[110] avg_epoch_loss=5.536964\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=5.572336673736572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [110]#011Speed: 1105.78 samples/sec#011loss=5.572337\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch[115] avg_epoch_loss=5.539789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=5.602488422393799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:47 INFO 140667699287680] Epoch[5] Batch [115]#011Speed: 1654.23 samples/sec#011loss=5.602488\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[120] avg_epoch_loss=5.542661\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=5.609313106536865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [120]#011Speed: 1095.90 samples/sec#011loss=5.609313\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[125] avg_epoch_loss=5.542468\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=5.537798118591309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [125]#011Speed: 1928.38 samples/sec#011loss=5.537798\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[130] avg_epoch_loss=5.552285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=5.799654388427735\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [130]#011Speed: 1089.19 samples/sec#011loss=5.799654\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[135] avg_epoch_loss=5.554671\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=5.61718635559082\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [135]#011Speed: 1898.56 samples/sec#011loss=5.617186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[140] avg_epoch_loss=5.556644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=5.610310173034668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [140]#011Speed: 1098.93 samples/sec#011loss=5.610310\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[145] avg_epoch_loss=5.554760\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=5.501622867584229\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [145]#011Speed: 1894.87 samples/sec#011loss=5.501623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[150] avg_epoch_loss=5.554939\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=5.560179996490478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [150]#011Speed: 1153.35 samples/sec#011loss=5.560180\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch[155] avg_epoch_loss=5.561192\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=5.750026416778565\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:48 INFO 140667699287680] Epoch[5] Batch [155]#011Speed: 1690.70 samples/sec#011loss=5.750026\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[160] avg_epoch_loss=5.557464\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=5.441169929504395\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [160]#011Speed: 1075.39 samples/sec#011loss=5.441170\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[165] avg_epoch_loss=5.551726\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=5.366936111450196\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [165]#011Speed: 1799.87 samples/sec#011loss=5.366936\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[170] avg_epoch_loss=5.548834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=5.45282211303711\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [170]#011Speed: 1076.13 samples/sec#011loss=5.452822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[175] avg_epoch_loss=5.540068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=5.24028902053833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [175]#011Speed: 1777.62 samples/sec#011loss=5.240289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[180] avg_epoch_loss=5.528592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=5.124615478515625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [180]#011Speed: 1083.15 samples/sec#011loss=5.124615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[185] avg_epoch_loss=5.522983\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=5.31993989944458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [185]#011Speed: 1841.72 samples/sec#011loss=5.319940\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[190] avg_epoch_loss=5.525162\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=5.606224632263183\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [190]#011Speed: 1126.66 samples/sec#011loss=5.606225\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch[195] avg_epoch_loss=5.522622\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=5.4256034851074215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:49 INFO 140667699287680] Epoch[5] Batch [195]#011Speed: 1899.67 samples/sec#011loss=5.425603\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[200] avg_epoch_loss=5.524326\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=5.591115093231201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [200]#011Speed: 1045.85 samples/sec#011loss=5.591115\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[205] avg_epoch_loss=5.520349\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=5.360476016998291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [205]#011Speed: 1908.23 samples/sec#011loss=5.360476\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[210] avg_epoch_loss=5.524245\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=5.684750080108643\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [210]#011Speed: 1033.60 samples/sec#011loss=5.684750\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[215] avg_epoch_loss=5.525429\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=5.575391006469727\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [215]#011Speed: 1760.92 samples/sec#011loss=5.575391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[220] avg_epoch_loss=5.525023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=5.507504558563232\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [220]#011Speed: 1031.23 samples/sec#011loss=5.507505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[225] avg_epoch_loss=5.523888\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=5.473726844787597\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [225]#011Speed: 1879.64 samples/sec#011loss=5.473727\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[230] avg_epoch_loss=5.525756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=5.61015739440918\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [230]#011Speed: 1068.36 samples/sec#011loss=5.610157\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[235] avg_epoch_loss=5.525996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=5.537098026275634\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [235]#011Speed: 1907.34 samples/sec#011loss=5.537098\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch[240] avg_epoch_loss=5.525174\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=5.4864051818847654\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:50 INFO 140667699287680] Epoch[5] Batch [240]#011Speed: 1097.27 samples/sec#011loss=5.486405\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[245] avg_epoch_loss=5.521018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=5.32065782546997\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [245]#011Speed: 1937.82 samples/sec#011loss=5.320658\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[250] avg_epoch_loss=5.522684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=5.604650402069092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [250]#011Speed: 1028.94 samples/sec#011loss=5.604650\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[255] avg_epoch_loss=5.523765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=5.5780510902404785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [255]#011Speed: 1911.36 samples/sec#011loss=5.578051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[260] avg_epoch_loss=5.526931\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=5.689005756378174\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [260]#011Speed: 1108.19 samples/sec#011loss=5.689006\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[265] avg_epoch_loss=5.527498\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=5.557102489471435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [265]#011Speed: 1794.27 samples/sec#011loss=5.557102\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[270] avg_epoch_loss=5.528271\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=270 train loss <loss>=5.569429969787597\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [270]#011Speed: 1079.00 samples/sec#011loss=5.569430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[275] avg_epoch_loss=5.527642\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=275 train loss <loss>=5.493511199951172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [275]#011Speed: 1879.00 samples/sec#011loss=5.493511\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[280] avg_epoch_loss=5.529846\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=280 train loss <loss>=5.651542282104492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [280]#011Speed: 1139.34 samples/sec#011loss=5.651542\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch[285] avg_epoch_loss=5.530606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=285 train loss <loss>=5.573321437835693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:51 INFO 140667699287680] Epoch[5] Batch [285]#011Speed: 1842.93 samples/sec#011loss=5.573321\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[290] avg_epoch_loss=5.531230\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=290 train loss <loss>=5.566924285888672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [290]#011Speed: 1100.77 samples/sec#011loss=5.566924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[295] avg_epoch_loss=5.532908\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=295 train loss <loss>=5.6305615425109865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [295]#011Speed: 1865.64 samples/sec#011loss=5.630562\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[300] avg_epoch_loss=5.534348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=300 train loss <loss>=5.619594287872315\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [300]#011Speed: 1142.10 samples/sec#011loss=5.619594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[305] avg_epoch_loss=5.535681\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=305 train loss <loss>=5.615933418273926\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [305]#011Speed: 1802.52 samples/sec#011loss=5.615933\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[310] avg_epoch_loss=5.534160\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=310 train loss <loss>=5.441037940979004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [310]#011Speed: 1063.62 samples/sec#011loss=5.441038\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[315] avg_epoch_loss=5.535108\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=315 train loss <loss>=5.594122123718262\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [315]#011Speed: 1965.39 samples/sec#011loss=5.594122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[320] avg_epoch_loss=5.535426\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=320 train loss <loss>=5.555514812469482\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [320]#011Speed: 1059.72 samples/sec#011loss=5.555515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch[325] avg_epoch_loss=5.536841\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=325 train loss <loss>=5.627632141113281\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:52 INFO 140667699287680] Epoch[5] Batch [325]#011Speed: 1843.58 samples/sec#011loss=5.627632\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[330] avg_epoch_loss=5.533520\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=330 train loss <loss>=5.317036914825439\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [330]#011Speed: 1004.69 samples/sec#011loss=5.317037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[335] avg_epoch_loss=5.533684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=335 train loss <loss>=5.544503688812256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [335]#011Speed: 1879.06 samples/sec#011loss=5.544504\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[340] avg_epoch_loss=5.536445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=340 train loss <loss>=5.722024440765381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [340]#011Speed: 1097.90 samples/sec#011loss=5.722024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[345] avg_epoch_loss=5.535801\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=345 train loss <loss>=5.4918396949768065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [345]#011Speed: 1735.33 samples/sec#011loss=5.491840\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[350] avg_epoch_loss=5.535291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=350 train loss <loss>=5.499990653991699\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [350]#011Speed: 1017.13 samples/sec#011loss=5.499991\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[355] avg_epoch_loss=5.535124\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=355 train loss <loss>=5.523460006713867\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [355]#011Speed: 1806.52 samples/sec#011loss=5.523460\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[360] avg_epoch_loss=5.539010\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=360 train loss <loss>=5.815684127807617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [360]#011Speed: 1072.45 samples/sec#011loss=5.815684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch[365] avg_epoch_loss=5.539134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=365 train loss <loss>=5.548086452484131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:53 INFO 140667699287680] Epoch[5] Batch [365]#011Speed: 1828.42 samples/sec#011loss=5.548086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[370] avg_epoch_loss=5.538096\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=370 train loss <loss>=5.462121963500977\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [370]#011Speed: 1097.37 samples/sec#011loss=5.462122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[375] avg_epoch_loss=5.536330\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=375 train loss <loss>=5.405267524719238\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [375]#011Speed: 1934.51 samples/sec#011loss=5.405268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[380] avg_epoch_loss=5.534121\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=380 train loss <loss>=5.367966938018799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [380]#011Speed: 1094.85 samples/sec#011loss=5.367967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[385] avg_epoch_loss=5.533935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=385 train loss <loss>=5.51977310180664\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [385]#011Speed: 1952.90 samples/sec#011loss=5.519773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[390] avg_epoch_loss=5.534170\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=390 train loss <loss>=5.552325916290283\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [390]#011Speed: 1105.55 samples/sec#011loss=5.552326\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[395] avg_epoch_loss=5.531624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=395 train loss <loss>=5.332568645477295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [395]#011Speed: 1860.93 samples/sec#011loss=5.332569\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[400] avg_epoch_loss=5.533708\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=400 train loss <loss>=5.698763847351074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [400]#011Speed: 1115.68 samples/sec#011loss=5.698764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[405] avg_epoch_loss=5.533216\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=405 train loss <loss>=5.493757534027099\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [405]#011Speed: 1852.73 samples/sec#011loss=5.493758\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch[410] avg_epoch_loss=5.535543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=410 train loss <loss>=5.72444896697998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:54 INFO 140667699287680] Epoch[5] Batch [410]#011Speed: 1138.95 samples/sec#011loss=5.724449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[415] avg_epoch_loss=5.536024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=415 train loss <loss>=5.575570106506348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [415]#011Speed: 1755.60 samples/sec#011loss=5.575570\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[420] avg_epoch_loss=5.534018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=420 train loss <loss>=5.367080783843994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [420]#011Speed: 1084.48 samples/sec#011loss=5.367081\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[425] avg_epoch_loss=5.534172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=425 train loss <loss>=5.547202396392822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [425]#011Speed: 1905.61 samples/sec#011loss=5.547202\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[430] avg_epoch_loss=5.533423\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=430 train loss <loss>=5.469601058959961\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [430]#011Speed: 1071.97 samples/sec#011loss=5.469601\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[435] avg_epoch_loss=5.533963\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=435 train loss <loss>=5.5805174827575685\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [435]#011Speed: 1531.87 samples/sec#011loss=5.580517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[440] avg_epoch_loss=5.533629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=440 train loss <loss>=5.50446310043335\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [440]#011Speed: 1044.55 samples/sec#011loss=5.504463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[445] avg_epoch_loss=5.530818\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=445 train loss <loss>=5.282878398895264\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [445]#011Speed: 1864.68 samples/sec#011loss=5.282878\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[450] avg_epoch_loss=5.528405\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=450 train loss <loss>=5.313236141204834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [450]#011Speed: 1065.52 samples/sec#011loss=5.313236\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch[455] avg_epoch_loss=5.529422\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=455 train loss <loss>=5.621140480041504\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:55 INFO 140667699287680] Epoch[5] Batch [455]#011Speed: 1806.10 samples/sec#011loss=5.621140\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[460] avg_epoch_loss=5.531678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=460 train loss <loss>=5.737380790710449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [460]#011Speed: 1118.32 samples/sec#011loss=5.737381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[465] avg_epoch_loss=5.529828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=465 train loss <loss>=5.359237289428711\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [465]#011Speed: 1850.43 samples/sec#011loss=5.359237\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[470] avg_epoch_loss=5.529329\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=470 train loss <loss>=5.4828136444091795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [470]#011Speed: 1040.82 samples/sec#011loss=5.482814\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[475] avg_epoch_loss=5.531585\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=475 train loss <loss>=5.74411973953247\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [475]#011Speed: 1802.73 samples/sec#011loss=5.744120\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[480] avg_epoch_loss=5.531854\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=480 train loss <loss>=5.557509803771973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [480]#011Speed: 1054.59 samples/sec#011loss=5.557510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[485] avg_epoch_loss=5.532430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=485 train loss <loss>=5.587861824035644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [485]#011Speed: 1681.46 samples/sec#011loss=5.587862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[490] avg_epoch_loss=5.533719\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=490 train loss <loss>=5.658981037139893\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [490]#011Speed: 1062.27 samples/sec#011loss=5.658981\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch[495] avg_epoch_loss=5.531889\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=495 train loss <loss>=5.3521472930908205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:56 INFO 140667699287680] Epoch[5] Batch [495]#011Speed: 1826.04 samples/sec#011loss=5.352147\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[500] avg_epoch_loss=5.529936\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=500 train loss <loss>=5.336201000213623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [500]#011Speed: 998.67 samples/sec#011loss=5.336201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[505] avg_epoch_loss=5.527030\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=505 train loss <loss>=5.235826110839843\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [505]#011Speed: 1802.60 samples/sec#011loss=5.235826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[510] avg_epoch_loss=5.527050\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=510 train loss <loss>=5.52909107208252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [510]#011Speed: 1085.61 samples/sec#011loss=5.529091\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[515] avg_epoch_loss=5.527581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=515 train loss <loss>=5.581888008117676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [515]#011Speed: 1885.62 samples/sec#011loss=5.581888\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[520] avg_epoch_loss=5.527436\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=520 train loss <loss>=5.512490844726562\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [520]#011Speed: 1071.01 samples/sec#011loss=5.512491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[525] avg_epoch_loss=5.527984\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=525 train loss <loss>=5.585006523132324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [525]#011Speed: 1734.93 samples/sec#011loss=5.585007\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[530] avg_epoch_loss=5.526992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=530 train loss <loss>=5.422688579559326\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [530]#011Speed: 1058.76 samples/sec#011loss=5.422689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch[535] avg_epoch_loss=5.528382\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=535 train loss <loss>=5.676035213470459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:57 INFO 140667699287680] Epoch[5] Batch [535]#011Speed: 1691.54 samples/sec#011loss=5.676035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[5] Batch[540] avg_epoch_loss=5.527515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=540 train loss <loss>=5.434509372711181\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[5] Batch [540]#011Speed: 993.55 samples/sec#011loss=5.434509\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[5] Batch[545] avg_epoch_loss=5.525231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=545 train loss <loss>=5.278133392333984\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[5] Batch [545]#011Speed: 1861.13 samples/sec#011loss=5.278133\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[5] Batch[550] avg_epoch_loss=5.524795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, batch=550 train loss <loss>=5.477161979675293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[5] Batch [550]#011Speed: 1529.58 samples/sec#011loss=5.477162\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] processed a total of 17686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989865.240601, \"EndTime\": 1620989878.291758, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13051.095247268677, \"count\": 1, \"min\": 13051.095247268677, \"max\": 13051.095247268677}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1355.1258778441072 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=5, train loss <loss>=5.523063514806047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_04942415-ed63-4081-8825-1a6091a20c4c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989878.2918193, \"EndTime\": 1620989878.3007712, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.52823257446289, \"count\": 1, \"min\": 8.52823257446289, \"max\": 8.52823257446289}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch[0] avg_epoch_loss=5.188130\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=5.1881303787231445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch[5] avg_epoch_loss=5.239321\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=5.239320675532023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch [5]#011Speed: 1943.97 samples/sec#011loss=5.239321\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch[10] avg_epoch_loss=5.318818\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=5.414213848114014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch [10]#011Speed: 1104.32 samples/sec#011loss=5.414214\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch[15] avg_epoch_loss=5.394698\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=5.56163444519043\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch [15]#011Speed: 1812.33 samples/sec#011loss=5.561634\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch[20] avg_epoch_loss=5.432601\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=5.553893184661865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch [20]#011Speed: 1103.53 samples/sec#011loss=5.553893\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch[25] avg_epoch_loss=5.435093\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=5.44555549621582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:58 INFO 140667699287680] Epoch[6] Batch [25]#011Speed: 1869.17 samples/sec#011loss=5.445555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[30] avg_epoch_loss=5.457644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=5.574908447265625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [30]#011Speed: 1062.27 samples/sec#011loss=5.574908\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[35] avg_epoch_loss=5.477235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=5.598702812194825\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [35]#011Speed: 1773.15 samples/sec#011loss=5.598703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[40] avg_epoch_loss=5.484559\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=5.537291717529297\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [40]#011Speed: 995.07 samples/sec#011loss=5.537292\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[45] avg_epoch_loss=5.471438\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=5.363844394683838\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [45]#011Speed: 1832.19 samples/sec#011loss=5.363844\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[50] avg_epoch_loss=5.475337\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=5.511208438873291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [50]#011Speed: 1076.57 samples/sec#011loss=5.511208\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[55] avg_epoch_loss=5.474630\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=5.467416667938233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [55]#011Speed: 1578.00 samples/sec#011loss=5.467417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[60] avg_epoch_loss=5.468413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=5.398783111572266\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [60]#011Speed: 1049.41 samples/sec#011loss=5.398783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch[65] avg_epoch_loss=5.484346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=5.678732681274414\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:57:59 INFO 140667699287680] Epoch[6] Batch [65]#011Speed: 1811.13 samples/sec#011loss=5.678733\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[70] avg_epoch_loss=5.472554\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=5.316892433166504\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [70]#011Speed: 1045.29 samples/sec#011loss=5.316892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[75] avg_epoch_loss=5.466180\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=5.3756755828857425\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [75]#011Speed: 1708.49 samples/sec#011loss=5.375676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[80] avg_epoch_loss=5.467118\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=5.481379985809326\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [80]#011Speed: 1006.43 samples/sec#011loss=5.481380\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[85] avg_epoch_loss=5.467373\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=5.471491432189941\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [85]#011Speed: 1601.79 samples/sec#011loss=5.471491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[90] avg_epoch_loss=5.466257\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=5.4470597267150875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [90]#011Speed: 987.87 samples/sec#011loss=5.447060\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[95] avg_epoch_loss=5.480926\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=5.747911357879639\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [95]#011Speed: 1632.70 samples/sec#011loss=5.747911\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[100] avg_epoch_loss=5.491398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=5.692465019226074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [100]#011Speed: 1091.27 samples/sec#011loss=5.692465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch[105] avg_epoch_loss=5.480316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=5.256443214416504\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:00 INFO 140667699287680] Epoch[6] Batch [105]#011Speed: 1825.05 samples/sec#011loss=5.256443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[110] avg_epoch_loss=5.474408\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=5.349160480499267\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [110]#011Speed: 1065.70 samples/sec#011loss=5.349160\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[115] avg_epoch_loss=5.470383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=5.381045532226563\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [115]#011Speed: 1821.42 samples/sec#011loss=5.381046\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[120] avg_epoch_loss=5.463795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=5.3109382629394535\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [120]#011Speed: 857.63 samples/sec#011loss=5.310938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[125] avg_epoch_loss=5.473363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=5.704921627044678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [125]#011Speed: 1533.66 samples/sec#011loss=5.704922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[130] avg_epoch_loss=5.475503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=5.529417991638184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [130]#011Speed: 920.93 samples/sec#011loss=5.529418\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[135] avg_epoch_loss=5.480557\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=5.612985038757325\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [135]#011Speed: 1769.80 samples/sec#011loss=5.612985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[140] avg_epoch_loss=5.487971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=5.689638137817383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [140]#011Speed: 1027.46 samples/sec#011loss=5.689638\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch[145] avg_epoch_loss=5.483247\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=5.350020122528076\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:01 INFO 140667699287680] Epoch[6] Batch [145]#011Speed: 1802.74 samples/sec#011loss=5.350020\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[150] avg_epoch_loss=5.485928\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=5.564195346832276\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [150]#011Speed: 1077.83 samples/sec#011loss=5.564195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[155] avg_epoch_loss=5.486114\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=5.491737174987793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [155]#011Speed: 1906.85 samples/sec#011loss=5.491737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[160] avg_epoch_loss=5.485546\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=5.467830181121826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [160]#011Speed: 1102.57 samples/sec#011loss=5.467830\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[165] avg_epoch_loss=5.488825\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=5.594425106048584\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [165]#011Speed: 1783.11 samples/sec#011loss=5.594425\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[170] avg_epoch_loss=5.482995\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=5.289430809020996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [170]#011Speed: 1092.32 samples/sec#011loss=5.289431\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[175] avg_epoch_loss=5.483333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=5.494888973236084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [175]#011Speed: 1852.81 samples/sec#011loss=5.494889\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[180] avg_epoch_loss=5.482833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=5.465231227874756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [180]#011Speed: 1022.60 samples/sec#011loss=5.465231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch[185] avg_epoch_loss=5.489862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=5.7443037033081055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:02 INFO 140667699287680] Epoch[6] Batch [185]#011Speed: 1966.10 samples/sec#011loss=5.744304\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[190] avg_epoch_loss=5.488344\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=5.431883716583252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [190]#011Speed: 1037.26 samples/sec#011loss=5.431884\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[195] avg_epoch_loss=5.488539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=5.495988273620606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [195]#011Speed: 1822.78 samples/sec#011loss=5.495988\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[200] avg_epoch_loss=5.493533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=5.689308166503906\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [200]#011Speed: 1057.83 samples/sec#011loss=5.689308\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[205] avg_epoch_loss=5.493815\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=5.505142784118652\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [205]#011Speed: 1948.48 samples/sec#011loss=5.505143\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[210] avg_epoch_loss=5.496546\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=5.609067726135254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [210]#011Speed: 1062.69 samples/sec#011loss=5.609068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[215] avg_epoch_loss=5.501847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=5.725553894042969\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [215]#011Speed: 1931.20 samples/sec#011loss=5.725554\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[220] avg_epoch_loss=5.510341\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=5.877273082733154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [220]#011Speed: 1092.02 samples/sec#011loss=5.877273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[225] avg_epoch_loss=5.510784\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=5.530340003967285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [225]#011Speed: 1612.67 samples/sec#011loss=5.530340\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch[230] avg_epoch_loss=5.506511\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=5.31341323852539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:03 INFO 140667699287680] Epoch[6] Batch [230]#011Speed: 1003.56 samples/sec#011loss=5.313413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[235] avg_epoch_loss=5.504009\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=5.388390827178955\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [235]#011Speed: 1569.93 samples/sec#011loss=5.388391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[240] avg_epoch_loss=5.501110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=5.364257907867431\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [240]#011Speed: 940.54 samples/sec#011loss=5.364258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[245] avg_epoch_loss=5.502055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=5.547608852386475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [245]#011Speed: 1890.08 samples/sec#011loss=5.547609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[250] avg_epoch_loss=5.503420\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=5.570617771148681\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [250]#011Speed: 1028.41 samples/sec#011loss=5.570618\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[255] avg_epoch_loss=5.500942\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=5.376512241363526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [255]#011Speed: 1970.30 samples/sec#011loss=5.376512\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[260] avg_epoch_loss=5.506199\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=5.775352668762207\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [260]#011Speed: 1091.25 samples/sec#011loss=5.775353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch[265] avg_epoch_loss=5.498973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=5.121809387207032\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:04 INFO 140667699287680] Epoch[6] Batch [265]#011Speed: 1640.72 samples/sec#011loss=5.121809\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[270] avg_epoch_loss=5.495119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=270 train loss <loss>=5.290086936950684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [270]#011Speed: 913.46 samples/sec#011loss=5.290087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[275] avg_epoch_loss=5.494970\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=275 train loss <loss>=5.486855983734131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [275]#011Speed: 1532.80 samples/sec#011loss=5.486856\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[280] avg_epoch_loss=5.496654\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=280 train loss <loss>=5.589614486694336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [280]#011Speed: 951.95 samples/sec#011loss=5.589614\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[285] avg_epoch_loss=5.495896\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=285 train loss <loss>=5.453322410583496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [285]#011Speed: 1601.07 samples/sec#011loss=5.453322\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[290] avg_epoch_loss=5.493344\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=290 train loss <loss>=5.3473631858825685\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [290]#011Speed: 909.51 samples/sec#011loss=5.347363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[295] avg_epoch_loss=5.498160\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=295 train loss <loss>=5.778464412689209\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [295]#011Speed: 1425.10 samples/sec#011loss=5.778464\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[300] avg_epoch_loss=5.498699\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=300 train loss <loss>=5.530577659606934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [300]#011Speed: 978.73 samples/sec#011loss=5.530578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch[305] avg_epoch_loss=5.498420\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=305 train loss <loss>=5.481636428833008\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:05 INFO 140667699287680] Epoch[6] Batch [305]#011Speed: 1536.30 samples/sec#011loss=5.481636\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[310] avg_epoch_loss=5.497152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=310 train loss <loss>=5.419524383544922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [310]#011Speed: 826.67 samples/sec#011loss=5.419524\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[315] avg_epoch_loss=5.494960\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=315 train loss <loss>=5.358631134033203\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [315]#011Speed: 1658.72 samples/sec#011loss=5.358631\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[320] avg_epoch_loss=5.491054\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=320 train loss <loss>=5.244235420227051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [320]#011Speed: 853.24 samples/sec#011loss=5.244235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[325] avg_epoch_loss=5.491034\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=325 train loss <loss>=5.489712905883789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [325]#011Speed: 1726.20 samples/sec#011loss=5.489713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[330] avg_epoch_loss=5.492979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=330 train loss <loss>=5.619783496856689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [330]#011Speed: 1005.84 samples/sec#011loss=5.619783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[335] avg_epoch_loss=5.488714\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=335 train loss <loss>=5.206371688842774\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [335]#011Speed: 1840.10 samples/sec#011loss=5.206372\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[340] avg_epoch_loss=5.489813\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=340 train loss <loss>=5.5636693954467775\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [340]#011Speed: 1036.91 samples/sec#011loss=5.563669\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch[345] avg_epoch_loss=5.488952\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=345 train loss <loss>=5.430273532867432\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:06 INFO 140667699287680] Epoch[6] Batch [345]#011Speed: 1772.01 samples/sec#011loss=5.430274\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[350] avg_epoch_loss=5.487491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=350 train loss <loss>=5.3863709449768065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [350]#011Speed: 1016.85 samples/sec#011loss=5.386371\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[355] avg_epoch_loss=5.486682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=355 train loss <loss>=5.429892826080322\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [355]#011Speed: 1992.30 samples/sec#011loss=5.429893\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[360] avg_epoch_loss=5.487425\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=360 train loss <loss>=5.540320873260498\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [360]#011Speed: 1096.23 samples/sec#011loss=5.540321\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[365] avg_epoch_loss=5.488099\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=365 train loss <loss>=5.53676290512085\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [365]#011Speed: 1720.32 samples/sec#011loss=5.536763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[370] avg_epoch_loss=5.488628\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=370 train loss <loss>=5.5273395538330075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [370]#011Speed: 1009.56 samples/sec#011loss=5.527340\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[375] avg_epoch_loss=5.486989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=375 train loss <loss>=5.365360736846924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [375]#011Speed: 1948.38 samples/sec#011loss=5.365361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[380] avg_epoch_loss=5.487042\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=380 train loss <loss>=5.491060733795166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [380]#011Speed: 1078.68 samples/sec#011loss=5.491061\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch[385] avg_epoch_loss=5.484795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=385 train loss <loss>=5.313574695587159\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:07 INFO 140667699287680] Epoch[6] Batch [385]#011Speed: 1945.92 samples/sec#011loss=5.313575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[390] avg_epoch_loss=5.488020\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=390 train loss <loss>=5.736941814422607\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [390]#011Speed: 1016.66 samples/sec#011loss=5.736942\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[395] avg_epoch_loss=5.489022\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=395 train loss <loss>=5.567411041259765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [395]#011Speed: 1907.25 samples/sec#011loss=5.567411\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[400] avg_epoch_loss=5.489810\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=400 train loss <loss>=5.552245140075684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [400]#011Speed: 1030.89 samples/sec#011loss=5.552245\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[405] avg_epoch_loss=5.490412\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=405 train loss <loss>=5.538703346252442\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [405]#011Speed: 1904.32 samples/sec#011loss=5.538703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[410] avg_epoch_loss=5.491687\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=410 train loss <loss>=5.595170879364014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [410]#011Speed: 1074.29 samples/sec#011loss=5.595171\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[415] avg_epoch_loss=5.492337\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=415 train loss <loss>=5.545784378051758\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [415]#011Speed: 1794.58 samples/sec#011loss=5.545784\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[420] avg_epoch_loss=5.493365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=420 train loss <loss>=5.578896427154541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [420]#011Speed: 1036.23 samples/sec#011loss=5.578896\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch[425] avg_epoch_loss=5.491394\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=425 train loss <loss>=5.3254210472106935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:08 INFO 140667699287680] Epoch[6] Batch [425]#011Speed: 1809.61 samples/sec#011loss=5.325421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[430] avg_epoch_loss=5.491693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=430 train loss <loss>=5.517172241210938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [430]#011Speed: 1103.66 samples/sec#011loss=5.517172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[435] avg_epoch_loss=5.490773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=435 train loss <loss>=5.411506175994873\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [435]#011Speed: 1792.32 samples/sec#011loss=5.411506\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[440] avg_epoch_loss=5.491519\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=440 train loss <loss>=5.556553077697754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [440]#011Speed: 1142.74 samples/sec#011loss=5.556553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[445] avg_epoch_loss=5.487367\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=445 train loss <loss>=5.121129894256592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [445]#011Speed: 1841.04 samples/sec#011loss=5.121130\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[450] avg_epoch_loss=5.486077\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=450 train loss <loss>=5.371068954467773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [450]#011Speed: 1052.78 samples/sec#011loss=5.371069\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[455] avg_epoch_loss=5.486085\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=455 train loss <loss>=5.486725807189941\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [455]#011Speed: 1867.38 samples/sec#011loss=5.486726\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[460] avg_epoch_loss=5.486709\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=460 train loss <loss>=5.543629455566406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [460]#011Speed: 1088.08 samples/sec#011loss=5.543629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[465] avg_epoch_loss=5.486194\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=465 train loss <loss>=5.43876428604126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [465]#011Speed: 1900.26 samples/sec#011loss=5.438764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch[470] avg_epoch_loss=5.486373\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=470 train loss <loss>=5.5029865264892575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:09 INFO 140667699287680] Epoch[6] Batch [470]#011Speed: 1130.44 samples/sec#011loss=5.502987\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[475] avg_epoch_loss=5.485592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=475 train loss <loss>=5.412072563171387\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [475]#011Speed: 1955.39 samples/sec#011loss=5.412073\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[480] avg_epoch_loss=5.485909\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=480 train loss <loss>=5.516099834442139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [480]#011Speed: 995.11 samples/sec#011loss=5.516100\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[485] avg_epoch_loss=5.486562\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=485 train loss <loss>=5.549319076538086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [485]#011Speed: 1932.88 samples/sec#011loss=5.549319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[490] avg_epoch_loss=5.486361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=490 train loss <loss>=5.466863441467285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [490]#011Speed: 1074.54 samples/sec#011loss=5.466863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[495] avg_epoch_loss=5.486995\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=495 train loss <loss>=5.54923677444458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [495]#011Speed: 1849.84 samples/sec#011loss=5.549237\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[500] avg_epoch_loss=5.484458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=500 train loss <loss>=5.232845878601074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [500]#011Speed: 989.69 samples/sec#011loss=5.232846\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[505] avg_epoch_loss=5.483489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=505 train loss <loss>=5.386380672454834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [505]#011Speed: 1872.86 samples/sec#011loss=5.386381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch[510] avg_epoch_loss=5.483135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=510 train loss <loss>=5.447332668304443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:10 INFO 140667699287680] Epoch[6] Batch [510]#011Speed: 1123.18 samples/sec#011loss=5.447333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[515] avg_epoch_loss=5.482593\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=515 train loss <loss>=5.427102279663086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [515]#011Speed: 1945.83 samples/sec#011loss=5.427102\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[520] avg_epoch_loss=5.485049\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=520 train loss <loss>=5.738528919219971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [520]#011Speed: 1099.20 samples/sec#011loss=5.738529\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[525] avg_epoch_loss=5.484549\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=525 train loss <loss>=5.432516288757324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [525]#011Speed: 1901.25 samples/sec#011loss=5.432516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[530] avg_epoch_loss=5.484971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=530 train loss <loss>=5.529356861114502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [530]#011Speed: 1119.14 samples/sec#011loss=5.529357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[535] avg_epoch_loss=5.483336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=535 train loss <loss>=5.309628582000732\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [535]#011Speed: 1887.73 samples/sec#011loss=5.309629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[540] avg_epoch_loss=5.481923\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=540 train loss <loss>=5.330483913421631\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [540]#011Speed: 1089.22 samples/sec#011loss=5.330484\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[545] avg_epoch_loss=5.483062\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=545 train loss <loss>=5.606274700164795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [545]#011Speed: 1851.57 samples/sec#011loss=5.606275\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[550] avg_epoch_loss=5.484453\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=550 train loss <loss>=5.636328411102295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [550]#011Speed: 1238.97 samples/sec#011loss=5.636328\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch[555] avg_epoch_loss=5.484894\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, batch=555 train loss <loss>=5.533586597442627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Epoch[6] Batch [555]#011Speed: 1805.77 samples/sec#011loss=5.533587\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] processed a total of 17799 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989878.300824, \"EndTime\": 1620989891.9425504, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13641.666173934937, \"count\": 1, \"min\": 13641.666173934937, \"max\": 13641.666173934937}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1304.7426783011952 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=6, train loss <loss>=5.4863324268073965\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:11 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_88e4b787-7eb3-443e-a17d-2cc380c50c04-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989891.9426231, \"EndTime\": 1620989891.9512517, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.1939697265625, \"count\": 1, \"min\": 8.1939697265625, \"max\": 8.1939697265625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[0] avg_epoch_loss=5.339494\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=5.339494228363037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[5] avg_epoch_loss=5.266587\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=5.266586860020955\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [5]#011Speed: 1946.22 samples/sec#011loss=5.266587\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[10] avg_epoch_loss=5.371340\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=5.497043704986572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [10]#011Speed: 1079.48 samples/sec#011loss=5.497044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[15] avg_epoch_loss=5.383382\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=5.409874439239502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [15]#011Speed: 1953.63 samples/sec#011loss=5.409874\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[20] avg_epoch_loss=5.413446\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=5.509650993347168\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [20]#011Speed: 1079.73 samples/sec#011loss=5.509651\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[25] avg_epoch_loss=5.441871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=5.561255073547363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [25]#011Speed: 1839.79 samples/sec#011loss=5.561255\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[30] avg_epoch_loss=5.439532\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=5.427369594573975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [30]#011Speed: 1099.74 samples/sec#011loss=5.427370\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[35] avg_epoch_loss=5.428062\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=5.356949520111084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [35]#011Speed: 1944.07 samples/sec#011loss=5.356950\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch[40] avg_epoch_loss=5.451449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=5.619837760925293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:12 INFO 140667699287680] Epoch[7] Batch [40]#011Speed: 995.78 samples/sec#011loss=5.619838\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[45] avg_epoch_loss=5.448110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=5.420726490020752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [45]#011Speed: 1818.06 samples/sec#011loss=5.420726\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[50] avg_epoch_loss=5.452776\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=5.495707893371582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [50]#011Speed: 1009.38 samples/sec#011loss=5.495708\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[55] avg_epoch_loss=5.460480\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=5.539061450958252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [55]#011Speed: 1866.34 samples/sec#011loss=5.539061\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[60] avg_epoch_loss=5.458934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=5.441613292694091\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [60]#011Speed: 1077.68 samples/sec#011loss=5.441613\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[65] avg_epoch_loss=5.483833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=5.787600135803222\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [65]#011Speed: 1806.96 samples/sec#011loss=5.787600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[70] avg_epoch_loss=5.504627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=5.779115772247314\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [70]#011Speed: 1045.27 samples/sec#011loss=5.779116\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[75] avg_epoch_loss=5.482368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=5.166286849975586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [75]#011Speed: 1784.46 samples/sec#011loss=5.166287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch[80] avg_epoch_loss=5.486911\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=5.555964756011963\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:13 INFO 140667699287680] Epoch[7] Batch [80]#011Speed: 1035.61 samples/sec#011loss=5.555965\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[85] avg_epoch_loss=5.484512\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=5.445643520355224\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [85]#011Speed: 1850.54 samples/sec#011loss=5.445644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[90] avg_epoch_loss=5.484280\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=5.480293464660645\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [90]#011Speed: 1066.92 samples/sec#011loss=5.480293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[95] avg_epoch_loss=5.496317\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=5.715390682220459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [95]#011Speed: 1680.72 samples/sec#011loss=5.715391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[100] avg_epoch_loss=5.496363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=5.497251796722412\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [100]#011Speed: 1059.80 samples/sec#011loss=5.497252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[105] avg_epoch_loss=5.490252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=5.366797065734863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [105]#011Speed: 1821.90 samples/sec#011loss=5.366797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[110] avg_epoch_loss=5.487752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=5.434756088256836\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [110]#011Speed: 1091.26 samples/sec#011loss=5.434756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[115] avg_epoch_loss=5.489083\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=5.5186238288879395\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [115]#011Speed: 1864.04 samples/sec#011loss=5.518624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[120] avg_epoch_loss=5.497114\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=5.6834441184997555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [120]#011Speed: 1135.64 samples/sec#011loss=5.683444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch[125] avg_epoch_loss=5.487235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=5.248148250579834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:14 INFO 140667699287680] Epoch[7] Batch [125]#011Speed: 1736.62 samples/sec#011loss=5.248148\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[130] avg_epoch_loss=5.487110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=5.483979892730713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [130]#011Speed: 1106.13 samples/sec#011loss=5.483980\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[135] avg_epoch_loss=5.485216\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=5.435589694976807\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [135]#011Speed: 1831.51 samples/sec#011loss=5.435590\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[140] avg_epoch_loss=5.481913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=5.392068386077881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [140]#011Speed: 1087.18 samples/sec#011loss=5.392068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[145] avg_epoch_loss=5.478193\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=5.3732749938964846\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [145]#011Speed: 1936.26 samples/sec#011loss=5.373275\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[150] avg_epoch_loss=5.476147\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=5.4164129257202145\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [150]#011Speed: 1094.85 samples/sec#011loss=5.416413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[155] avg_epoch_loss=5.474347\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=5.419999313354492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [155]#011Speed: 1827.59 samples/sec#011loss=5.419999\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[160] avg_epoch_loss=5.476003\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=5.527647399902344\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [160]#011Speed: 992.11 samples/sec#011loss=5.527647\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch[165] avg_epoch_loss=5.470273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=5.285792446136474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:15 INFO 140667699287680] Epoch[7] Batch [165]#011Speed: 1965.78 samples/sec#011loss=5.285792\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[170] avg_epoch_loss=5.476804\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=5.693607997894287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [170]#011Speed: 1105.62 samples/sec#011loss=5.693608\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[175] avg_epoch_loss=5.481034\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=5.625720596313476\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [175]#011Speed: 1889.38 samples/sec#011loss=5.625721\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[180] avg_epoch_loss=5.476568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=5.319369316101074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [180]#011Speed: 1089.91 samples/sec#011loss=5.319369\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[185] avg_epoch_loss=5.475119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=5.422647857666016\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [185]#011Speed: 1867.75 samples/sec#011loss=5.422648\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[190] avg_epoch_loss=5.475651\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=5.495433902740478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [190]#011Speed: 1015.29 samples/sec#011loss=5.495434\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[195] avg_epoch_loss=5.472391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=5.347866344451904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [195]#011Speed: 1770.85 samples/sec#011loss=5.347866\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[200] avg_epoch_loss=5.473562\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=5.519474601745605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [200]#011Speed: 1094.47 samples/sec#011loss=5.519475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[205] avg_epoch_loss=5.476511\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=5.595073890686035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [205]#011Speed: 1928.63 samples/sec#011loss=5.595074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch[210] avg_epoch_loss=5.476179\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=5.462480926513672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:16 INFO 140667699287680] Epoch[7] Batch [210]#011Speed: 1144.31 samples/sec#011loss=5.462481\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[215] avg_epoch_loss=5.476805\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=5.503218269348144\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [215]#011Speed: 1633.84 samples/sec#011loss=5.503218\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[220] avg_epoch_loss=5.480650\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=5.646774196624756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [220]#011Speed: 1059.25 samples/sec#011loss=5.646774\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[225] avg_epoch_loss=5.480713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=5.483473491668701\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [225]#011Speed: 1633.62 samples/sec#011loss=5.483473\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[230] avg_epoch_loss=5.483134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=5.592584037780762\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [230]#011Speed: 1129.17 samples/sec#011loss=5.592584\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[235] avg_epoch_loss=5.481799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=5.420108032226563\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [235]#011Speed: 1814.18 samples/sec#011loss=5.420108\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[240] avg_epoch_loss=5.474501\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=5.130053997039795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [240]#011Speed: 1153.47 samples/sec#011loss=5.130054\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[245] avg_epoch_loss=5.474788\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=5.488611125946045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [245]#011Speed: 1873.04 samples/sec#011loss=5.488611\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch[250] avg_epoch_loss=5.473827\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=5.426525974273682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:17 INFO 140667699287680] Epoch[7] Batch [250]#011Speed: 1124.24 samples/sec#011loss=5.426526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[255] avg_epoch_loss=5.471519\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=5.355682754516602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [255]#011Speed: 1780.11 samples/sec#011loss=5.355683\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[260] avg_epoch_loss=5.468049\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=5.290357971191407\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [260]#011Speed: 1043.90 samples/sec#011loss=5.290358\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[265] avg_epoch_loss=5.467767\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=5.453052425384522\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [265]#011Speed: 1670.12 samples/sec#011loss=5.453052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[270] avg_epoch_loss=5.464742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=270 train loss <loss>=5.303802871704102\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [270]#011Speed: 1032.57 samples/sec#011loss=5.303803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[275] avg_epoch_loss=5.465315\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=275 train loss <loss>=5.496367168426514\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [275]#011Speed: 1864.66 samples/sec#011loss=5.496367\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[280] avg_epoch_loss=5.464151\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=280 train loss <loss>=5.399918842315674\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [280]#011Speed: 1102.17 samples/sec#011loss=5.399919\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[285] avg_epoch_loss=5.466734\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=285 train loss <loss>=5.611910724639893\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [285]#011Speed: 1789.95 samples/sec#011loss=5.611911\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[290] avg_epoch_loss=5.469993\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=290 train loss <loss>=5.656427669525146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [290]#011Speed: 1034.28 samples/sec#011loss=5.656428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch[295] avg_epoch_loss=5.472911\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=295 train loss <loss>=5.642722702026367\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:18 INFO 140667699287680] Epoch[7] Batch [295]#011Speed: 1703.63 samples/sec#011loss=5.642723\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[300] avg_epoch_loss=5.471128\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=300 train loss <loss>=5.3655674934387205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [300]#011Speed: 1073.95 samples/sec#011loss=5.365567\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[305] avg_epoch_loss=5.472979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=305 train loss <loss>=5.584425640106201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [305]#011Speed: 1899.30 samples/sec#011loss=5.584426\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[310] avg_epoch_loss=5.474840\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=310 train loss <loss>=5.588707351684571\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [310]#011Speed: 1076.11 samples/sec#011loss=5.588707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[315] avg_epoch_loss=5.475692\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=315 train loss <loss>=5.528679752349854\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [315]#011Speed: 1885.45 samples/sec#011loss=5.528680\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[320] avg_epoch_loss=5.473087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=320 train loss <loss>=5.308443260192871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [320]#011Speed: 1044.55 samples/sec#011loss=5.308443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[325] avg_epoch_loss=5.471448\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=325 train loss <loss>=5.366224002838135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [325]#011Speed: 1889.26 samples/sec#011loss=5.366224\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[330] avg_epoch_loss=5.467372\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=330 train loss <loss>=5.201646995544434\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [330]#011Speed: 1100.34 samples/sec#011loss=5.201647\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch[335] avg_epoch_loss=5.465078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=335 train loss <loss>=5.313194942474365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:19 INFO 140667699287680] Epoch[7] Batch [335]#011Speed: 1925.41 samples/sec#011loss=5.313195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[340] avg_epoch_loss=5.465092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=340 train loss <loss>=5.466049861907959\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [340]#011Speed: 1022.79 samples/sec#011loss=5.466050\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[345] avg_epoch_loss=5.463482\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=345 train loss <loss>=5.353693294525146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [345]#011Speed: 1865.39 samples/sec#011loss=5.353693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[350] avg_epoch_loss=5.461173\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=350 train loss <loss>=5.3013434410095215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [350]#011Speed: 1036.96 samples/sec#011loss=5.301343\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[355] avg_epoch_loss=5.458844\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=355 train loss <loss>=5.295352935791016\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [355]#011Speed: 1583.70 samples/sec#011loss=5.295353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[360] avg_epoch_loss=5.460847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=360 train loss <loss>=5.603445053100586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [360]#011Speed: 1016.18 samples/sec#011loss=5.603445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[365] avg_epoch_loss=5.460284\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=365 train loss <loss>=5.419652843475342\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [365]#011Speed: 1691.92 samples/sec#011loss=5.419653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[370] avg_epoch_loss=5.458065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=370 train loss <loss>=5.2956164360046385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [370]#011Speed: 1107.92 samples/sec#011loss=5.295616\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch[375] avg_epoch_loss=5.456052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=375 train loss <loss>=5.306688404083252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:20 INFO 140667699287680] Epoch[7] Batch [375]#011Speed: 1572.38 samples/sec#011loss=5.306688\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[380] avg_epoch_loss=5.456383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=380 train loss <loss>=5.481343078613281\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [380]#011Speed: 1050.85 samples/sec#011loss=5.481343\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[385] avg_epoch_loss=5.456992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=385 train loss <loss>=5.5033495903015135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [385]#011Speed: 1862.42 samples/sec#011loss=5.503350\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[390] avg_epoch_loss=5.455678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=390 train loss <loss>=5.35424165725708\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [390]#011Speed: 1123.82 samples/sec#011loss=5.354242\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[395] avg_epoch_loss=5.453520\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=395 train loss <loss>=5.284764385223388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [395]#011Speed: 1663.20 samples/sec#011loss=5.284764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[400] avg_epoch_loss=5.453798\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=400 train loss <loss>=5.475827407836914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [400]#011Speed: 1086.21 samples/sec#011loss=5.475827\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[405] avg_epoch_loss=5.453938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=405 train loss <loss>=5.465198612213134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [405]#011Speed: 1851.34 samples/sec#011loss=5.465199\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[410] avg_epoch_loss=5.452789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=410 train loss <loss>=5.359421062469482\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [410]#011Speed: 1146.23 samples/sec#011loss=5.359421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch[415] avg_epoch_loss=5.451079\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=415 train loss <loss>=5.310580539703369\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:21 INFO 140667699287680] Epoch[7] Batch [415]#011Speed: 1804.24 samples/sec#011loss=5.310581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[420] avg_epoch_loss=5.448630\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=420 train loss <loss>=5.244859981536865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [420]#011Speed: 1063.71 samples/sec#011loss=5.244860\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[425] avg_epoch_loss=5.446772\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=425 train loss <loss>=5.29029655456543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [425]#011Speed: 1891.82 samples/sec#011loss=5.290297\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[430] avg_epoch_loss=5.446553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=430 train loss <loss>=5.427871131896973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [430]#011Speed: 1045.04 samples/sec#011loss=5.427871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[435] avg_epoch_loss=5.447326\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=435 train loss <loss>=5.514022636413574\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [435]#011Speed: 1896.26 samples/sec#011loss=5.514023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[440] avg_epoch_loss=5.448110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=440 train loss <loss>=5.5164745330810545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [440]#011Speed: 1113.40 samples/sec#011loss=5.516475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[445] avg_epoch_loss=5.448746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=445 train loss <loss>=5.504773139953613\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [445]#011Speed: 1788.28 samples/sec#011loss=5.504773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[450] avg_epoch_loss=5.447988\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=450 train loss <loss>=5.380379581451416\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [450]#011Speed: 1022.20 samples/sec#011loss=5.380380\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[455] avg_epoch_loss=5.443712\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=455 train loss <loss>=5.058055782318116\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [455]#011Speed: 1939.20 samples/sec#011loss=5.058056\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch[460] avg_epoch_loss=5.444963\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=460 train loss <loss>=5.55900936126709\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:22 INFO 140667699287680] Epoch[7] Batch [460]#011Speed: 1150.84 samples/sec#011loss=5.559009\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[465] avg_epoch_loss=5.442912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=465 train loss <loss>=5.253821563720703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [465]#011Speed: 1950.44 samples/sec#011loss=5.253822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[470] avg_epoch_loss=5.442308\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=470 train loss <loss>=5.386024475097656\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [470]#011Speed: 1113.80 samples/sec#011loss=5.386024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[475] avg_epoch_loss=5.442582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=475 train loss <loss>=5.468372821807861\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [475]#011Speed: 1851.80 samples/sec#011loss=5.468373\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[480] avg_epoch_loss=5.444582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=480 train loss <loss>=5.635024070739746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [480]#011Speed: 1141.90 samples/sec#011loss=5.635024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[485] avg_epoch_loss=5.442455\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=485 train loss <loss>=5.237860870361328\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [485]#011Speed: 1865.25 samples/sec#011loss=5.237861\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[490] avg_epoch_loss=5.442063\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=490 train loss <loss>=5.403985214233399\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [490]#011Speed: 1141.96 samples/sec#011loss=5.403985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[495] avg_epoch_loss=5.444481\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=495 train loss <loss>=5.681923294067383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [495]#011Speed: 1786.07 samples/sec#011loss=5.681923\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[500] avg_epoch_loss=5.443902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=500 train loss <loss>=5.386380195617676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [500]#011Speed: 1121.27 samples/sec#011loss=5.386380\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch[505] avg_epoch_loss=5.444591\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=505 train loss <loss>=5.513649845123291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:23 INFO 140667699287680] Epoch[7] Batch [505]#011Speed: 1735.11 samples/sec#011loss=5.513650\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[510] avg_epoch_loss=5.442150\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=510 train loss <loss>=5.1951850891113285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [510]#011Speed: 1101.16 samples/sec#011loss=5.195185\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[515] avg_epoch_loss=5.440789\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=515 train loss <loss>=5.301601505279541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [515]#011Speed: 1835.30 samples/sec#011loss=5.301602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[520] avg_epoch_loss=5.441033\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=520 train loss <loss>=5.466312980651855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [520]#011Speed: 1075.25 samples/sec#011loss=5.466313\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[525] avg_epoch_loss=5.440172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=525 train loss <loss>=5.350399303436279\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [525]#011Speed: 1887.54 samples/sec#011loss=5.350399\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[530] avg_epoch_loss=5.439602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=530 train loss <loss>=5.379616451263428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [530]#011Speed: 1071.48 samples/sec#011loss=5.379616\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[535] avg_epoch_loss=5.442962\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=535 train loss <loss>=5.799819564819336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [535]#011Speed: 1763.36 samples/sec#011loss=5.799820\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[540] avg_epoch_loss=5.442558\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=540 train loss <loss>=5.399229526519775\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [540]#011Speed: 1056.78 samples/sec#011loss=5.399230\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch[545] avg_epoch_loss=5.440204\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=545 train loss <loss>=5.185497856140136\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:24 INFO 140667699287680] Epoch[7] Batch [545]#011Speed: 1894.60 samples/sec#011loss=5.185498\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[7] Batch[550] avg_epoch_loss=5.439884\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, batch=550 train loss <loss>=5.404986190795898\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[7] Batch [550]#011Speed: 1441.13 samples/sec#011loss=5.404986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] processed a total of 17693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989891.9512963, \"EndTime\": 1620989905.040891, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13089.54381942749, \"count\": 1, \"min\": 13089.54381942749, \"max\": 13089.54381942749}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1351.681111626981 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=7, train loss <loss>=5.43906376633463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_0516d499-1041-43af-817d-2930010d02a4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989905.0409484, \"EndTime\": 1620989905.0499372, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.568525314331055, \"count\": 1, \"min\": 8.568525314331055, \"max\": 8.568525314331055}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[0] avg_epoch_loss=4.909045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=4.909045219421387\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[5] avg_epoch_loss=5.130825\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=5.130825042724609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [5]#011Speed: 1833.42 samples/sec#011loss=5.130825\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[10] avg_epoch_loss=5.229842\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=5.348662948608398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [10]#011Speed: 1116.77 samples/sec#011loss=5.348663\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[15] avg_epoch_loss=5.248394\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=5.2892077445983885\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [15]#011Speed: 1754.20 samples/sec#011loss=5.289208\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[20] avg_epoch_loss=5.277781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=5.371820068359375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [20]#011Speed: 963.65 samples/sec#011loss=5.371820\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[25] avg_epoch_loss=5.285922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=5.320111083984375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [25]#011Speed: 1930.88 samples/sec#011loss=5.320111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[30] avg_epoch_loss=5.316254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=5.473985958099365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [30]#011Speed: 1062.74 samples/sec#011loss=5.473986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch[35] avg_epoch_loss=5.315202\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=5.3086745262146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:25 INFO 140667699287680] Epoch[8] Batch [35]#011Speed: 1790.94 samples/sec#011loss=5.308675\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[40] avg_epoch_loss=5.320141\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=5.355703067779541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [40]#011Speed: 979.45 samples/sec#011loss=5.355703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[45] avg_epoch_loss=5.321999\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=5.337234210968018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [45]#011Speed: 1950.41 samples/sec#011loss=5.337234\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[50] avg_epoch_loss=5.334799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=5.452562618255615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [50]#011Speed: 1036.89 samples/sec#011loss=5.452563\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[55] avg_epoch_loss=5.362797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=5.648375797271728\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [55]#011Speed: 1785.25 samples/sec#011loss=5.648376\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[60] avg_epoch_loss=5.366616\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=5.409381866455078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [60]#011Speed: 976.60 samples/sec#011loss=5.409382\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[65] avg_epoch_loss=5.368208\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=5.387635517120361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [65]#011Speed: 1794.14 samples/sec#011loss=5.387636\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[70] avg_epoch_loss=5.374133\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=5.452348899841309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [70]#011Speed: 1012.55 samples/sec#011loss=5.452349\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch[75] avg_epoch_loss=5.372803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=5.353918838500976\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:26 INFO 140667699287680] Epoch[8] Batch [75]#011Speed: 1795.91 samples/sec#011loss=5.353919\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[80] avg_epoch_loss=5.388733\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=5.630857753753662\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [80]#011Speed: 1088.17 samples/sec#011loss=5.630858\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[85] avg_epoch_loss=5.385610\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=5.335029411315918\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [85]#011Speed: 1928.22 samples/sec#011loss=5.335029\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[90] avg_epoch_loss=5.371902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=5.136119747161866\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [90]#011Speed: 1110.23 samples/sec#011loss=5.136120\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[95] avg_epoch_loss=5.381263\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=5.5516357421875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [95]#011Speed: 1832.85 samples/sec#011loss=5.551636\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[100] avg_epoch_loss=5.377401\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=5.303243160247803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [100]#011Speed: 1030.95 samples/sec#011loss=5.303243\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[105] avg_epoch_loss=5.368715\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=5.1932652473449705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [105]#011Speed: 1935.85 samples/sec#011loss=5.193265\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[110] avg_epoch_loss=5.367303\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=5.337358283996582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [110]#011Speed: 1100.86 samples/sec#011loss=5.337358\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[115] avg_epoch_loss=5.365698\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=5.330066871643067\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [115]#011Speed: 1873.34 samples/sec#011loss=5.330067\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch[120] avg_epoch_loss=5.363241\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=5.306232357025147\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:27 INFO 140667699287680] Epoch[8] Batch [120]#011Speed: 1152.33 samples/sec#011loss=5.306232\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[125] avg_epoch_loss=5.364796\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=5.402439117431641\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [125]#011Speed: 1808.20 samples/sec#011loss=5.402439\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[130] avg_epoch_loss=5.355954\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=5.133133602142334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [130]#011Speed: 1090.66 samples/sec#011loss=5.133134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[135] avg_epoch_loss=5.361702\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=5.512299537658691\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [135]#011Speed: 1691.57 samples/sec#011loss=5.512300\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[140] avg_epoch_loss=5.358480\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=5.270832061767578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [140]#011Speed: 1014.60 samples/sec#011loss=5.270832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[145] avg_epoch_loss=5.366435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=5.590783882141113\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [145]#011Speed: 1804.71 samples/sec#011loss=5.590784\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[150] avg_epoch_loss=5.363768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=5.285880470275879\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [150]#011Speed: 1124.28 samples/sec#011loss=5.285880\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[155] avg_epoch_loss=5.365437\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=5.415837001800537\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [155]#011Speed: 1851.10 samples/sec#011loss=5.415837\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch[160] avg_epoch_loss=5.354472\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=5.012376594543457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:28 INFO 140667699287680] Epoch[8] Batch [160]#011Speed: 1105.90 samples/sec#011loss=5.012377\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[165] avg_epoch_loss=5.349316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=5.183294677734375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [165]#011Speed: 1946.65 samples/sec#011loss=5.183295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[170] avg_epoch_loss=5.346144\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=5.2408349990844725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [170]#011Speed: 1123.20 samples/sec#011loss=5.240835\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[175] avg_epoch_loss=5.352241\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=5.560739898681641\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [175]#011Speed: 1803.92 samples/sec#011loss=5.560740\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[180] avg_epoch_loss=5.349551\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=5.2548778533935545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [180]#011Speed: 1049.76 samples/sec#011loss=5.254878\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[185] avg_epoch_loss=5.354796\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=5.544648838043213\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [185]#011Speed: 1818.87 samples/sec#011loss=5.544649\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[190] avg_epoch_loss=5.358738\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=5.505387973785401\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [190]#011Speed: 1075.96 samples/sec#011loss=5.505388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[195] avg_epoch_loss=5.360786\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=5.43901481628418\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [195]#011Speed: 1891.35 samples/sec#011loss=5.439015\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[200] avg_epoch_loss=5.357218\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=5.21735372543335\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [200]#011Speed: 1097.20 samples/sec#011loss=5.217354\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch[205] avg_epoch_loss=5.352490\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=5.162434482574463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:29 INFO 140667699287680] Epoch[8] Batch [205]#011Speed: 1936.85 samples/sec#011loss=5.162434\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[210] avg_epoch_loss=5.352249\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=5.342308139801025\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [210]#011Speed: 1144.60 samples/sec#011loss=5.342308\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[215] avg_epoch_loss=5.358094\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=5.604766464233398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [215]#011Speed: 1944.44 samples/sec#011loss=5.604766\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[220] avg_epoch_loss=5.359535\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=5.421779346466065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [220]#011Speed: 1126.46 samples/sec#011loss=5.421779\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[225] avg_epoch_loss=5.365602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=5.633749771118164\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [225]#011Speed: 1938.06 samples/sec#011loss=5.633750\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[230] avg_epoch_loss=5.362492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=5.221938133239746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [230]#011Speed: 1100.93 samples/sec#011loss=5.221938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[235] avg_epoch_loss=5.359044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=5.1997425079345705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [235]#011Speed: 1859.40 samples/sec#011loss=5.199743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[240] avg_epoch_loss=5.359988\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=5.404539489746094\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [240]#011Speed: 1146.09 samples/sec#011loss=5.404539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch[245] avg_epoch_loss=5.365679\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=5.640007591247558\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:30 INFO 140667699287680] Epoch[8] Batch [245]#011Speed: 1871.07 samples/sec#011loss=5.640008\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[250] avg_epoch_loss=5.367181\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=5.441077709197998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [250]#011Speed: 1052.60 samples/sec#011loss=5.441078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[255] avg_epoch_loss=5.372343\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=5.631478977203369\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [255]#011Speed: 1762.15 samples/sec#011loss=5.631479\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[260] avg_epoch_loss=5.377184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=5.625003242492676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [260]#011Speed: 1022.95 samples/sec#011loss=5.625003\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[265] avg_epoch_loss=5.383143\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=265 train loss <loss>=5.694236946105957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [265]#011Speed: 1850.04 samples/sec#011loss=5.694237\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[270] avg_epoch_loss=5.384121\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=270 train loss <loss>=5.436154556274414\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [270]#011Speed: 1013.31 samples/sec#011loss=5.436155\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[275] avg_epoch_loss=5.384869\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=275 train loss <loss>=5.425412368774414\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [275]#011Speed: 1840.74 samples/sec#011loss=5.425412\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[280] avg_epoch_loss=5.385319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=280 train loss <loss>=5.410144901275634\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [280]#011Speed: 1062.56 samples/sec#011loss=5.410145\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[285] avg_epoch_loss=5.386572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=285 train loss <loss>=5.4569803237915036\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [285]#011Speed: 1831.07 samples/sec#011loss=5.456980\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch[290] avg_epoch_loss=5.386546\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=290 train loss <loss>=5.385042381286621\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:31 INFO 140667699287680] Epoch[8] Batch [290]#011Speed: 1099.75 samples/sec#011loss=5.385042\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[295] avg_epoch_loss=5.385261\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=295 train loss <loss>=5.310494136810303\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [295]#011Speed: 1927.04 samples/sec#011loss=5.310494\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[300] avg_epoch_loss=5.381353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=300 train loss <loss>=5.149974822998047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [300]#011Speed: 1032.63 samples/sec#011loss=5.149975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[305] avg_epoch_loss=5.385134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=305 train loss <loss>=5.612754535675049\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [305]#011Speed: 1832.83 samples/sec#011loss=5.612755\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[310] avg_epoch_loss=5.386545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=310 train loss <loss>=5.472938156127929\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [310]#011Speed: 952.06 samples/sec#011loss=5.472938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[315] avg_epoch_loss=5.386624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=315 train loss <loss>=5.391490459442139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [315]#011Speed: 1707.70 samples/sec#011loss=5.391490\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[320] avg_epoch_loss=5.386442\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=320 train loss <loss>=5.374987411499023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [320]#011Speed: 1030.06 samples/sec#011loss=5.374987\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[325] avg_epoch_loss=5.381134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=325 train loss <loss>=5.040365600585938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [325]#011Speed: 1804.71 samples/sec#011loss=5.040366\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch[330] avg_epoch_loss=5.378743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=330 train loss <loss>=5.222823429107666\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:32 INFO 140667699287680] Epoch[8] Batch [330]#011Speed: 1069.25 samples/sec#011loss=5.222823\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[335] avg_epoch_loss=5.375840\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=335 train loss <loss>=5.183631706237793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [335]#011Speed: 1912.38 samples/sec#011loss=5.183632\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[340] avg_epoch_loss=5.376227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=340 train loss <loss>=5.402256298065185\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [340]#011Speed: 1002.34 samples/sec#011loss=5.402256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[345] avg_epoch_loss=5.379994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=345 train loss <loss>=5.63691349029541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [345]#011Speed: 1904.48 samples/sec#011loss=5.636913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[350] avg_epoch_loss=5.378785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=350 train loss <loss>=5.295152282714843\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [350]#011Speed: 1063.90 samples/sec#011loss=5.295152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[355] avg_epoch_loss=5.380474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=355 train loss <loss>=5.499002075195312\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [355]#011Speed: 1885.90 samples/sec#011loss=5.499002\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[360] avg_epoch_loss=5.382624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=360 train loss <loss>=5.5356871604919435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [360]#011Speed: 1115.57 samples/sec#011loss=5.535687\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[365] avg_epoch_loss=5.383123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=365 train loss <loss>=5.419186305999756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [365]#011Speed: 1841.22 samples/sec#011loss=5.419186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[370] avg_epoch_loss=5.382747\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=370 train loss <loss>=5.355230236053467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [370]#011Speed: 1090.60 samples/sec#011loss=5.355230\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch[375] avg_epoch_loss=5.383856\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=375 train loss <loss>=5.466130065917969\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:33 INFO 140667699287680] Epoch[8] Batch [375]#011Speed: 1794.84 samples/sec#011loss=5.466130\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[380] avg_epoch_loss=5.384390\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=380 train loss <loss>=5.424510383605957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [380]#011Speed: 1081.12 samples/sec#011loss=5.424510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[385] avg_epoch_loss=5.386868\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=385 train loss <loss>=5.575704860687256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [385]#011Speed: 1769.07 samples/sec#011loss=5.575705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[390] avg_epoch_loss=5.389297\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=390 train loss <loss>=5.576860237121582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [390]#011Speed: 1083.10 samples/sec#011loss=5.576860\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[395] avg_epoch_loss=5.392989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=395 train loss <loss>=5.681700897216797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [395]#011Speed: 1811.23 samples/sec#011loss=5.681701\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[400] avg_epoch_loss=5.395579\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=400 train loss <loss>=5.600675392150879\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [400]#011Speed: 1098.86 samples/sec#011loss=5.600675\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[405] avg_epoch_loss=5.394774\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=405 train loss <loss>=5.3302428245544435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [405]#011Speed: 1830.13 samples/sec#011loss=5.330243\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[410] avg_epoch_loss=5.397288\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=410 train loss <loss>=5.601386833190918\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [410]#011Speed: 1153.14 samples/sec#011loss=5.601387\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch[415] avg_epoch_loss=5.396760\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=415 train loss <loss>=5.353403568267822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:34 INFO 140667699287680] Epoch[8] Batch [415]#011Speed: 1799.31 samples/sec#011loss=5.353404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[420] avg_epoch_loss=5.396643\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=420 train loss <loss>=5.386922359466553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [420]#011Speed: 1043.16 samples/sec#011loss=5.386922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[425] avg_epoch_loss=5.398765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=425 train loss <loss>=5.577409076690674\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [425]#011Speed: 1940.00 samples/sec#011loss=5.577409\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[430] avg_epoch_loss=5.401941\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=430 train loss <loss>=5.6725160598754885\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [430]#011Speed: 1070.90 samples/sec#011loss=5.672516\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[435] avg_epoch_loss=5.404080\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=435 train loss <loss>=5.588465881347656\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [435]#011Speed: 1939.27 samples/sec#011loss=5.588466\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[440] avg_epoch_loss=5.401795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=440 train loss <loss>=5.202569103240966\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [440]#011Speed: 1085.46 samples/sec#011loss=5.202569\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[445] avg_epoch_loss=5.401087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=445 train loss <loss>=5.33857831954956\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [445]#011Speed: 1934.18 samples/sec#011loss=5.338578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[450] avg_epoch_loss=5.399621\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=450 train loss <loss>=5.268935012817383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [450]#011Speed: 966.03 samples/sec#011loss=5.268935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch[455] avg_epoch_loss=5.396121\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=455 train loss <loss>=5.080417633056641\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:35 INFO 140667699287680] Epoch[8] Batch [455]#011Speed: 1905.09 samples/sec#011loss=5.080418\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[460] avg_epoch_loss=5.396513\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=460 train loss <loss>=5.432202243804932\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [460]#011Speed: 1094.15 samples/sec#011loss=5.432202\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[465] avg_epoch_loss=5.396029\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=465 train loss <loss>=5.351384067535401\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [465]#011Speed: 1567.17 samples/sec#011loss=5.351384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[470] avg_epoch_loss=5.395386\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=470 train loss <loss>=5.335509777069092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [470]#011Speed: 990.00 samples/sec#011loss=5.335510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[475] avg_epoch_loss=5.396913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=475 train loss <loss>=5.540764617919922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [475]#011Speed: 1668.91 samples/sec#011loss=5.540765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[480] avg_epoch_loss=5.397617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=480 train loss <loss>=5.464607048034668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [480]#011Speed: 986.35 samples/sec#011loss=5.464607\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[485] avg_epoch_loss=5.396749\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=485 train loss <loss>=5.313235282897949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [485]#011Speed: 1729.12 samples/sec#011loss=5.313235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[490] avg_epoch_loss=5.396512\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=490 train loss <loss>=5.373458194732666\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [490]#011Speed: 1060.49 samples/sec#011loss=5.373458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch[495] avg_epoch_loss=5.396609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=495 train loss <loss>=5.406190299987793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:36 INFO 140667699287680] Epoch[8] Batch [495]#011Speed: 1875.67 samples/sec#011loss=5.406190\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[500] avg_epoch_loss=5.397204\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=500 train loss <loss>=5.456205368041992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [500]#011Speed: 1108.26 samples/sec#011loss=5.456205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[505] avg_epoch_loss=5.397131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=505 train loss <loss>=5.38980655670166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [505]#011Speed: 1831.17 samples/sec#011loss=5.389807\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[510] avg_epoch_loss=5.396759\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=510 train loss <loss>=5.3591711044311525\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [510]#011Speed: 1112.74 samples/sec#011loss=5.359171\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[515] avg_epoch_loss=5.394316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=515 train loss <loss>=5.144601058959961\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [515]#011Speed: 1945.87 samples/sec#011loss=5.144601\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[520] avg_epoch_loss=5.393309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=520 train loss <loss>=5.289428043365478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [520]#011Speed: 971.39 samples/sec#011loss=5.289428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[525] avg_epoch_loss=5.390336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=525 train loss <loss>=5.0805353164672855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [525]#011Speed: 1797.27 samples/sec#011loss=5.080535\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[530] avg_epoch_loss=5.388169\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=530 train loss <loss>=5.160137462615967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [530]#011Speed: 1074.84 samples/sec#011loss=5.160137\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[535] avg_epoch_loss=5.387448\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=535 train loss <loss>=5.310887241363526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [535]#011Speed: 1856.57 samples/sec#011loss=5.310887\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch[540] avg_epoch_loss=5.386145\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=540 train loss <loss>=5.2464454650878904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:37 INFO 140667699287680] Epoch[8] Batch [540]#011Speed: 1108.00 samples/sec#011loss=5.246445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[8] Batch[545] avg_epoch_loss=5.386307\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=545 train loss <loss>=5.403841209411621\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[8] Batch [545]#011Speed: 1889.62 samples/sec#011loss=5.403841\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[8] Batch[550] avg_epoch_loss=5.384711\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, batch=550 train loss <loss>=5.210496807098389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[8] Batch [550]#011Speed: 1624.67 samples/sec#011loss=5.210497\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] processed a total of 17682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989905.049988, \"EndTime\": 1620989918.1823437, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13132.301092147827, \"count\": 1, \"min\": 13132.301092147827, \"max\": 13132.301092147827}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1346.4425223774133 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=8, train loss <loss>=5.382748713329515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_b1fb00bf-f00b-4b12-963c-cc234fdcd4cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989918.1823971, \"EndTime\": 1620989918.1897314, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.9293975830078125, \"count\": 1, \"min\": 6.9293975830078125, \"max\": 6.9293975830078125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[0] avg_epoch_loss=5.387611\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=5.387611389160156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[5] avg_epoch_loss=5.418384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=5.418384472529094\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch [5]#011Speed: 1957.15 samples/sec#011loss=5.418384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[10] avg_epoch_loss=5.417620\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=5.416703510284424\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch [10]#011Speed: 1000.73 samples/sec#011loss=5.416704\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[15] avg_epoch_loss=5.392323\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=5.336667251586914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch [15]#011Speed: 1914.31 samples/sec#011loss=5.336667\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[20] avg_epoch_loss=5.389392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=5.380014133453369\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch [20]#011Speed: 1058.00 samples/sec#011loss=5.380014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[25] avg_epoch_loss=5.398224\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=5.435321044921875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch [25]#011Speed: 1763.09 samples/sec#011loss=5.435321\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch[30] avg_epoch_loss=5.398111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=5.397520065307617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:38 INFO 140667699287680] Epoch[9] Batch [30]#011Speed: 1075.88 samples/sec#011loss=5.397520\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[35] avg_epoch_loss=5.373599\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=5.221623134613037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [35]#011Speed: 1646.04 samples/sec#011loss=5.221623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[40] avg_epoch_loss=5.354445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=5.216539573669434\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [40]#011Speed: 1006.88 samples/sec#011loss=5.216540\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[45] avg_epoch_loss=5.315103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=4.992501449584961\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [45]#011Speed: 1885.42 samples/sec#011loss=4.992501\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[50] avg_epoch_loss=5.318231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=5.3470064163208\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [50]#011Speed: 1038.02 samples/sec#011loss=5.347006\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[55] avg_epoch_loss=5.306045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=5.181749248504639\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [55]#011Speed: 1816.16 samples/sec#011loss=5.181749\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[60] avg_epoch_loss=5.326778\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=5.558981418609619\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [60]#011Speed: 998.13 samples/sec#011loss=5.558981\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[65] avg_epoch_loss=5.310570\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=5.112829780578613\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [65]#011Speed: 1669.09 samples/sec#011loss=5.112830\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch[70] avg_epoch_loss=5.297267\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=5.121666526794433\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:39 INFO 140667699287680] Epoch[9] Batch [70]#011Speed: 1056.18 samples/sec#011loss=5.121667\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[75] avg_epoch_loss=5.298640\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=5.318137550354004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [75]#011Speed: 1809.20 samples/sec#011loss=5.318138\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[80] avg_epoch_loss=5.310060\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=5.48365364074707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [80]#011Speed: 1057.15 samples/sec#011loss=5.483654\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[85] avg_epoch_loss=5.308330\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=5.280299377441406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [85]#011Speed: 1918.31 samples/sec#011loss=5.280299\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[90] avg_epoch_loss=5.291526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=5.002497386932373\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [90]#011Speed: 1034.54 samples/sec#011loss=5.002497\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[95] avg_epoch_loss=5.303859\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=5.52831335067749\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [95]#011Speed: 1763.92 samples/sec#011loss=5.528313\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[100] avg_epoch_loss=5.302593\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=5.27830057144165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [100]#011Speed: 1023.26 samples/sec#011loss=5.278301\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[105] avg_epoch_loss=5.310122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=5.462208843231201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [105]#011Speed: 1921.51 samples/sec#011loss=5.462209\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch[110] avg_epoch_loss=5.315093\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=5.42046594619751\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:40 INFO 140667699287680] Epoch[9] Batch [110]#011Speed: 1076.20 samples/sec#011loss=5.420466\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[115] avg_epoch_loss=5.323720\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=5.515245342254639\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [115]#011Speed: 1852.23 samples/sec#011loss=5.515245\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[120] avg_epoch_loss=5.331394\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=5.509415912628174\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [120]#011Speed: 1040.88 samples/sec#011loss=5.509416\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[125] avg_epoch_loss=5.341935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=5.597042083740234\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [125]#011Speed: 1887.83 samples/sec#011loss=5.597042\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[130] avg_epoch_loss=5.340296\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=5.2989836692810055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [130]#011Speed: 1052.15 samples/sec#011loss=5.298984\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[135] avg_epoch_loss=5.343373\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=5.424009704589844\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [135]#011Speed: 1609.46 samples/sec#011loss=5.424010\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[140] avg_epoch_loss=5.339034\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=5.221003150939941\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [140]#011Speed: 1038.55 samples/sec#011loss=5.221003\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[145] avg_epoch_loss=5.337573\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=5.296363353729248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [145]#011Speed: 1910.56 samples/sec#011loss=5.296363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[150] avg_epoch_loss=5.339550\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=5.3972728729248045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [150]#011Speed: 1042.06 samples/sec#011loss=5.397273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch[155] avg_epoch_loss=5.341833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=5.4107818603515625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:41 INFO 140667699287680] Epoch[9] Batch [155]#011Speed: 1767.16 samples/sec#011loss=5.410782\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[160] avg_epoch_loss=5.338133\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=5.222699546813965\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [160]#011Speed: 1031.48 samples/sec#011loss=5.222700\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[165] avg_epoch_loss=5.340510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=5.417061233520508\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [165]#011Speed: 1825.34 samples/sec#011loss=5.417061\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[170] avg_epoch_loss=5.344035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=5.461071872711182\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [170]#011Speed: 1092.92 samples/sec#011loss=5.461072\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[175] avg_epoch_loss=5.348725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=5.5091087341308596\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [175]#011Speed: 1792.77 samples/sec#011loss=5.509109\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[180] avg_epoch_loss=5.354261\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=5.549110221862793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [180]#011Speed: 1055.18 samples/sec#011loss=5.549110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[185] avg_epoch_loss=5.348603\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=5.143804264068604\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [185]#011Speed: 1930.27 samples/sec#011loss=5.143804\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[190] avg_epoch_loss=5.347189\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=5.294601535797119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [190]#011Speed: 1060.95 samples/sec#011loss=5.294602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch[195] avg_epoch_loss=5.349651\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=5.443692302703857\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:42 INFO 140667699287680] Epoch[9] Batch [195]#011Speed: 1748.20 samples/sec#011loss=5.443692\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[200] avg_epoch_loss=5.352605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=5.468388652801513\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [200]#011Speed: 1077.42 samples/sec#011loss=5.468389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[205] avg_epoch_loss=5.358865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=5.610527420043946\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [205]#011Speed: 1790.88 samples/sec#011loss=5.610527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[210] avg_epoch_loss=5.360656\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=5.4344429016113285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [210]#011Speed: 1076.31 samples/sec#011loss=5.434443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[215] avg_epoch_loss=5.357886\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=5.240997791290283\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [215]#011Speed: 1855.73 samples/sec#011loss=5.240998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[220] avg_epoch_loss=5.351995\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=5.09749927520752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [220]#011Speed: 933.80 samples/sec#011loss=5.097499\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[225] avg_epoch_loss=5.352136\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=5.358363628387451\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [225]#011Speed: 1890.50 samples/sec#011loss=5.358364\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[230] avg_epoch_loss=5.355020\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=5.485362148284912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [230]#011Speed: 1088.47 samples/sec#011loss=5.485362\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch[235] avg_epoch_loss=5.354129\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=5.312967109680176\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:43 INFO 140667699287680] Epoch[9] Batch [235]#011Speed: 1871.04 samples/sec#011loss=5.312967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[240] avg_epoch_loss=5.348694\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=5.092185688018799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [240]#011Speed: 1087.90 samples/sec#011loss=5.092186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[245] avg_epoch_loss=5.348612\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=5.344625854492188\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [245]#011Speed: 1899.86 samples/sec#011loss=5.344626\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[250] avg_epoch_loss=5.344079\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=5.121089458465576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [250]#011Speed: 1096.75 samples/sec#011loss=5.121089\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[255] avg_epoch_loss=5.346692\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=5.477835655212402\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [255]#011Speed: 1930.58 samples/sec#011loss=5.477836\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[260] avg_epoch_loss=5.351044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=5.573869705200195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [260]#011Speed: 1005.14 samples/sec#011loss=5.573870\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[265] avg_epoch_loss=5.356349\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=5.633268356323242\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [265]#011Speed: 1741.35 samples/sec#011loss=5.633268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[270] avg_epoch_loss=5.361862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=5.655140495300293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [270]#011Speed: 1018.22 samples/sec#011loss=5.655140\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch[275] avg_epoch_loss=5.363514\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=275 train loss <loss>=5.453081798553467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:44 INFO 140667699287680] Epoch[9] Batch [275]#011Speed: 1892.72 samples/sec#011loss=5.453082\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[280] avg_epoch_loss=5.363251\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=280 train loss <loss>=5.348754215240478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [280]#011Speed: 1096.63 samples/sec#011loss=5.348754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[285] avg_epoch_loss=5.364193\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=285 train loss <loss>=5.417092132568359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [285]#011Speed: 1951.10 samples/sec#011loss=5.417092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[290] avg_epoch_loss=5.359768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=290 train loss <loss>=5.106700229644775\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [290]#011Speed: 1124.87 samples/sec#011loss=5.106700\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[295] avg_epoch_loss=5.355719\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=295 train loss <loss>=5.12006893157959\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [295]#011Speed: 1936.15 samples/sec#011loss=5.120069\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[300] avg_epoch_loss=5.355847\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=300 train loss <loss>=5.363381195068359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [300]#011Speed: 1130.14 samples/sec#011loss=5.363381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[305] avg_epoch_loss=5.354950\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=305 train loss <loss>=5.300983333587647\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [305]#011Speed: 1740.31 samples/sec#011loss=5.300983\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[310] avg_epoch_loss=5.352233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=310 train loss <loss>=5.185928153991699\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [310]#011Speed: 1032.73 samples/sec#011loss=5.185928\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[315] avg_epoch_loss=5.352132\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=315 train loss <loss>=5.345840835571289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [315]#011Speed: 1669.27 samples/sec#011loss=5.345841\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch[320] avg_epoch_loss=5.354239\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=320 train loss <loss>=5.487428855895996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:45 INFO 140667699287680] Epoch[9] Batch [320]#011Speed: 1101.05 samples/sec#011loss=5.487429\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[325] avg_epoch_loss=5.356333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=325 train loss <loss>=5.49079008102417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [325]#011Speed: 1732.31 samples/sec#011loss=5.490790\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[330] avg_epoch_loss=5.355168\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=330 train loss <loss>=5.279201316833496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [330]#011Speed: 1141.09 samples/sec#011loss=5.279201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[335] avg_epoch_loss=5.351039\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=335 train loss <loss>=5.077697372436523\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [335]#011Speed: 1666.03 samples/sec#011loss=5.077697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[340] avg_epoch_loss=5.348414\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=340 train loss <loss>=5.1719818115234375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [340]#011Speed: 1139.92 samples/sec#011loss=5.171982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[345] avg_epoch_loss=5.346637\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=345 train loss <loss>=5.225432968139648\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [345]#011Speed: 1794.27 samples/sec#011loss=5.225433\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[350] avg_epoch_loss=5.347206\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=350 train loss <loss>=5.386588191986084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [350]#011Speed: 1016.05 samples/sec#011loss=5.386588\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[355] avg_epoch_loss=5.350501\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=355 train loss <loss>=5.5817952156066895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [355]#011Speed: 1744.22 samples/sec#011loss=5.581795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[360] avg_epoch_loss=5.347049\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=360 train loss <loss>=5.101307487487793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [360]#011Speed: 1113.65 samples/sec#011loss=5.101307\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch[365] avg_epoch_loss=5.345921\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=365 train loss <loss>=5.264470386505127\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:46 INFO 140667699287680] Epoch[9] Batch [365]#011Speed: 1656.80 samples/sec#011loss=5.264470\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[370] avg_epoch_loss=5.346930\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=370 train loss <loss>=5.420778560638428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [370]#011Speed: 1107.08 samples/sec#011loss=5.420779\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[375] avg_epoch_loss=5.345761\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=375 train loss <loss>=5.259008693695068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [375]#011Speed: 1851.53 samples/sec#011loss=5.259009\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[380] avg_epoch_loss=5.346286\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=380 train loss <loss>=5.385762691497803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [380]#011Speed: 1016.30 samples/sec#011loss=5.385763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[385] avg_epoch_loss=5.346415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=385 train loss <loss>=5.356248950958252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [385]#011Speed: 1758.21 samples/sec#011loss=5.356249\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[390] avg_epoch_loss=5.348998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=390 train loss <loss>=5.548429203033447\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [390]#011Speed: 1002.97 samples/sec#011loss=5.548429\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[395] avg_epoch_loss=5.347595\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=395 train loss <loss>=5.237838935852051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [395]#011Speed: 1884.76 samples/sec#011loss=5.237839\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[400] avg_epoch_loss=5.345790\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=400 train loss <loss>=5.202880096435547\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [400]#011Speed: 1014.12 samples/sec#011loss=5.202880\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch[405] avg_epoch_loss=5.344827\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=405 train loss <loss>=5.267606544494629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:47 INFO 140667699287680] Epoch[9] Batch [405]#011Speed: 1906.96 samples/sec#011loss=5.267607\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[410] avg_epoch_loss=5.345867\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=410 train loss <loss>=5.430292129516602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [410]#011Speed: 1047.61 samples/sec#011loss=5.430292\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[415] avg_epoch_loss=5.345251\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=415 train loss <loss>=5.294625091552734\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [415]#011Speed: 1957.36 samples/sec#011loss=5.294625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[420] avg_epoch_loss=5.344542\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=420 train loss <loss>=5.285544681549072\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [420]#011Speed: 1019.16 samples/sec#011loss=5.285545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[425] avg_epoch_loss=5.344548\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=425 train loss <loss>=5.345055294036865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [425]#011Speed: 1957.06 samples/sec#011loss=5.345055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[430] avg_epoch_loss=5.345331\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=430 train loss <loss>=5.412050819396972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [430]#011Speed: 948.11 samples/sec#011loss=5.412051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[435] avg_epoch_loss=5.345266\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=435 train loss <loss>=5.339674568176269\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [435]#011Speed: 1891.18 samples/sec#011loss=5.339675\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[440] avg_epoch_loss=5.347286\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=440 train loss <loss>=5.523429679870605\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [440]#011Speed: 1041.70 samples/sec#011loss=5.523430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch[445] avg_epoch_loss=5.348833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=445 train loss <loss>=5.485281181335449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:48 INFO 140667699287680] Epoch[9] Batch [445]#011Speed: 1917.03 samples/sec#011loss=5.485281\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[450] avg_epoch_loss=5.348018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=450 train loss <loss>=5.275305557250976\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [450]#011Speed: 1074.88 samples/sec#011loss=5.275306\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[455] avg_epoch_loss=5.349191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=455 train loss <loss>=5.4550196647644045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [455]#011Speed: 1888.46 samples/sec#011loss=5.455020\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[460] avg_epoch_loss=5.349990\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=460 train loss <loss>=5.422829341888428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [460]#011Speed: 1096.32 samples/sec#011loss=5.422829\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[465] avg_epoch_loss=5.349371\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=465 train loss <loss>=5.292318344116211\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [465]#011Speed: 1968.75 samples/sec#011loss=5.292318\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[470] avg_epoch_loss=5.349887\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=470 train loss <loss>=5.397938346862793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [470]#011Speed: 1066.28 samples/sec#011loss=5.397938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[475] avg_epoch_loss=5.352125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=475 train loss <loss>=5.56294002532959\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [475]#011Speed: 1623.50 samples/sec#011loss=5.562940\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[480] avg_epoch_loss=5.352239\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=480 train loss <loss>=5.363103866577148\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [480]#011Speed: 965.38 samples/sec#011loss=5.363104\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch[485] avg_epoch_loss=5.351271\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=485 train loss <loss>=5.258115959167481\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:49 INFO 140667699287680] Epoch[9] Batch [485]#011Speed: 1887.04 samples/sec#011loss=5.258116\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[490] avg_epoch_loss=5.350454\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=490 train loss <loss>=5.271118545532227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [490]#011Speed: 1047.05 samples/sec#011loss=5.271119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[495] avg_epoch_loss=5.348254\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=495 train loss <loss>=5.13216199874878\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [495]#011Speed: 1933.44 samples/sec#011loss=5.132162\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[500] avg_epoch_loss=5.346088\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=500 train loss <loss>=5.131196689605713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [500]#011Speed: 1066.61 samples/sec#011loss=5.131197\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[505] avg_epoch_loss=5.344268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=505 train loss <loss>=5.161983394622803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [505]#011Speed: 1848.19 samples/sec#011loss=5.161983\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[510] avg_epoch_loss=5.342914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=510 train loss <loss>=5.205886459350586\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [510]#011Speed: 1051.19 samples/sec#011loss=5.205886\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[515] avg_epoch_loss=5.344575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=515 train loss <loss>=5.514321613311767\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [515]#011Speed: 1671.97 samples/sec#011loss=5.514322\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[520] avg_epoch_loss=5.343717\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=520 train loss <loss>=5.255164718627929\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [520]#011Speed: 1111.70 samples/sec#011loss=5.255165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[525] avg_epoch_loss=5.342973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=525 train loss <loss>=5.265477561950684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [525]#011Speed: 1867.34 samples/sec#011loss=5.265478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch[530] avg_epoch_loss=5.343232\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=530 train loss <loss>=5.3704526901245115\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:50 INFO 140667699287680] Epoch[9] Batch [530]#011Speed: 1005.11 samples/sec#011loss=5.370453\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch[535] avg_epoch_loss=5.342610\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=535 train loss <loss>=5.276526641845703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch [535]#011Speed: 1833.74 samples/sec#011loss=5.276527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch[540] avg_epoch_loss=5.343422\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=540 train loss <loss>=5.430465030670166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch [540]#011Speed: 1083.48 samples/sec#011loss=5.430465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch[545] avg_epoch_loss=5.344079\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=545 train loss <loss>=5.415220737457275\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch [545]#011Speed: 1699.17 samples/sec#011loss=5.415221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch[550] avg_epoch_loss=5.345131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, batch=550 train loss <loss>=5.4599480628967285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[9] Batch [550]#011Speed: 1365.85 samples/sec#011loss=5.459948\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] processed a total of 17681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989918.1897826, \"EndTime\": 1620989931.4823117, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13292.476892471313, \"count\": 1, \"min\": 13292.476892471313, \"max\": 13292.476892471313}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1330.1417309140968 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=9, train loss <loss>=5.345946151567842\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_065e143f-53bf-499e-a1c2-eadef79bc359-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989931.4823754, \"EndTime\": 1620989931.4920454, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.299993515014648, \"count\": 1, \"min\": 9.299993515014648, \"max\": 9.299993515014648}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch[0] avg_epoch_loss=4.993139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=4.993138790130615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch[5] avg_epoch_loss=5.422895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=5.422895431518555\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch [5]#011Speed: 1656.32 samples/sec#011loss=5.422895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch[10] avg_epoch_loss=5.329330\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=5.217051315307617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch [10]#011Speed: 1105.33 samples/sec#011loss=5.217051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch[15] avg_epoch_loss=5.321112\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=5.303033542633057\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:51 INFO 140667699287680] Epoch[10] Batch [15]#011Speed: 1847.79 samples/sec#011loss=5.303034\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[20] avg_epoch_loss=5.353593\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=5.457532787322998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [20]#011Speed: 1057.41 samples/sec#011loss=5.457533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[25] avg_epoch_loss=5.362329\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=5.3990199089050295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [25]#011Speed: 1827.19 samples/sec#011loss=5.399020\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[30] avg_epoch_loss=5.420671\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=5.724050903320313\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [30]#011Speed: 1119.34 samples/sec#011loss=5.724051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[35] avg_epoch_loss=5.445413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=5.598807334899902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [35]#011Speed: 1879.02 samples/sec#011loss=5.598807\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[40] avg_epoch_loss=5.441610\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=5.414230060577393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [40]#011Speed: 1108.87 samples/sec#011loss=5.414230\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[45] avg_epoch_loss=5.429090\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=5.326425838470459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [45]#011Speed: 1663.58 samples/sec#011loss=5.326426\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[50] avg_epoch_loss=5.419648\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=5.332784748077392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [50]#011Speed: 1033.57 samples/sec#011loss=5.332785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch[55] avg_epoch_loss=5.424874\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=5.478177738189697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:52 INFO 140667699287680] Epoch[10] Batch [55]#011Speed: 1751.81 samples/sec#011loss=5.478178\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[60] avg_epoch_loss=5.407304\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=5.210525989532471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [60]#011Speed: 1109.03 samples/sec#011loss=5.210526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[65] avg_epoch_loss=5.408647\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=5.425021457672119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [65]#011Speed: 1849.47 samples/sec#011loss=5.425021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[70] avg_epoch_loss=5.420177\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=5.57237548828125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [70]#011Speed: 1035.09 samples/sec#011loss=5.572375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[75] avg_epoch_loss=5.413492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=5.318574142456055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [75]#011Speed: 1689.57 samples/sec#011loss=5.318574\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[80] avg_epoch_loss=5.405197\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=5.279099464416504\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [80]#011Speed: 1073.45 samples/sec#011loss=5.279099\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[85] avg_epoch_loss=5.385827\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=5.072046852111816\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [85]#011Speed: 1772.27 samples/sec#011loss=5.072047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[90] avg_epoch_loss=5.379317\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=5.267333507537842\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [90]#011Speed: 1050.52 samples/sec#011loss=5.267334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[95] avg_epoch_loss=5.377768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=5.3495711326599125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [95]#011Speed: 1941.49 samples/sec#011loss=5.349571\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch[100] avg_epoch_loss=5.380938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=5.441800785064697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:53 INFO 140667699287680] Epoch[10] Batch [100]#011Speed: 1117.97 samples/sec#011loss=5.441801\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[105] avg_epoch_loss=5.385654\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=5.480917835235596\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [105]#011Speed: 1721.57 samples/sec#011loss=5.480918\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[110] avg_epoch_loss=5.393327\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=5.556011486053467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [110]#011Speed: 1035.04 samples/sec#011loss=5.556011\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[115] avg_epoch_loss=5.397198\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=5.483125495910644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [115]#011Speed: 1803.32 samples/sec#011loss=5.483125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[120] avg_epoch_loss=5.394548\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=5.333058071136475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [120]#011Speed: 1100.94 samples/sec#011loss=5.333058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[125] avg_epoch_loss=5.401759\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=5.576284599304199\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [125]#011Speed: 1944.27 samples/sec#011loss=5.576285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[130] avg_epoch_loss=5.398946\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=5.328046035766602\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [130]#011Speed: 956.53 samples/sec#011loss=5.328046\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[135] avg_epoch_loss=5.394959\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=5.290501689910888\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [135]#011Speed: 1908.56 samples/sec#011loss=5.290502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch[140] avg_epoch_loss=5.388828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=5.222065258026123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:54 INFO 140667699287680] Epoch[10] Batch [140]#011Speed: 1082.88 samples/sec#011loss=5.222065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[145] avg_epoch_loss=5.385385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=5.288292789459229\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [145]#011Speed: 1897.18 samples/sec#011loss=5.288293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[150] avg_epoch_loss=5.393090\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=5.618076133728027\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [150]#011Speed: 1072.18 samples/sec#011loss=5.618076\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[155] avg_epoch_loss=5.387287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=5.21205244064331\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [155]#011Speed: 1919.36 samples/sec#011loss=5.212052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[160] avg_epoch_loss=5.387528\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=5.395022964477539\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [160]#011Speed: 1105.52 samples/sec#011loss=5.395023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[165] avg_epoch_loss=5.392031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=5.537051677703857\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [165]#011Speed: 1752.70 samples/sec#011loss=5.537052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[170] avg_epoch_loss=5.395650\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=5.515794563293457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [170]#011Speed: 1122.75 samples/sec#011loss=5.515795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[175] avg_epoch_loss=5.391510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=5.249905109405518\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [175]#011Speed: 1650.91 samples/sec#011loss=5.249905\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[180] avg_epoch_loss=5.392431\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=5.42484827041626\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [180]#011Speed: 1118.09 samples/sec#011loss=5.424848\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch[185] avg_epoch_loss=5.391251\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=5.348544979095459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:55 INFO 140667699287680] Epoch[10] Batch [185]#011Speed: 1801.18 samples/sec#011loss=5.348545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[190] avg_epoch_loss=5.389915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=5.340221786499024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [190]#011Speed: 1105.75 samples/sec#011loss=5.340222\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[195] avg_epoch_loss=5.386676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=5.262942695617676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [195]#011Speed: 1934.46 samples/sec#011loss=5.262943\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[200] avg_epoch_loss=5.389096\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=5.483948802947998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [200]#011Speed: 1062.88 samples/sec#011loss=5.483949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[205] avg_epoch_loss=5.398484\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=5.775904560089112\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [205]#011Speed: 1713.17 samples/sec#011loss=5.775905\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[210] avg_epoch_loss=5.402845\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=5.582486534118653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [210]#011Speed: 1029.29 samples/sec#011loss=5.582487\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[215] avg_epoch_loss=5.404191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=5.4610189437866214\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [215]#011Speed: 1826.30 samples/sec#011loss=5.461019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[220] avg_epoch_loss=5.401268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=5.274992656707764\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [220]#011Speed: 1017.53 samples/sec#011loss=5.274993\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch[225] avg_epoch_loss=5.400103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=5.3485918045043945\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:56 INFO 140667699287680] Epoch[10] Batch [225]#011Speed: 1923.93 samples/sec#011loss=5.348592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[230] avg_epoch_loss=5.399260\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=5.361165714263916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [230]#011Speed: 1057.91 samples/sec#011loss=5.361166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[235] avg_epoch_loss=5.402687\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=5.561023235321045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [235]#011Speed: 1713.09 samples/sec#011loss=5.561023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[240] avg_epoch_loss=5.406136\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=5.568935108184815\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [240]#011Speed: 1052.15 samples/sec#011loss=5.568935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[245] avg_epoch_loss=5.404047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=5.303345966339111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [245]#011Speed: 1952.36 samples/sec#011loss=5.303346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[250] avg_epoch_loss=5.405986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=5.5014067649841305\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [250]#011Speed: 1040.90 samples/sec#011loss=5.501407\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[255] avg_epoch_loss=5.409913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=5.607014465332031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [255]#011Speed: 1834.83 samples/sec#011loss=5.607014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[260] avg_epoch_loss=5.412044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=5.521179962158203\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [260]#011Speed: 1005.34 samples/sec#011loss=5.521180\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch[265] avg_epoch_loss=5.404543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=5.012977981567383\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:57 INFO 140667699287680] Epoch[10] Batch [265]#011Speed: 1800.00 samples/sec#011loss=5.012978\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[270] avg_epoch_loss=5.401903\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=5.26146879196167\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [270]#011Speed: 1074.17 samples/sec#011loss=5.261469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[275] avg_epoch_loss=5.402488\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=275 train loss <loss>=5.434180736541748\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [275]#011Speed: 1794.77 samples/sec#011loss=5.434181\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[280] avg_epoch_loss=5.399677\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=280 train loss <loss>=5.244525623321533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [280]#011Speed: 1076.33 samples/sec#011loss=5.244526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[285] avg_epoch_loss=5.398133\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=285 train loss <loss>=5.311322116851807\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [285]#011Speed: 1932.51 samples/sec#011loss=5.311322\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[290] avg_epoch_loss=5.395755\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=290 train loss <loss>=5.2597222328186035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [290]#011Speed: 1044.86 samples/sec#011loss=5.259722\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[295] avg_epoch_loss=5.394892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=295 train loss <loss>=5.344689655303955\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [295]#011Speed: 1823.85 samples/sec#011loss=5.344690\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[300] avg_epoch_loss=5.392111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=300 train loss <loss>=5.227474975585937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [300]#011Speed: 1015.25 samples/sec#011loss=5.227475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[305] avg_epoch_loss=5.389252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=305 train loss <loss>=5.217146110534668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [305]#011Speed: 1665.37 samples/sec#011loss=5.217146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch[310] avg_epoch_loss=5.387873\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=310 train loss <loss>=5.303473567962646\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:58 INFO 140667699287680] Epoch[10] Batch [310]#011Speed: 1070.57 samples/sec#011loss=5.303474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[315] avg_epoch_loss=5.388032\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=315 train loss <loss>=5.397949981689453\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [315]#011Speed: 1902.72 samples/sec#011loss=5.397950\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[320] avg_epoch_loss=5.384089\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=320 train loss <loss>=5.134876155853272\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [320]#011Speed: 1011.62 samples/sec#011loss=5.134876\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[325] avg_epoch_loss=5.386404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=325 train loss <loss>=5.535040187835693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [325]#011Speed: 1821.33 samples/sec#011loss=5.535040\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[330] avg_epoch_loss=5.383985\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=330 train loss <loss>=5.226268768310547\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [330]#011Speed: 1032.34 samples/sec#011loss=5.226269\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[335] avg_epoch_loss=5.387117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=335 train loss <loss>=5.594439888000489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [335]#011Speed: 1755.78 samples/sec#011loss=5.594440\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[340] avg_epoch_loss=5.391439\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=340 train loss <loss>=5.681857872009277\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [340]#011Speed: 1079.04 samples/sec#011loss=5.681858\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[345] avg_epoch_loss=5.393253\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=345 train loss <loss>=5.5169861793518065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [345]#011Speed: 1775.79 samples/sec#011loss=5.516986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch[350] avg_epoch_loss=5.391139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=350 train loss <loss>=5.244813060760498\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:58:59 INFO 140667699287680] Epoch[10] Batch [350]#011Speed: 1045.56 samples/sec#011loss=5.244813\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[355] avg_epoch_loss=5.390556\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=355 train loss <loss>=5.349687767028809\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [355]#011Speed: 1813.91 samples/sec#011loss=5.349688\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[360] avg_epoch_loss=5.394277\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=360 train loss <loss>=5.659173583984375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [360]#011Speed: 1100.44 samples/sec#011loss=5.659174\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[365] avg_epoch_loss=5.393366\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=365 train loss <loss>=5.327575016021728\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [365]#011Speed: 1854.18 samples/sec#011loss=5.327575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[370] avg_epoch_loss=5.391490\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=370 train loss <loss>=5.254163455963135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [370]#011Speed: 1121.70 samples/sec#011loss=5.254163\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[375] avg_epoch_loss=5.393212\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=375 train loss <loss>=5.520990467071533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [375]#011Speed: 1862.68 samples/sec#011loss=5.520990\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[380] avg_epoch_loss=5.392315\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=380 train loss <loss>=5.32488260269165\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [380]#011Speed: 1060.77 samples/sec#011loss=5.324883\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[385] avg_epoch_loss=5.391807\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=385 train loss <loss>=5.353092002868652\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [385]#011Speed: 1885.89 samples/sec#011loss=5.353092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[390] avg_epoch_loss=5.388421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=390 train loss <loss>=5.127027606964111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [390]#011Speed: 1025.38 samples/sec#011loss=5.127028\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch[395] avg_epoch_loss=5.384737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=395 train loss <loss>=5.096643924713135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:00 INFO 140667699287680] Epoch[10] Batch [395]#011Speed: 1837.67 samples/sec#011loss=5.096644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[400] avg_epoch_loss=5.385205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=400 train loss <loss>=5.422248268127442\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [400]#011Speed: 1034.91 samples/sec#011loss=5.422248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[405] avg_epoch_loss=5.387277\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=405 train loss <loss>=5.553499984741211\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [405]#011Speed: 1770.63 samples/sec#011loss=5.553500\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[410] avg_epoch_loss=5.387037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=410 train loss <loss>=5.367502307891845\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [410]#011Speed: 1077.55 samples/sec#011loss=5.367502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[415] avg_epoch_loss=5.388491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=415 train loss <loss>=5.508052349090576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [415]#011Speed: 1772.14 samples/sec#011loss=5.508052\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[420] avg_epoch_loss=5.387177\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=420 train loss <loss>=5.277863025665283\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [420]#011Speed: 837.93 samples/sec#011loss=5.277863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[425] avg_epoch_loss=5.386424\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=425 train loss <loss>=5.323032379150391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [425]#011Speed: 1521.97 samples/sec#011loss=5.323032\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch[430] avg_epoch_loss=5.387436\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=430 train loss <loss>=5.473600101470947\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:01 INFO 140667699287680] Epoch[10] Batch [430]#011Speed: 897.47 samples/sec#011loss=5.473600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[435] avg_epoch_loss=5.386773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=435 train loss <loss>=5.329651546478272\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [435]#011Speed: 1976.57 samples/sec#011loss=5.329652\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[440] avg_epoch_loss=5.385890\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=440 train loss <loss>=5.308856582641601\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [440]#011Speed: 1029.94 samples/sec#011loss=5.308857\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[445] avg_epoch_loss=5.382686\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=445 train loss <loss>=5.1001355171203615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [445]#011Speed: 1821.18 samples/sec#011loss=5.100136\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[450] avg_epoch_loss=5.381569\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=450 train loss <loss>=5.281875801086426\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [450]#011Speed: 1087.21 samples/sec#011loss=5.281876\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[455] avg_epoch_loss=5.382154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=455 train loss <loss>=5.434939384460449\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [455]#011Speed: 1611.95 samples/sec#011loss=5.434939\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[460] avg_epoch_loss=5.383137\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=460 train loss <loss>=5.472832298278808\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [460]#011Speed: 1034.63 samples/sec#011loss=5.472832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[465] avg_epoch_loss=5.383101\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=465 train loss <loss>=5.379766654968262\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [465]#011Speed: 1778.67 samples/sec#011loss=5.379767\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[470] avg_epoch_loss=5.383638\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=470 train loss <loss>=5.4336838722229\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [470]#011Speed: 1110.44 samples/sec#011loss=5.433684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch[475] avg_epoch_loss=5.383667\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=475 train loss <loss>=5.386413478851319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:02 INFO 140667699287680] Epoch[10] Batch [475]#011Speed: 1850.54 samples/sec#011loss=5.386413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[480] avg_epoch_loss=5.380811\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=480 train loss <loss>=5.108854866027832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [480]#011Speed: 1094.89 samples/sec#011loss=5.108855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[485] avg_epoch_loss=5.382522\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=485 train loss <loss>=5.547155380249023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [485]#011Speed: 1927.05 samples/sec#011loss=5.547155\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[490] avg_epoch_loss=5.384107\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=490 train loss <loss>=5.538185882568359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [490]#011Speed: 1134.90 samples/sec#011loss=5.538186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[495] avg_epoch_loss=5.383644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=495 train loss <loss>=5.338190174102783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [495]#011Speed: 1834.10 samples/sec#011loss=5.338190\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[500] avg_epoch_loss=5.381962\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=500 train loss <loss>=5.215047168731689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [500]#011Speed: 1133.73 samples/sec#011loss=5.215047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[505] avg_epoch_loss=5.380713\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=505 train loss <loss>=5.255566501617432\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [505]#011Speed: 1872.10 samples/sec#011loss=5.255567\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[510] avg_epoch_loss=5.380785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=510 train loss <loss>=5.3880561828613285\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [510]#011Speed: 939.03 samples/sec#011loss=5.388056\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch[515] avg_epoch_loss=5.379835\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=515 train loss <loss>=5.282812786102295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:03 INFO 140667699287680] Epoch[10] Batch [515]#011Speed: 1598.41 samples/sec#011loss=5.282813\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[520] avg_epoch_loss=5.378144\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=520 train loss <loss>=5.203597831726074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [520]#011Speed: 1030.42 samples/sec#011loss=5.203598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[525] avg_epoch_loss=5.379205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=525 train loss <loss>=5.4898124694824215\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [525]#011Speed: 1562.15 samples/sec#011loss=5.489812\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[530] avg_epoch_loss=5.378993\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=530 train loss <loss>=5.356675910949707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [530]#011Speed: 977.63 samples/sec#011loss=5.356676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[535] avg_epoch_loss=5.380888\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=535 train loss <loss>=5.58207950592041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [535]#011Speed: 1675.18 samples/sec#011loss=5.582080\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[540] avg_epoch_loss=5.379534\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=540 train loss <loss>=5.234474945068359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [540]#011Speed: 1076.67 samples/sec#011loss=5.234475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[545] avg_epoch_loss=5.377126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=545 train loss <loss>=5.116581630706787\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [545]#011Speed: 1878.96 samples/sec#011loss=5.116582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch[550] avg_epoch_loss=5.374538\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, batch=550 train loss <loss>=5.091921424865722\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[10] Batch [550]#011Speed: 1387.81 samples/sec#011loss=5.091921\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] processed a total of 17739 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989931.4921007, \"EndTime\": 1620989944.8872738, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13395.108938217163, \"count\": 1, \"min\": 13395.108938217163, \"max\": 13395.108938217163}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1324.2756001549344 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=10, train loss <loss>=5.370645392907632\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] Epoch[11] Batch[0] avg_epoch_loss=5.909265\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=5.90926456451416\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[5] avg_epoch_loss=5.325940\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=5.325940370559692\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [5]#011Speed: 1506.55 samples/sec#011loss=5.325940\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[10] avg_epoch_loss=5.461986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=5.625241088867187\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [10]#011Speed: 841.53 samples/sec#011loss=5.625241\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[15] avg_epoch_loss=5.454747\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=5.438822460174561\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [15]#011Speed: 1525.08 samples/sec#011loss=5.438822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[20] avg_epoch_loss=5.409366\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=5.264143180847168\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [20]#011Speed: 902.94 samples/sec#011loss=5.264143\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[25] avg_epoch_loss=5.417487\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=5.451596069335937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [25]#011Speed: 1635.74 samples/sec#011loss=5.451596\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[30] avg_epoch_loss=5.418534\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=5.4239821434021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [30]#011Speed: 913.77 samples/sec#011loss=5.423982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch[35] avg_epoch_loss=5.380881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=5.147427272796631\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:05 INFO 140667699287680] Epoch[11] Batch [35]#011Speed: 1505.96 samples/sec#011loss=5.147427\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[40] avg_epoch_loss=5.347499\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=5.107150363922119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [40]#011Speed: 898.12 samples/sec#011loss=5.107150\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[45] avg_epoch_loss=5.317500\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=5.071513080596924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [45]#011Speed: 1613.92 samples/sec#011loss=5.071513\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[50] avg_epoch_loss=5.310819\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=5.2493537902832035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [50]#011Speed: 973.17 samples/sec#011loss=5.249354\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[55] avg_epoch_loss=5.292903\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=5.110154724121093\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [55]#011Speed: 1811.47 samples/sec#011loss=5.110155\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[60] avg_epoch_loss=5.307467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=5.470581912994385\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [60]#011Speed: 891.84 samples/sec#011loss=5.470582\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[65] avg_epoch_loss=5.306909\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=5.300108242034912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [65]#011Speed: 1728.08 samples/sec#011loss=5.300108\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[70] avg_epoch_loss=5.326171\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=5.580422306060791\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [70]#011Speed: 1053.83 samples/sec#011loss=5.580422\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch[75] avg_epoch_loss=5.329640\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=5.378902626037598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:06 INFO 140667699287680] Epoch[11] Batch [75]#011Speed: 1777.47 samples/sec#011loss=5.378903\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[80] avg_epoch_loss=5.325075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=5.255686950683594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [80]#011Speed: 954.97 samples/sec#011loss=5.255687\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[85] avg_epoch_loss=5.331030\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=5.427495956420898\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [85]#011Speed: 1843.89 samples/sec#011loss=5.427496\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[90] avg_epoch_loss=5.324832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=5.2182306289672855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [90]#011Speed: 1110.98 samples/sec#011loss=5.218231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[95] avg_epoch_loss=5.308796\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=5.016933631896973\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [95]#011Speed: 1828.86 samples/sec#011loss=5.016934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[100] avg_epoch_loss=5.316058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=5.455489253997802\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [100]#011Speed: 1139.91 samples/sec#011loss=5.455489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[105] avg_epoch_loss=5.317712\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=5.351138401031494\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [105]#011Speed: 1784.72 samples/sec#011loss=5.351138\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[110] avg_epoch_loss=5.312016\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=5.19124402999878\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [110]#011Speed: 1007.64 samples/sec#011loss=5.191244\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch[115] avg_epoch_loss=5.318032\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=5.451586723327637\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:07 INFO 140667699287680] Epoch[11] Batch [115]#011Speed: 1936.91 samples/sec#011loss=5.451587\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[120] avg_epoch_loss=5.317492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=5.304979133605957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [120]#011Speed: 1043.59 samples/sec#011loss=5.304979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[125] avg_epoch_loss=5.320344\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=5.389347743988037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [125]#011Speed: 1839.58 samples/sec#011loss=5.389348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[130] avg_epoch_loss=5.327503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=5.5079303741455075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [130]#011Speed: 1088.79 samples/sec#011loss=5.507930\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[135] avg_epoch_loss=5.321653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=5.168362140655518\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [135]#011Speed: 1939.73 samples/sec#011loss=5.168362\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[140] avg_epoch_loss=5.317946\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=5.217123031616211\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [140]#011Speed: 1084.04 samples/sec#011loss=5.217123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[145] avg_epoch_loss=5.308069\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=5.02953519821167\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [145]#011Speed: 2010.91 samples/sec#011loss=5.029535\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[150] avg_epoch_loss=5.310495\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=5.381336688995361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [150]#011Speed: 1124.47 samples/sec#011loss=5.381337\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch[155] avg_epoch_loss=5.317469\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=5.528085613250733\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:08 INFO 140667699287680] Epoch[11] Batch [155]#011Speed: 1695.88 samples/sec#011loss=5.528086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[160] avg_epoch_loss=5.317577\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=5.3209484100341795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [160]#011Speed: 1053.01 samples/sec#011loss=5.320948\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[165] avg_epoch_loss=5.324501\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=5.547462749481201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [165]#011Speed: 1940.34 samples/sec#011loss=5.547463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[170] avg_epoch_loss=5.317220\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=5.075478839874267\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [170]#011Speed: 1112.86 samples/sec#011loss=5.075479\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[175] avg_epoch_loss=5.322846\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=5.515255641937256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [175]#011Speed: 1922.15 samples/sec#011loss=5.515256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[180] avg_epoch_loss=5.321508\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=5.274406051635742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [180]#011Speed: 1111.81 samples/sec#011loss=5.274406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[185] avg_epoch_loss=5.322871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=5.372209644317627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [185]#011Speed: 1883.95 samples/sec#011loss=5.372210\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[190] avg_epoch_loss=5.323628\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=5.351805305480957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [190]#011Speed: 1134.26 samples/sec#011loss=5.351805\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[195] avg_epoch_loss=5.319231\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=5.151268100738525\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [195]#011Speed: 1640.24 samples/sec#011loss=5.151268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch[200] avg_epoch_loss=5.313144\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=5.074523258209228\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:09 INFO 140667699287680] Epoch[11] Batch [200]#011Speed: 1072.61 samples/sec#011loss=5.074523\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[205] avg_epoch_loss=5.311510\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=5.2458268165588375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [205]#011Speed: 1733.51 samples/sec#011loss=5.245827\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[210] avg_epoch_loss=5.312391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=5.348700046539307\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [210]#011Speed: 1097.29 samples/sec#011loss=5.348700\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[215] avg_epoch_loss=5.310934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=5.249420928955078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [215]#011Speed: 1868.14 samples/sec#011loss=5.249421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[220] avg_epoch_loss=5.307021\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=5.137977027893067\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [220]#011Speed: 1143.10 samples/sec#011loss=5.137977\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[225] avg_epoch_loss=5.306826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=5.298219490051269\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [225]#011Speed: 1710.98 samples/sec#011loss=5.298219\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[230] avg_epoch_loss=5.310916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=5.495760822296143\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [230]#011Speed: 1116.22 samples/sec#011loss=5.495761\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[235] avg_epoch_loss=5.308661\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=5.204491901397705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [235]#011Speed: 1969.82 samples/sec#011loss=5.204492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch[240] avg_epoch_loss=5.314589\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=5.594413471221924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:10 INFO 140667699287680] Epoch[11] Batch [240]#011Speed: 997.68 samples/sec#011loss=5.594413\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[245] avg_epoch_loss=5.317981\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=5.481472778320312\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [245]#011Speed: 1700.22 samples/sec#011loss=5.481473\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[250] avg_epoch_loss=5.322027\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=5.521087169647217\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [250]#011Speed: 1038.14 samples/sec#011loss=5.521087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[255] avg_epoch_loss=5.332134\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=5.839492511749268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [255]#011Speed: 1711.24 samples/sec#011loss=5.839493\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[260] avg_epoch_loss=5.335811\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=5.524063682556152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [260]#011Speed: 1113.62 samples/sec#011loss=5.524064\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[265] avg_epoch_loss=5.338221\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=5.46401309967041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [265]#011Speed: 1886.42 samples/sec#011loss=5.464013\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[270] avg_epoch_loss=5.337311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=270 train loss <loss>=5.288937950134278\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [270]#011Speed: 1005.74 samples/sec#011loss=5.288938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[275] avg_epoch_loss=5.338181\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=275 train loss <loss>=5.385324573516845\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [275]#011Speed: 1625.37 samples/sec#011loss=5.385325\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[280] avg_epoch_loss=5.338949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=280 train loss <loss>=5.381353282928467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [280]#011Speed: 1050.90 samples/sec#011loss=5.381353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch[285] avg_epoch_loss=5.335265\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=285 train loss <loss>=5.1281938552856445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:11 INFO 140667699287680] Epoch[11] Batch [285]#011Speed: 1939.65 samples/sec#011loss=5.128194\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[290] avg_epoch_loss=5.335107\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=290 train loss <loss>=5.326104068756104\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [290]#011Speed: 1137.19 samples/sec#011loss=5.326104\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[295] avg_epoch_loss=5.336714\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=295 train loss <loss>=5.430234909057617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [295]#011Speed: 1919.91 samples/sec#011loss=5.430235\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[300] avg_epoch_loss=5.339674\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=300 train loss <loss>=5.5148824691772464\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [300]#011Speed: 1135.38 samples/sec#011loss=5.514882\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[305] avg_epoch_loss=5.339914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=305 train loss <loss>=5.354378986358642\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [305]#011Speed: 1918.36 samples/sec#011loss=5.354379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[310] avg_epoch_loss=5.338625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=310 train loss <loss>=5.259744262695312\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [310]#011Speed: 1121.55 samples/sec#011loss=5.259744\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[315] avg_epoch_loss=5.340489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=315 train loss <loss>=5.45638952255249\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [315]#011Speed: 1900.30 samples/sec#011loss=5.456390\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[320] avg_epoch_loss=5.340077\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=320 train loss <loss>=5.314071750640869\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [320]#011Speed: 1123.93 samples/sec#011loss=5.314072\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch[325] avg_epoch_loss=5.341282\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=325 train loss <loss>=5.418616008758545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:12 INFO 140667699287680] Epoch[11] Batch [325]#011Speed: 1730.61 samples/sec#011loss=5.418616\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[330] avg_epoch_loss=5.343445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=330 train loss <loss>=5.484504699707031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [330]#011Speed: 999.69 samples/sec#011loss=5.484505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[335] avg_epoch_loss=5.339298\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=335 train loss <loss>=5.064791202545166\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [335]#011Speed: 1698.07 samples/sec#011loss=5.064791\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[340] avg_epoch_loss=5.337110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=340 train loss <loss>=5.190018653869629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [340]#011Speed: 1065.60 samples/sec#011loss=5.190019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[345] avg_epoch_loss=5.336059\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=345 train loss <loss>=5.264414501190186\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [345]#011Speed: 1819.16 samples/sec#011loss=5.264415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[350] avg_epoch_loss=5.337417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=350 train loss <loss>=5.431376266479492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [350]#011Speed: 1100.03 samples/sec#011loss=5.431376\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[355] avg_epoch_loss=5.341746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=355 train loss <loss>=5.645672225952149\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [355]#011Speed: 1873.32 samples/sec#011loss=5.645672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[360] avg_epoch_loss=5.342515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=360 train loss <loss>=5.397227096557617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [360]#011Speed: 1118.68 samples/sec#011loss=5.397227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[365] avg_epoch_loss=5.343150\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=365 train loss <loss>=5.389004230499268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [365]#011Speed: 1830.08 samples/sec#011loss=5.389004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch[370] avg_epoch_loss=5.342316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=370 train loss <loss>=5.281261444091797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:13 INFO 140667699287680] Epoch[11] Batch [370]#011Speed: 1017.55 samples/sec#011loss=5.281261\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[375] avg_epoch_loss=5.342581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=375 train loss <loss>=5.362259483337402\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [375]#011Speed: 1768.27 samples/sec#011loss=5.362259\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[380] avg_epoch_loss=5.346121\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=380 train loss <loss>=5.612309074401855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [380]#011Speed: 1050.81 samples/sec#011loss=5.612309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[385] avg_epoch_loss=5.346595\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=385 train loss <loss>=5.382702732086182\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [385]#011Speed: 1849.30 samples/sec#011loss=5.382703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[390] avg_epoch_loss=5.346479\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=390 train loss <loss>=5.337557125091553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [390]#011Speed: 988.75 samples/sec#011loss=5.337557\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[395] avg_epoch_loss=5.346320\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=395 train loss <loss>=5.333856105804443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [395]#011Speed: 1750.16 samples/sec#011loss=5.333856\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[400] avg_epoch_loss=5.347680\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=400 train loss <loss>=5.4554191589355465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [400]#011Speed: 1034.64 samples/sec#011loss=5.455419\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[405] avg_epoch_loss=5.346437\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=405 train loss <loss>=5.24678144454956\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [405]#011Speed: 1778.72 samples/sec#011loss=5.246781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch[410] avg_epoch_loss=5.344959\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=410 train loss <loss>=5.224917221069336\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:14 INFO 140667699287680] Epoch[11] Batch [410]#011Speed: 1076.38 samples/sec#011loss=5.224917\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[415] avg_epoch_loss=5.347690\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=415 train loss <loss>=5.572151374816895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [415]#011Speed: 1748.54 samples/sec#011loss=5.572151\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[420] avg_epoch_loss=5.346169\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=420 train loss <loss>=5.219668292999268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [420]#011Speed: 1090.59 samples/sec#011loss=5.219668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[425] avg_epoch_loss=5.347714\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=425 train loss <loss>=5.477791500091553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [425]#011Speed: 1895.11 samples/sec#011loss=5.477792\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[430] avg_epoch_loss=5.348206\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=430 train loss <loss>=5.39009370803833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [430]#011Speed: 1121.48 samples/sec#011loss=5.390094\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[435] avg_epoch_loss=5.347644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=435 train loss <loss>=5.2992167472839355\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [435]#011Speed: 1805.07 samples/sec#011loss=5.299217\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[440] avg_epoch_loss=5.347013\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=440 train loss <loss>=5.292005825042724\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [440]#011Speed: 1093.36 samples/sec#011loss=5.292006\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[445] avg_epoch_loss=5.342489\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=445 train loss <loss>=4.943475246429443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [445]#011Speed: 1818.63 samples/sec#011loss=4.943475\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch[450] avg_epoch_loss=5.341112\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=450 train loss <loss>=5.218238258361817\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:15 INFO 140667699287680] Epoch[11] Batch [450]#011Speed: 1044.35 samples/sec#011loss=5.218238\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[455] avg_epoch_loss=5.341376\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=455 train loss <loss>=5.365201091766357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [455]#011Speed: 1749.37 samples/sec#011loss=5.365201\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[460] avg_epoch_loss=5.338445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=460 train loss <loss>=5.071151256561279\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [460]#011Speed: 1005.90 samples/sec#011loss=5.071151\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[465] avg_epoch_loss=5.339043\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=465 train loss <loss>=5.394197750091553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [465]#011Speed: 1800.19 samples/sec#011loss=5.394198\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[470] avg_epoch_loss=5.339806\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=470 train loss <loss>=5.410913562774658\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [470]#011Speed: 1049.24 samples/sec#011loss=5.410914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[475] avg_epoch_loss=5.340415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=475 train loss <loss>=5.397751235961914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [475]#011Speed: 1897.79 samples/sec#011loss=5.397751\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[480] avg_epoch_loss=5.343065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=480 train loss <loss>=5.5953929901123045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [480]#011Speed: 1095.50 samples/sec#011loss=5.595393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[485] avg_epoch_loss=5.343995\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=485 train loss <loss>=5.433470726013184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [485]#011Speed: 1711.35 samples/sec#011loss=5.433471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[490] avg_epoch_loss=5.341543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=490 train loss <loss>=5.103196144104004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [490]#011Speed: 917.12 samples/sec#011loss=5.103196\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch[495] avg_epoch_loss=5.338971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=495 train loss <loss>=5.086403179168701\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:16 INFO 140667699287680] Epoch[11] Batch [495]#011Speed: 1753.75 samples/sec#011loss=5.086403\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[500] avg_epoch_loss=5.337154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=500 train loss <loss>=5.156891536712647\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [500]#011Speed: 1064.87 samples/sec#011loss=5.156892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[505] avg_epoch_loss=5.334736\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=505 train loss <loss>=5.092418956756592\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [505]#011Speed: 1841.71 samples/sec#011loss=5.092419\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[510] avg_epoch_loss=5.333370\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=510 train loss <loss>=5.195146465301514\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [510]#011Speed: 1094.80 samples/sec#011loss=5.195146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[515] avg_epoch_loss=5.333344\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=515 train loss <loss>=5.330653667449951\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [515]#011Speed: 1743.20 samples/sec#011loss=5.330654\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[520] avg_epoch_loss=5.334309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=520 train loss <loss>=5.433947658538818\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [520]#011Speed: 1108.66 samples/sec#011loss=5.433948\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[525] avg_epoch_loss=5.335294\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=525 train loss <loss>=5.437921810150146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [525]#011Speed: 1903.10 samples/sec#011loss=5.437922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[530] avg_epoch_loss=5.332513\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=530 train loss <loss>=5.0398962020874025\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [530]#011Speed: 1024.72 samples/sec#011loss=5.039896\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch[535] avg_epoch_loss=5.332588\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=535 train loss <loss>=5.3405906677246096\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:17 INFO 140667699287680] Epoch[11] Batch [535]#011Speed: 1655.77 samples/sec#011loss=5.340591\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[11] Batch[540] avg_epoch_loss=5.332426\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=540 train loss <loss>=5.315018939971924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[11] Batch [540]#011Speed: 1041.57 samples/sec#011loss=5.315019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[11] Batch[545] avg_epoch_loss=5.330862\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=545 train loss <loss>=5.161648845672607\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[11] Batch [545]#011Speed: 1891.23 samples/sec#011loss=5.161649\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[11] Batch[550] avg_epoch_loss=5.330359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, batch=550 train loss <loss>=5.275471115112305\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[11] Batch [550]#011Speed: 1499.74 samples/sec#011loss=5.275471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] processed a total of 17716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989944.8873706, \"EndTime\": 1620989958.3543653, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13466.46237373352, \"count\": 1, \"min\": 13466.46237373352, \"max\": 13466.46237373352}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1315.554310293164 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=11, train loss <loss>=5.326488803440053\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_d5b882fa-059c-4c7f-873e-fd371bbfb45d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989958.3544395, \"EndTime\": 1620989958.363091, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.23211669921875, \"count\": 1, \"min\": 8.23211669921875, \"max\": 8.23211669921875}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch[0] avg_epoch_loss=5.822244\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=5.822243690490723\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch[5] avg_epoch_loss=5.400379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=5.400378704071045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch [5]#011Speed: 1888.90 samples/sec#011loss=5.400379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch[10] avg_epoch_loss=5.390540\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=5.378733539581299\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch [10]#011Speed: 1065.29 samples/sec#011loss=5.378734\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch[15] avg_epoch_loss=5.343945\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=5.2414346694946286\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch [15]#011Speed: 1854.36 samples/sec#011loss=5.241435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch[20] avg_epoch_loss=5.369046\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=5.449371242523194\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:18 INFO 140667699287680] Epoch[12] Batch [20]#011Speed: 983.03 samples/sec#011loss=5.449371\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[25] avg_epoch_loss=5.348912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=5.264346885681152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [25]#011Speed: 1715.82 samples/sec#011loss=5.264347\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[30] avg_epoch_loss=5.330537\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=5.23498945236206\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [30]#011Speed: 1057.89 samples/sec#011loss=5.234989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[35] avg_epoch_loss=5.350677\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=5.475544738769531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [35]#011Speed: 1879.31 samples/sec#011loss=5.475545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[40] avg_epoch_loss=5.336184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=5.231833457946777\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [40]#011Speed: 1098.13 samples/sec#011loss=5.231833\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[45] avg_epoch_loss=5.315634\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=5.1471258163452145\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [45]#011Speed: 1863.74 samples/sec#011loss=5.147126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[50] avg_epoch_loss=5.319617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=5.356263256072998\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [50]#011Speed: 1132.66 samples/sec#011loss=5.356263\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[55] avg_epoch_loss=5.330360\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=5.439934158325196\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [55]#011Speed: 1890.34 samples/sec#011loss=5.439934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[60] avg_epoch_loss=5.315046\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=5.143526935577393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [60]#011Speed: 1097.10 samples/sec#011loss=5.143527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch[65] avg_epoch_loss=5.316878\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=5.339230060577393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:19 INFO 140667699287680] Epoch[12] Batch [65]#011Speed: 1904.39 samples/sec#011loss=5.339230\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[70] avg_epoch_loss=5.303002\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=5.11984224319458\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [70]#011Speed: 1054.86 samples/sec#011loss=5.119842\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[75] avg_epoch_loss=5.306297\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=5.353089141845703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [75]#011Speed: 1918.85 samples/sec#011loss=5.353089\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[80] avg_epoch_loss=5.305243\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=5.289213466644287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [80]#011Speed: 1104.67 samples/sec#011loss=5.289213\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[85] avg_epoch_loss=5.288053\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=5.009574699401855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [85]#011Speed: 1738.46 samples/sec#011loss=5.009575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[90] avg_epoch_loss=5.290568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=5.333823204040527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [90]#011Speed: 1089.51 samples/sec#011loss=5.333823\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[95] avg_epoch_loss=5.287910\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=5.2395401954650875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [95]#011Speed: 1795.15 samples/sec#011loss=5.239540\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[100] avg_epoch_loss=5.280028\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=5.128697490692138\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [100]#011Speed: 1070.36 samples/sec#011loss=5.128697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch[105] avg_epoch_loss=5.287619\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=5.4409482955932615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:20 INFO 140667699287680] Epoch[12] Batch [105]#011Speed: 1793.09 samples/sec#011loss=5.440948\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[110] avg_epoch_loss=5.282149\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=5.166187381744384\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [110]#011Speed: 1003.34 samples/sec#011loss=5.166187\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[115] avg_epoch_loss=5.278397\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=5.19511661529541\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [115]#011Speed: 1759.60 samples/sec#011loss=5.195117\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[120] avg_epoch_loss=5.284826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=5.433960056304931\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [120]#011Speed: 1077.22 samples/sec#011loss=5.433960\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[125] avg_epoch_loss=5.280233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=5.169095993041992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [125]#011Speed: 1891.93 samples/sec#011loss=5.169096\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[130] avg_epoch_loss=5.276804\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=5.190386390686035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [130]#011Speed: 1053.97 samples/sec#011loss=5.190386\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[135] avg_epoch_loss=5.265810\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=4.9777806282043455\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [135]#011Speed: 1900.10 samples/sec#011loss=4.977781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[140] avg_epoch_loss=5.270151\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=5.3882091522216795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [140]#011Speed: 1128.01 samples/sec#011loss=5.388209\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch[145] avg_epoch_loss=5.269705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=5.257122421264649\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:21 INFO 140667699287680] Epoch[12] Batch [145]#011Speed: 1579.24 samples/sec#011loss=5.257122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[150] avg_epoch_loss=5.269375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=5.259758377075196\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [150]#011Speed: 957.40 samples/sec#011loss=5.259758\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[155] avg_epoch_loss=5.266112\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=5.167553806304932\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [155]#011Speed: 1710.31 samples/sec#011loss=5.167554\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[160] avg_epoch_loss=5.264080\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=5.200679016113281\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [160]#011Speed: 1089.08 samples/sec#011loss=5.200679\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[165] avg_epoch_loss=5.266794\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=5.354194259643554\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [165]#011Speed: 1819.68 samples/sec#011loss=5.354194\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[170] avg_epoch_loss=5.274609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=5.534064197540284\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [170]#011Speed: 1082.17 samples/sec#011loss=5.534064\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[175] avg_epoch_loss=5.274908\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=5.285125064849853\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [175]#011Speed: 1608.45 samples/sec#011loss=5.285125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[180] avg_epoch_loss=5.277125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=5.355189990997315\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [180]#011Speed: 1084.13 samples/sec#011loss=5.355190\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[185] avg_epoch_loss=5.275346\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=5.210933971405029\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [185]#011Speed: 1641.90 samples/sec#011loss=5.210934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch[190] avg_epoch_loss=5.283878\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=5.60125150680542\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:22 INFO 140667699287680] Epoch[12] Batch [190]#011Speed: 1040.50 samples/sec#011loss=5.601252\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[195] avg_epoch_loss=5.287127\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=5.4112451553344725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [195]#011Speed: 1642.12 samples/sec#011loss=5.411245\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[200] avg_epoch_loss=5.280902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=5.036897468566894\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [200]#011Speed: 1100.93 samples/sec#011loss=5.036897\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[205] avg_epoch_loss=5.285502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=5.470426177978515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [205]#011Speed: 1861.67 samples/sec#011loss=5.470426\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[210] avg_epoch_loss=5.284806\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=5.256137561798096\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [210]#011Speed: 1110.23 samples/sec#011loss=5.256138\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[215] avg_epoch_loss=5.280063\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=5.079899406433105\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [215]#011Speed: 1966.58 samples/sec#011loss=5.079899\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[220] avg_epoch_loss=5.277799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=5.179999351501465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [220]#011Speed: 1102.96 samples/sec#011loss=5.179999\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[225] avg_epoch_loss=5.272227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=5.025912189483643\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [225]#011Speed: 1950.43 samples/sec#011loss=5.025912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch[230] avg_epoch_loss=5.266276\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=4.997328567504883\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:23 INFO 140667699287680] Epoch[12] Batch [230]#011Speed: 1131.35 samples/sec#011loss=4.997329\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[235] avg_epoch_loss=5.265601\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=5.234407711029053\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [235]#011Speed: 1819.42 samples/sec#011loss=5.234408\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[240] avg_epoch_loss=5.263915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=5.18432388305664\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [240]#011Speed: 1128.66 samples/sec#011loss=5.184324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[245] avg_epoch_loss=5.265544\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=5.344066905975342\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [245]#011Speed: 1956.38 samples/sec#011loss=5.344067\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[250] avg_epoch_loss=5.266013\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=5.289098072052002\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [250]#011Speed: 1054.72 samples/sec#011loss=5.289098\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[255] avg_epoch_loss=5.266074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=5.269143962860108\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [255]#011Speed: 1827.73 samples/sec#011loss=5.269144\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[260] avg_epoch_loss=5.270031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=5.472605609893799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [260]#011Speed: 1136.62 samples/sec#011loss=5.472606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[265] avg_epoch_loss=5.269724\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=5.253687953948974\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [265]#011Speed: 1918.23 samples/sec#011loss=5.253688\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[270] avg_epoch_loss=5.268154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=270 train loss <loss>=5.184644317626953\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [270]#011Speed: 1042.72 samples/sec#011loss=5.184644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch[275] avg_epoch_loss=5.271018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=275 train loss <loss>=5.426217269897461\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:24 INFO 140667699287680] Epoch[12] Batch [275]#011Speed: 1798.48 samples/sec#011loss=5.426217\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[280] avg_epoch_loss=5.271322\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=280 train loss <loss>=5.288156223297119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [280]#011Speed: 1087.43 samples/sec#011loss=5.288156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[285] avg_epoch_loss=5.269317\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=285 train loss <loss>=5.156590557098388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [285]#011Speed: 1808.74 samples/sec#011loss=5.156591\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[290] avg_epoch_loss=5.265306\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=290 train loss <loss>=5.035922527313232\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [290]#011Speed: 1062.78 samples/sec#011loss=5.035923\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[295] avg_epoch_loss=5.265122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=295 train loss <loss>=5.254380798339843\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [295]#011Speed: 1684.97 samples/sec#011loss=5.254381\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[300] avg_epoch_loss=5.263000\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=300 train loss <loss>=5.137376976013184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [300]#011Speed: 1098.82 samples/sec#011loss=5.137377\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[305] avg_epoch_loss=5.263505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=305 train loss <loss>=5.293889713287354\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [305]#011Speed: 1638.98 samples/sec#011loss=5.293890\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[310] avg_epoch_loss=5.265966\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=310 train loss <loss>=5.4165754318237305\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [310]#011Speed: 1028.06 samples/sec#011loss=5.416575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch[315] avg_epoch_loss=5.270324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=315 train loss <loss>=5.541417789459229\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:25 INFO 140667699287680] Epoch[12] Batch [315]#011Speed: 1641.84 samples/sec#011loss=5.541418\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[320] avg_epoch_loss=5.270723\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=320 train loss <loss>=5.295919513702392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [320]#011Speed: 1069.49 samples/sec#011loss=5.295920\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[325] avg_epoch_loss=5.272184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=325 train loss <loss>=5.366018295288086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [325]#011Speed: 1855.97 samples/sec#011loss=5.366018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[330] avg_epoch_loss=5.271912\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=330 train loss <loss>=5.254126262664795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [330]#011Speed: 1149.41 samples/sec#011loss=5.254126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[335] avg_epoch_loss=5.274883\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=335 train loss <loss>=5.471583652496338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [335]#011Speed: 1950.49 samples/sec#011loss=5.471584\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[340] avg_epoch_loss=5.274987\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=340 train loss <loss>=5.28200855255127\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [340]#011Speed: 1123.88 samples/sec#011loss=5.282009\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[345] avg_epoch_loss=5.272572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=345 train loss <loss>=5.107852268218994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [345]#011Speed: 1837.68 samples/sec#011loss=5.107852\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[350] avg_epoch_loss=5.274508\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=350 train loss <loss>=5.408483505249023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [350]#011Speed: 1109.90 samples/sec#011loss=5.408484\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[355] avg_epoch_loss=5.274354\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=355 train loss <loss>=5.263502979278565\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [355]#011Speed: 1931.12 samples/sec#011loss=5.263503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch[360] avg_epoch_loss=5.272853\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=360 train loss <loss>=5.166010951995849\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:26 INFO 140667699287680] Epoch[12] Batch [360]#011Speed: 1009.37 samples/sec#011loss=5.166011\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[365] avg_epoch_loss=5.272755\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=365 train loss <loss>=5.265673446655273\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [365]#011Speed: 1920.07 samples/sec#011loss=5.265673\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[370] avg_epoch_loss=5.273118\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=370 train loss <loss>=5.299706172943115\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [370]#011Speed: 1073.53 samples/sec#011loss=5.299706\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[375] avg_epoch_loss=5.275860\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=375 train loss <loss>=5.4793164253234865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [375]#011Speed: 1797.59 samples/sec#011loss=5.479316\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[380] avg_epoch_loss=5.276834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=380 train loss <loss>=5.350070476531982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [380]#011Speed: 1075.87 samples/sec#011loss=5.350070\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[385] avg_epoch_loss=5.273711\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=385 train loss <loss>=5.0357739448547365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [385]#011Speed: 1922.60 samples/sec#011loss=5.035774\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[390] avg_epoch_loss=5.274079\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=390 train loss <loss>=5.302415752410889\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [390]#011Speed: 1124.35 samples/sec#011loss=5.302416\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[395] avg_epoch_loss=5.272044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=395 train loss <loss>=5.1129615783691404\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [395]#011Speed: 1920.11 samples/sec#011loss=5.112962\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch[400] avg_epoch_loss=5.273311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=400 train loss <loss>=5.373630142211914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:27 INFO 140667699287680] Epoch[12] Batch [400]#011Speed: 1058.02 samples/sec#011loss=5.373630\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[405] avg_epoch_loss=5.271486\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=405 train loss <loss>=5.125125694274902\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [405]#011Speed: 1826.74 samples/sec#011loss=5.125126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[410] avg_epoch_loss=5.273141\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=410 train loss <loss>=5.4075212478637695\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [410]#011Speed: 1070.28 samples/sec#011loss=5.407521\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[415] avg_epoch_loss=5.273956\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=415 train loss <loss>=5.340931701660156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [415]#011Speed: 1615.65 samples/sec#011loss=5.340932\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[420] avg_epoch_loss=5.274061\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=420 train loss <loss>=5.2828339576721195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [420]#011Speed: 1106.48 samples/sec#011loss=5.282834\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[425] avg_epoch_loss=5.274668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=425 train loss <loss>=5.32576322555542\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [425]#011Speed: 1697.03 samples/sec#011loss=5.325763\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[430] avg_epoch_loss=5.274259\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=430 train loss <loss>=5.239450931549072\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [430]#011Speed: 1040.18 samples/sec#011loss=5.239451\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[435] avg_epoch_loss=5.273717\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=435 train loss <loss>=5.227007293701172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [435]#011Speed: 1825.89 samples/sec#011loss=5.227007\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[440] avg_epoch_loss=5.276073\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=440 train loss <loss>=5.481447982788086\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [440]#011Speed: 1045.08 samples/sec#011loss=5.481448\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch[445] avg_epoch_loss=5.275540\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=445 train loss <loss>=5.22852087020874\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:28 INFO 140667699287680] Epoch[12] Batch [445]#011Speed: 1853.19 samples/sec#011loss=5.228521\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[450] avg_epoch_loss=5.275585\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=450 train loss <loss>=5.279673004150391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [450]#011Speed: 1085.24 samples/sec#011loss=5.279673\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[455] avg_epoch_loss=5.275651\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=455 train loss <loss>=5.281584930419922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [455]#011Speed: 1708.14 samples/sec#011loss=5.281585\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[460] avg_epoch_loss=5.276110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=460 train loss <loss>=5.317929363250732\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [460]#011Speed: 1043.64 samples/sec#011loss=5.317929\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[465] avg_epoch_loss=5.275797\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=465 train loss <loss>=5.246993350982666\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [465]#011Speed: 1774.70 samples/sec#011loss=5.246993\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[470] avg_epoch_loss=5.276858\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=470 train loss <loss>=5.375679302215576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [470]#011Speed: 1131.64 samples/sec#011loss=5.375679\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[475] avg_epoch_loss=5.277474\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=475 train loss <loss>=5.335562419891358\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [475]#011Speed: 1959.63 samples/sec#011loss=5.335562\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[480] avg_epoch_loss=5.277172\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=480 train loss <loss>=5.248412418365478\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [480]#011Speed: 1119.55 samples/sec#011loss=5.248412\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch[485] avg_epoch_loss=5.279814\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=485 train loss <loss>=5.533971786499023\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:29 INFO 140667699287680] Epoch[12] Batch [485]#011Speed: 1894.40 samples/sec#011loss=5.533972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[490] avg_epoch_loss=5.280693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=490 train loss <loss>=5.366110134124756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [490]#011Speed: 1076.64 samples/sec#011loss=5.366110\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[495] avg_epoch_loss=5.281340\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=495 train loss <loss>=5.344829940795899\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [495]#011Speed: 1863.08 samples/sec#011loss=5.344830\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[500] avg_epoch_loss=5.281503\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=500 train loss <loss>=5.297697067260742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [500]#011Speed: 1071.89 samples/sec#011loss=5.297697\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[505] avg_epoch_loss=5.281350\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=505 train loss <loss>=5.266073894500733\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [505]#011Speed: 1846.02 samples/sec#011loss=5.266074\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[510] avg_epoch_loss=5.280506\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=510 train loss <loss>=5.195057678222656\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [510]#011Speed: 1122.56 samples/sec#011loss=5.195058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[515] avg_epoch_loss=5.280358\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=515 train loss <loss>=5.265257930755615\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [515]#011Speed: 1940.84 samples/sec#011loss=5.265258\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[520] avg_epoch_loss=5.279737\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=520 train loss <loss>=5.215627765655517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [520]#011Speed: 1051.21 samples/sec#011loss=5.215628\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[525] avg_epoch_loss=5.283398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=525 train loss <loss>=5.6649223327636715\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [525]#011Speed: 1669.53 samples/sec#011loss=5.664922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch[530] avg_epoch_loss=5.281672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=530 train loss <loss>=5.10009355545044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:30 INFO 140667699287680] Epoch[12] Batch [530]#011Speed: 1096.88 samples/sec#011loss=5.100094\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch[535] avg_epoch_loss=5.282638\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=535 train loss <loss>=5.385178947448731\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch [535]#011Speed: 1840.53 samples/sec#011loss=5.385179\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch[540] avg_epoch_loss=5.279971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=540 train loss <loss>=4.994107723236084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch [540]#011Speed: 1026.86 samples/sec#011loss=4.994108\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch[545] avg_epoch_loss=5.279984\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=545 train loss <loss>=5.281398773193359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch [545]#011Speed: 1712.63 samples/sec#011loss=5.281399\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch[550] avg_epoch_loss=5.279389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=550 train loss <loss>=5.214334487915039\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch [550]#011Speed: 1283.53 samples/sec#011loss=5.214334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch[555] avg_epoch_loss=5.277855\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, batch=555 train loss <loss>=5.1087925910949705\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[12] Batch [555]#011Speed: 1632.68 samples/sec#011loss=5.108793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] processed a total of 17836 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989958.363139, \"EndTime\": 1620989971.5922313, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13229.033708572388, \"count\": 1, \"min\": 13229.033708572388, \"max\": 13229.033708572388}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1348.2368775815737 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=12, train loss <loss>=5.280114249943832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_f074ca4f-dc11-4b1b-8c04-3b8a7f380f45-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989971.5922952, \"EndTime\": 1620989971.6007981, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.080244064331055, \"count\": 1, \"min\": 8.080244064331055, \"max\": 8.080244064331055}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[13] Batch[0] avg_epoch_loss=6.775338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=6.775338172912598\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[13] Batch[5] avg_epoch_loss=5.609392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=5.609392325083415\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[13] Batch [5]#011Speed: 1761.51 samples/sec#011loss=5.609392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[13] Batch[10] avg_epoch_loss=5.474268\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=5.312119388580323\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:31 INFO 140667699287680] Epoch[13] Batch [10]#011Speed: 1116.69 samples/sec#011loss=5.312119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[15] avg_epoch_loss=5.448686\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=5.392404556274414\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [15]#011Speed: 1816.37 samples/sec#011loss=5.392405\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[20] avg_epoch_loss=5.476853\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=5.566988945007324\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [20]#011Speed: 962.46 samples/sec#011loss=5.566989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[25] avg_epoch_loss=5.390668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=5.028688716888428\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [25]#011Speed: 1691.70 samples/sec#011loss=5.028689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[30] avg_epoch_loss=5.396689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=5.428000545501709\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [30]#011Speed: 1026.19 samples/sec#011loss=5.428001\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[35] avg_epoch_loss=5.387065\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=5.327392578125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [35]#011Speed: 1720.83 samples/sec#011loss=5.327393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[40] avg_epoch_loss=5.376825\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=5.30310173034668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [40]#011Speed: 1103.07 samples/sec#011loss=5.303102\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[45] avg_epoch_loss=5.356031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=5.18551721572876\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [45]#011Speed: 1910.09 samples/sec#011loss=5.185517\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[50] avg_epoch_loss=5.350841\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=5.303095436096191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [50]#011Speed: 1111.01 samples/sec#011loss=5.303095\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch[55] avg_epoch_loss=5.338910\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=5.217209911346435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:32 INFO 140667699287680] Epoch[13] Batch [55]#011Speed: 1941.70 samples/sec#011loss=5.217210\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[60] avg_epoch_loss=5.332577\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=5.261650466918946\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [60]#011Speed: 1004.86 samples/sec#011loss=5.261650\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[65] avg_epoch_loss=5.330234\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=5.301644229888916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [65]#011Speed: 1892.17 samples/sec#011loss=5.301644\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[70] avg_epoch_loss=5.345035\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=5.540417289733886\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [70]#011Speed: 1038.05 samples/sec#011loss=5.540417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[75] avg_epoch_loss=5.347729\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=5.3859786033630375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [75]#011Speed: 1917.62 samples/sec#011loss=5.385979\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[80] avg_epoch_loss=5.346579\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=5.329104423522949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [80]#011Speed: 1136.14 samples/sec#011loss=5.329104\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[85] avg_epoch_loss=5.337873\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=5.196829032897949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [85]#011Speed: 1840.83 samples/sec#011loss=5.196829\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[90] avg_epoch_loss=5.338746\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=5.353772258758545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [90]#011Speed: 1135.25 samples/sec#011loss=5.353772\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch[95] avg_epoch_loss=5.336558\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=5.296724605560303\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:33 INFO 140667699287680] Epoch[13] Batch [95]#011Speed: 1870.62 samples/sec#011loss=5.296725\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[100] avg_epoch_loss=5.344447\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=5.495913028717041\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [100]#011Speed: 1121.12 samples/sec#011loss=5.495913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[105] avg_epoch_loss=5.342606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=5.305416774749756\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [105]#011Speed: 1682.82 samples/sec#011loss=5.305417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[110] avg_epoch_loss=5.338660\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=5.2550050735473635\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [110]#011Speed: 1144.92 samples/sec#011loss=5.255005\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[115] avg_epoch_loss=5.340567\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=5.38291711807251\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [115]#011Speed: 1716.82 samples/sec#011loss=5.382917\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[120] avg_epoch_loss=5.331349\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=5.11748628616333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [120]#011Speed: 1079.83 samples/sec#011loss=5.117486\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[125] avg_epoch_loss=5.325031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=5.172123146057129\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [125]#011Speed: 1686.51 samples/sec#011loss=5.172123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[130] avg_epoch_loss=5.319077\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=5.169040012359619\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [130]#011Speed: 1043.55 samples/sec#011loss=5.169040\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch[135] avg_epoch_loss=5.313421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=5.1652405738830565\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:34 INFO 140667699287680] Epoch[13] Batch [135]#011Speed: 1769.93 samples/sec#011loss=5.165241\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[140] avg_epoch_loss=5.309553\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=5.204334354400634\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [140]#011Speed: 1116.84 samples/sec#011loss=5.204334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[145] avg_epoch_loss=5.311037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=5.352899074554443\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [145]#011Speed: 1583.00 samples/sec#011loss=5.352899\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[150] avg_epoch_loss=5.308704\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=5.24057445526123\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [150]#011Speed: 1029.21 samples/sec#011loss=5.240574\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[155] avg_epoch_loss=5.303799\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=5.155653095245361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [155]#011Speed: 1646.18 samples/sec#011loss=5.155653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[160] avg_epoch_loss=5.301402\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=5.226622581481934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [160]#011Speed: 1055.29 samples/sec#011loss=5.226623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[165] avg_epoch_loss=5.304661\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=5.409617805480957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [165]#011Speed: 1892.29 samples/sec#011loss=5.409618\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[170] avg_epoch_loss=5.304219\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=5.289535427093506\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [170]#011Speed: 1056.13 samples/sec#011loss=5.289535\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[175] avg_epoch_loss=5.301784\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=5.218520832061768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [175]#011Speed: 1843.25 samples/sec#011loss=5.218521\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch[180] avg_epoch_loss=5.301913\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=5.3064557075500485\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:35 INFO 140667699287680] Epoch[13] Batch [180]#011Speed: 1053.11 samples/sec#011loss=5.306456\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[185] avg_epoch_loss=5.299195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=5.200792980194092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [185]#011Speed: 1678.78 samples/sec#011loss=5.200793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[190] avg_epoch_loss=5.298505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=5.2728166580200195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [190]#011Speed: 1048.66 samples/sec#011loss=5.272817\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[195] avg_epoch_loss=5.292814\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=5.075442314147949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [195]#011Speed: 1714.45 samples/sec#011loss=5.075442\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[200] avg_epoch_loss=5.288495\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=5.119174957275391\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [200]#011Speed: 1087.77 samples/sec#011loss=5.119175\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[205] avg_epoch_loss=5.288357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=5.282822990417481\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [205]#011Speed: 1908.25 samples/sec#011loss=5.282823\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[210] avg_epoch_loss=5.286949\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=5.228930854797364\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [210]#011Speed: 1088.37 samples/sec#011loss=5.228931\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[215] avg_epoch_loss=5.293639\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=5.575975131988526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [215]#011Speed: 1919.39 samples/sec#011loss=5.575975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch[220] avg_epoch_loss=5.293900\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=5.305177974700928\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:36 INFO 140667699287680] Epoch[13] Batch [220]#011Speed: 1141.03 samples/sec#011loss=5.305178\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[225] avg_epoch_loss=5.294575\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=5.324373340606689\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [225]#011Speed: 1801.29 samples/sec#011loss=5.324373\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[230] avg_epoch_loss=5.291984\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=5.17488317489624\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [230]#011Speed: 897.69 samples/sec#011loss=5.174883\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[235] avg_epoch_loss=5.288356\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=5.12073860168457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [235]#011Speed: 1870.55 samples/sec#011loss=5.120739\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[240] avg_epoch_loss=5.287895\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=5.266143417358398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [240]#011Speed: 931.54 samples/sec#011loss=5.266143\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[245] avg_epoch_loss=5.287972\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=5.291667747497558\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [245]#011Speed: 1954.94 samples/sec#011loss=5.291668\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[250] avg_epoch_loss=5.286667\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=5.222488498687744\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [250]#011Speed: 1108.67 samples/sec#011loss=5.222488\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[255] avg_epoch_loss=5.285075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=5.2051393508911135\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [255]#011Speed: 1944.85 samples/sec#011loss=5.205139\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[260] avg_epoch_loss=5.285854\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=5.325767612457275\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [260]#011Speed: 1052.77 samples/sec#011loss=5.325768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch[265] avg_epoch_loss=5.285025\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=5.241718292236328\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:37 INFO 140667699287680] Epoch[13] Batch [265]#011Speed: 1923.80 samples/sec#011loss=5.241718\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[270] avg_epoch_loss=5.283686\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=270 train loss <loss>=5.212449645996093\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [270]#011Speed: 1068.85 samples/sec#011loss=5.212450\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[275] avg_epoch_loss=5.279305\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=275 train loss <loss>=5.041891860961914\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [275]#011Speed: 1899.24 samples/sec#011loss=5.041892\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[280] avg_epoch_loss=5.279163\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=280 train loss <loss>=5.271282196044922\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [280]#011Speed: 1039.15 samples/sec#011loss=5.271282\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[285] avg_epoch_loss=5.278125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=285 train loss <loss>=5.2197826385498045\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [285]#011Speed: 1764.55 samples/sec#011loss=5.219783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[290] avg_epoch_loss=5.276477\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=290 train loss <loss>=5.182209873199463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [290]#011Speed: 1110.31 samples/sec#011loss=5.182210\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[295] avg_epoch_loss=5.274244\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=295 train loss <loss>=5.144298076629639\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [295]#011Speed: 1857.44 samples/sec#011loss=5.144298\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[300] avg_epoch_loss=5.274765\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=300 train loss <loss>=5.305609893798828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [300]#011Speed: 1048.64 samples/sec#011loss=5.305610\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch[305] avg_epoch_loss=5.272981\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=305 train loss <loss>=5.16558141708374\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:38 INFO 140667699287680] Epoch[13] Batch [305]#011Speed: 1743.84 samples/sec#011loss=5.165581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[310] avg_epoch_loss=5.274068\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=310 train loss <loss>=5.34058027267456\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [310]#011Speed: 1057.88 samples/sec#011loss=5.340580\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[315] avg_epoch_loss=5.271618\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=315 train loss <loss>=5.119276618957519\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [315]#011Speed: 1780.39 samples/sec#011loss=5.119277\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[320] avg_epoch_loss=5.270621\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=320 train loss <loss>=5.207592868804932\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [320]#011Speed: 1105.05 samples/sec#011loss=5.207593\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[325] avg_epoch_loss=5.266842\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=325 train loss <loss>=5.024214458465576\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [325]#011Speed: 1943.69 samples/sec#011loss=5.024214\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[330] avg_epoch_loss=5.263306\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=330 train loss <loss>=5.0327756881713865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [330]#011Speed: 1012.19 samples/sec#011loss=5.032776\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[335] avg_epoch_loss=5.260279\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=335 train loss <loss>=5.059878826141357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [335]#011Speed: 1878.62 samples/sec#011loss=5.059879\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[340] avg_epoch_loss=5.259269\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=340 train loss <loss>=5.191429901123047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [340]#011Speed: 1023.13 samples/sec#011loss=5.191430\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch[345] avg_epoch_loss=5.258793\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=345 train loss <loss>=5.226328277587891\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:39 INFO 140667699287680] Epoch[13] Batch [345]#011Speed: 1584.38 samples/sec#011loss=5.226328\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[350] avg_epoch_loss=5.259456\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=350 train loss <loss>=5.305283164978027\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [350]#011Speed: 1083.74 samples/sec#011loss=5.305283\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[355] avg_epoch_loss=5.258452\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=355 train loss <loss>=5.187991905212402\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [355]#011Speed: 1755.41 samples/sec#011loss=5.187992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[360] avg_epoch_loss=5.258011\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=360 train loss <loss>=5.226634693145752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [360]#011Speed: 1020.01 samples/sec#011loss=5.226635\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[365] avg_epoch_loss=5.258739\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=365 train loss <loss>=5.311271286010742\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [365]#011Speed: 1666.11 samples/sec#011loss=5.311271\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[370] avg_epoch_loss=5.257971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=370 train loss <loss>=5.201739120483398\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [370]#011Speed: 1000.77 samples/sec#011loss=5.201739\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[375] avg_epoch_loss=5.255948\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=375 train loss <loss>=5.105863761901856\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [375]#011Speed: 1697.57 samples/sec#011loss=5.105864\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[380] avg_epoch_loss=5.256676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=380 train loss <loss>=5.3114439964294435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [380]#011Speed: 1042.83 samples/sec#011loss=5.311444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch[385] avg_epoch_loss=5.255361\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=385 train loss <loss>=5.1551305770874025\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:40 INFO 140667699287680] Epoch[13] Batch [385]#011Speed: 1790.13 samples/sec#011loss=5.155131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[390] avg_epoch_loss=5.256230\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=390 train loss <loss>=5.32329797744751\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [390]#011Speed: 1007.46 samples/sec#011loss=5.323298\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[395] avg_epoch_loss=5.255309\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=395 train loss <loss>=5.183348369598389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [395]#011Speed: 1686.69 samples/sec#011loss=5.183348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[400] avg_epoch_loss=5.256760\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=400 train loss <loss>=5.371629428863526\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [400]#011Speed: 1054.20 samples/sec#011loss=5.371629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[405] avg_epoch_loss=5.254084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=405 train loss <loss>=5.039455890655518\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [405]#011Speed: 1856.51 samples/sec#011loss=5.039456\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[410] avg_epoch_loss=5.254360\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=410 train loss <loss>=5.276809024810791\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [410]#011Speed: 1135.48 samples/sec#011loss=5.276809\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[415] avg_epoch_loss=5.255198\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=415 train loss <loss>=5.324100971221924\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [415]#011Speed: 1954.53 samples/sec#011loss=5.324101\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[420] avg_epoch_loss=5.255509\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=420 train loss <loss>=5.281332969665527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [420]#011Speed: 1138.96 samples/sec#011loss=5.281333\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[425] avg_epoch_loss=5.255054\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=425 train loss <loss>=5.216772651672363\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [425]#011Speed: 1922.44 samples/sec#011loss=5.216773\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch[430] avg_epoch_loss=5.254356\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=430 train loss <loss>=5.194906997680664\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:41 INFO 140667699287680] Epoch[13] Batch [430]#011Speed: 1143.19 samples/sec#011loss=5.194907\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[435] avg_epoch_loss=5.253752\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=435 train loss <loss>=5.201616954803467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [435]#011Speed: 1863.36 samples/sec#011loss=5.201617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[440] avg_epoch_loss=5.252857\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=440 train loss <loss>=5.174830913543701\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [440]#011Speed: 1036.04 samples/sec#011loss=5.174831\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[445] avg_epoch_loss=5.250968\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=445 train loss <loss>=5.084420871734619\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [445]#011Speed: 1836.61 samples/sec#011loss=5.084421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[450] avg_epoch_loss=5.251319\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=450 train loss <loss>=5.282556629180908\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [450]#011Speed: 1050.28 samples/sec#011loss=5.282557\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[455] avg_epoch_loss=5.250302\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=455 train loss <loss>=5.158581352233886\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [455]#011Speed: 1715.13 samples/sec#011loss=5.158581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[460] avg_epoch_loss=5.249826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=460 train loss <loss>=5.206466770172119\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [460]#011Speed: 1055.59 samples/sec#011loss=5.206467\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[465] avg_epoch_loss=5.250579\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=465 train loss <loss>=5.320009422302246\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [465]#011Speed: 1824.43 samples/sec#011loss=5.320009\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch[470] avg_epoch_loss=5.249992\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=470 train loss <loss>=5.195249271392822\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:42 INFO 140667699287680] Epoch[13] Batch [470]#011Speed: 1054.34 samples/sec#011loss=5.195249\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[475] avg_epoch_loss=5.247604\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=475 train loss <loss>=5.022690868377685\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [475]#011Speed: 1806.33 samples/sec#011loss=5.022691\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[480] avg_epoch_loss=5.249147\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=480 train loss <loss>=5.395956516265869\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [480]#011Speed: 1090.35 samples/sec#011loss=5.395957\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[485] avg_epoch_loss=5.249821\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=485 train loss <loss>=5.314724063873291\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [485]#011Speed: 1769.21 samples/sec#011loss=5.314724\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[490] avg_epoch_loss=5.250579\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=490 train loss <loss>=5.324227428436279\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [490]#011Speed: 1068.98 samples/sec#011loss=5.324227\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[495] avg_epoch_loss=5.250184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=495 train loss <loss>=5.211444664001465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [495]#011Speed: 1939.20 samples/sec#011loss=5.211445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[500] avg_epoch_loss=5.251393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=500 train loss <loss>=5.371326446533203\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [500]#011Speed: 990.30 samples/sec#011loss=5.371326\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[505] avg_epoch_loss=5.249682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=505 train loss <loss>=5.078204250335693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [505]#011Speed: 1936.98 samples/sec#011loss=5.078204\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[510] avg_epoch_loss=5.246781\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=510 train loss <loss>=4.953235626220703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [510]#011Speed: 1069.01 samples/sec#011loss=4.953236\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch[515] avg_epoch_loss=5.246523\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=515 train loss <loss>=5.2201080322265625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:43 INFO 140667699287680] Epoch[13] Batch [515]#011Speed: 1943.74 samples/sec#011loss=5.220108\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[520] avg_epoch_loss=5.244848\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=520 train loss <loss>=5.071997165679932\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [520]#011Speed: 1055.19 samples/sec#011loss=5.071997\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[525] avg_epoch_loss=5.243505\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=525 train loss <loss>=5.10355167388916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [525]#011Speed: 1866.79 samples/sec#011loss=5.103552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[530] avg_epoch_loss=5.243783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=530 train loss <loss>=5.272999572753906\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [530]#011Speed: 1055.90 samples/sec#011loss=5.273000\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[535] avg_epoch_loss=5.243567\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=535 train loss <loss>=5.220719718933106\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [535]#011Speed: 1799.57 samples/sec#011loss=5.220720\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[540] avg_epoch_loss=5.243681\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=540 train loss <loss>=5.255842113494873\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [540]#011Speed: 1036.12 samples/sec#011loss=5.255842\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[545] avg_epoch_loss=5.242726\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=545 train loss <loss>=5.13941650390625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [545]#011Speed: 1946.45 samples/sec#011loss=5.139417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch[550] avg_epoch_loss=5.244410\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, batch=550 train loss <loss>=5.4283203125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[13] Batch [550]#011Speed: 1695.28 samples/sec#011loss=5.428320\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] processed a total of 17661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989971.6008499, \"EndTime\": 1620989984.8192205, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13218.314170837402, \"count\": 1, \"min\": 13218.314170837402, \"max\": 13218.314170837402}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1336.0906679349218 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=13, train loss <loss>=5.244801009910694\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_7d026934-22dd-4206-96c6-dcd99f847a98-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989984.8192902, \"EndTime\": 1620989984.8291802, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.528875350952148, \"count\": 1, \"min\": 9.528875350952148, \"max\": 9.528875350952148}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[14] Batch[0] avg_epoch_loss=5.554417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=5.554417133331299\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[14] Batch[5] avg_epoch_loss=5.324487\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=5.324486653010051\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:44 INFO 140667699287680] Epoch[14] Batch [5]#011Speed: 1939.96 samples/sec#011loss=5.324487\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[10] avg_epoch_loss=5.316609\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=5.307156085968018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [10]#011Speed: 1095.98 samples/sec#011loss=5.307156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[15] avg_epoch_loss=5.300693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=5.265676116943359\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [15]#011Speed: 1802.65 samples/sec#011loss=5.265676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[20] avg_epoch_loss=5.291114\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=5.2604625701904295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [20]#011Speed: 1023.52 samples/sec#011loss=5.260463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[25] avg_epoch_loss=5.264493\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=5.152683925628662\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [25]#011Speed: 1810.10 samples/sec#011loss=5.152684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[30] avg_epoch_loss=5.251182\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=5.181967258453369\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [30]#011Speed: 1054.27 samples/sec#011loss=5.181967\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[35] avg_epoch_loss=5.247360\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=5.223662662506103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [35]#011Speed: 1943.14 samples/sec#011loss=5.223663\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[40] avg_epoch_loss=5.245126\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=5.229037475585938\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [40]#011Speed: 1136.33 samples/sec#011loss=5.229037\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch[45] avg_epoch_loss=5.238982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=5.188599967956543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:45 INFO 140667699287680] Epoch[14] Batch [45]#011Speed: 1933.49 samples/sec#011loss=5.188600\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[50] avg_epoch_loss=5.233047\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=5.1784515380859375\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [50]#011Speed: 1151.72 samples/sec#011loss=5.178452\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[55] avg_epoch_loss=5.228678\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=5.184111785888672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [55]#011Speed: 1863.34 samples/sec#011loss=5.184112\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[60] avg_epoch_loss=5.238038\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=5.342871284484863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [60]#011Speed: 1107.66 samples/sec#011loss=5.342871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[65] avg_epoch_loss=5.237676\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=5.23326301574707\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [65]#011Speed: 1869.98 samples/sec#011loss=5.233263\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[70] avg_epoch_loss=5.259462\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=5.547028541564941\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [70]#011Speed: 1133.84 samples/sec#011loss=5.547029\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[75] avg_epoch_loss=5.264492\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=5.335914611816406\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [75]#011Speed: 1919.00 samples/sec#011loss=5.335915\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[80] avg_epoch_loss=5.271662\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=5.380647277832031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [80]#011Speed: 1121.15 samples/sec#011loss=5.380647\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[85] avg_epoch_loss=5.267703\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=5.203569412231445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [85]#011Speed: 1792.96 samples/sec#011loss=5.203569\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch[90] avg_epoch_loss=5.279863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=5.489015388488769\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:46 INFO 140667699287680] Epoch[14] Batch [90]#011Speed: 1111.34 samples/sec#011loss=5.489015\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[95] avg_epoch_loss=5.282612\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=5.332653427124024\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [95]#011Speed: 1986.05 samples/sec#011loss=5.332653\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[100] avg_epoch_loss=5.290557\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=5.443090534210205\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [100]#011Speed: 1107.68 samples/sec#011loss=5.443091\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[105] avg_epoch_loss=5.290884\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=5.297493839263916\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [105]#011Speed: 1701.01 samples/sec#011loss=5.297494\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[110] avg_epoch_loss=5.287095\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=5.206774044036865\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [110]#011Speed: 940.04 samples/sec#011loss=5.206774\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[115] avg_epoch_loss=5.282564\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=5.181960010528565\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [115]#011Speed: 1894.82 samples/sec#011loss=5.181960\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[120] avg_epoch_loss=5.289256\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=5.444522094726563\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [120]#011Speed: 1113.95 samples/sec#011loss=5.444522\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[125] avg_epoch_loss=5.282152\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=5.110244560241699\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [125]#011Speed: 1852.98 samples/sec#011loss=5.110245\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch[130] avg_epoch_loss=5.276058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=5.122490501403808\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:47 INFO 140667699287680] Epoch[14] Batch [130]#011Speed: 1131.10 samples/sec#011loss=5.122491\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[135] avg_epoch_loss=5.286203\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=5.55198221206665\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [135]#011Speed: 1807.87 samples/sec#011loss=5.551982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[140] avg_epoch_loss=5.284982\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=5.2517845153808596\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [140]#011Speed: 1136.85 samples/sec#011loss=5.251785\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[145] avg_epoch_loss=5.291693\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=5.480935192108154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [145]#011Speed: 1852.89 samples/sec#011loss=5.480935\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[150] avg_epoch_loss=5.295161\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=5.3964310646057125\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [150]#011Speed: 1110.77 samples/sec#011loss=5.396431\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[155] avg_epoch_loss=5.295798\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=5.315039443969726\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [155]#011Speed: 1846.32 samples/sec#011loss=5.315039\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[160] avg_epoch_loss=5.293395\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=5.218402671813965\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [160]#011Speed: 1164.82 samples/sec#011loss=5.218403\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[165] avg_epoch_loss=5.289606\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=5.167621707916259\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [165]#011Speed: 1631.99 samples/sec#011loss=5.167622\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[170] avg_epoch_loss=5.287754\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=5.226271724700927\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [170]#011Speed: 1144.04 samples/sec#011loss=5.226272\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch[175] avg_epoch_loss=5.283551\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=5.13981065750122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:48 INFO 140667699287680] Epoch[14] Batch [175]#011Speed: 1873.29 samples/sec#011loss=5.139811\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[180] avg_epoch_loss=5.285552\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=5.355953979492187\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [180]#011Speed: 1131.48 samples/sec#011loss=5.355954\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[185] avg_epoch_loss=5.282918\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=5.187593650817871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [185]#011Speed: 1931.15 samples/sec#011loss=5.187594\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[190] avg_epoch_loss=5.284682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=5.350311183929444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [190]#011Speed: 1053.81 samples/sec#011loss=5.350311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[195] avg_epoch_loss=5.286825\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=5.3686620712280275\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [195]#011Speed: 1947.52 samples/sec#011loss=5.368662\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[200] avg_epoch_loss=5.288427\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=5.351233291625976\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [200]#011Speed: 1041.08 samples/sec#011loss=5.351233\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[205] avg_epoch_loss=5.287783\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=5.2618742942810055\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [205]#011Speed: 1726.77 samples/sec#011loss=5.261874\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[210] avg_epoch_loss=5.285661\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=5.198260688781739\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [210]#011Speed: 1017.39 samples/sec#011loss=5.198261\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch[215] avg_epoch_loss=5.282671\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=5.156472778320312\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:49 INFO 140667699287680] Epoch[14] Batch [215]#011Speed: 1891.18 samples/sec#011loss=5.156473\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[220] avg_epoch_loss=5.281956\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=5.251084232330323\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [220]#011Speed: 1015.38 samples/sec#011loss=5.251084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[225] avg_epoch_loss=5.284311\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=5.388404655456543\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [225]#011Speed: 1806.94 samples/sec#011loss=5.388405\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[230] avg_epoch_loss=5.280389\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=5.103122043609619\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [230]#011Speed: 1016.23 samples/sec#011loss=5.103122\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[235] avg_epoch_loss=5.281743\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=5.344295024871826\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [235]#011Speed: 1641.82 samples/sec#011loss=5.344295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[240] avg_epoch_loss=5.278348\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=5.118077659606934\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [240]#011Speed: 1097.02 samples/sec#011loss=5.118078\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[245] avg_epoch_loss=5.271284\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=4.930828094482422\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [245]#011Speed: 1950.45 samples/sec#011loss=4.930828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[250] avg_epoch_loss=5.271531\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=5.283672428131103\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [250]#011Speed: 1142.53 samples/sec#011loss=5.283672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[255] avg_epoch_loss=5.270142\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=5.200427436828614\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [255]#011Speed: 1955.59 samples/sec#011loss=5.200427\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch[260] avg_epoch_loss=5.269198\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=5.220827960968018\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:50 INFO 140667699287680] Epoch[14] Batch [260]#011Speed: 1131.40 samples/sec#011loss=5.220828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[265] avg_epoch_loss=5.269547\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=5.287814331054688\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [265]#011Speed: 1954.95 samples/sec#011loss=5.287814\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[270] avg_epoch_loss=5.266593\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=270 train loss <loss>=5.10943603515625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [270]#011Speed: 1102.70 samples/sec#011loss=5.109436\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[275] avg_epoch_loss=5.267380\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=275 train loss <loss>=5.309988689422608\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [275]#011Speed: 1673.46 samples/sec#011loss=5.309989\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[280] avg_epoch_loss=5.270441\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=280 train loss <loss>=5.439416599273682\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [280]#011Speed: 1008.77 samples/sec#011loss=5.439417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[285] avg_epoch_loss=5.271906\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=285 train loss <loss>=5.3542430877685545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [285]#011Speed: 1612.99 samples/sec#011loss=5.354243\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[290] avg_epoch_loss=5.273014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=290 train loss <loss>=5.336420917510987\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [290]#011Speed: 1071.85 samples/sec#011loss=5.336421\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[295] avg_epoch_loss=5.274755\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=295 train loss <loss>=5.376034355163574\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [295]#011Speed: 1781.60 samples/sec#011loss=5.376034\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch[300] avg_epoch_loss=5.277058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=300 train loss <loss>=5.41340913772583\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:51 INFO 140667699287680] Epoch[14] Batch [300]#011Speed: 1116.22 samples/sec#011loss=5.413409\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[305] avg_epoch_loss=5.275337\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=305 train loss <loss>=5.171770095825195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [305]#011Speed: 1895.32 samples/sec#011loss=5.171770\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[310] avg_epoch_loss=5.274282\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=310 train loss <loss>=5.209695529937744\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [310]#011Speed: 1092.10 samples/sec#011loss=5.209696\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[315] avg_epoch_loss=5.275828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=315 train loss <loss>=5.371996116638184\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [315]#011Speed: 1700.10 samples/sec#011loss=5.371996\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[320] avg_epoch_loss=5.279031\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=320 train loss <loss>=5.481482124328613\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [320]#011Speed: 906.26 samples/sec#011loss=5.481482\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[325] avg_epoch_loss=5.277457\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=325 train loss <loss>=5.176346778869629\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [325]#011Speed: 1804.25 samples/sec#011loss=5.176347\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[330] avg_epoch_loss=5.278168\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=330 train loss <loss>=5.324585056304931\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [330]#011Speed: 1069.01 samples/sec#011loss=5.324585\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[335] avg_epoch_loss=5.273889\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=335 train loss <loss>=4.990581130981445\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [335]#011Speed: 1716.13 samples/sec#011loss=4.990581\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch[340] avg_epoch_loss=5.272507\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=340 train loss <loss>=5.179671955108643\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:52 INFO 140667699287680] Epoch[14] Batch [340]#011Speed: 1064.97 samples/sec#011loss=5.179672\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[345] avg_epoch_loss=5.276728\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=345 train loss <loss>=5.56454906463623\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [345]#011Speed: 1720.47 samples/sec#011loss=5.564549\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[350] avg_epoch_loss=5.273325\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=350 train loss <loss>=5.0378443717956545\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [350]#011Speed: 1094.76 samples/sec#011loss=5.037844\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[355] avg_epoch_loss=5.270722\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=355 train loss <loss>=5.088019561767578\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [355]#011Speed: 1928.33 samples/sec#011loss=5.088020\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[360] avg_epoch_loss=5.269771\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=360 train loss <loss>=5.202018928527832\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [360]#011Speed: 1074.24 samples/sec#011loss=5.202019\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[365] avg_epoch_loss=5.269530\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=365 train loss <loss>=5.2521946907043455\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [365]#011Speed: 1920.79 samples/sec#011loss=5.252195\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[370] avg_epoch_loss=5.268889\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=370 train loss <loss>=5.2219664573669435\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [370]#011Speed: 984.44 samples/sec#011loss=5.221966\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[375] avg_epoch_loss=5.265884\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=375 train loss <loss>=5.042904663085937\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [375]#011Speed: 1858.57 samples/sec#011loss=5.042905\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[380] avg_epoch_loss=5.266160\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=380 train loss <loss>=5.286908721923828\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [380]#011Speed: 1078.36 samples/sec#011loss=5.286909\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch[385] avg_epoch_loss=5.265069\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=385 train loss <loss>=5.181935977935791\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:53 INFO 140667699287680] Epoch[14] Batch [385]#011Speed: 1898.39 samples/sec#011loss=5.181936\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[390] avg_epoch_loss=5.267663\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=390 train loss <loss>=5.467904472351075\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [390]#011Speed: 1028.62 samples/sec#011loss=5.467904\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[395] avg_epoch_loss=5.266648\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=395 train loss <loss>=5.187234020233154\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [395]#011Speed: 1903.64 samples/sec#011loss=5.187234\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[400] avg_epoch_loss=5.266083\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=400 train loss <loss>=5.221357154846191\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [400]#011Speed: 1059.74 samples/sec#011loss=5.221357\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[405] avg_epoch_loss=5.264483\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=405 train loss <loss>=5.136145687103271\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [405]#011Speed: 1971.96 samples/sec#011loss=5.136146\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[410] avg_epoch_loss=5.264527\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=410 train loss <loss>=5.268157291412353\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [410]#011Speed: 1000.65 samples/sec#011loss=5.268157\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[415] avg_epoch_loss=5.263211\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=415 train loss <loss>=5.154998683929444\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [415]#011Speed: 1941.91 samples/sec#011loss=5.154999\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[420] avg_epoch_loss=5.263111\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=420 train loss <loss>=5.254811477661133\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [420]#011Speed: 1091.33 samples/sec#011loss=5.254811\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch[425] avg_epoch_loss=5.263263\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=425 train loss <loss>=5.27601432800293\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:54 INFO 140667699287680] Epoch[14] Batch [425]#011Speed: 1588.50 samples/sec#011loss=5.276014\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[430] avg_epoch_loss=5.263637\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=430 train loss <loss>=5.295567989349365\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [430]#011Speed: 1036.32 samples/sec#011loss=5.295568\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[435] avg_epoch_loss=5.263370\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=435 train loss <loss>=5.240328598022461\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [435]#011Speed: 1845.65 samples/sec#011loss=5.240329\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[440] avg_epoch_loss=5.261812\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=440 train loss <loss>=5.125986385345459\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [440]#011Speed: 1104.50 samples/sec#011loss=5.125986\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[445] avg_epoch_loss=5.261151\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=445 train loss <loss>=5.202810573577881\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [445]#011Speed: 1609.01 samples/sec#011loss=5.202811\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[450] avg_epoch_loss=5.258551\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=450 train loss <loss>=5.026617431640625\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [450]#011Speed: 1119.04 samples/sec#011loss=5.026617\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[455] avg_epoch_loss=5.258351\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=455 train loss <loss>=5.240334415435791\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [455]#011Speed: 1860.99 samples/sec#011loss=5.240334\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[460] avg_epoch_loss=5.259218\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=460 train loss <loss>=5.3382800102233885\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [460]#011Speed: 1092.18 samples/sec#011loss=5.338280\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch[465] avg_epoch_loss=5.261343\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=465 train loss <loss>=5.457269859313965\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:55 INFO 140667699287680] Epoch[14] Batch [465]#011Speed: 1874.44 samples/sec#011loss=5.457270\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[470] avg_epoch_loss=5.264180\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=470 train loss <loss>=5.528571701049804\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [470]#011Speed: 1156.11 samples/sec#011loss=5.528572\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[475] avg_epoch_loss=5.265057\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=475 train loss <loss>=5.347727584838867\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [475]#011Speed: 1900.06 samples/sec#011loss=5.347728\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[480] avg_epoch_loss=5.265082\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=480 train loss <loss>=5.267430686950684\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [480]#011Speed: 1132.10 samples/sec#011loss=5.267431\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[485] avg_epoch_loss=5.265280\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=485 train loss <loss>=5.284293556213379\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [485]#011Speed: 1955.94 samples/sec#011loss=5.284294\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[490] avg_epoch_loss=5.266990\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=490 train loss <loss>=5.43327054977417\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [490]#011Speed: 1099.75 samples/sec#011loss=5.433271\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[495] avg_epoch_loss=5.265795\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=495 train loss <loss>=5.148370742797852\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [495]#011Speed: 1863.79 samples/sec#011loss=5.148371\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[500] avg_epoch_loss=5.263338\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=500 train loss <loss>=5.019650077819824\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [500]#011Speed: 1021.62 samples/sec#011loss=5.019650\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[505] avg_epoch_loss=5.262663\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=505 train loss <loss>=5.195044422149659\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [505]#011Speed: 1641.92 samples/sec#011loss=5.195044\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch[510] avg_epoch_loss=5.259533\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=510 train loss <loss>=4.942768287658692\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:56 INFO 140667699287680] Epoch[14] Batch [510]#011Speed: 1007.61 samples/sec#011loss=4.942768\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[515] avg_epoch_loss=5.258463\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=515 train loss <loss>=5.149087238311767\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [515]#011Speed: 1694.58 samples/sec#011loss=5.149087\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[520] avg_epoch_loss=5.258528\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=520 train loss <loss>=5.26524076461792\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [520]#011Speed: 1053.32 samples/sec#011loss=5.265241\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[525] avg_epoch_loss=5.257863\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=525 train loss <loss>=5.1885148048400875\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [525]#011Speed: 1800.86 samples/sec#011loss=5.188515\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[530] avg_epoch_loss=5.258471\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=530 train loss <loss>=5.322465419769287\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [530]#011Speed: 1035.60 samples/sec#011loss=5.322465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[535] avg_epoch_loss=5.259368\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=535 train loss <loss>=5.35463228225708\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [535]#011Speed: 1626.83 samples/sec#011loss=5.354632\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[540] avg_epoch_loss=5.258181\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=540 train loss <loss>=5.130962467193603\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [540]#011Speed: 1079.96 samples/sec#011loss=5.130962\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[545] avg_epoch_loss=5.255694\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=545 train loss <loss>=4.986637020111084\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [545]#011Speed: 1904.76 samples/sec#011loss=4.986637\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch[550] avg_epoch_loss=5.256006\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, batch=550 train loss <loss>=5.290057563781739\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[14] Batch [550]#011Speed: 1682.26 samples/sec#011loss=5.290058\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] processed a total of 17634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989984.8292396, \"EndTime\": 1620989997.894067, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13064.768075942993, \"count\": 1, \"min\": 13064.768075942993, \"max\": 13064.768075942993}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1349.7277214747119 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=14, train loss <loss>=5.257333435874054\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] Epoch[15] Batch[0] avg_epoch_loss=5.253871\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=5.253871440887451\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[5] avg_epoch_loss=5.283864\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=5.283863623936971\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [5]#011Speed: 2006.86 samples/sec#011loss=5.283864\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[10] avg_epoch_loss=5.270815\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=5.255155849456787\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [10]#011Speed: 1078.00 samples/sec#011loss=5.255156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[15] avg_epoch_loss=5.323143\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=5.438265705108643\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [15]#011Speed: 1844.28 samples/sec#011loss=5.438266\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[20] avg_epoch_loss=5.298131\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=5.218091773986816\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [20]#011Speed: 1059.98 samples/sec#011loss=5.218092\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[25] avg_epoch_loss=5.317266\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=5.3976335525512695\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [25]#011Speed: 1665.69 samples/sec#011loss=5.397634\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[30] avg_epoch_loss=5.295899\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=5.184787940979004\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [30]#011Speed: 1048.07 samples/sec#011loss=5.184788\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[35] avg_epoch_loss=5.272666\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=5.128627014160156\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [35]#011Speed: 1786.83 samples/sec#011loss=5.128627\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch[40] avg_epoch_loss=5.275804\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=5.298391819000244\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:58 INFO 140667699287680] Epoch[15] Batch [40]#011Speed: 1119.61 samples/sec#011loss=5.298392\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[45] avg_epoch_loss=5.255388\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=5.087975025177002\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [45]#011Speed: 1797.78 samples/sec#011loss=5.087975\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[50] avg_epoch_loss=5.251317\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=5.213872623443604\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [50]#011Speed: 1004.14 samples/sec#011loss=5.213873\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[55] avg_epoch_loss=5.265709\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=5.412500286102295\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [55]#011Speed: 1785.23 samples/sec#011loss=5.412500\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[60] avg_epoch_loss=5.269502\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=5.3119913101196286\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [60]#011Speed: 1050.06 samples/sec#011loss=5.311991\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[65] avg_epoch_loss=5.283011\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=5.447816562652588\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [65]#011Speed: 1799.43 samples/sec#011loss=5.447817\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[70] avg_epoch_loss=5.255248\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=4.8887687683105465\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [70]#011Speed: 1094.88 samples/sec#011loss=4.888769\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[75] avg_epoch_loss=5.250265\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=5.179512691497803\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [75]#011Speed: 1776.33 samples/sec#011loss=5.179513\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[80] avg_epoch_loss=5.252347\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=5.28399429321289\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [80]#011Speed: 1104.91 samples/sec#011loss=5.283994\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch[85] avg_epoch_loss=5.252885\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=5.261593341827393\u001b[0m\n",
      "\u001b[34m[05/14/2021 10:59:59 INFO 140667699287680] Epoch[15] Batch [85]#011Speed: 1763.55 samples/sec#011loss=5.261593\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[90] avg_epoch_loss=5.263561\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=5.447203350067139\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [90]#011Speed: 1153.01 samples/sec#011loss=5.447203\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[95] avg_epoch_loss=5.262540\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=5.243944835662842\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [95]#011Speed: 1886.89 samples/sec#011loss=5.243945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[100] avg_epoch_loss=5.256004\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=5.130511856079101\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [100]#011Speed: 1131.03 samples/sec#011loss=5.130512\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[105] avg_epoch_loss=5.258485\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=5.30860595703125\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [105]#011Speed: 1678.51 samples/sec#011loss=5.308606\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[110] avg_epoch_loss=5.259929\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=5.290543079376221\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [110]#011Speed: 1043.61 samples/sec#011loss=5.290543\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[115] avg_epoch_loss=5.259585\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=5.251957130432129\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [115]#011Speed: 1885.00 samples/sec#011loss=5.251957\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[120] avg_epoch_loss=5.253615\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=5.11509895324707\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [120]#011Speed: 1088.91 samples/sec#011loss=5.115099\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch[125] avg_epoch_loss=5.254938\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=5.2869562149047855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:00 INFO 140667699287680] Epoch[15] Batch [125]#011Speed: 1868.06 samples/sec#011loss=5.286956\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[130] avg_epoch_loss=5.259875\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=5.384282207489013\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [130]#011Speed: 1020.03 samples/sec#011loss=5.384282\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[135] avg_epoch_loss=5.267800\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=5.475428104400635\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [135]#011Speed: 1862.25 samples/sec#011loss=5.475428\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[140] avg_epoch_loss=5.272859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=5.410465049743652\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [140]#011Speed: 1111.49 samples/sec#011loss=5.410465\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[145] avg_epoch_loss=5.280105\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=5.484445190429687\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [145]#011Speed: 1447.94 samples/sec#011loss=5.484445\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[150] avg_epoch_loss=5.278356\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=5.227280330657959\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [150]#011Speed: 914.43 samples/sec#011loss=5.227280\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[155] avg_epoch_loss=5.274747\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=5.165778064727784\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [155]#011Speed: 1542.41 samples/sec#011loss=5.165778\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[160] avg_epoch_loss=5.274916\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=5.280171585083008\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [160]#011Speed: 955.65 samples/sec#011loss=5.280172\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch[165] avg_epoch_loss=5.268166\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=5.050838279724121\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:01 INFO 140667699287680] Epoch[15] Batch [165]#011Speed: 1890.04 samples/sec#011loss=5.050838\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[170] avg_epoch_loss=5.262667\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=5.080097007751465\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [170]#011Speed: 1084.76 samples/sec#011loss=5.080097\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[175] avg_epoch_loss=5.260768\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=5.195813941955566\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [175]#011Speed: 1909.91 samples/sec#011loss=5.195814\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[180] avg_epoch_loss=5.256151\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=5.0936356544494625\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [180]#011Speed: 1056.99 samples/sec#011loss=5.093636\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[185] avg_epoch_loss=5.258121\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=5.329438781738281\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [185]#011Speed: 1847.24 samples/sec#011loss=5.329439\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[190] avg_epoch_loss=5.258305\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=5.2651591300964355\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [190]#011Speed: 1047.05 samples/sec#011loss=5.265159\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[195] avg_epoch_loss=5.256125\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=5.172849845886231\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [195]#011Speed: 1554.50 samples/sec#011loss=5.172850\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[200] avg_epoch_loss=5.263298\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=5.544470596313476\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [200]#011Speed: 1020.85 samples/sec#011loss=5.544471\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch[205] avg_epoch_loss=5.266630\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=5.400578022003174\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:02 INFO 140667699287680] Epoch[15] Batch [205]#011Speed: 1996.62 samples/sec#011loss=5.400578\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[210] avg_epoch_loss=5.268123\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=5.329628562927246\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [210]#011Speed: 1092.80 samples/sec#011loss=5.329629\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[215] avg_epoch_loss=5.267241\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=5.230033683776855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [215]#011Speed: 1957.98 samples/sec#011loss=5.230034\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[220] avg_epoch_loss=5.262812\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=5.071446132659912\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [220]#011Speed: 1077.16 samples/sec#011loss=5.071446\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[225] avg_epoch_loss=5.260616\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=5.163587188720703\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [225]#011Speed: 1918.22 samples/sec#011loss=5.163587\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[230] avg_epoch_loss=5.257038\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=5.09527063369751\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [230]#011Speed: 1066.11 samples/sec#011loss=5.095271\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[235] avg_epoch_loss=5.252627\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=5.048854732513428\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [235]#011Speed: 1813.25 samples/sec#011loss=5.048855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[240] avg_epoch_loss=5.254966\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=5.3653843879699705\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [240]#011Speed: 1081.58 samples/sec#011loss=5.365384\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch[245] avg_epoch_loss=5.255708\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=5.291436386108399\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:03 INFO 140667699287680] Epoch[15] Batch [245]#011Speed: 1535.27 samples/sec#011loss=5.291436\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[250] avg_epoch_loss=5.256511\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=5.296045780181885\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [250]#011Speed: 896.76 samples/sec#011loss=5.296046\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[255] avg_epoch_loss=5.253522\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=5.103492736816406\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [255]#011Speed: 1576.10 samples/sec#011loss=5.103493\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[260] avg_epoch_loss=5.257748\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=5.474113273620605\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [260]#011Speed: 950.14 samples/sec#011loss=5.474113\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[265] avg_epoch_loss=5.254352\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=5.077067184448242\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [265]#011Speed: 1604.05 samples/sec#011loss=5.077067\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[270] avg_epoch_loss=5.254809\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=270 train loss <loss>=5.279141807556153\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [270]#011Speed: 955.87 samples/sec#011loss=5.279142\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[275] avg_epoch_loss=5.257193\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=275 train loss <loss>=5.386402130126953\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [275]#011Speed: 1749.23 samples/sec#011loss=5.386402\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[280] avg_epoch_loss=5.257492\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=280 train loss <loss>=5.273982143402099\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [280]#011Speed: 1067.15 samples/sec#011loss=5.273982\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch[285] avg_epoch_loss=5.256557\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=285 train loss <loss>=5.204007720947265\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:04 INFO 140667699287680] Epoch[15] Batch [285]#011Speed: 1788.14 samples/sec#011loss=5.204008\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[290] avg_epoch_loss=5.253936\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=290 train loss <loss>=5.10401086807251\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [290]#011Speed: 953.90 samples/sec#011loss=5.104011\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[295] avg_epoch_loss=5.254019\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=295 train loss <loss>=5.2588372230529785\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [295]#011Speed: 1558.14 samples/sec#011loss=5.258837\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[300] avg_epoch_loss=5.249348\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=300 train loss <loss>=4.972834777832031\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [300]#011Speed: 877.81 samples/sec#011loss=4.972835\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[305] avg_epoch_loss=5.246681\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=305 train loss <loss>=5.086148452758789\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [305]#011Speed: 1431.03 samples/sec#011loss=5.086148\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[310] avg_epoch_loss=5.245348\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=310 train loss <loss>=5.163736820220947\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [310]#011Speed: 927.38 samples/sec#011loss=5.163737\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[315] avg_epoch_loss=5.244605\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=315 train loss <loss>=5.198384857177734\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [315]#011Speed: 1675.48 samples/sec#011loss=5.198385\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[320] avg_epoch_loss=5.242718\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=320 train loss <loss>=5.123467636108399\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [320]#011Speed: 944.50 samples/sec#011loss=5.123468\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch[325] avg_epoch_loss=5.242443\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=325 train loss <loss>=5.224808406829834\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:05 INFO 140667699287680] Epoch[15] Batch [325]#011Speed: 1507.00 samples/sec#011loss=5.224808\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[330] avg_epoch_loss=5.246249\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=330 train loss <loss>=5.4943647384643555\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [330]#011Speed: 869.40 samples/sec#011loss=5.494365\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[335] avg_epoch_loss=5.242908\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=335 train loss <loss>=5.0217536926269535\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [335]#011Speed: 1687.62 samples/sec#011loss=5.021754\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[340] avg_epoch_loss=5.240953\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=340 train loss <loss>=5.1095991134643555\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [340]#011Speed: 975.34 samples/sec#011loss=5.109599\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[345] avg_epoch_loss=5.241632\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=345 train loss <loss>=5.2879026412963865\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [345]#011Speed: 1676.59 samples/sec#011loss=5.287903\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[350] avg_epoch_loss=5.241350\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=350 train loss <loss>=5.221840572357178\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [350]#011Speed: 1017.98 samples/sec#011loss=5.221841\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[355] avg_epoch_loss=5.240711\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=355 train loss <loss>=5.195886898040771\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [355]#011Speed: 1850.68 samples/sec#011loss=5.195887\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch[360] avg_epoch_loss=5.242125\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=360 train loss <loss>=5.342764186859131\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:06 INFO 140667699287680] Epoch[15] Batch [360]#011Speed: 1053.84 samples/sec#011loss=5.342764\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[365] avg_epoch_loss=5.239985\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=365 train loss <loss>=5.085494041442871\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [365]#011Speed: 1693.07 samples/sec#011loss=5.085494\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[370] avg_epoch_loss=5.237147\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=370 train loss <loss>=5.02941780090332\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [370]#011Speed: 1009.04 samples/sec#011loss=5.029418\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[375] avg_epoch_loss=5.241821\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=375 train loss <loss>=5.5886022567749025\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [375]#011Speed: 1817.59 samples/sec#011loss=5.588602\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[380] avg_epoch_loss=5.242942\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=380 train loss <loss>=5.327270984649658\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [380]#011Speed: 1055.78 samples/sec#011loss=5.327271\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[385] avg_epoch_loss=5.245357\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=385 train loss <loss>=5.429368686676026\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [385]#011Speed: 1525.34 samples/sec#011loss=5.429369\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[390] avg_epoch_loss=5.245368\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=390 train loss <loss>=5.246234512329101\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [390]#011Speed: 922.58 samples/sec#011loss=5.246235\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[395] avg_epoch_loss=5.244112\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=395 train loss <loss>=5.145842456817627\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [395]#011Speed: 1662.13 samples/sec#011loss=5.145842\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch[400] avg_epoch_loss=5.242982\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=400 train loss <loss>=5.153491973876953\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:07 INFO 140667699287680] Epoch[15] Batch [400]#011Speed: 914.18 samples/sec#011loss=5.153492\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[405] avg_epoch_loss=5.243768\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=405 train loss <loss>=5.306820583343506\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [405]#011Speed: 1932.24 samples/sec#011loss=5.306821\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[410] avg_epoch_loss=5.244490\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=410 train loss <loss>=5.303137493133545\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [410]#011Speed: 1073.60 samples/sec#011loss=5.303137\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[415] avg_epoch_loss=5.241792\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=415 train loss <loss>=5.019977474212647\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [415]#011Speed: 1946.71 samples/sec#011loss=5.019977\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[420] avg_epoch_loss=5.243285\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=420 train loss <loss>=5.367500686645508\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [420]#011Speed: 1090.99 samples/sec#011loss=5.367501\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[425] avg_epoch_loss=5.242894\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=425 train loss <loss>=5.2099730491638185\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [425]#011Speed: 1771.90 samples/sec#011loss=5.209973\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[430] avg_epoch_loss=5.241121\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=430 train loss <loss>=5.0900904655456545\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [430]#011Speed: 990.31 samples/sec#011loss=5.090090\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[435] avg_epoch_loss=5.241656\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=435 train loss <loss>=5.287755966186523\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [435]#011Speed: 1839.16 samples/sec#011loss=5.287756\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch[440] avg_epoch_loss=5.242756\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=440 train loss <loss>=5.338732528686523\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:08 INFO 140667699287680] Epoch[15] Batch [440]#011Speed: 1073.13 samples/sec#011loss=5.338733\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[445] avg_epoch_loss=5.242622\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=445 train loss <loss>=5.230798530578613\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [445]#011Speed: 1815.71 samples/sec#011loss=5.230799\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[450] avg_epoch_loss=5.242806\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=450 train loss <loss>=5.25915937423706\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [450]#011Speed: 1014.70 samples/sec#011loss=5.259159\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[455] avg_epoch_loss=5.243054\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=455 train loss <loss>=5.265462875366211\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [455]#011Speed: 1923.96 samples/sec#011loss=5.265463\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[460] avg_epoch_loss=5.243622\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=460 train loss <loss>=5.295403099060058\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [460]#011Speed: 1039.63 samples/sec#011loss=5.295403\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[465] avg_epoch_loss=5.243477\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=465 train loss <loss>=5.2301023483276365\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [465]#011Speed: 1874.96 samples/sec#011loss=5.230102\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[470] avg_epoch_loss=5.245103\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=470 train loss <loss>=5.396618747711182\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [470]#011Speed: 999.62 samples/sec#011loss=5.396619\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[475] avg_epoch_loss=5.245544\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=475 train loss <loss>=5.28713436126709\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [475]#011Speed: 1694.95 samples/sec#011loss=5.287134\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[480] avg_epoch_loss=5.247482\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=480 train loss <loss>=5.432005500793457\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [480]#011Speed: 1075.87 samples/sec#011loss=5.432006\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch[485] avg_epoch_loss=5.247760\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=485 train loss <loss>=5.274457263946533\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:09 INFO 140667699287680] Epoch[15] Batch [485]#011Speed: 1871.96 samples/sec#011loss=5.274457\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[490] avg_epoch_loss=5.245088\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=490 train loss <loss>=4.9854048728942875\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [490]#011Speed: 1048.99 samples/sec#011loss=4.985405\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[495] avg_epoch_loss=5.244578\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=495 train loss <loss>=5.1944609642028805\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [495]#011Speed: 1866.08 samples/sec#011loss=5.194461\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[500] avg_epoch_loss=5.242876\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=500 train loss <loss>=5.074098205566406\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [500]#011Speed: 1090.72 samples/sec#011loss=5.074098\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[505] avg_epoch_loss=5.243469\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=505 train loss <loss>=5.302870559692383\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [505]#011Speed: 1678.57 samples/sec#011loss=5.302871\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[510] avg_epoch_loss=5.243473\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=510 train loss <loss>=5.243807315826416\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [510]#011Speed: 1065.51 samples/sec#011loss=5.243807\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[515] avg_epoch_loss=5.244006\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=515 train loss <loss>=5.2984874725341795\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [515]#011Speed: 1855.86 samples/sec#011loss=5.298487\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[520] avg_epoch_loss=5.243716\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=520 train loss <loss>=5.213789749145508\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [520]#011Speed: 1152.85 samples/sec#011loss=5.213790\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch[525] avg_epoch_loss=5.245916\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=525 train loss <loss>=5.475163364410401\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:10 INFO 140667699287680] Epoch[15] Batch [525]#011Speed: 1871.96 samples/sec#011loss=5.475163\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch[530] avg_epoch_loss=5.245591\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=530 train loss <loss>=5.211418628692627\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch [530]#011Speed: 1114.08 samples/sec#011loss=5.211419\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch[535] avg_epoch_loss=5.243761\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=535 train loss <loss>=5.049464702606201\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch [535]#011Speed: 1900.81 samples/sec#011loss=5.049465\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch[540] avg_epoch_loss=5.244773\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=540 train loss <loss>=5.353197383880615\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch [540]#011Speed: 1100.01 samples/sec#011loss=5.353197\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch[545] avg_epoch_loss=5.243516\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=545 train loss <loss>=5.1075798034667965\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch [545]#011Speed: 1905.42 samples/sec#011loss=5.107580\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch[550] avg_epoch_loss=5.244514\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, batch=550 train loss <loss>=5.35340690612793\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[15] Batch [550]#011Speed: 1600.51 samples/sec#011loss=5.353407\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] processed a total of 17607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620989997.8941271, \"EndTime\": 1620990011.4825776, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13588.045597076416, \"count\": 1, \"min\": 13588.045597076416, \"max\": 13588.045597076416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1295.7626511823182 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=15, train loss <loss>=5.244513670026499\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_d77da883-b94f-4d1f-a841-b6a561998635-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990011.4826367, \"EndTime\": 1620990011.489913, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.943225860595703, \"count\": 1, \"min\": 6.943225860595703, \"max\": 6.943225860595703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch[0] avg_epoch_loss=5.375852\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=5.375851631164551\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch[5] avg_epoch_loss=5.116341\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=5.1163413524627686\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch [5]#011Speed: 1867.74 samples/sec#011loss=5.116341\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch[10] avg_epoch_loss=5.029055\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=4.92431116104126\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch [10]#011Speed: 1078.55 samples/sec#011loss=4.924311\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch[15] avg_epoch_loss=5.140089\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=5.384365463256836\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:11 INFO 140667699287680] Epoch[16] Batch [15]#011Speed: 1949.65 samples/sec#011loss=5.384365\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[20] avg_epoch_loss=5.194142\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=5.36710901260376\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [20]#011Speed: 971.77 samples/sec#011loss=5.367109\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[25] avg_epoch_loss=5.240758\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=5.436546993255615\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [25]#011Speed: 1833.37 samples/sec#011loss=5.436547\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[30] avg_epoch_loss=5.269665\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=5.419979667663574\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [30]#011Speed: 1063.16 samples/sec#011loss=5.419980\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[35] avg_epoch_loss=5.294908\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=5.451415348052978\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [35]#011Speed: 1934.96 samples/sec#011loss=5.451415\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[40] avg_epoch_loss=5.291590\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=5.26770133972168\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [40]#011Speed: 1065.02 samples/sec#011loss=5.267701\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[45] avg_epoch_loss=5.283042\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=5.212944984436035\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [45]#011Speed: 1877.95 samples/sec#011loss=5.212945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[50] avg_epoch_loss=5.283949\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=5.292299461364746\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [50]#011Speed: 971.54 samples/sec#011loss=5.292299\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch[55] avg_epoch_loss=5.291472\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=5.368206787109375\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:12 INFO 140667699287680] Epoch[16] Batch [55]#011Speed: 1870.03 samples/sec#011loss=5.368207\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[60] avg_epoch_loss=5.289434\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=5.26660680770874\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [60]#011Speed: 986.13 samples/sec#011loss=5.266607\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[65] avg_epoch_loss=5.281231\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=5.181148719787598\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [65]#011Speed: 1991.31 samples/sec#011loss=5.181149\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[70] avg_epoch_loss=5.267449\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=5.0855365753173825\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [70]#011Speed: 1056.71 samples/sec#011loss=5.085537\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[75] avg_epoch_loss=5.250577\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=5.010988521575928\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [75]#011Speed: 1904.96 samples/sec#011loss=5.010989\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[80] avg_epoch_loss=5.238243\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=5.050758171081543\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [80]#011Speed: 1085.76 samples/sec#011loss=5.050758\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[85] avg_epoch_loss=5.233014\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=5.148308372497558\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [85]#011Speed: 1773.28 samples/sec#011loss=5.148308\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[90] avg_epoch_loss=5.229801\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=5.174536323547363\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [90]#011Speed: 1097.41 samples/sec#011loss=5.174536\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[95] avg_epoch_loss=5.228537\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=5.205538558959961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [95]#011Speed: 1805.01 samples/sec#011loss=5.205539\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch[100] avg_epoch_loss=5.221961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=5.095709609985351\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:13 INFO 140667699287680] Epoch[16] Batch [100]#011Speed: 1092.97 samples/sec#011loss=5.095710\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[105] avg_epoch_loss=5.214190\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=5.057201099395752\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [105]#011Speed: 1864.75 samples/sec#011loss=5.057201\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[110] avg_epoch_loss=5.212955\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=5.186782646179199\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [110]#011Speed: 1020.67 samples/sec#011loss=5.186783\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[115] avg_epoch_loss=5.212612\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=5.204989814758301\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [115]#011Speed: 1855.13 samples/sec#011loss=5.204990\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[120] avg_epoch_loss=5.206750\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=5.070766544342041\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [120]#011Speed: 1089.68 samples/sec#011loss=5.070767\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[125] avg_epoch_loss=5.206345\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=5.196529865264893\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [125]#011Speed: 1855.14 samples/sec#011loss=5.196530\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[130] avg_epoch_loss=5.218934\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=5.536178684234619\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [130]#011Speed: 994.93 samples/sec#011loss=5.536179\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[135] avg_epoch_loss=5.221522\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=5.289321613311768\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [135]#011Speed: 1873.32 samples/sec#011loss=5.289322\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch[140] avg_epoch_loss=5.221254\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=5.213974285125732\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:14 INFO 140667699287680] Epoch[16] Batch [140]#011Speed: 1087.94 samples/sec#011loss=5.213974\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[145] avg_epoch_loss=5.234970\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=5.621760463714599\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [145]#011Speed: 1781.10 samples/sec#011loss=5.621760\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[150] avg_epoch_loss=5.233827\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=5.200452518463135\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [150]#011Speed: 1069.99 samples/sec#011loss=5.200453\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[155] avg_epoch_loss=5.236452\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=5.315733146667481\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [155]#011Speed: 1966.08 samples/sec#011loss=5.315733\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[160] avg_epoch_loss=5.230557\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=5.046615505218506\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [160]#011Speed: 1056.95 samples/sec#011loss=5.046616\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[165] avg_epoch_loss=5.230169\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=5.217688274383545\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [165]#011Speed: 1921.37 samples/sec#011loss=5.217688\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[170] avg_epoch_loss=5.229771\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=5.2165453910827635\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [170]#011Speed: 1021.22 samples/sec#011loss=5.216545\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[175] avg_epoch_loss=5.239968\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=5.5887116432189945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [175]#011Speed: 1793.00 samples/sec#011loss=5.588712\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[180] avg_epoch_loss=5.244328\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=5.397785377502442\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [180]#011Speed: 1059.57 samples/sec#011loss=5.397785\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch[185] avg_epoch_loss=5.244952\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=5.267553043365479\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:15 INFO 140667699287680] Epoch[16] Batch [185]#011Speed: 1840.45 samples/sec#011loss=5.267553\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[190] avg_epoch_loss=5.243826\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=5.201957511901855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [190]#011Speed: 1049.15 samples/sec#011loss=5.201958\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[195] avg_epoch_loss=5.245052\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=5.29185733795166\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [195]#011Speed: 1900.52 samples/sec#011loss=5.291857\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[200] avg_epoch_loss=5.244808\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=5.235254955291748\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [200]#011Speed: 990.41 samples/sec#011loss=5.235255\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[205] avg_epoch_loss=5.245326\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=5.2661693572998045\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [205]#011Speed: 1693.80 samples/sec#011loss=5.266169\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[210] avg_epoch_loss=5.248005\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=5.35836877822876\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [210]#011Speed: 1033.89 samples/sec#011loss=5.358369\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[215] avg_epoch_loss=5.246217\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=5.170745372772217\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [215]#011Speed: 1820.63 samples/sec#011loss=5.170745\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[220] avg_epoch_loss=5.249397\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=5.386770153045655\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [220]#011Speed: 1071.90 samples/sec#011loss=5.386770\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch[225] avg_epoch_loss=5.251277\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=5.334383201599121\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:16 INFO 140667699287680] Epoch[16] Batch [225]#011Speed: 1877.04 samples/sec#011loss=5.334383\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[230] avg_epoch_loss=5.248067\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=5.102962779998779\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [230]#011Speed: 1038.06 samples/sec#011loss=5.102963\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[235] avg_epoch_loss=5.248092\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=5.249266147613525\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [235]#011Speed: 1927.62 samples/sec#011loss=5.249266\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[240] avg_epoch_loss=5.245715\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=5.133529949188232\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [240]#011Speed: 1089.96 samples/sec#011loss=5.133530\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[245] avg_epoch_loss=5.250577\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=5.484933662414551\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [245]#011Speed: 1810.24 samples/sec#011loss=5.484934\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[250] avg_epoch_loss=5.250732\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=5.258343029022217\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [250]#011Speed: 1094.18 samples/sec#011loss=5.258343\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[255] avg_epoch_loss=5.254777\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=5.457836437225342\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [255]#011Speed: 1778.63 samples/sec#011loss=5.457836\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[260] avg_epoch_loss=5.265667\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=5.823231220245361\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [260]#011Speed: 1038.83 samples/sec#011loss=5.823231\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch[265] avg_epoch_loss=5.271369\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=5.568990039825439\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:17 INFO 140667699287680] Epoch[16] Batch [265]#011Speed: 1627.01 samples/sec#011loss=5.568990\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[270] avg_epoch_loss=5.273661\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=270 train loss <loss>=5.395593166351318\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [270]#011Speed: 1116.57 samples/sec#011loss=5.395593\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[275] avg_epoch_loss=5.271375\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=275 train loss <loss>=5.147497463226318\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [275]#011Speed: 1760.53 samples/sec#011loss=5.147497\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[280] avg_epoch_loss=5.269524\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=280 train loss <loss>=5.167331600189209\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [280]#011Speed: 1099.12 samples/sec#011loss=5.167332\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[285] avg_epoch_loss=5.266995\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=285 train loss <loss>=5.124866580963134\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [285]#011Speed: 1921.88 samples/sec#011loss=5.124867\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[290] avg_epoch_loss=5.266413\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=290 train loss <loss>=5.233115386962891\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [290]#011Speed: 1022.80 samples/sec#011loss=5.233115\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[295] avg_epoch_loss=5.263977\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=295 train loss <loss>=5.122213745117188\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [295]#011Speed: 1701.47 samples/sec#011loss=5.122214\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[300] avg_epoch_loss=5.265462\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=300 train loss <loss>=5.353387451171875\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [300]#011Speed: 1076.45 samples/sec#011loss=5.353387\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch[305] avg_epoch_loss=5.261661\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=305 train loss <loss>=5.032865810394287\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:18 INFO 140667699287680] Epoch[16] Batch [305]#011Speed: 1733.08 samples/sec#011loss=5.032866\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[310] avg_epoch_loss=5.266479\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=310 train loss <loss>=5.561286354064942\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [310]#011Speed: 997.71 samples/sec#011loss=5.561286\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[315] avg_epoch_loss=5.267582\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=315 train loss <loss>=5.336218357086182\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [315]#011Speed: 1934.82 samples/sec#011loss=5.336218\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[320] avg_epoch_loss=5.266878\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=320 train loss <loss>=5.2224123001098635\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [320]#011Speed: 1058.60 samples/sec#011loss=5.222412\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[325] avg_epoch_loss=5.268411\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=325 train loss <loss>=5.366773319244385\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [325]#011Speed: 1944.07 samples/sec#011loss=5.366773\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[330] avg_epoch_loss=5.267668\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=330 train loss <loss>=5.219228267669678\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [330]#011Speed: 1078.22 samples/sec#011loss=5.219228\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[335] avg_epoch_loss=5.264682\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=335 train loss <loss>=5.066999816894532\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [335]#011Speed: 1920.77 samples/sec#011loss=5.067000\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[340] avg_epoch_loss=5.264950\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=340 train loss <loss>=5.282991600036621\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [340]#011Speed: 1026.05 samples/sec#011loss=5.282992\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[345] avg_epoch_loss=5.268449\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=345 train loss <loss>=5.507096290588379\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [345]#011Speed: 1895.67 samples/sec#011loss=5.507096\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch[350] avg_epoch_loss=5.265020\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=350 train loss <loss>=5.027731800079346\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:19 INFO 140667699287680] Epoch[16] Batch [350]#011Speed: 1071.60 samples/sec#011loss=5.027732\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[355] avg_epoch_loss=5.265246\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=355 train loss <loss>=5.281083011627198\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [355]#011Speed: 1892.95 samples/sec#011loss=5.281083\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[360] avg_epoch_loss=5.263321\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=360 train loss <loss>=5.126289558410645\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [360]#011Speed: 1093.48 samples/sec#011loss=5.126290\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[365] avg_epoch_loss=5.263695\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=365 train loss <loss>=5.290712928771972\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [365]#011Speed: 1921.19 samples/sec#011loss=5.290713\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[370] avg_epoch_loss=5.260614\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=370 train loss <loss>=5.035049152374268\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [370]#011Speed: 1042.99 samples/sec#011loss=5.035049\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[375] avg_epoch_loss=5.258594\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=375 train loss <loss>=5.108681583404541\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [375]#011Speed: 1769.69 samples/sec#011loss=5.108682\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[380] avg_epoch_loss=5.256738\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=380 train loss <loss>=5.117236709594726\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [380]#011Speed: 1066.00 samples/sec#011loss=5.117237\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[385] avg_epoch_loss=5.258625\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=385 train loss <loss>=5.4024077415466305\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [385]#011Speed: 1658.54 samples/sec#011loss=5.402408\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[390] avg_epoch_loss=5.256629\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=390 train loss <loss>=5.102541255950928\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [390]#011Speed: 1064.46 samples/sec#011loss=5.102541\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch[395] avg_epoch_loss=5.258251\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=395 train loss <loss>=5.385075092315674\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:20 INFO 140667699287680] Epoch[16] Batch [395]#011Speed: 1824.06 samples/sec#011loss=5.385075\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[400] avg_epoch_loss=5.261653\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=400 train loss <loss>=5.531093788146973\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [400]#011Speed: 1084.04 samples/sec#011loss=5.531094\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[405] avg_epoch_loss=5.263875\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=405 train loss <loss>=5.442096614837647\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [405]#011Speed: 1606.40 samples/sec#011loss=5.442097\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[410] avg_epoch_loss=5.262957\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=410 train loss <loss>=5.1884137153625485\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [410]#011Speed: 1091.44 samples/sec#011loss=5.188414\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[415] avg_epoch_loss=5.262532\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=415 train loss <loss>=5.227581882476807\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [415]#011Speed: 1636.66 samples/sec#011loss=5.227582\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[420] avg_epoch_loss=5.259620\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=420 train loss <loss>=5.017301368713379\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [420]#011Speed: 1127.86 samples/sec#011loss=5.017301\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[425] avg_epoch_loss=5.263806\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=425 train loss <loss>=5.616295719146729\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [425]#011Speed: 1620.94 samples/sec#011loss=5.616296\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[430] avg_epoch_loss=5.262498\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=430 train loss <loss>=5.151074504852295\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [430]#011Speed: 1126.31 samples/sec#011loss=5.151075\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch[435] avg_epoch_loss=5.262006\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=435 train loss <loss>=5.219593334197998\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:21 INFO 140667699287680] Epoch[16] Batch [435]#011Speed: 1740.52 samples/sec#011loss=5.219593\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[440] avg_epoch_loss=5.262244\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=440 train loss <loss>=5.282950115203858\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [440]#011Speed: 925.09 samples/sec#011loss=5.282950\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[445] avg_epoch_loss=5.255124\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=445 train loss <loss>=4.627130222320557\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [445]#011Speed: 1812.95 samples/sec#011loss=4.627130\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[450] avg_epoch_loss=5.254160\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=450 train loss <loss>=5.168246555328369\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [450]#011Speed: 1065.08 samples/sec#011loss=5.168247\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[455] avg_epoch_loss=5.254018\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=455 train loss <loss>=5.241158866882325\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [455]#011Speed: 1851.01 samples/sec#011loss=5.241159\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[460] avg_epoch_loss=5.254200\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=460 train loss <loss>=5.2707620620727536\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [460]#011Speed: 1091.90 samples/sec#011loss=5.270762\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[465] avg_epoch_loss=5.254849\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=465 train loss <loss>=5.314695644378662\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [465]#011Speed: 1719.75 samples/sec#011loss=5.314696\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[470] avg_epoch_loss=5.253498\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=470 train loss <loss>=5.127655410766602\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [470]#011Speed: 1032.13 samples/sec#011loss=5.127655\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch[475] avg_epoch_loss=5.254355\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=475 train loss <loss>=5.335075950622558\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:22 INFO 140667699287680] Epoch[16] Batch [475]#011Speed: 1569.94 samples/sec#011loss=5.335076\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[480] avg_epoch_loss=5.253083\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=480 train loss <loss>=5.131970977783203\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [480]#011Speed: 1044.52 samples/sec#011loss=5.131971\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[485] avg_epoch_loss=5.253604\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=485 train loss <loss>=5.303729057312012\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [485]#011Speed: 1952.41 samples/sec#011loss=5.303729\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[490] avg_epoch_loss=5.252562\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=490 train loss <loss>=5.1512350082397464\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [490]#011Speed: 1072.78 samples/sec#011loss=5.151235\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[495] avg_epoch_loss=5.250825\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=495 train loss <loss>=5.080264472961426\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [495]#011Speed: 1921.17 samples/sec#011loss=5.080264\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[500] avg_epoch_loss=5.250790\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=500 train loss <loss>=5.247365188598633\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [500]#011Speed: 1069.01 samples/sec#011loss=5.247365\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[505] avg_epoch_loss=5.251420\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=505 train loss <loss>=5.3144941329956055\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [505]#011Speed: 1892.88 samples/sec#011loss=5.314494\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[510] avg_epoch_loss=5.250287\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=510 train loss <loss>=5.135603332519532\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [510]#011Speed: 1062.74 samples/sec#011loss=5.135603\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch[515] avg_epoch_loss=5.250611\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=515 train loss <loss>=5.283745288848877\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:23 INFO 140667699287680] Epoch[16] Batch [515]#011Speed: 1846.30 samples/sec#011loss=5.283745\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch[520] avg_epoch_loss=5.250543\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=520 train loss <loss>=5.243579959869384\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch [520]#011Speed: 1050.39 samples/sec#011loss=5.243580\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch[525] avg_epoch_loss=5.251564\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=525 train loss <loss>=5.357905101776123\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch [525]#011Speed: 1931.30 samples/sec#011loss=5.357905\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch[530] avg_epoch_loss=5.251112\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=530 train loss <loss>=5.203622722625733\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch [530]#011Speed: 1088.25 samples/sec#011loss=5.203623\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch[535] avg_epoch_loss=5.251041\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=535 train loss <loss>=5.243403530120849\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch [535]#011Speed: 1863.03 samples/sec#011loss=5.243404\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch[540] avg_epoch_loss=5.250029\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=540 train loss <loss>=5.141637706756592\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch [540]#011Speed: 1139.03 samples/sec#011loss=5.141638\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch[545] avg_epoch_loss=5.249286\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, batch=545 train loss <loss>=5.168870830535889\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[16] Batch [545]#011Speed: 1830.18 samples/sec#011loss=5.168871\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] processed a total of 17557 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990011.489953, \"EndTime\": 1620990024.6300292, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13140.03038406372, \"count\": 1, \"min\": 13140.03038406372, \"max\": 13140.03038406372}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1336.136812243149 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=16, train loss <loss>=5.248645785076371\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[17] Batch[0] avg_epoch_loss=5.136784\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=5.136784076690674\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[17] Batch[5] avg_epoch_loss=5.161684\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=5.161684433619182\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[17] Batch [5]#011Speed: 1867.99 samples/sec#011loss=5.161684\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[17] Batch[10] avg_epoch_loss=5.218067\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=5.28572645187378\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:24 INFO 140667699287680] Epoch[17] Batch [10]#011Speed: 1032.70 samples/sec#011loss=5.285726\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[15] avg_epoch_loss=5.163191\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=5.042464733123779\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [15]#011Speed: 1829.63 samples/sec#011loss=5.042465\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[20] avg_epoch_loss=5.123738\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=4.997486972808838\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [20]#011Speed: 1125.26 samples/sec#011loss=4.997487\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[25] avg_epoch_loss=5.158805\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=5.306086635589599\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [25]#011Speed: 1928.51 samples/sec#011loss=5.306087\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[30] avg_epoch_loss=5.183257\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=5.310410022735596\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [30]#011Speed: 1110.51 samples/sec#011loss=5.310410\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[35] avg_epoch_loss=5.180233\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=5.1614806175231935\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [35]#011Speed: 1694.84 samples/sec#011loss=5.161481\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[40] avg_epoch_loss=5.196579\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=5.314271259307861\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [40]#011Speed: 1087.71 samples/sec#011loss=5.314271\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[45] avg_epoch_loss=5.197693\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=5.206830883026123\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [45]#011Speed: 1720.02 samples/sec#011loss=5.206831\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[50] avg_epoch_loss=5.203820\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=5.260185241699219\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [50]#011Speed: 1024.22 samples/sec#011loss=5.260185\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch[55] avg_epoch_loss=5.185661\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=5.000433540344238\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:25 INFO 140667699287680] Epoch[17] Batch [55]#011Speed: 1864.02 samples/sec#011loss=5.000434\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[60] avg_epoch_loss=5.220371\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=5.609126281738281\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [60]#011Speed: 1001.72 samples/sec#011loss=5.609126\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[65] avg_epoch_loss=5.214378\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=5.141259574890137\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [65]#011Speed: 1896.23 samples/sec#011loss=5.141260\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[70] avg_epoch_loss=5.217953\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=5.265149307250977\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [70]#011Speed: 1087.06 samples/sec#011loss=5.265149\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[75] avg_epoch_loss=5.219544\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=5.24213981628418\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [75]#011Speed: 1903.36 samples/sec#011loss=5.242140\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[80] avg_epoch_loss=5.231217\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=5.408642292022705\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [80]#011Speed: 1039.09 samples/sec#011loss=5.408642\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[85] avg_epoch_loss=5.239838\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=5.379502201080323\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [85]#011Speed: 1662.34 samples/sec#011loss=5.379502\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[90] avg_epoch_loss=5.230917\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=5.07747859954834\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [90]#011Speed: 992.07 samples/sec#011loss=5.077479\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch[95] avg_epoch_loss=5.235623\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=5.321268844604492\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:26 INFO 140667699287680] Epoch[17] Batch [95]#011Speed: 1711.00 samples/sec#011loss=5.321269\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[100] avg_epoch_loss=5.229640\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=5.114754772186279\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [100]#011Speed: 1094.46 samples/sec#011loss=5.114755\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[105] avg_epoch_loss=5.224180\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=5.113895511627197\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [105]#011Speed: 1949.59 samples/sec#011loss=5.113896\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[110] avg_epoch_loss=5.230017\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=5.353752136230469\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [110]#011Speed: 1166.00 samples/sec#011loss=5.353752\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[115] avg_epoch_loss=5.230442\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=5.239883518218994\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [115]#011Speed: 1771.95 samples/sec#011loss=5.239884\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[120] avg_epoch_loss=5.232421\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=5.278348159790039\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [120]#011Speed: 1135.21 samples/sec#011loss=5.278348\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[125] avg_epoch_loss=5.230859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=5.19304084777832\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [125]#011Speed: 1963.99 samples/sec#011loss=5.193041\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[130] avg_epoch_loss=5.230446\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=5.220037746429443\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [130]#011Speed: 1079.82 samples/sec#011loss=5.220038\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch[135] avg_epoch_loss=5.223561\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=5.043193721771241\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:27 INFO 140667699287680] Epoch[17] Batch [135]#011Speed: 1890.88 samples/sec#011loss=5.043194\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[140] avg_epoch_loss=5.223697\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=5.227381038665771\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [140]#011Speed: 951.21 samples/sec#011loss=5.227381\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[145] avg_epoch_loss=5.222751\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=5.196085834503174\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [145]#011Speed: 1892.42 samples/sec#011loss=5.196086\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[150] avg_epoch_loss=5.225747\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=5.313208389282226\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [150]#011Speed: 1131.01 samples/sec#011loss=5.313208\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[155] avg_epoch_loss=5.226873\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=5.260881042480468\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [155]#011Speed: 1856.58 samples/sec#011loss=5.260881\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[160] avg_epoch_loss=5.216204\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=4.883351230621338\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [160]#011Speed: 1061.33 samples/sec#011loss=4.883351\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[165] avg_epoch_loss=5.221543\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=5.393446254730224\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [165]#011Speed: 1853.28 samples/sec#011loss=5.393446\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[170] avg_epoch_loss=5.214321\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=4.974559020996094\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [170]#011Speed: 1004.40 samples/sec#011loss=4.974559\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch[175] avg_epoch_loss=5.211956\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=5.131080627441406\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:28 INFO 140667699287680] Epoch[17] Batch [175]#011Speed: 1911.28 samples/sec#011loss=5.131081\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[180] avg_epoch_loss=5.210987\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=5.176880359649658\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [180]#011Speed: 1024.54 samples/sec#011loss=5.176880\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[185] avg_epoch_loss=5.221216\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=5.591496849060059\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [185]#011Speed: 1872.39 samples/sec#011loss=5.591497\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[190] avg_epoch_loss=5.220952\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=5.211116790771484\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [190]#011Speed: 1135.42 samples/sec#011loss=5.211117\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[195] avg_epoch_loss=5.223437\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=5.3183893203735355\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [195]#011Speed: 1853.87 samples/sec#011loss=5.318389\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[200] avg_epoch_loss=5.222515\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=5.186342716217041\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [200]#011Speed: 1161.92 samples/sec#011loss=5.186343\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[205] avg_epoch_loss=5.215413\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=4.929911327362061\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [205]#011Speed: 1755.09 samples/sec#011loss=4.929911\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[210] avg_epoch_loss=5.217972\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=5.323405933380127\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [210]#011Speed: 1006.77 samples/sec#011loss=5.323406\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[215] avg_epoch_loss=5.220320\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=5.319418144226074\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [215]#011Speed: 1776.36 samples/sec#011loss=5.319418\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch[220] avg_epoch_loss=5.219980\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=5.205268859863281\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:29 INFO 140667699287680] Epoch[17] Batch [220]#011Speed: 1083.77 samples/sec#011loss=5.205269\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[225] avg_epoch_loss=5.213264\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=4.916429138183593\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [225]#011Speed: 1822.59 samples/sec#011loss=4.916429\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[230] avg_epoch_loss=5.210357\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=5.078983879089355\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [230]#011Speed: 1096.43 samples/sec#011loss=5.078984\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[235] avg_epoch_loss=5.211452\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=5.2620110511779785\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [235]#011Speed: 1947.30 samples/sec#011loss=5.262011\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[240] avg_epoch_loss=5.212286\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=5.25166072845459\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [240]#011Speed: 1035.31 samples/sec#011loss=5.251661\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[245] avg_epoch_loss=5.216295\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=5.409539031982422\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [245]#011Speed: 1948.13 samples/sec#011loss=5.409539\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[250] avg_epoch_loss=5.216674\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=5.235313510894775\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [250]#011Speed: 1050.72 samples/sec#011loss=5.235314\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[255] avg_epoch_loss=5.215635\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=5.163479518890381\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [255]#011Speed: 1946.85 samples/sec#011loss=5.163480\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[260] avg_epoch_loss=5.212051\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=5.028548717498779\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [260]#011Speed: 1082.45 samples/sec#011loss=5.028549\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch[265] avg_epoch_loss=5.213723\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=5.301024723052978\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:30 INFO 140667699287680] Epoch[17] Batch [265]#011Speed: 1912.64 samples/sec#011loss=5.301025\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[270] avg_epoch_loss=5.213692\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=270 train loss <loss>=5.212020969390869\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [270]#011Speed: 1081.66 samples/sec#011loss=5.212021\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[275] avg_epoch_loss=5.220204\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=275 train loss <loss>=5.573152256011963\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [275]#011Speed: 1919.45 samples/sec#011loss=5.573152\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[280] avg_epoch_loss=5.219531\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=280 train loss <loss>=5.182377433776855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [280]#011Speed: 1127.03 samples/sec#011loss=5.182377\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[285] avg_epoch_loss=5.219684\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=285 train loss <loss>=5.228317356109619\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [285]#011Speed: 1905.79 samples/sec#011loss=5.228317\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[290] avg_epoch_loss=5.215083\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=290 train loss <loss>=4.951902103424072\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [290]#011Speed: 1090.50 samples/sec#011loss=4.951902\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[295] avg_epoch_loss=5.217420\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=295 train loss <loss>=5.353392505645752\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [295]#011Speed: 1948.35 samples/sec#011loss=5.353393\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[300] avg_epoch_loss=5.215183\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=300 train loss <loss>=5.082771587371826\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [300]#011Speed: 1058.87 samples/sec#011loss=5.082772\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch[305] avg_epoch_loss=5.215254\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=305 train loss <loss>=5.219552040100098\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:31 INFO 140667699287680] Epoch[17] Batch [305]#011Speed: 1883.03 samples/sec#011loss=5.219552\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[310] avg_epoch_loss=5.217945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=310 train loss <loss>=5.382630252838135\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [310]#011Speed: 1049.62 samples/sec#011loss=5.382630\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[315] avg_epoch_loss=5.217935\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=315 train loss <loss>=5.217281723022461\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [315]#011Speed: 1912.37 samples/sec#011loss=5.217282\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[320] avg_epoch_loss=5.218679\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=320 train loss <loss>=5.265715217590332\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [320]#011Speed: 1076.65 samples/sec#011loss=5.265715\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[325] avg_epoch_loss=5.221299\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=325 train loss <loss>=5.389521789550781\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [325]#011Speed: 1829.91 samples/sec#011loss=5.389522\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[330] avg_epoch_loss=5.225410\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=330 train loss <loss>=5.493425178527832\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [330]#011Speed: 1122.15 samples/sec#011loss=5.493425\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[335] avg_epoch_loss=5.222548\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=335 train loss <loss>=5.033060359954834\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [335]#011Speed: 1923.46 samples/sec#011loss=5.033060\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[340] avg_epoch_loss=5.223790\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=340 train loss <loss>=5.307244777679443\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [340]#011Speed: 1037.40 samples/sec#011loss=5.307245\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[345] avg_epoch_loss=5.221555\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=345 train loss <loss>=5.069137859344482\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [345]#011Speed: 1784.22 samples/sec#011loss=5.069138\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch[350] avg_epoch_loss=5.221774\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=350 train loss <loss>=5.236971759796143\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:32 INFO 140667699287680] Epoch[17] Batch [350]#011Speed: 1040.10 samples/sec#011loss=5.236972\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[355] avg_epoch_loss=5.218126\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=355 train loss <loss>=4.962032699584961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [355]#011Speed: 1572.61 samples/sec#011loss=4.962033\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[360] avg_epoch_loss=5.219192\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=360 train loss <loss>=5.295075798034668\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [360]#011Speed: 1056.20 samples/sec#011loss=5.295076\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[365] avg_epoch_loss=5.218739\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=365 train loss <loss>=5.1860357284545895\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [365]#011Speed: 1950.69 samples/sec#011loss=5.186036\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[370] avg_epoch_loss=5.218165\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=370 train loss <loss>=5.176144027709961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [370]#011Speed: 1114.01 samples/sec#011loss=5.176144\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[375] avg_epoch_loss=5.220175\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=375 train loss <loss>=5.369342422485351\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [375]#011Speed: 1946.82 samples/sec#011loss=5.369342\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[380] avg_epoch_loss=5.223314\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=380 train loss <loss>=5.459313297271729\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [380]#011Speed: 1072.41 samples/sec#011loss=5.459313\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[385] avg_epoch_loss=5.220288\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=385 train loss <loss>=4.989740467071533\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [385]#011Speed: 1851.61 samples/sec#011loss=4.989740\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch[390] avg_epoch_loss=5.219795\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=390 train loss <loss>=5.181724548339844\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:33 INFO 140667699287680] Epoch[17] Batch [390]#011Speed: 1061.41 samples/sec#011loss=5.181725\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[395] avg_epoch_loss=5.219486\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=395 train loss <loss>=5.195322322845459\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [395]#011Speed: 1676.77 samples/sec#011loss=5.195322\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[400] avg_epoch_loss=5.216769\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=400 train loss <loss>=5.001621913909912\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [400]#011Speed: 1092.46 samples/sec#011loss=5.001622\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[405] avg_epoch_loss=5.218859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=405 train loss <loss>=5.386447906494141\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [405]#011Speed: 1899.17 samples/sec#011loss=5.386448\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[410] avg_epoch_loss=5.216528\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=410 train loss <loss>=5.027246570587158\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [410]#011Speed: 1081.87 samples/sec#011loss=5.027247\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[415] avg_epoch_loss=5.218335\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=415 train loss <loss>=5.366827964782715\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [415]#011Speed: 1957.90 samples/sec#011loss=5.366828\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[420] avg_epoch_loss=5.219573\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=420 train loss <loss>=5.322649383544922\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [420]#011Speed: 1080.34 samples/sec#011loss=5.322649\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[425] avg_epoch_loss=5.219271\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=425 train loss <loss>=5.193785381317139\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [425]#011Speed: 1875.25 samples/sec#011loss=5.193785\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[430] avg_epoch_loss=5.220602\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=430 train loss <loss>=5.334030723571777\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [430]#011Speed: 1102.22 samples/sec#011loss=5.334031\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch[435] avg_epoch_loss=5.222347\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=435 train loss <loss>=5.3727799415588375\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:34 INFO 140667699287680] Epoch[17] Batch [435]#011Speed: 1818.43 samples/sec#011loss=5.372780\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[440] avg_epoch_loss=5.220559\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=440 train loss <loss>=5.06458215713501\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [440]#011Speed: 992.53 samples/sec#011loss=5.064582\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[445] avg_epoch_loss=5.221074\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=445 train loss <loss>=5.266553020477295\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [445]#011Speed: 1934.88 samples/sec#011loss=5.266553\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[450] avg_epoch_loss=5.220793\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=450 train loss <loss>=5.195697593688965\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [450]#011Speed: 1145.25 samples/sec#011loss=5.195698\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[455] avg_epoch_loss=5.220129\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=455 train loss <loss>=5.160227203369141\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [455]#011Speed: 1965.78 samples/sec#011loss=5.160227\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[460] avg_epoch_loss=5.218800\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=460 train loss <loss>=5.09757661819458\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [460]#011Speed: 1157.97 samples/sec#011loss=5.097577\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[465] avg_epoch_loss=5.219636\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=465 train loss <loss>=5.296798419952393\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [465]#011Speed: 1903.35 samples/sec#011loss=5.296798\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[470] avg_epoch_loss=5.219623\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=470 train loss <loss>=5.21836404800415\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [470]#011Speed: 1039.20 samples/sec#011loss=5.218364\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch[475] avg_epoch_loss=5.218217\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=475 train loss <loss>=5.085790920257568\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:35 INFO 140667699287680] Epoch[17] Batch [475]#011Speed: 1825.24 samples/sec#011loss=5.085791\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[480] avg_epoch_loss=5.217933\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=480 train loss <loss>=5.1909050941467285\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [480]#011Speed: 1133.08 samples/sec#011loss=5.190905\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[485] avg_epoch_loss=5.217725\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=485 train loss <loss>=5.197731590270996\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [485]#011Speed: 1967.00 samples/sec#011loss=5.197732\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[490] avg_epoch_loss=5.213272\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=490 train loss <loss>=4.780372619628906\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [490]#011Speed: 1048.77 samples/sec#011loss=4.780373\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[495] avg_epoch_loss=5.211020\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=495 train loss <loss>=4.989858722686767\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [495]#011Speed: 1925.65 samples/sec#011loss=4.989859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[500] avg_epoch_loss=5.210475\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=500 train loss <loss>=5.156438255310059\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [500]#011Speed: 1124.70 samples/sec#011loss=5.156438\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[505] avg_epoch_loss=5.208430\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=505 train loss <loss>=5.003520584106445\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [505]#011Speed: 1977.47 samples/sec#011loss=5.003521\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[510] avg_epoch_loss=5.205389\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=510 train loss <loss>=4.8976997375488285\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [510]#011Speed: 1119.15 samples/sec#011loss=4.897700\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[515] avg_epoch_loss=5.204362\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=515 train loss <loss>=5.099384498596192\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [515]#011Speed: 1959.69 samples/sec#011loss=5.099384\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch[520] avg_epoch_loss=5.205589\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=520 train loss <loss>=5.332141780853272\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:36 INFO 140667699287680] Epoch[17] Batch [520]#011Speed: 1056.72 samples/sec#011loss=5.332142\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[525] avg_epoch_loss=5.205038\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=525 train loss <loss>=5.147700595855713\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [525]#011Speed: 1832.50 samples/sec#011loss=5.147701\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[530] avg_epoch_loss=5.204449\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=530 train loss <loss>=5.1424384117126465\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [530]#011Speed: 1086.83 samples/sec#011loss=5.142438\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[535] avg_epoch_loss=5.204216\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=535 train loss <loss>=5.1794942855834964\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [535]#011Speed: 1886.83 samples/sec#011loss=5.179494\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[540] avg_epoch_loss=5.202155\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=540 train loss <loss>=4.981231689453125\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [540]#011Speed: 1083.06 samples/sec#011loss=4.981232\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[545] avg_epoch_loss=5.203373\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=545 train loss <loss>=5.3351295471191404\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [545]#011Speed: 1938.45 samples/sec#011loss=5.335130\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[550] avg_epoch_loss=5.203907\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=550 train loss <loss>=5.262202548980713\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [550]#011Speed: 1287.36 samples/sec#011loss=5.262203\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch[555] avg_epoch_loss=5.204536\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, batch=555 train loss <loss>=5.273854827880859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[17] Batch [555]#011Speed: 1884.05 samples/sec#011loss=5.273855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] processed a total of 17794 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990024.6300917, \"EndTime\": 1620990037.715199, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13084.780931472778, \"count\": 1, \"min\": 13084.780931472778, \"max\": 13084.780931472778}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1359.890925420177 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=17, train loss <loss>=5.206119117017709\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_a0672c2b-45c2-4f28-80cd-60e1900979cc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990037.715261, \"EndTime\": 1620990037.7248194, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.220123291015625, \"count\": 1, \"min\": 9.220123291015625, \"max\": 9.220123291015625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[18] Batch[0] avg_epoch_loss=4.913509\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=4.913509368896484\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[18] Batch[5] avg_epoch_loss=4.896001\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=4.8960011800130205\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:37 INFO 140667699287680] Epoch[18] Batch [5]#011Speed: 1679.28 samples/sec#011loss=4.896001\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[10] avg_epoch_loss=4.907373\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=4.921018314361572\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [10]#011Speed: 1005.04 samples/sec#011loss=4.921018\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[15] avg_epoch_loss=5.037627\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=5.3241852760314945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [15]#011Speed: 1677.20 samples/sec#011loss=5.324185\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[20] avg_epoch_loss=5.084354\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=5.233881664276123\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [20]#011Speed: 947.35 samples/sec#011loss=5.233882\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[25] avg_epoch_loss=5.114086\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=5.238963031768799\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [25]#011Speed: 1942.81 samples/sec#011loss=5.238963\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[30] avg_epoch_loss=5.157410\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=5.382691287994385\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [30]#011Speed: 1061.87 samples/sec#011loss=5.382691\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[35] avg_epoch_loss=5.171710\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=5.2603730201721195\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [35]#011Speed: 1892.43 samples/sec#011loss=5.260373\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[40] avg_epoch_loss=5.187520\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=5.301350212097168\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [40]#011Speed: 1084.81 samples/sec#011loss=5.301350\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch[45] avg_epoch_loss=5.173859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=5.061841583251953\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:38 INFO 140667699287680] Epoch[18] Batch [45]#011Speed: 1837.57 samples/sec#011loss=5.061842\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[50] avg_epoch_loss=5.150431\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=4.934886837005616\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [50]#011Speed: 970.34 samples/sec#011loss=4.934887\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[55] avg_epoch_loss=5.156996\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=5.223964214324951\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [55]#011Speed: 1997.66 samples/sec#011loss=5.223964\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[60] avg_epoch_loss=5.153116\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=5.109654808044434\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [60]#011Speed: 1059.63 samples/sec#011loss=5.109655\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[65] avg_epoch_loss=5.160965\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=5.256732749938965\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [65]#011Speed: 1809.98 samples/sec#011loss=5.256733\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[70] avg_epoch_loss=5.157307\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=5.109009265899658\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [70]#011Speed: 1094.09 samples/sec#011loss=5.109009\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[75] avg_epoch_loss=5.158024\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=5.168208312988281\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [75]#011Speed: 1964.98 samples/sec#011loss=5.168208\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[80] avg_epoch_loss=5.177488\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=5.473348140716553\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [80]#011Speed: 1133.16 samples/sec#011loss=5.473348\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[85] avg_epoch_loss=5.175241\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=5.138826847076416\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [85]#011Speed: 1926.74 samples/sec#011loss=5.138827\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch[90] avg_epoch_loss=5.189260\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=5.430388259887695\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:39 INFO 140667699287680] Epoch[18] Batch [90]#011Speed: 1051.61 samples/sec#011loss=5.430388\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[95] avg_epoch_loss=5.185858\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=5.1239574432373045\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [95]#011Speed: 1647.24 samples/sec#011loss=5.123957\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[100] avg_epoch_loss=5.195472\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=5.380043983459473\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [100]#011Speed: 1014.60 samples/sec#011loss=5.380044\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[105] avg_epoch_loss=5.185769\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=4.989774894714356\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [105]#011Speed: 1885.29 samples/sec#011loss=4.989775\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[110] avg_epoch_loss=5.175485\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=4.957459545135498\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [110]#011Speed: 1166.44 samples/sec#011loss=4.957460\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[115] avg_epoch_loss=5.170240\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=5.053814029693603\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [115]#011Speed: 1957.87 samples/sec#011loss=5.053814\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[120] avg_epoch_loss=5.165842\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=5.063801670074463\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [120]#011Speed: 1139.50 samples/sec#011loss=5.063802\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[125] avg_epoch_loss=5.163561\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=5.1083649635314945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [125]#011Speed: 1839.03 samples/sec#011loss=5.108365\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[130] avg_epoch_loss=5.166136\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=5.231024837493896\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [130]#011Speed: 1090.49 samples/sec#011loss=5.231025\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch[135] avg_epoch_loss=5.157258\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=4.924644470214844\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:40 INFO 140667699287680] Epoch[18] Batch [135]#011Speed: 1950.64 samples/sec#011loss=4.924644\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[140] avg_epoch_loss=5.155689\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=5.113019752502441\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [140]#011Speed: 1117.91 samples/sec#011loss=5.113020\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[145] avg_epoch_loss=5.160277\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=5.289670467376709\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [145]#011Speed: 1776.95 samples/sec#011loss=5.289670\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[150] avg_epoch_loss=5.154210\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=4.977053928375244\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [150]#011Speed: 1114.52 samples/sec#011loss=4.977054\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[155] avg_epoch_loss=5.159883\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=5.331203556060791\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [155]#011Speed: 1809.82 samples/sec#011loss=5.331204\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[160] avg_epoch_loss=5.159847\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=5.158700847625733\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [160]#011Speed: 1114.28 samples/sec#011loss=5.158701\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[165] avg_epoch_loss=5.160994\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=5.197937297821045\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [165]#011Speed: 1918.65 samples/sec#011loss=5.197937\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[170] avg_epoch_loss=5.160371\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=5.139687442779541\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [170]#011Speed: 1175.52 samples/sec#011loss=5.139687\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch[175] avg_epoch_loss=5.160190\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=5.15400447845459\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:41 INFO 140667699287680] Epoch[18] Batch [175]#011Speed: 1799.81 samples/sec#011loss=5.154004\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[180] avg_epoch_loss=5.164758\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=5.325541305541992\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [180]#011Speed: 1039.62 samples/sec#011loss=5.325541\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[185] avg_epoch_loss=5.163009\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=5.099694633483887\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [185]#011Speed: 1710.80 samples/sec#011loss=5.099695\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[190] avg_epoch_loss=5.176065\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=5.661759757995606\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [190]#011Speed: 1087.18 samples/sec#011loss=5.661760\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[195] avg_epoch_loss=5.175053\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=5.1363951683044435\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [195]#011Speed: 1899.17 samples/sec#011loss=5.136395\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[200] avg_epoch_loss=5.175415\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=5.189597702026367\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [200]#011Speed: 1115.17 samples/sec#011loss=5.189598\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[205] avg_epoch_loss=5.172770\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=5.066459465026855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [205]#011Speed: 1710.41 samples/sec#011loss=5.066459\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[210] avg_epoch_loss=5.173947\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=5.2224396705627445\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [210]#011Speed: 1156.85 samples/sec#011loss=5.222440\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[215] avg_epoch_loss=5.173015\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=5.133682727813721\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [215]#011Speed: 1963.37 samples/sec#011loss=5.133683\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch[220] avg_epoch_loss=5.167163\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=4.914358329772949\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:42 INFO 140667699287680] Epoch[18] Batch [220]#011Speed: 1081.99 samples/sec#011loss=4.914358\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[225] avg_epoch_loss=5.164494\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=5.046516799926758\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [225]#011Speed: 1709.15 samples/sec#011loss=5.046517\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[230] avg_epoch_loss=5.161372\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=5.020258808135987\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [230]#011Speed: 1025.24 samples/sec#011loss=5.020259\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[235] avg_epoch_loss=5.161029\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=5.145174789428711\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [235]#011Speed: 1940.56 samples/sec#011loss=5.145175\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[240] avg_epoch_loss=5.165730\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=5.38764123916626\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [240]#011Speed: 1115.11 samples/sec#011loss=5.387641\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[245] avg_epoch_loss=5.164939\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=5.126785087585449\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [245]#011Speed: 1950.34 samples/sec#011loss=5.126785\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[250] avg_epoch_loss=5.169819\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=5.409918403625488\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [250]#011Speed: 1099.84 samples/sec#011loss=5.409918\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[255] avg_epoch_loss=5.170520\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=5.205710124969483\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [255]#011Speed: 1960.42 samples/sec#011loss=5.205710\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch[260] avg_epoch_loss=5.171980\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=260 train loss <loss>=5.246723270416259\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:43 INFO 140667699287680] Epoch[18] Batch [260]#011Speed: 1082.07 samples/sec#011loss=5.246723\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[265] avg_epoch_loss=5.172313\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=265 train loss <loss>=5.189696216583252\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [265]#011Speed: 1815.68 samples/sec#011loss=5.189696\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[270] avg_epoch_loss=5.175203\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=270 train loss <loss>=5.328960704803467\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [270]#011Speed: 1102.57 samples/sec#011loss=5.328961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[275] avg_epoch_loss=5.177710\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=275 train loss <loss>=5.313599586486816\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [275]#011Speed: 1959.75 samples/sec#011loss=5.313600\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[280] avg_epoch_loss=5.168479\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=280 train loss <loss>=4.658891391754151\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [280]#011Speed: 1031.85 samples/sec#011loss=4.658891\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[285] avg_epoch_loss=5.170366\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=285 train loss <loss>=5.2764442443847654\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [285]#011Speed: 1918.78 samples/sec#011loss=5.276444\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[290] avg_epoch_loss=5.163834\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=290 train loss <loss>=4.790228462219238\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [290]#011Speed: 1099.07 samples/sec#011loss=4.790228\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[295] avg_epoch_loss=5.163660\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=295 train loss <loss>=5.153530216217041\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [295]#011Speed: 1918.36 samples/sec#011loss=5.153530\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[300] avg_epoch_loss=5.164905\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=300 train loss <loss>=5.238569927215576\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [300]#011Speed: 1125.56 samples/sec#011loss=5.238570\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch[305] avg_epoch_loss=5.164929\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=305 train loss <loss>=5.166365432739258\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:44 INFO 140667699287680] Epoch[18] Batch [305]#011Speed: 1790.23 samples/sec#011loss=5.166365\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[310] avg_epoch_loss=5.166038\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=310 train loss <loss>=5.233924007415771\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [310]#011Speed: 1057.85 samples/sec#011loss=5.233924\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[315] avg_epoch_loss=5.166848\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=315 train loss <loss>=5.217206859588623\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [315]#011Speed: 1941.68 samples/sec#011loss=5.217207\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[320] avg_epoch_loss=5.163686\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=320 train loss <loss>=4.963892269134521\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [320]#011Speed: 1155.16 samples/sec#011loss=4.963892\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[325] avg_epoch_loss=5.165777\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=325 train loss <loss>=5.299976348876953\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [325]#011Speed: 1944.22 samples/sec#011loss=5.299976\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[330] avg_epoch_loss=5.165067\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=330 train loss <loss>=5.118797969818115\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [330]#011Speed: 1151.60 samples/sec#011loss=5.118798\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[335] avg_epoch_loss=5.165835\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=335 train loss <loss>=5.216700744628906\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [335]#011Speed: 1957.98 samples/sec#011loss=5.216701\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[340] avg_epoch_loss=5.164312\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=340 train loss <loss>=5.061936759948731\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [340]#011Speed: 1156.14 samples/sec#011loss=5.061937\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[345] avg_epoch_loss=5.163859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=345 train loss <loss>=5.132948970794677\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [345]#011Speed: 1897.17 samples/sec#011loss=5.132949\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch[350] avg_epoch_loss=5.163398\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=350 train loss <loss>=5.131535053253174\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:45 INFO 140667699287680] Epoch[18] Batch [350]#011Speed: 986.65 samples/sec#011loss=5.131535\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[355] avg_epoch_loss=5.161779\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=355 train loss <loss>=5.0481010437011715\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [355]#011Speed: 1896.17 samples/sec#011loss=5.048101\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[360] avg_epoch_loss=5.163675\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=360 train loss <loss>=5.2986725807189945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [360]#011Speed: 1109.27 samples/sec#011loss=5.298673\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[365] avg_epoch_loss=5.156714\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=365 train loss <loss>=4.654150104522705\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [365]#011Speed: 1783.25 samples/sec#011loss=4.654150\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[370] avg_epoch_loss=5.155642\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=370 train loss <loss>=5.077144145965576\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [370]#011Speed: 1077.83 samples/sec#011loss=5.077144\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[375] avg_epoch_loss=5.157435\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=375 train loss <loss>=5.290525627136231\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [375]#011Speed: 1935.77 samples/sec#011loss=5.290526\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[380] avg_epoch_loss=5.156717\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=380 train loss <loss>=5.102668952941895\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [380]#011Speed: 1050.52 samples/sec#011loss=5.102669\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[385] avg_epoch_loss=5.155420\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=385 train loss <loss>=5.056604862213135\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [385]#011Speed: 1928.71 samples/sec#011loss=5.056605\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch[390] avg_epoch_loss=5.155052\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=390 train loss <loss>=5.12665023803711\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:46 INFO 140667699287680] Epoch[18] Batch [390]#011Speed: 1065.19 samples/sec#011loss=5.126650\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[395] avg_epoch_loss=5.154483\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=395 train loss <loss>=5.109996128082275\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [395]#011Speed: 1727.96 samples/sec#011loss=5.109996\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[400] avg_epoch_loss=5.154445\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=400 train loss <loss>=5.151460456848144\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [400]#011Speed: 1037.83 samples/sec#011loss=5.151460\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[405] avg_epoch_loss=5.154939\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=405 train loss <loss>=5.194507694244384\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [405]#011Speed: 1895.99 samples/sec#011loss=5.194508\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[410] avg_epoch_loss=5.152415\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=410 train loss <loss>=4.947479343414306\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [410]#011Speed: 1030.12 samples/sec#011loss=4.947479\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[415] avg_epoch_loss=5.153276\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=415 train loss <loss>=5.224039363861084\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [415]#011Speed: 1901.93 samples/sec#011loss=5.224039\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[420] avg_epoch_loss=5.151939\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=420 train loss <loss>=5.040708827972412\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [420]#011Speed: 1158.82 samples/sec#011loss=5.040709\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[425] avg_epoch_loss=5.150795\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=425 train loss <loss>=5.054474639892578\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [425]#011Speed: 1951.57 samples/sec#011loss=5.054475\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[430] avg_epoch_loss=5.150413\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=430 train loss <loss>=5.117883586883545\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [430]#011Speed: 1166.62 samples/sec#011loss=5.117884\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch[435] avg_epoch_loss=5.149266\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=435 train loss <loss>=5.0503819465637205\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:47 INFO 140667699287680] Epoch[18] Batch [435]#011Speed: 1846.43 samples/sec#011loss=5.050382\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[440] avg_epoch_loss=5.151751\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=440 train loss <loss>=5.368456649780273\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [440]#011Speed: 1100.05 samples/sec#011loss=5.368457\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[445] avg_epoch_loss=5.152312\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=445 train loss <loss>=5.201775455474854\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [445]#011Speed: 1946.85 samples/sec#011loss=5.201775\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[450] avg_epoch_loss=5.148847\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=450 train loss <loss>=4.839785575866699\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [450]#011Speed: 1094.42 samples/sec#011loss=4.839786\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[455] avg_epoch_loss=5.148514\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=455 train loss <loss>=5.118480014801025\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [455]#011Speed: 1873.23 samples/sec#011loss=5.118480\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[460] avg_epoch_loss=5.146511\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=460 train loss <loss>=4.963818359375\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [460]#011Speed: 1115.17 samples/sec#011loss=4.963818\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[465] avg_epoch_loss=5.146659\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=465 train loss <loss>=5.160332202911377\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [465]#011Speed: 1947.83 samples/sec#011loss=5.160332\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[470] avg_epoch_loss=5.148648\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=470 train loss <loss>=5.333984851837158\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [470]#011Speed: 1152.81 samples/sec#011loss=5.333985\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[475] avg_epoch_loss=5.150875\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=475 train loss <loss>=5.360701942443848\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [475]#011Speed: 1960.36 samples/sec#011loss=5.360702\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch[480] avg_epoch_loss=5.150619\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=480 train loss <loss>=5.126250267028809\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:48 INFO 140667699287680] Epoch[18] Batch [480]#011Speed: 1131.56 samples/sec#011loss=5.126250\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[485] avg_epoch_loss=5.152823\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=485 train loss <loss>=5.364812278747559\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [485]#011Speed: 1771.38 samples/sec#011loss=5.364812\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[490] avg_epoch_loss=5.153741\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=490 train loss <loss>=5.242949771881103\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [490]#011Speed: 1054.86 samples/sec#011loss=5.242950\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[495] avg_epoch_loss=5.153824\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=495 train loss <loss>=5.161954498291015\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [495]#011Speed: 1719.70 samples/sec#011loss=5.161954\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[500] avg_epoch_loss=5.152829\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=500 train loss <loss>=5.054145050048828\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [500]#011Speed: 1120.44 samples/sec#011loss=5.054145\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[505] avg_epoch_loss=5.152092\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=505 train loss <loss>=5.0782773971557615\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [505]#011Speed: 1888.03 samples/sec#011loss=5.078277\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[510] avg_epoch_loss=5.152371\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=510 train loss <loss>=5.180578422546387\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [510]#011Speed: 1126.95 samples/sec#011loss=5.180578\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[515] avg_epoch_loss=5.151230\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=515 train loss <loss>=5.034613037109375\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [515]#011Speed: 1891.06 samples/sec#011loss=5.034613\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch[520] avg_epoch_loss=5.148859\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=520 train loss <loss>=4.9042376518249515\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:49 INFO 140667699287680] Epoch[18] Batch [520]#011Speed: 1139.00 samples/sec#011loss=4.904238\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[525] avg_epoch_loss=5.152355\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=525 train loss <loss>=5.5166410446167\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [525]#011Speed: 1917.57 samples/sec#011loss=5.516641\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[530] avg_epoch_loss=5.154124\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=530 train loss <loss>=5.3402244567871096\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [530]#011Speed: 1123.10 samples/sec#011loss=5.340224\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[535] avg_epoch_loss=5.154413\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=535 train loss <loss>=5.185085105895996\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [535]#011Speed: 1833.82 samples/sec#011loss=5.185085\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[540] avg_epoch_loss=5.154038\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=540 train loss <loss>=5.113842391967774\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [540]#011Speed: 1109.09 samples/sec#011loss=5.113842\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[545] avg_epoch_loss=5.154388\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=545 train loss <loss>=5.192200756072998\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [545]#011Speed: 1981.46 samples/sec#011loss=5.192201\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[550] avg_epoch_loss=5.153492\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=550 train loss <loss>=5.0556254386901855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [550]#011Speed: 1146.64 samples/sec#011loss=5.055625\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch[555] avg_epoch_loss=5.150786\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, batch=555 train loss <loss>=4.852664661407471\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[18] Batch [555]#011Speed: 1925.89 samples/sec#011loss=4.852665\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] processed a total of 17880 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990037.7248778, \"EndTime\": 1620990050.7342975, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13009.366512298584, \"count\": 1, \"min\": 13009.366512298584, \"max\": 13009.366512298584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1374.3847411611928 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=18, train loss <loss>=5.1494563141961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/state_e39e15dc-77bf-4e4d-a60e-75bf60a997cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990050.7343588, \"EndTime\": 1620990050.744328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 9.598970413208008, \"count\": 1, \"min\": 9.598970413208008, \"max\": 9.598970413208008}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[19] Batch[0] avg_epoch_loss=5.838853\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=5.838852882385254\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[19] Batch[5] avg_epoch_loss=5.203600\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=5.203599770863851\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:50 INFO 140667699287680] Epoch[19] Batch [5]#011Speed: 1958.86 samples/sec#011loss=5.203600\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[10] avg_epoch_loss=5.211837\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=5.221722030639649\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [10]#011Speed: 1026.70 samples/sec#011loss=5.221722\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[15] avg_epoch_loss=5.204892\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=5.189612674713135\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [15]#011Speed: 1945.06 samples/sec#011loss=5.189613\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[20] avg_epoch_loss=5.235141\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=5.331936454772949\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [20]#011Speed: 1146.20 samples/sec#011loss=5.331936\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[25] avg_epoch_loss=5.252988\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=5.327945518493652\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [25]#011Speed: 1869.85 samples/sec#011loss=5.327946\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[30] avg_epoch_loss=5.234884\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=5.14074478149414\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [30]#011Speed: 1136.06 samples/sec#011loss=5.140745\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[35] avg_epoch_loss=5.192130\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=4.927055358886719\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [35]#011Speed: 1823.77 samples/sec#011loss=4.927055\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[40] avg_epoch_loss=5.194984\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=5.2155311584472654\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [40]#011Speed: 1072.99 samples/sec#011loss=5.215531\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[45] avg_epoch_loss=5.164675\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=4.916144561767578\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [45]#011Speed: 1787.76 samples/sec#011loss=4.916145\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch[50] avg_epoch_loss=5.123957\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=4.749345016479492\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:51 INFO 140667699287680] Epoch[19] Batch [50]#011Speed: 1047.85 samples/sec#011loss=4.749345\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[55] avg_epoch_loss=5.143286\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=5.340442752838134\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [55]#011Speed: 1921.49 samples/sec#011loss=5.340443\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[60] avg_epoch_loss=5.142724\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=5.136429309844971\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [60]#011Speed: 1096.56 samples/sec#011loss=5.136429\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[65] avg_epoch_loss=5.142805\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=5.143800449371338\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [65]#011Speed: 1947.02 samples/sec#011loss=5.143800\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[70] avg_epoch_loss=5.157152\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=5.346535682678223\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [70]#011Speed: 1046.30 samples/sec#011loss=5.346536\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[75] avg_epoch_loss=5.153824\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=5.106564617156982\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [75]#011Speed: 1846.96 samples/sec#011loss=5.106565\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[80] avg_epoch_loss=5.149990\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=5.0917082786560055\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [80]#011Speed: 1047.61 samples/sec#011loss=5.091708\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[85] avg_epoch_loss=5.154313\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=5.224339485168457\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [85]#011Speed: 1958.42 samples/sec#011loss=5.224339\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch[90] avg_epoch_loss=5.154977\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=5.166411590576172\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:52 INFO 140667699287680] Epoch[19] Batch [90]#011Speed: 1130.03 samples/sec#011loss=5.166412\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[95] avg_epoch_loss=5.164015\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=5.3284906387329105\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [95]#011Speed: 1894.26 samples/sec#011loss=5.328491\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[100] avg_epoch_loss=5.167513\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=5.234673309326172\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [100]#011Speed: 1044.38 samples/sec#011loss=5.234673\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[105] avg_epoch_loss=5.178848\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=5.407818603515625\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [105]#011Speed: 1955.35 samples/sec#011loss=5.407819\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[110] avg_epoch_loss=5.191965\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=5.470042133331299\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [110]#011Speed: 1088.37 samples/sec#011loss=5.470042\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[115] avg_epoch_loss=5.198237\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=5.337487602233887\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [115]#011Speed: 1895.14 samples/sec#011loss=5.337488\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[120] avg_epoch_loss=5.191849\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=5.0436371803283695\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [120]#011Speed: 1134.70 samples/sec#011loss=5.043637\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[125] avg_epoch_loss=5.190105\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=5.147912502288818\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [125]#011Speed: 1866.15 samples/sec#011loss=5.147913\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[130] avg_epoch_loss=5.189784\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=5.181682872772217\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [130]#011Speed: 1083.45 samples/sec#011loss=5.181683\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch[135] avg_epoch_loss=5.182249\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=4.984830379486084\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:53 INFO 140667699287680] Epoch[19] Batch [135]#011Speed: 1966.30 samples/sec#011loss=4.984830\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[140] avg_epoch_loss=5.181140\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=5.150989627838134\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [140]#011Speed: 1055.43 samples/sec#011loss=5.150990\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[145] avg_epoch_loss=5.182730\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=5.227573204040527\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [145]#011Speed: 1931.32 samples/sec#011loss=5.227573\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[150] avg_epoch_loss=5.179289\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=5.078801918029785\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [150]#011Speed: 1098.58 samples/sec#011loss=5.078802\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[155] avg_epoch_loss=5.175947\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=5.075010871887207\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [155]#011Speed: 1949.22 samples/sec#011loss=5.075011\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[160] avg_epoch_loss=5.182377\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=5.383010005950927\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [160]#011Speed: 1081.61 samples/sec#011loss=5.383010\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[165] avg_epoch_loss=5.182169\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=5.1754679679870605\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [165]#011Speed: 1728.88 samples/sec#011loss=5.175468\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[170] avg_epoch_loss=5.182553\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=5.1952790260314945\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [170]#011Speed: 1062.05 samples/sec#011loss=5.195279\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch[175] avg_epoch_loss=5.175965\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=4.950654029846191\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:54 INFO 140667699287680] Epoch[19] Batch [175]#011Speed: 1692.13 samples/sec#011loss=4.950654\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[180] avg_epoch_loss=5.177438\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=5.229298210144043\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [180]#011Speed: 1106.96 samples/sec#011loss=5.229298\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[185] avg_epoch_loss=5.181653\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=5.334255981445312\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [185]#011Speed: 1993.81 samples/sec#011loss=5.334256\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[190] avg_epoch_loss=5.180214\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=5.126655101776123\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [190]#011Speed: 1099.62 samples/sec#011loss=5.126655\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[195] avg_epoch_loss=5.187138\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=5.451653289794922\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [195]#011Speed: 1954.73 samples/sec#011loss=5.451653\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[200] avg_epoch_loss=5.195165\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=5.509820365905762\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [200]#011Speed: 1106.00 samples/sec#011loss=5.509820\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[205] avg_epoch_loss=5.192017\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=5.065449905395508\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [205]#011Speed: 1930.15 samples/sec#011loss=5.065450\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[210] avg_epoch_loss=5.195099\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=5.322099399566651\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [210]#011Speed: 1097.51 samples/sec#011loss=5.322099\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[215] avg_epoch_loss=5.192787\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=5.095220756530762\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [215]#011Speed: 1898.34 samples/sec#011loss=5.095221\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch[220] avg_epoch_loss=5.186762\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=4.926459789276123\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:55 INFO 140667699287680] Epoch[19] Batch [220]#011Speed: 1140.54 samples/sec#011loss=4.926460\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[225] avg_epoch_loss=5.182883\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=5.011430931091309\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [225]#011Speed: 1911.76 samples/sec#011loss=5.011431\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[230] avg_epoch_loss=5.178298\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=4.971061038970947\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [230]#011Speed: 1083.88 samples/sec#011loss=4.971061\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[235] avg_epoch_loss=5.177131\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=5.123208045959473\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [235]#011Speed: 1961.54 samples/sec#011loss=5.123208\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[240] avg_epoch_loss=5.174835\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=5.06648359298706\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [240]#011Speed: 1155.74 samples/sec#011loss=5.066484\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[245] avg_epoch_loss=5.173001\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=5.08458776473999\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [245]#011Speed: 1802.18 samples/sec#011loss=5.084588\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[250] avg_epoch_loss=5.176294\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=5.338324451446534\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [250]#011Speed: 1162.40 samples/sec#011loss=5.338324\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[255] avg_epoch_loss=5.176735\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=5.198891067504883\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [255]#011Speed: 1918.52 samples/sec#011loss=5.198891\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[260] avg_epoch_loss=5.176523\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=5.165651321411133\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [260]#011Speed: 1152.72 samples/sec#011loss=5.165651\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch[265] avg_epoch_loss=5.178550\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=5.2843725204467775\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:56 INFO 140667699287680] Epoch[19] Batch [265]#011Speed: 1938.84 samples/sec#011loss=5.284373\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[270] avg_epoch_loss=5.179664\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=5.238929271697998\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [270]#011Speed: 1036.09 samples/sec#011loss=5.238929\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[275] avg_epoch_loss=5.179114\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=275 train loss <loss>=5.149309539794922\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [275]#011Speed: 1720.33 samples/sec#011loss=5.149310\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[280] avg_epoch_loss=5.178802\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=280 train loss <loss>=5.161574172973633\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [280]#011Speed: 1114.94 samples/sec#011loss=5.161574\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[285] avg_epoch_loss=5.176311\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=285 train loss <loss>=5.036276912689209\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [285]#011Speed: 1893.33 samples/sec#011loss=5.036277\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[290] avg_epoch_loss=5.178313\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=290 train loss <loss>=5.292879962921143\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [290]#011Speed: 1064.17 samples/sec#011loss=5.292880\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[295] avg_epoch_loss=5.176175\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=295 train loss <loss>=5.051703548431396\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [295]#011Speed: 1851.91 samples/sec#011loss=5.051704\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[300] avg_epoch_loss=5.175990\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=300 train loss <loss>=5.165075874328613\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [300]#011Speed: 1076.79 samples/sec#011loss=5.165076\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch[305] avg_epoch_loss=5.185230\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=305 train loss <loss>=5.741445922851563\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:57 INFO 140667699287680] Epoch[19] Batch [305]#011Speed: 1781.70 samples/sec#011loss=5.741446\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[310] avg_epoch_loss=5.184533\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=310 train loss <loss>=5.141883277893067\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [310]#011Speed: 1112.53 samples/sec#011loss=5.141883\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[315] avg_epoch_loss=5.181626\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=315 train loss <loss>=5.000786399841308\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [315]#011Speed: 1860.98 samples/sec#011loss=5.000786\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[320] avg_epoch_loss=5.187323\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=320 train loss <loss>=5.547424793243408\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [320]#011Speed: 1150.38 samples/sec#011loss=5.547425\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[325] avg_epoch_loss=5.190762\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=325 train loss <loss>=5.411503696441651\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [325]#011Speed: 1691.15 samples/sec#011loss=5.411504\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[330] avg_epoch_loss=5.194538\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=330 train loss <loss>=5.440742111206054\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [330]#011Speed: 1026.15 samples/sec#011loss=5.440742\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[335] avg_epoch_loss=5.189855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=335 train loss <loss>=4.879828357696534\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [335]#011Speed: 1809.39 samples/sec#011loss=4.879828\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[340] avg_epoch_loss=5.190488\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=340 train loss <loss>=5.233058071136474\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [340]#011Speed: 1108.38 samples/sec#011loss=5.233058\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[345] avg_epoch_loss=5.190035\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=345 train loss <loss>=5.159112644195557\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [345]#011Speed: 1911.90 samples/sec#011loss=5.159113\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch[350] avg_epoch_loss=5.188889\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=350 train loss <loss>=5.109622669219971\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:58 INFO 140667699287680] Epoch[19] Batch [350]#011Speed: 1094.21 samples/sec#011loss=5.109623\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[355] avg_epoch_loss=5.187509\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=355 train loss <loss>=5.0905779838562015\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [355]#011Speed: 1923.30 samples/sec#011loss=5.090578\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[360] avg_epoch_loss=5.186267\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=360 train loss <loss>=5.097875022888184\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [360]#011Speed: 1069.15 samples/sec#011loss=5.097875\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[365] avg_epoch_loss=5.184946\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=365 train loss <loss>=5.089546585083008\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [365]#011Speed: 1928.96 samples/sec#011loss=5.089547\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[370] avg_epoch_loss=5.185108\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=370 train loss <loss>=5.197007560729981\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [370]#011Speed: 1069.29 samples/sec#011loss=5.197008\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[375] avg_epoch_loss=5.185353\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=375 train loss <loss>=5.203471279144287\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [375]#011Speed: 1942.30 samples/sec#011loss=5.203471\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[380] avg_epoch_loss=5.186508\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=380 train loss <loss>=5.2734123229980465\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [380]#011Speed: 1110.62 samples/sec#011loss=5.273412\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[385] avg_epoch_loss=5.186101\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=385 train loss <loss>=5.155056095123291\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [385]#011Speed: 1925.70 samples/sec#011loss=5.155056\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[390] avg_epoch_loss=5.185710\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=390 train loss <loss>=5.155566120147705\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [390]#011Speed: 1090.14 samples/sec#011loss=5.155566\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch[395] avg_epoch_loss=5.184929\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=395 train loss <loss>=5.123825359344482\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:00:59 INFO 140667699287680] Epoch[19] Batch [395]#011Speed: 1809.04 samples/sec#011loss=5.123825\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[400] avg_epoch_loss=5.187906\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=400 train loss <loss>=5.423670291900635\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [400]#011Speed: 1048.20 samples/sec#011loss=5.423670\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[405] avg_epoch_loss=5.190534\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=405 train loss <loss>=5.401284790039062\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [405]#011Speed: 1998.95 samples/sec#011loss=5.401285\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[410] avg_epoch_loss=5.191553\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=410 train loss <loss>=5.274330520629883\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [410]#011Speed: 1091.73 samples/sec#011loss=5.274331\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[415] avg_epoch_loss=5.189639\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=415 train loss <loss>=5.0323175430297855\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [415]#011Speed: 1912.18 samples/sec#011loss=5.032318\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[420] avg_epoch_loss=5.187749\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=420 train loss <loss>=5.030532455444336\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [420]#011Speed: 1043.50 samples/sec#011loss=5.030532\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[425] avg_epoch_loss=5.188837\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=425 train loss <loss>=5.280401802062988\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [425]#011Speed: 1881.75 samples/sec#011loss=5.280402\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[430] avg_epoch_loss=5.187871\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=430 train loss <loss>=5.105540752410889\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [430]#011Speed: 1077.29 samples/sec#011loss=5.105541\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch[435] avg_epoch_loss=5.186593\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=435 train loss <loss>=5.076458930969238\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:00 INFO 140667699287680] Epoch[19] Batch [435]#011Speed: 1771.65 samples/sec#011loss=5.076459\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[440] avg_epoch_loss=5.187649\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=440 train loss <loss>=5.279751396179199\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [440]#011Speed: 1053.67 samples/sec#011loss=5.279751\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[445] avg_epoch_loss=5.187588\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=445 train loss <loss>=5.182180786132813\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [445]#011Speed: 1712.37 samples/sec#011loss=5.182181\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[450] avg_epoch_loss=5.184970\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=450 train loss <loss>=4.951475620269775\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [450]#011Speed: 1109.15 samples/sec#011loss=4.951476\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[455] avg_epoch_loss=5.186118\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=455 train loss <loss>=5.289650630950928\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [455]#011Speed: 1911.81 samples/sec#011loss=5.289651\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[460] avg_epoch_loss=5.184109\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=460 train loss <loss>=5.000878810882568\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [460]#011Speed: 935.00 samples/sec#011loss=5.000879\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[465] avg_epoch_loss=5.185301\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=465 train loss <loss>=5.295183944702148\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [465]#011Speed: 1466.27 samples/sec#011loss=5.295184\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[470] avg_epoch_loss=5.182109\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=470 train loss <loss>=4.884667205810547\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [470]#011Speed: 1005.76 samples/sec#011loss=4.884667\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch[475] avg_epoch_loss=5.183216\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=475 train loss <loss>=5.287424755096436\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:01 INFO 140667699287680] Epoch[19] Batch [475]#011Speed: 1850.66 samples/sec#011loss=5.287425\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[480] avg_epoch_loss=5.182568\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=480 train loss <loss>=5.120882797241211\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [480]#011Speed: 1006.99 samples/sec#011loss=5.120883\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[485] avg_epoch_loss=5.182212\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=485 train loss <loss>=5.147986507415771\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [485]#011Speed: 1895.32 samples/sec#011loss=5.147987\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[490] avg_epoch_loss=5.183195\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=490 train loss <loss>=5.278711891174316\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [490]#011Speed: 1059.36 samples/sec#011loss=5.278712\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[495] avg_epoch_loss=5.182723\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=495 train loss <loss>=5.136440277099609\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [495]#011Speed: 1951.13 samples/sec#011loss=5.136440\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[500] avg_epoch_loss=5.184510\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=500 train loss <loss>=5.36174783706665\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [500]#011Speed: 1081.20 samples/sec#011loss=5.361748\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[505] avg_epoch_loss=5.183200\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=505 train loss <loss>=5.051962184906006\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [505]#011Speed: 1805.02 samples/sec#011loss=5.051962\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[510] avg_epoch_loss=5.181989\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=510 train loss <loss>=5.05941333770752\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [510]#011Speed: 1061.74 samples/sec#011loss=5.059413\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[515] avg_epoch_loss=5.186523\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=515 train loss <loss>=5.649954795837402\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [515]#011Speed: 1919.80 samples/sec#011loss=5.649955\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch[520] avg_epoch_loss=5.189433\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=520 train loss <loss>=5.489706993103027\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:02 INFO 140667699287680] Epoch[19] Batch [520]#011Speed: 1037.16 samples/sec#011loss=5.489707\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[525] avg_epoch_loss=5.193710\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=525 train loss <loss>=5.639402961730957\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [525]#011Speed: 1859.68 samples/sec#011loss=5.639403\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[530] avg_epoch_loss=5.196539\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=530 train loss <loss>=5.494129848480225\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [530]#011Speed: 1059.78 samples/sec#011loss=5.494130\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[535] avg_epoch_loss=5.199227\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=535 train loss <loss>=5.4847180366516115\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [535]#011Speed: 1823.19 samples/sec#011loss=5.484718\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[540] avg_epoch_loss=5.202630\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=540 train loss <loss>=5.567362117767334\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [540]#011Speed: 1161.35 samples/sec#011loss=5.567362\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[545] avg_epoch_loss=5.205197\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=545 train loss <loss>=5.4830162048339846\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [545]#011Speed: 1960.14 samples/sec#011loss=5.483016\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[550] avg_epoch_loss=5.205871\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=550 train loss <loss>=5.279424571990967\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [550]#011Speed: 1143.91 samples/sec#011loss=5.279425\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[555] avg_epoch_loss=5.205014\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=555 train loss <loss>=5.110605239868164\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [555]#011Speed: 1892.89 samples/sec#011loss=5.110605\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch[560] avg_epoch_loss=5.206485\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, batch=560 train loss <loss>=5.370003414154053\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Epoch[19] Batch [560]#011Speed: 1558.03 samples/sec#011loss=5.370003\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] processed a total of 18012 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990050.7443845, \"EndTime\": 1620990063.904586, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 13160.147905349731, \"count\": 1, \"min\": 13160.147905349731, \"max\": 13160.147905349731}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #throughput_metric: host=algo-1, train throughput=1368.6677330326465 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, epoch=19, train loss <loss>=5.2060276847961315\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Final loss: 5.1494563141961 (occurred at epoch 18)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #quality_metric: host=algo-1, train final_loss <loss>=5.1494563141961\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 WARNING 140667699287680] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990063.9046514, \"EndTime\": 1620990063.954772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 49.4990348815918, \"count\": 1, \"min\": 49.4990348815918, \"max\": 49.4990348815918}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990063.9548354, \"EndTime\": 1620990063.983576, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 78.33337783813477, \"count\": 1, \"min\": 78.33337783813477, \"max\": 78.33337783813477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990063.9836416, \"EndTime\": 1620990063.988264, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 4.58836555480957, \"count\": 1, \"min\": 4.58836555480957, \"max\": 4.58836555480957}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] #memory_usage::<batchbuffer> = 0.26302337646484375 mb\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:03 INFO 140667699287680] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990063.9883041, \"EndTime\": 1620990063.9891863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.036716461181640625, \"count\": 1, \"min\": 0.036716461181640625, \"max\": 0.036716461181640625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:06 INFO 140667699287680] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:08 INFO 140667699287680] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:09 INFO 140667699287680] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.6/site-packages/numpy/ma/core.py:2788: UserWarning: Warning: converting a masked element to nan.\n",
      "  order=order, subok=True, ndmin=ndmin)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990063.9892426, \"EndTime\": 1620990071.1152012, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 7126.051664352417, \"count\": 1, \"min\": 7126.051664352417, \"max\": 7126.051664352417}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, RMSE): 1383.2476840795407\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, mean_absolute_QuantileLoss): 4379100.838028971\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, mean_wQuantileLoss): 1.4995061701354049\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.1]): 1.4239305939401266\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.2]): 1.6963373819391332\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.3]): 1.7401477954457747\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.4]): 1.7789035232956163\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.5]): 1.7802814849074013\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.6]): 1.6741230662787643\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.7]): 1.4686451542902017\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.8]): 1.1698750619893181\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #test_score (algo-1, wQuantileLoss[0.9]): 0.7633114691323075\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #quality_metric: host=algo-1, test RMSE <loss>=1383.2476840795407\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:01:11 INFO 140667699287680] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=1.4995061701354049\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990071.1152735, \"EndTime\": 1620990071.12265, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 5.541324615478516, \"count\": 1, \"min\": 5.541324615478516, \"max\": 5.541324615478516}, \"totaltime\": {\"sum\": 275300.00591278076, \"count\": 1, \"min\": 275300.00591278076, \"max\": 275300.00591278076}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-14 11:01:45 Uploading - Uploading generated training model\n",
      "2021-05-14 11:01:45 Completed - Training job completed\n",
      "Training seconds: 381\n",
      "Billable seconds: 381\n"
     ]
    }
   ],
   "source": [
    "dar_estimator.fit(inputs=dar_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mt-motor-maintenance-2021-05-14-10-53-27-268'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_job_name = dar_estimator.latest_training_job.name\n",
    "dar_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Cut Forest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3079934 entries, 2020-02-22 23:59:59 to 2020-02-25 22:03:11\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Dtype\n",
      "---  ------         -----\n",
      " 0   motor_peak_mA  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 47.0 MB\n"
     ]
    }
   ],
   "source": [
    "anomalies = data[[\"motor_peak_mA\"]]\n",
    "anomalies = anomalies[anomalies[\"motor_peak_mA\"] > 0]\n",
    "anomalies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_dataframe = train_test_split(anomalies, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anomaly</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>615637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         motor_peak_mA\n",
       "anomaly               \n",
       "0               615637\n",
       "1                  350"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_dataframe.copy()\n",
    "test_data[\"anomaly\"] = test_data[\"motor_peak_mA\"] > 4000\n",
    "test_data[\"anomaly\"] = test_data[\"anomaly\"] | (test_data[\"motor_peak_mA\"] > 50) & (test_data[\"motor_peak_mA\"] < 200)\n",
    "test_data[\"anomaly\"] = test_data[\"anomaly\"].astype(int) \n",
    "test_data.groupby(\"anomaly\").count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>615987.000000</td>\n",
       "      <td>615987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>524.811933</td>\n",
       "      <td>0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>685.952785</td>\n",
       "      <td>0.023830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>797.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5752.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       motor_peak_mA        anomaly\n",
       "count  615987.000000  615987.000000\n",
       "mean      524.811933       0.000568\n",
       "std       685.952785       0.023830\n",
       "min         9.000000       0.000000\n",
       "25%        10.000000       0.000000\n",
       "50%        21.000000       0.000000\n",
       "75%       797.000000       0.000000\n",
       "max      5752.000000       1.000000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motor_peak_mA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.463947e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.251241e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.858596e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.980000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.730000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       motor_peak_mA\n",
       "count   2.463947e+06\n",
       "mean    5.251241e+02\n",
       "std     6.858596e+02\n",
       "min     9.000000e+00\n",
       "25%     1.000000e+01\n",
       "50%     2.100000e+01\n",
       "75%     7.980000e+02\n",
       "max     7.730000e+03"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2733],\n",
       "       [ 502],\n",
       "       [ 588],\n",
       "       ...,\n",
       "       [  10],\n",
       "       [   9],\n",
       "       [   9]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array = train_data.values\n",
    "train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10],\n",
       "       [774],\n",
       "       [ 21],\n",
       "       ...,\n",
       "       [657],\n",
       "       [  9],\n",
       "       [ 10]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = test_data[[\"motor_peak_mA\"]].values\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array = test_data[\"anomaly\"].values\n",
    "labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "import boto3\n",
    "\n",
    "s3bucket = boto3.resource('s3').Bucket(bucket)\n",
    "\n",
    "def upload_records(array,key,labels=None):\n",
    "    result = {} \n",
    "    buf = io.BytesIO()\n",
    "    if (labels is not None):\n",
    "        smac.write_numpy_to_dense_tensor(buf, array, labels)\n",
    "    else:\n",
    "        smac.write_numpy_to_dense_tensor(buf, array)\n",
    "    buf.seek(0)\n",
    "    s3bucket.Object(key).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <sagemaker.inputs.TrainingInput at 0x7fc595013b10>,\n",
       " 'test': <sagemaker.inputs.TrainingInput at 0x7fc595c55c50>}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "prefix = \"mt-motor-anomaly\" \n",
    "\n",
    "cwd = os.getcwd()\n",
    "train_key  = \"{}/input/{}\".format(prefix,\"train.rio\")\n",
    "test_key  = \"{}/input/{}\".format(prefix, \"test.rio\")\n",
    "\n",
    "upload_records(train_array,train_key)\n",
    "upload_records(test_array,test_key,labels_array)\n",
    "\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "       s3_data=\"s3://{}/{}\".format(bucket,train_key),\n",
    "       content_type='application/x-recordio-protobuf',\n",
    "       distribution='ShardedByS3Key')\n",
    "\n",
    "test_input = sagemaker.inputs.TrainingInput(\n",
    "       s3_data=\"s3://{}/{}\".format(bucket,test_key),\n",
    "       content_type='application/x-recordio-protobuf',\n",
    "       distribution='FullyReplicated')\n",
    "\n",
    "rcf_input = {\n",
    "    'train': train_input,\n",
    "    'test': test_input     \n",
    "}\n",
    "\n",
    "rcf_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'174872318107.dkr.ecr.us-west-2.amazonaws.com/randomcutforest:1'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "rcf_container = sagemaker.image_uris.retrieve('randomcutforest', region)\n",
    "rcf_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcf_hparams = {\n",
    "    \"num_samples_per_tree\":512,\n",
    "    \"num_trees\":50,\n",
    "    \"feature_dim\":1,\n",
    "    \"eval_metrics\": \"accuracy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcf_estimator = sagemaker.estimator.Estimator(\n",
    "                      rcf_container,\n",
    "                      role=sagemaker.get_execution_role(),\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.m5.large',\n",
    "                      base_job_name=\"mt-motor-anomaly\",\n",
    "                      output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                      hyperparameters = rcf_hparams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 11:02:55 Starting - Starting the training job...\n",
      "2021-05-14 11:02:57 Starting - Launching requested ML instances......\n",
      "2021-05-14 11:04:06 Starting - Preparing the instances for training......\n",
      "2021-05-14 11:04:56 Downloading - Downloading input data...\n",
      "2021-05-14 11:05:40 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'num_samples_per_tree': 256, 'num_trees': 100, 'force_dense': 'true', 'eval_metrics': ['accuracy', 'precision_recall_fscore'], 'epochs': 1, 'mini_batch_size': 1000, '_log_level': 'info', '_kvstore': 'dist_async', '_num_kv_servers': 'auto', '_num_gpus': 'auto', '_tuning_objective_metric': '', '_ftp_port': 8999}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'num_trees': '50', 'num_samples_per_tree': '512', 'feature_dim': '1', 'eval_metrics': 'accuracy'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Final configuration: {'num_samples_per_tree': '512', 'num_trees': '50', 'force_dense': 'true', 'eval_metrics': 'accuracy', 'epochs': 1, 'mini_batch_size': 1000, '_log_level': 'info', '_kvstore': 'dist_async', '_num_kv_servers': 'auto', '_num_gpus': 'auto', '_tuning_objective_metric': '', '_ftp_port': 8999, 'feature_dim': '1'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 WARNING 140128255715136] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-187-123.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2021-05-14-11-02-55-160', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:053081517504:training-job/mt-motor-anomaly-2021-05-14-11-02-55-160', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/50a2aa67-dbc7-4a49-ba60-fd05cf78ed34', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '1', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-187-123.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2021-05-14-11-02-55-160', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:053081517504:training-job/mt-motor-anomaly-2021-05-14-11-02-55-160', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/50a2aa67-dbc7-4a49-ba60-fd05cf78ed34', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '1', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.0.187.123', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-187-123.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2021-05-14-11-02-55-160', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:053081517504:training-job/mt-motor-anomaly-2021-05-14-11-02-55-160', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/50a2aa67-dbc7-4a49-ba60-fd05cf78ed34', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '1', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-187-123.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2021-05-14-11-02-55-160', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:053081517504:training-job/mt-motor-anomaly-2021-05-14-11-02-55-160', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/50a2aa67-dbc7-4a49-ba60-fd05cf78ed34', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '1', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.0.187.123', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-187-123.us-west-2.compute.internal', 'TRAINING_JOB_NAME': 'mt-motor-anomaly-2021-05-14-11-02-55-160', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-2:053081517504:training-job/mt-motor-anomaly-2021-05-14-11-02-55-160', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/50a2aa67-dbc7-4a49-ba60-fd05cf78ed34', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'MXNET_KVSTORE_BIGARRAY_BOUND': '400000000', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'SAGEMAKER_METRICS_DIRECTORY': '/opt/ml/output/metrics/sagemaker', 'AWS_REGION': 'us-west-2', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '1', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/3fe8103c-d53c-4aa6-890e-274aacf3dab0', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'KMP_DUPLICATE_LIB_OK': 'True', 'KMP_INIT_AT_FORK': 'FALSE', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.0.187.123', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34mProcess 32 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 44 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-05-14 11:06:04.519] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Verifying hyperparamemters...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Hyperparameters are correct.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Validating that feature_dim agrees with dimensions in training data...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] feature_dim is correct.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Validating memory limits...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Available memory in bytes: 6547054592\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Estimated sample size in bytes: 204800\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Estimated memory needed to build the forest in bytes: 1024000\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Memory limits validated.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Starting cluster sharing facilities...\u001b[0m\n",
      "\u001b[34m[I 21-05-14 11:06:04] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140128255715136] Create Store: dist_async\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140126629902080] >>> starting FTP server on 0.0.0.0:8999, pid=1 <<<\u001b[0m\n",
      "\u001b[34m[I 21-05-14 11:06:04] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[34m[I 21-05-14 11:06:04] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140126629902080] poller: <class 'pyftpdlib.ioloop.Epoll'>\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140126629902080] masquerade (NAT) address: None\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140126629902080] passive ports: None\u001b[0m\n",
      "\u001b[34m[I 21-05-14 11:06:04] passive ports: None\u001b[0m\n",
      "\u001b[34m[I 21-05-14 11:06:04] use sendfile(2): True\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:04 INFO 140126629902080] use sendfile(2): True\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:06 INFO 140128255715136] Cluster sharing facilities started.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:06 INFO 140128255715136] Verifying all workers are accessible...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:06 INFO 140128255715136] All workers accessible.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:06 INFO 140128255715136] Initializing Sampler...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:06 INFO 140128255715136] Sampler correctly initialized.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990364.5128295, \"EndTime\": 1620990366.4367607, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 1905.1108360290527, \"count\": 1, \"min\": 1905.1108360290527, \"max\": 1905.1108360290527}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990366.436901, \"EndTime\": 1620990366.43693, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-05-14 11:06:06.440] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 1927, \"num_examples\": 1, \"num_bytes\": 28000}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:06 INFO 140128255715136] Sampling training data...\u001b[0m\n",
      "\u001b[34m[2021-05-14 11:06:10.356] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 3915, \"num_examples\": 2464, \"num_bytes\": 68990516}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Sampling training data completed.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990366.436862, \"EndTime\": 1620990370.3644614, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 3923.5379695892334, \"count\": 1, \"min\": 3923.5379695892334, \"max\": 3923.5379695892334}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990366.440847, \"EndTime\": 1620990370.365141, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2463947.0, \"count\": 1, \"min\": 2463947, \"max\": 2463947}, \"Total Batches Seen\": {\"sum\": 2464.0, \"count\": 1, \"min\": 2464, \"max\": 2464}, \"Max Records Seen Between Resets\": {\"sum\": 2463947.0, \"count\": 1, \"min\": 2463947, \"max\": 2463947}, \"Max Batches Seen Between Resets\": {\"sum\": 2464.0, \"count\": 1, \"min\": 2464, \"max\": 2464}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 2463947.0, \"count\": 1, \"min\": 2463947, \"max\": 2463947}, \"Number of Batches Since Last Reset\": {\"sum\": 2464.0, \"count\": 1, \"min\": 2464, \"max\": 2464}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] #throughput_metric: host=algo-1, train throughput=627845.9131672858 records/second\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Master node: building Random Cut Forest...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Gathering samples...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] 25600 samples gathered\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Building Random Cut Forest...\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Random Cut Forest built: \n",
      "\u001b[0m\n",
      "\u001b[34mForestInfo{num_trees: 50, num_samples_in_forest: 25600, num_samples_per_tree: 512, sample_dim: 1, shingle_size: 1, trees_num_nodes: [441, 469, 453, 477, 471, 505, 461, 461, 459, 461, 435, 455, 477, 471, 481, 451, 457, 475, 477, 479, 441, 471, 467, 449, 467, 445, 461, 469, 465, 431, 483, 475, 461, 449, 435, 475, 443, 451, 485, 449, 465, 483, 493, 461, 493, 471, 495, 445, 473, 519, ], trees_depth: [16, 19, 21, 18, 18, 16, 16, 17, 20, 17, 20, 18, 21, 20, 16, 18, 21, 17, 19, 24, 19, 19, 19, 16, 20, 20, 18, 17, 19, 18, 18, 17, 17, 21, 18, 18, 18, 15, 19, 15, 20, 17, 21, 16, 24, 21, 18, 16, 17, 21, ], max_num_nodes: 519, min_num_nodes: 431, avg_num_nodes: 465, max_tree_depth: 24, min_tree_depth: 15, avg_tree_depth: 18, mem_size: 2422192}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990370.3645384, \"EndTime\": 1620990370.3817558, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"fit_model.time\": {\"sum\": 9.046792984008789, \"count\": 1, \"min\": 9.046792984008789, \"max\": 9.046792984008789}, \"model.bytes\": {\"sum\": 2422192.0, \"count\": 1, \"min\": 2422192, \"max\": 2422192}, \"finalize.time\": {\"sum\": 16.16978645324707, \"count\": 1, \"min\": 16.16978645324707, \"max\": 16.16978645324707}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Master node: Serializing the RandomCutForest model\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990370.3818228, \"EndTime\": 1620990370.4096463, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"serialize_model.time\": {\"sum\": 27.786731719970703, \"count\": 1, \"min\": 27.786731719970703, \"max\": 27.786731719970703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:10 INFO 140128255715136] Labels shape [DataDesc[out_label,(1000,),<class 'numpy.int32'>,NCHW]]\u001b[0m\n",
      "\u001b[34m[2021-05-14 11:06:10.411] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 5892, \"num_examples\": 1, \"num_bytes\": 44000}\u001b[0m\n",
      "\n",
      "2021-05-14 11:06:22 Uploading - Uploading generated training model\u001b[34m[2021-05-14 11:06:17.064] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 2, \"duration\": 6652, \"num_examples\": 616, \"num_bytes\": 27103428}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990370.4097052, \"EndTime\": 1620990377.0643704, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"evaluate.time\": {\"sum\": 6652.998208999634, \"count\": 1, \"min\": 6652.998208999634, \"max\": 6652.998208999634}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-05-14 11:06:17.999] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 4, \"duration\": 866, \"num_examples\": 616, \"num_bytes\": 27103428}\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #precision_recall_fscore: [('precision', 0.034537201499901325), ('negative_precision', 1.0), ('recall', 1.0), ('negative_recall', 0.9841075179042196), ('f1', 0.06676840900419688), ('negative_f1', 0.9919901104388902)]\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #accuracy: [('accuracy', 0.9841165479141605)]\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990377.0644498, \"EndTime\": 1620990378.341534, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"score.time\": {\"sum\": 7931.47873878479, \"count\": 1, \"min\": 7931.47873878479, \"max\": 7931.47873878479}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990370.4100196, \"EndTime\": 1620990378.3416858, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1232974.0, \"count\": 1, \"min\": 1232974, \"max\": 1232974}, \"Total Batches Seen\": {\"sum\": 1233.0, \"count\": 1, \"min\": 1233, \"max\": 1233}, \"Max Records Seen Between Resets\": {\"sum\": 615987.0, \"count\": 1, \"min\": 615987, \"max\": 615987}, \"Max Batches Seen Between Resets\": {\"sum\": 616.0, \"count\": 1, \"min\": 616, \"max\": 616}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 615987.0, \"count\": 1, \"min\": 615987, \"max\": 615987}, \"Number of Batches Since Last Reset\": {\"sum\": 616.0, \"count\": 1, \"min\": 616, \"max\": 616}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('precision', 0.034537201499901325)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('negative_precision', 1.0)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('recall', 1.0)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('negative_recall', 0.9841075179042196)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('f1', 0.06676840900419688)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('negative_f1', 0.9919901104388902)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #test_score (algo-1) : ('accuracy', 0.9841165479141605)\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140128255715136] #quality_metric: host=algo-1, test f1 <score>=0.06676840900419688\u001b[0m\n",
      "\u001b[34m[I 21-05-14 11:06:18] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[34m[05/14/2021 11:06:18 INFO 140126629902080] >>> shutting down FTP server (0 active fds) <<<\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1620990378.3416374, \"EndTime\": 1620990378.3929913, \"Dimensions\": {\"Algorithm\": \"RandomCutForest\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 29.80494499206543, \"count\": 1, \"min\": 29.80494499206543, \"max\": 29.80494499206543}, \"totaltime\": {\"sum\": 13922.033309936523, \"count\": 1, \"min\": 13922.033309936523, \"max\": 13922.033309936523}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-05-14 11:06:28 Completed - Training job completed\n",
      "Training seconds: 92\n",
      "Billable seconds: 92\n"
     ]
    }
   ],
   "source": [
    "rcf_estimator.fit(rcf_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: mt-motor-anomaly-2021-05-14-11-02-55-160\n"
     ]
    }
   ],
   "source": [
    "print('Training job name: {}'.format(rcf_estimator.latest_training_job.job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Cut Forest Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "rcf_inference = rcf_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'rcf_inference_endpoint' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-motor-anomaly-2021-05-14-11-07-07-725'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcf_inference_endpoint = rcf_inference.endpoint_name\n",
    "%store rcf_inference_endpoint\n",
    "rcf_inference_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "rcf_inference.serializer = sagemaker.serializers.CSVSerializer()\n",
    "rcf_inference.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2733],\n",
       "       [ 502],\n",
       "       [ 588],\n",
       "       [   9],\n",
       "       [1716]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = train_data[:5].values\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': [{'score': 2.1405117711},\n",
       "  {'score': 0.7650028567},\n",
       "  {'score': 0.7646428522},\n",
       "  {'score': 0.7519637363},\n",
       "  {'score': 0.8903589727}]}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rcf_inference.predict(sample_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0624960377999997, 2.1405117711, 0.6052681458807184, 1.6677641836807182)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sigmas = 1\n",
    "\n",
    "scores = results[\"scores\"]\n",
    "scores = [score[\"score\"] for score in scores]\n",
    "series = pd.Series(scores)\n",
    "score_mean = series.mean()\n",
    "score_max = series.max()\n",
    "score_std = series.std()\n",
    "score_cutoff = score_mean + sigmas*score_std\n",
    "(score_mean,score_max,score_std,score_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.140512\n",
       "dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies = series[series > score_cutoff ]  \n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 anomalies detected'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{} anomalies detected\".format(len(anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep AR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mt-motor-maintenance-2021-05-14-10-53-27-268'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dar_endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=dar_job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    image_uri=dar_image_name,\n",
    "    role=role\n",
    ")\n",
    "dar_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16946"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = list(train_tss.values())[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = {\n",
    "    \"instances\": instances,\n",
    "    \"configuration\": {\n",
    "         \"output_types\": [\"mean\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instances\": [\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        0\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1843.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        1\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2171.0,\n",
      "        1949.0,\n",
      "        1769.0,\n",
      "        871.0,\n",
      "        477.0,\n",
      "        529.0,\n",
      "        570.0,\n",
      "        2202.0,\n",
      "        1483.0,\n",
      "        734.0,\n",
      "        10.0,\n",
      "        532.0,\n",
      "        817.0,\n",
      "        519.0,\n",
      "        617.0,\n",
      "        2146.0,\n",
      "        1870.0,\n",
      "        1397.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        2\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2145.0,\n",
      "        1772.0,\n",
      "        1392.0,\n",
      "        909.0,\n",
      "        556.0,\n",
      "        658.0,\n",
      "        680.0,\n",
      "        2354.0,\n",
      "        1151.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        681.0,\n",
      "        553.0,\n",
      "        608.0,\n",
      "        2014.0,\n",
      "        1685.0,\n",
      "        1518.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        3\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1580.0,\n",
      "        1997.0,\n",
      "        1735.0,\n",
      "        1202.0,\n",
      "        952.0,\n",
      "        436.0,\n",
      "        648.0,\n",
      "        694.0,\n",
      "        2252.0,\n",
      "        1345.0,\n",
      "        621.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        562.0,\n",
      "        563.0,\n",
      "        10.0,\n",
      "        801.0,\n",
      "        495.0,\n",
      "        1510.0,\n",
      "        1800.0,\n",
      "        1675.0,\n",
      "        1106.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        4\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1830.0,\n",
      "        2195.0,\n",
      "        1846.0,\n",
      "        1503.0,\n",
      "        722.0,\n",
      "        440.0,\n",
      "        575.0,\n",
      "        665.0,\n",
      "        2630.0,\n",
      "        1505.0,\n",
      "        625.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        544.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        563.0,\n",
      "        511.0,\n",
      "        567.0,\n",
      "        2031.0,\n",
      "        1677.0,\n",
      "        1082.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        5\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2324.0,\n",
      "        2592.0,\n",
      "        2225.0,\n",
      "        1298.0,\n",
      "        609.0,\n",
      "        549.0,\n",
      "        863.0,\n",
      "        1103.0,\n",
      "        3073.0,\n",
      "        1784.0,\n",
      "        638.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        880.0,\n",
      "        616.0,\n",
      "        2066.0,\n",
      "        2321.0,\n",
      "        1519.0,\n",
      "        1207.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        6\n",
      "      ],\n",
      "      \"target\": [\n",
      "        88.0,\n",
      "        2173.0,\n",
      "        1697.0,\n",
      "        1427.0,\n",
      "        560.0,\n",
      "        457.0,\n",
      "        538.0,\n",
      "        584.0,\n",
      "        2157.0,\n",
      "        1408.0,\n",
      "        575.0,\n",
      "        617.0,\n",
      "        871.0,\n",
      "        473.0,\n",
      "        1778.0,\n",
      "        2081.0,\n",
      "        1587.0,\n",
      "        1125.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        7\n",
      "      ],\n",
      "      \"target\": [\n",
      "        22.0,\n",
      "        2028.0,\n",
      "        1723.0,\n",
      "        1474.0,\n",
      "        500.0,\n",
      "        537.0,\n",
      "        584.0,\n",
      "        649.0,\n",
      "        2323.0,\n",
      "        1494.0,\n",
      "        674.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        594.0,\n",
      "        515.0,\n",
      "        1513.0,\n",
      "        1938.0,\n",
      "        1901.0,\n",
      "        1033.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        8\n",
      "      ],\n",
      "      \"target\": [\n",
      "        492.0,\n",
      "        2157.0,\n",
      "        1900.0,\n",
      "        1505.0,\n",
      "        908.0,\n",
      "        443.0,\n",
      "        574.0,\n",
      "        642.0,\n",
      "        2446.0,\n",
      "        1514.0,\n",
      "        629.0,\n",
      "        494.0,\n",
      "        827.0,\n",
      "        418.0,\n",
      "        516.0,\n",
      "        1995.0,\n",
      "        1761.0,\n",
      "        1290.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        9\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1704.0,\n",
      "        2060.0,\n",
      "        1764.0,\n",
      "        1498.0,\n",
      "        579.0,\n",
      "        500.0,\n",
      "        586.0,\n",
      "        600.0,\n",
      "        2392.0,\n",
      "        1398.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        547.0,\n",
      "        496.0,\n",
      "        1641.0,\n",
      "        1994.0,\n",
      "        1565.0,\n",
      "        1229.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        10\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2069.0,\n",
      "        1723.0,\n",
      "        1293.0,\n",
      "        1218.0,\n",
      "        563.0,\n",
      "        718.0,\n",
      "        710.0,\n",
      "        2439.0,\n",
      "        2373.0,\n",
      "        676.0,\n",
      "        10.0,\n",
      "        915.0,\n",
      "        447.0,\n",
      "        2004.0,\n",
      "        2183.0,\n",
      "        1802.0,\n",
      "        1258.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        11\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1738.0,\n",
      "        2067.0,\n",
      "        1815.0,\n",
      "        1556.0,\n",
      "        700.0,\n",
      "        397.0,\n",
      "        469.0,\n",
      "        470.0,\n",
      "        2093.0,\n",
      "        1300.0,\n",
      "        693.0,\n",
      "        423.0,\n",
      "        1622.0,\n",
      "        2048.0,\n",
      "        1690.0,\n",
      "        1267.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        12\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1833.0,\n",
      "        2346.0,\n",
      "        1706.0,\n",
      "        1399.0,\n",
      "        908.0,\n",
      "        531.0,\n",
      "        645.0,\n",
      "        644.0,\n",
      "        2198.0,\n",
      "        1436.0,\n",
      "        754.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        32.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        947.0,\n",
      "        518.0,\n",
      "        1846.0,\n",
      "        2182.0,\n",
      "        1684.0,\n",
      "        1021.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        13\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2239.0,\n",
      "        1884.0,\n",
      "        1466.0,\n",
      "        516.0,\n",
      "        528.0,\n",
      "        743.0,\n",
      "        690.0,\n",
      "        2624.0,\n",
      "        1444.0,\n",
      "        660.0,\n",
      "        555.0,\n",
      "        886.0,\n",
      "        480.0,\n",
      "        586.0,\n",
      "        1992.0,\n",
      "        1873.0,\n",
      "        1098.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        14\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2364.0,\n",
      "        2325.0,\n",
      "        1910.0,\n",
      "        1218.0,\n",
      "        1033.0,\n",
      "        627.0,\n",
      "        736.0,\n",
      "        754.0,\n",
      "        2519.0,\n",
      "        1615.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        636.0,\n",
      "        606.0,\n",
      "        628.0,\n",
      "        2134.0,\n",
      "        1793.0,\n",
      "        1253.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        15\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1791.0,\n",
      "        2146.0,\n",
      "        1813.0,\n",
      "        1652.0,\n",
      "        599.0,\n",
      "        494.0,\n",
      "        561.0,\n",
      "        545.0,\n",
      "        2156.0,\n",
      "        1117.0,\n",
      "        705.0,\n",
      "        10.0,\n",
      "        568.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        903.0,\n",
      "        469.0,\n",
      "        492.0,\n",
      "        2158.0,\n",
      "        1586.0,\n",
      "        1037.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        16\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        1999.0,\n",
      "        1753.0,\n",
      "        1336.0,\n",
      "        566.0,\n",
      "        492.0,\n",
      "        637.0,\n",
      "        660.0,\n",
      "        2474.0,\n",
      "        1540.0,\n",
      "        589.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        798.0,\n",
      "        484.0,\n",
      "        492.0,\n",
      "        1919.0,\n",
      "        1713.0,\n",
      "        1012.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        17\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1958.0,\n",
      "        2077.0,\n",
      "        1945.0,\n",
      "        1377.0,\n",
      "        774.0,\n",
      "        488.0,\n",
      "        533.0,\n",
      "        515.0,\n",
      "        1478.0,\n",
      "        1543.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        572.0,\n",
      "        437.0,\n",
      "        1981.0,\n",
      "        1973.0,\n",
      "        1584.0,\n",
      "        1256.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        18\n",
      "      ],\n",
      "      \"target\": [\n",
      "        513.0,\n",
      "        2218.0,\n",
      "        2034.0,\n",
      "        1543.0,\n",
      "        1019.0,\n",
      "        406.0,\n",
      "        476.0,\n",
      "        542.0,\n",
      "        2078.0,\n",
      "        955.0,\n",
      "        781.0,\n",
      "        857.0,\n",
      "        436.0,\n",
      "        2054.0,\n",
      "        2104.0,\n",
      "        1534.0,\n",
      "        1107.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        19\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2265.0,\n",
      "        2159.0,\n",
      "        1533.0,\n",
      "        1027.0,\n",
      "        630.0,\n",
      "        730.0,\n",
      "        741.0,\n",
      "        2426.0,\n",
      "        1551.0,\n",
      "        770.0,\n",
      "        995.0,\n",
      "        557.0,\n",
      "        2044.0,\n",
      "        2077.0,\n",
      "        1688.0,\n",
      "        1168.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        20\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1942.0,\n",
      "        2245.0,\n",
      "        1852.0,\n",
      "        1400.0,\n",
      "        1009.0,\n",
      "        739.0,\n",
      "        1128.0,\n",
      "        1275.0,\n",
      "        2706.0,\n",
      "        1824.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        886.0,\n",
      "        579.0,\n",
      "        630.0,\n",
      "        2199.0,\n",
      "        1753.0,\n",
      "        1429.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        21\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2701.0,\n",
      "        1941.0,\n",
      "        2142.0,\n",
      "        783.0,\n",
      "        641.0,\n",
      "        883.0,\n",
      "        988.0,\n",
      "        3126.0,\n",
      "        1751.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        645.0,\n",
      "        704.0,\n",
      "        738.0,\n",
      "        2523.0,\n",
      "        2063.0,\n",
      "        1423.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        22\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2297.0,\n",
      "        1916.0,\n",
      "        1494.0,\n",
      "        886.0,\n",
      "        596.0,\n",
      "        897.0,\n",
      "        938.0,\n",
      "        2885.0,\n",
      "        1543.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        910.0,\n",
      "        470.0,\n",
      "        2304.0,\n",
      "        2187.0,\n",
      "        1997.0,\n",
      "        1346.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        23\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2000.0,\n",
      "        2446.0,\n",
      "        2075.0,\n",
      "        1662.0,\n",
      "        1253.0,\n",
      "        726.0,\n",
      "        979.0,\n",
      "        1043.0,\n",
      "        2974.0,\n",
      "        1820.0,\n",
      "        728.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        876.0,\n",
      "        568.0,\n",
      "        2264.0,\n",
      "        2361.0,\n",
      "        2253.0,\n",
      "        1432.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        24\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1759.0,\n",
      "        2316.0,\n",
      "        1988.0,\n",
      "        1893.0,\n",
      "        1010.0,\n",
      "        1509.0,\n",
      "        1496.0,\n",
      "        2192.0,\n",
      "        2608.0,\n",
      "        1466.0,\n",
      "        654.0,\n",
      "        979.0,\n",
      "        616.0,\n",
      "        2153.0,\n",
      "        2159.0,\n",
      "        1791.0,\n",
      "        1331.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        25\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2398.0,\n",
      "        2016.0,\n",
      "        1609.0,\n",
      "        845.0,\n",
      "        454.0,\n",
      "        624.0,\n",
      "        838.0,\n",
      "        2365.0,\n",
      "        1355.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        796.0,\n",
      "        561.0,\n",
      "        2096.0,\n",
      "        2195.0,\n",
      "        1794.0,\n",
      "        1462.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        26\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2449.0,\n",
      "        1943.0,\n",
      "        1581.0,\n",
      "        1348.0,\n",
      "        516.0,\n",
      "        607.0,\n",
      "        664.0,\n",
      "        2658.0,\n",
      "        1649.0,\n",
      "        785.0,\n",
      "        1080.0,\n",
      "        572.0,\n",
      "        624.0,\n",
      "        2420.0,\n",
      "        1882.0,\n",
      "        1298.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        27\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        2403.0,\n",
      "        2208.0,\n",
      "        1631.0,\n",
      "        718.0,\n",
      "        665.0,\n",
      "        732.0,\n",
      "        791.0,\n",
      "        3161.0,\n",
      "        1123.0,\n",
      "        667.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1070.0,\n",
      "        585.0,\n",
      "        1742.0,\n",
      "        2400.0,\n",
      "        1687.0,\n",
      "        1276.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        28\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1805.0,\n",
      "        2242.0,\n",
      "        1993.0,\n",
      "        1493.0,\n",
      "        426.0,\n",
      "        522.0,\n",
      "        591.0,\n",
      "        720.0,\n",
      "        21.0,\n",
      "        2404.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        564.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        22.0,\n",
      "        20.0,\n",
      "        943.0,\n",
      "        574.0,\n",
      "        1683.0,\n",
      "        2150.0,\n",
      "        2077.0,\n",
      "        1375.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        29\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1774.0,\n",
      "        2210.0,\n",
      "        1941.0,\n",
      "        1472.0,\n",
      "        700.0,\n",
      "        604.0,\n",
      "        657.0,\n",
      "        753.0,\n",
      "        2579.0,\n",
      "        1053.0,\n",
      "        782.0,\n",
      "        585.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        882.0,\n",
      "        590.0,\n",
      "        1686.0,\n",
      "        2132.0,\n",
      "        1922.0,\n",
      "        1423.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        30\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1627.0,\n",
      "        2077.0,\n",
      "        1755.0,\n",
      "        1431.0,\n",
      "        664.0,\n",
      "        470.0,\n",
      "        503.0,\n",
      "        539.0,\n",
      "        2284.0,\n",
      "        1326.0,\n",
      "        693.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        810.0,\n",
      "        424.0,\n",
      "        487.0,\n",
      "        2028.0,\n",
      "        1824.0,\n",
      "        1304.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        31\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2040.0,\n",
      "        1700.0,\n",
      "        1495.0,\n",
      "        842.0,\n",
      "        460.0,\n",
      "        547.0,\n",
      "        547.0,\n",
      "        2347.0,\n",
      "        1422.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        888.0,\n",
      "        439.0,\n",
      "        2080.0,\n",
      "        1991.0,\n",
      "        1692.0,\n",
      "        1155.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        32\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1883.0,\n",
      "        2385.0,\n",
      "        1931.0,\n",
      "        1652.0,\n",
      "        804.0,\n",
      "        603.0,\n",
      "        677.0,\n",
      "        735.0,\n",
      "        2465.0,\n",
      "        666.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        850.0,\n",
      "        496.0,\n",
      "        1838.0,\n",
      "        2040.0,\n",
      "        1619.0,\n",
      "        1269.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        33\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2157.0,\n",
      "        1646.0,\n",
      "        1326.0,\n",
      "        608.0,\n",
      "        509.0,\n",
      "        546.0,\n",
      "        685.0,\n",
      "        2104.0,\n",
      "        1387.0,\n",
      "        571.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        32.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1008.0,\n",
      "        538.0,\n",
      "        1514.0,\n",
      "        2059.0,\n",
      "        1546.0,\n",
      "        1127.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        34\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1759.0,\n",
      "        2015.0,\n",
      "        2082.0,\n",
      "        1436.0,\n",
      "        1010.0,\n",
      "        502.0,\n",
      "        554.0,\n",
      "        653.0,\n",
      "        2624.0,\n",
      "        1519.0,\n",
      "        704.0,\n",
      "        602.0,\n",
      "        599.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        940.0,\n",
      "        481.0,\n",
      "        1632.0,\n",
      "        2026.0,\n",
      "        1979.0,\n",
      "        1326.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        35\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1779.0,\n",
      "        2091.0,\n",
      "        1934.0,\n",
      "        1722.0,\n",
      "        715.0,\n",
      "        571.0,\n",
      "        622.0,\n",
      "        691.0,\n",
      "        2664.0,\n",
      "        1147.0,\n",
      "        757.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        574.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        989.0,\n",
      "        635.0,\n",
      "        1665.0,\n",
      "        1974.0,\n",
      "        1603.0,\n",
      "        1293.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        36\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2412.0,\n",
      "        2296.0,\n",
      "        1643.0,\n",
      "        1092.0,\n",
      "        547.0,\n",
      "        598.0,\n",
      "        704.0,\n",
      "        2495.0,\n",
      "        1020.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        593.0,\n",
      "        489.0,\n",
      "        2340.0,\n",
      "        2220.0,\n",
      "        2065.0,\n",
      "        1595.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        37\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1660.0,\n",
      "        2242.0,\n",
      "        2062.0,\n",
      "        1644.0,\n",
      "        898.0,\n",
      "        541.0,\n",
      "        666.0,\n",
      "        667.0,\n",
      "        2254.0,\n",
      "        899.0,\n",
      "        720.0,\n",
      "        531.0,\n",
      "        852.0,\n",
      "        496.0,\n",
      "        1753.0,\n",
      "        2153.0,\n",
      "        1765.0,\n",
      "        1583.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        38\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1737.0,\n",
      "        2032.0,\n",
      "        1699.0,\n",
      "        1220.0,\n",
      "        1139.0,\n",
      "        505.0,\n",
      "        534.0,\n",
      "        569.0,\n",
      "        2226.0,\n",
      "        1082.0,\n",
      "        643.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        887.0,\n",
      "        448.0,\n",
      "        1664.0,\n",
      "        1994.0,\n",
      "        1446.0,\n",
      "        1074.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        39\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1816.0,\n",
      "        2361.0,\n",
      "        1916.0,\n",
      "        1372.0,\n",
      "        526.0,\n",
      "        506.0,\n",
      "        685.0,\n",
      "        800.0,\n",
      "        2712.0,\n",
      "        957.0,\n",
      "        775.0,\n",
      "        493.0,\n",
      "        775.0,\n",
      "        509.0,\n",
      "        1701.0,\n",
      "        2209.0,\n",
      "        1709.0,\n",
      "        1212.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        40\n",
      "      ],\n",
      "      \"target\": [\n",
      "        21.0,\n",
      "        2269.0,\n",
      "        1922.0,\n",
      "        1502.0,\n",
      "        1121.0,\n",
      "        487.0,\n",
      "        628.0,\n",
      "        741.0,\n",
      "        2442.0,\n",
      "        1700.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        558.0,\n",
      "        552.0,\n",
      "        644.0,\n",
      "        2222.0,\n",
      "        1972.0,\n",
      "        1350.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        41\n",
      "      ],\n",
      "      \"target\": [\n",
      "        592.0,\n",
      "        2280.0,\n",
      "        2200.0,\n",
      "        1743.0,\n",
      "        1151.0,\n",
      "        537.0,\n",
      "        705.0,\n",
      "        709.0,\n",
      "        2240.0,\n",
      "        1387.0,\n",
      "        677.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        514.0,\n",
      "        531.0,\n",
      "        1669.0,\n",
      "        2273.0,\n",
      "        2180.0,\n",
      "        1526.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        42\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2606.0,\n",
      "        2055.0,\n",
      "        1920.0,\n",
      "        783.0,\n",
      "        730.0,\n",
      "        925.0,\n",
      "        1045.0,\n",
      "        2759.0,\n",
      "        2510.0,\n",
      "        1088.0,\n",
      "        702.0,\n",
      "        2359.0,\n",
      "        2605.0,\n",
      "        2135.0,\n",
      "        1609.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        43\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2236.0,\n",
      "        1858.0,\n",
      "        1624.0,\n",
      "        887.0,\n",
      "        521.0,\n",
      "        598.0,\n",
      "        647.0,\n",
      "        2322.0,\n",
      "        1378.0,\n",
      "        582.0,\n",
      "        558.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        878.0,\n",
      "        468.0,\n",
      "        465.0,\n",
      "        2241.0,\n",
      "        1844.0,\n",
      "        1121.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        44\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1889.0,\n",
      "        2145.0,\n",
      "        1934.0,\n",
      "        1464.0,\n",
      "        763.0,\n",
      "        628.0,\n",
      "        638.0,\n",
      "        716.0,\n",
      "        2394.0,\n",
      "        1575.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        991.0,\n",
      "        481.0,\n",
      "        1699.0,\n",
      "        2085.0,\n",
      "        1620.0,\n",
      "        1402.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        45\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1720.0,\n",
      "        2053.0,\n",
      "        1744.0,\n",
      "        1176.0,\n",
      "        851.0,\n",
      "        417.0,\n",
      "        572.0,\n",
      "        610.0,\n",
      "        2290.0,\n",
      "        1414.0,\n",
      "        524.0,\n",
      "        507.0,\n",
      "        791.0,\n",
      "        421.0,\n",
      "        1665.0,\n",
      "        1975.0,\n",
      "        1625.0,\n",
      "        1013.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        46\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2084.0,\n",
      "        1752.0,\n",
      "        1314.0,\n",
      "        958.0,\n",
      "        453.0,\n",
      "        579.0,\n",
      "        663.0,\n",
      "        2361.0,\n",
      "        1381.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        808.0,\n",
      "        517.0,\n",
      "        2125.0,\n",
      "        2111.0,\n",
      "        1560.0,\n",
      "        1174.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        47\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1875.0,\n",
      "        2467.0,\n",
      "        2198.0,\n",
      "        2058.0,\n",
      "        775.0,\n",
      "        614.0,\n",
      "        811.0,\n",
      "        776.0,\n",
      "        2262.0,\n",
      "        1504.0,\n",
      "        741.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        566.0,\n",
      "        649.0,\n",
      "        656.0,\n",
      "        2326.0,\n",
      "        1776.0,\n",
      "        1207.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        48\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2106.0,\n",
      "        2282.0,\n",
      "        2216.0,\n",
      "        1618.0,\n",
      "        436.0,\n",
      "        553.0,\n",
      "        717.0,\n",
      "        896.0,\n",
      "        2757.0,\n",
      "        1292.0,\n",
      "        555.0,\n",
      "        839.0,\n",
      "        552.0,\n",
      "        1452.0,\n",
      "        2172.0,\n",
      "        1861.0,\n",
      "        1414.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        49\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2267.0,\n",
      "        2228.0,\n",
      "        1887.0,\n",
      "        1448.0,\n",
      "        605.0,\n",
      "        504.0,\n",
      "        608.0,\n",
      "        691.0,\n",
      "        21.0,\n",
      "        2701.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        885.0,\n",
      "        581.0,\n",
      "        10.0,\n",
      "        2176.0,\n",
      "        1882.0,\n",
      "        1282.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        50\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2106.0,\n",
      "        1825.0,\n",
      "        1230.0,\n",
      "        704.0,\n",
      "        534.0,\n",
      "        619.0,\n",
      "        638.0,\n",
      "        2291.0,\n",
      "        2324.0,\n",
      "        511.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        596.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        613.0,\n",
      "        492.0,\n",
      "        1834.0,\n",
      "        1956.0,\n",
      "        1707.0,\n",
      "        1010.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        51\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2177.0,\n",
      "        2199.0,\n",
      "        2108.0,\n",
      "        2003.0,\n",
      "        895.0,\n",
      "        540.0,\n",
      "        756.0,\n",
      "        692.0,\n",
      "        2604.0,\n",
      "        1583.0,\n",
      "        610.0,\n",
      "        10.0,\n",
      "        671.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        960.0,\n",
      "        691.0,\n",
      "        1701.0,\n",
      "        2188.0,\n",
      "        1816.0,\n",
      "        1524.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        52\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2097.0,\n",
      "        2277.0,\n",
      "        1961.0,\n",
      "        1527.0,\n",
      "        671.0,\n",
      "        455.0,\n",
      "        500.0,\n",
      "        590.0,\n",
      "        2634.0,\n",
      "        1160.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        639.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        955.0,\n",
      "        449.0,\n",
      "        2038.0,\n",
      "        2195.0,\n",
      "        1753.0,\n",
      "        1166.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        53\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2274.0,\n",
      "        2001.0,\n",
      "        1652.0,\n",
      "        837.0,\n",
      "        597.0,\n",
      "        820.0,\n",
      "        837.0,\n",
      "        2719.0,\n",
      "        1578.0,\n",
      "        610.0,\n",
      "        594.0,\n",
      "        820.0,\n",
      "        482.0,\n",
      "        608.0,\n",
      "        2157.0,\n",
      "        1810.0,\n",
      "        1305.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        54\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1897.0,\n",
      "        2269.0,\n",
      "        2420.0,\n",
      "        2136.0,\n",
      "        928.0,\n",
      "        569.0,\n",
      "        738.0,\n",
      "        742.0,\n",
      "        2513.0,\n",
      "        1717.0,\n",
      "        562.0,\n",
      "        503.0,\n",
      "        829.0,\n",
      "        594.0,\n",
      "        1699.0,\n",
      "        2234.0,\n",
      "        1713.0,\n",
      "        1382.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        55\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2313.0,\n",
      "        1865.0,\n",
      "        1418.0,\n",
      "        833.0,\n",
      "        509.0,\n",
      "        599.0,\n",
      "        740.0,\n",
      "        2508.0,\n",
      "        1842.0,\n",
      "        741.0,\n",
      "        562.0,\n",
      "        565.0,\n",
      "        895.0,\n",
      "        536.0,\n",
      "        578.0,\n",
      "        2162.0,\n",
      "        2111.0,\n",
      "        1159.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        56\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2003.0,\n",
      "        1840.0,\n",
      "        1486.0,\n",
      "        726.0,\n",
      "        483.0,\n",
      "        599.0,\n",
      "        579.0,\n",
      "        2237.0,\n",
      "        1295.0,\n",
      "        636.0,\n",
      "        518.0,\n",
      "        792.0,\n",
      "        401.0,\n",
      "        806.0,\n",
      "        2003.0,\n",
      "        1470.0,\n",
      "        1007.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        57\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1998.0,\n",
      "        2300.0,\n",
      "        1863.0,\n",
      "        1548.0,\n",
      "        863.0,\n",
      "        605.0,\n",
      "        697.0,\n",
      "        732.0,\n",
      "        2424.0,\n",
      "        1142.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        590.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        605.0,\n",
      "        619.0,\n",
      "        672.0,\n",
      "        2174.0,\n",
      "        1669.0,\n",
      "        1252.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        58\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2088.0,\n",
      "        2866.0,\n",
      "        2390.0,\n",
      "        1745.0,\n",
      "        1101.0,\n",
      "        575.0,\n",
      "        711.0,\n",
      "        871.0,\n",
      "        2709.0,\n",
      "        1361.0,\n",
      "        744.0,\n",
      "        686.0,\n",
      "        651.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        644.0,\n",
      "        918.0,\n",
      "        2103.0,\n",
      "        2503.0,\n",
      "        2089.0,\n",
      "        1428.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        59\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1827.0,\n",
      "        2143.0,\n",
      "        1879.0,\n",
      "        1516.0,\n",
      "        867.0,\n",
      "        443.0,\n",
      "        523.0,\n",
      "        559.0,\n",
      "        2176.0,\n",
      "        1131.0,\n",
      "        699.0,\n",
      "        540.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        876.0,\n",
      "        504.0,\n",
      "        1814.0,\n",
      "        2019.0,\n",
      "        1896.0,\n",
      "        1469.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        60\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1933.0,\n",
      "        2080.0,\n",
      "        1874.0,\n",
      "        1415.0,\n",
      "        569.0,\n",
      "        463.0,\n",
      "        542.0,\n",
      "        626.0,\n",
      "        2357.0,\n",
      "        1493.0,\n",
      "        666.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        596.0,\n",
      "        499.0,\n",
      "        1850.0,\n",
      "        2020.0,\n",
      "        1390.0,\n",
      "        1203.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        61\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1831.0,\n",
      "        2295.0,\n",
      "        2083.0,\n",
      "        1752.0,\n",
      "        1106.0,\n",
      "        495.0,\n",
      "        699.0,\n",
      "        828.0,\n",
      "        3027.0,\n",
      "        1582.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        776.0,\n",
      "        510.0,\n",
      "        591.0,\n",
      "        2352.0,\n",
      "        1789.0,\n",
      "        1414.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        62\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1800.0,\n",
      "        2263.0,\n",
      "        1654.0,\n",
      "        1461.0,\n",
      "        1133.0,\n",
      "        456.0,\n",
      "        561.0,\n",
      "        606.0,\n",
      "        2506.0,\n",
      "        1099.0,\n",
      "        673.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        570.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        897.0,\n",
      "        558.0,\n",
      "        1820.0,\n",
      "        2136.0,\n",
      "        1704.0,\n",
      "        1091.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        63\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        2291.0,\n",
      "        1915.0,\n",
      "        1608.0,\n",
      "        1246.0,\n",
      "        551.0,\n",
      "        591.0,\n",
      "        749.0,\n",
      "        20.0,\n",
      "        2601.0,\n",
      "        828.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        935.0,\n",
      "        543.0,\n",
      "        1763.0,\n",
      "        2193.0,\n",
      "        1898.0,\n",
      "        1189.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        64\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2146.0,\n",
      "        2040.0,\n",
      "        1761.0,\n",
      "        1413.0,\n",
      "        763.0,\n",
      "        478.0,\n",
      "        680.0,\n",
      "        655.0,\n",
      "        2148.0,\n",
      "        1145.0,\n",
      "        926.0,\n",
      "        656.0,\n",
      "        2049.0,\n",
      "        2052.0,\n",
      "        1672.0,\n",
      "        1362.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        65\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2375.0,\n",
      "        2245.0,\n",
      "        1429.0,\n",
      "        1182.0,\n",
      "        485.0,\n",
      "        587.0,\n",
      "        649.0,\n",
      "        2712.0,\n",
      "        1557.0,\n",
      "        556.0,\n",
      "        470.0,\n",
      "        817.0,\n",
      "        459.0,\n",
      "        485.0,\n",
      "        2167.0,\n",
      "        1767.0,\n",
      "        1375.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        66\n",
      "      ],\n",
      "      \"target\": [\n",
      "        41.0,\n",
      "        2383.0,\n",
      "        2145.0,\n",
      "        1516.0,\n",
      "        1380.0,\n",
      "        529.0,\n",
      "        597.0,\n",
      "        672.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        3044.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        673.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        2305.0,\n",
      "        2013.0,\n",
      "        1329.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        67\n",
      "      ],\n",
      "      \"target\": [\n",
      "        20.0,\n",
      "        2268.0,\n",
      "        2134.0,\n",
      "        1497.0,\n",
      "        863.0,\n",
      "        687.0,\n",
      "        809.0,\n",
      "        814.0,\n",
      "        2613.0,\n",
      "        1694.0,\n",
      "        781.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        1051.0,\n",
      "        565.0,\n",
      "        2104.0,\n",
      "        2313.0,\n",
      "        1872.0,\n",
      "        1291.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        68\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1759.0,\n",
      "        2245.0,\n",
      "        2225.0,\n",
      "        1534.0,\n",
      "        789.0,\n",
      "        527.0,\n",
      "        665.0,\n",
      "        734.0,\n",
      "        2421.0,\n",
      "        1091.0,\n",
      "        730.0,\n",
      "        819.0,\n",
      "        605.0,\n",
      "        1753.0,\n",
      "        2148.0,\n",
      "        2044.0,\n",
      "        1473.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        69\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2268.0,\n",
      "        1947.0,\n",
      "        1248.0,\n",
      "        443.0,\n",
      "        525.0,\n",
      "        690.0,\n",
      "        740.0,\n",
      "        2408.0,\n",
      "        1527.0,\n",
      "        484.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        447.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        744.0,\n",
      "        402.0,\n",
      "        492.0,\n",
      "        2119.0,\n",
      "        1765.0,\n",
      "        1304.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        70\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2207.0,\n",
      "        10.0,\n",
      "        1543.0,\n",
      "        403.0,\n",
      "        525.0,\n",
      "        640.0,\n",
      "        724.0,\n",
      "        2410.0,\n",
      "        960.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        581.0,\n",
      "        550.0,\n",
      "        2160.0,\n",
      "        2026.0,\n",
      "        1815.0,\n",
      "        929.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        71\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1979.0,\n",
      "        2092.0,\n",
      "        1767.0,\n",
      "        1404.0,\n",
      "        591.0,\n",
      "        520.0,\n",
      "        627.0,\n",
      "        782.0,\n",
      "        2627.0,\n",
      "        1642.0,\n",
      "        496.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        836.0,\n",
      "        478.0,\n",
      "        1658.0,\n",
      "        2006.0,\n",
      "        1527.0,\n",
      "        1215.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        72\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1972.0,\n",
      "        2351.0,\n",
      "        1761.0,\n",
      "        1712.0,\n",
      "        853.0,\n",
      "        561.0,\n",
      "        657.0,\n",
      "        791.0,\n",
      "        2742.0,\n",
      "        1738.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        30.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        1031.0,\n",
      "        696.0,\n",
      "        678.0,\n",
      "        2156.0,\n",
      "        1554.0,\n",
      "        1332.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        73\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1843.0,\n",
      "        2216.0,\n",
      "        1910.0,\n",
      "        1549.0,\n",
      "        931.0,\n",
      "        457.0,\n",
      "        593.0,\n",
      "        630.0,\n",
      "        2099.0,\n",
      "        954.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        544.0,\n",
      "        578.0,\n",
      "        568.0,\n",
      "        2143.0,\n",
      "        1701.0,\n",
      "        1067.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        74\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1735.0,\n",
      "        2235.0,\n",
      "        1817.0,\n",
      "        1672.0,\n",
      "        972.0,\n",
      "        442.0,\n",
      "        608.0,\n",
      "        595.0,\n",
      "        2362.0,\n",
      "        1134.0,\n",
      "        742.0,\n",
      "        899.0,\n",
      "        485.0,\n",
      "        1686.0,\n",
      "        2018.0,\n",
      "        1566.0,\n",
      "        1138.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        75\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1872.0,\n",
      "        2106.0,\n",
      "        1763.0,\n",
      "        1724.0,\n",
      "        619.0,\n",
      "        488.0,\n",
      "        553.0,\n",
      "        613.0,\n",
      "        2155.0,\n",
      "        1258.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        870.0,\n",
      "        525.0,\n",
      "        1708.0,\n",
      "        2141.0,\n",
      "        1381.0,\n",
      "        1136.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        76\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2186.0,\n",
      "        2493.0,\n",
      "        2047.0,\n",
      "        1659.0,\n",
      "        1201.0,\n",
      "        561.0,\n",
      "        572.0,\n",
      "        787.0,\n",
      "        2516.0,\n",
      "        1167.0,\n",
      "        805.0,\n",
      "        20.0,\n",
      "        578.0,\n",
      "        591.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        22.0,\n",
      "        585.0,\n",
      "        622.0,\n",
      "        2085.0,\n",
      "        2390.0,\n",
      "        1788.0,\n",
      "        1234.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        77\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2583.0,\n",
      "        2308.0,\n",
      "        2078.0,\n",
      "        1526.0,\n",
      "        810.0,\n",
      "        1001.0,\n",
      "        1200.0,\n",
      "        2812.0,\n",
      "        1837.0,\n",
      "        967.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1140.0,\n",
      "        715.0,\n",
      "        2029.0,\n",
      "        2541.0,\n",
      "        2222.0,\n",
      "        1583.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        78\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1704.0,\n",
      "        2108.0,\n",
      "        2142.0,\n",
      "        1679.0,\n",
      "        1092.0,\n",
      "        538.0,\n",
      "        710.0,\n",
      "        859.0,\n",
      "        2529.0,\n",
      "        1080.0,\n",
      "        760.0,\n",
      "        522.0,\n",
      "        873.0,\n",
      "        559.0,\n",
      "        1747.0,\n",
      "        2082.0,\n",
      "        1673.0,\n",
      "        1258.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        79\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2038.0,\n",
      "        1726.0,\n",
      "        1513.0,\n",
      "        797.0,\n",
      "        517.0,\n",
      "        586.0,\n",
      "        596.0,\n",
      "        2420.0,\n",
      "        1483.0,\n",
      "        651.0,\n",
      "        848.0,\n",
      "        443.0,\n",
      "        1954.0,\n",
      "        1928.0,\n",
      "        1721.0,\n",
      "        1290.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        80\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1738.0,\n",
      "        2341.0,\n",
      "        2074.0,\n",
      "        1785.0,\n",
      "        841.0,\n",
      "        515.0,\n",
      "        647.0,\n",
      "        710.0,\n",
      "        2583.0,\n",
      "        1457.0,\n",
      "        627.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        847.0,\n",
      "        667.0,\n",
      "        1703.0,\n",
      "        2055.0,\n",
      "        1719.0,\n",
      "        1156.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        81\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1730.0,\n",
      "        2071.0,\n",
      "        1840.0,\n",
      "        1275.0,\n",
      "        935.0,\n",
      "        516.0,\n",
      "        616.0,\n",
      "        680.0,\n",
      "        2488.0,\n",
      "        1112.0,\n",
      "        545.0,\n",
      "        546.0,\n",
      "        542.0,\n",
      "        830.0,\n",
      "        399.0,\n",
      "        1576.0,\n",
      "        1904.0,\n",
      "        1520.0,\n",
      "        1045.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        82\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2122.0,\n",
      "        1785.0,\n",
      "        1443.0,\n",
      "        926.0,\n",
      "        489.0,\n",
      "        546.0,\n",
      "        715.0,\n",
      "        2237.0,\n",
      "        1635.0,\n",
      "        719.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        804.0,\n",
      "        455.0,\n",
      "        484.0,\n",
      "        2108.0,\n",
      "        1714.0,\n",
      "        1157.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        83\n",
      "      ],\n",
      "      \"target\": [\n",
      "        9.0,\n",
      "        2193.0,\n",
      "        1948.0,\n",
      "        1521.0,\n",
      "        576.0,\n",
      "        542.0,\n",
      "        673.0,\n",
      "        700.0,\n",
      "        2363.0,\n",
      "        1897.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        598.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        556.0,\n",
      "        575.0,\n",
      "        610.0,\n",
      "        2129.0,\n",
      "        1910.0,\n",
      "        1238.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        84\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1656.0,\n",
      "        2202.0,\n",
      "        1846.0,\n",
      "        1479.0,\n",
      "        869.0,\n",
      "        459.0,\n",
      "        661.0,\n",
      "        642.0,\n",
      "        2583.0,\n",
      "        1572.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        536.0,\n",
      "        477.0,\n",
      "        1558.0,\n",
      "        2056.0,\n",
      "        1638.0,\n",
      "        1322.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        85\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1564.0,\n",
      "        2081.0,\n",
      "        1646.0,\n",
      "        1340.0,\n",
      "        834.0,\n",
      "        519.0,\n",
      "        607.0,\n",
      "        624.0,\n",
      "        2285.0,\n",
      "        1067.0,\n",
      "        612.0,\n",
      "        997.0,\n",
      "        493.0,\n",
      "        1555.0,\n",
      "        1999.0,\n",
      "        1502.0,\n",
      "        1267.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        86\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1746.0,\n",
      "        2211.0,\n",
      "        2001.0,\n",
      "        1354.0,\n",
      "        1029.0,\n",
      "        624.0,\n",
      "        755.0,\n",
      "        803.0,\n",
      "        2181.0,\n",
      "        1551.0,\n",
      "        822.0,\n",
      "        725.0,\n",
      "        675.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        688.0,\n",
      "        558.0,\n",
      "        572.0,\n",
      "        2266.0,\n",
      "        1903.0,\n",
      "        1347.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        87\n",
      "      ],\n",
      "      \"target\": [\n",
      "        21.0,\n",
      "        2243.0,\n",
      "        1988.0,\n",
      "        1316.0,\n",
      "        1009.0,\n",
      "        690.0,\n",
      "        781.0,\n",
      "        766.0,\n",
      "        2564.0,\n",
      "        1511.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        1020.0,\n",
      "        642.0,\n",
      "        1759.0,\n",
      "        2046.0,\n",
      "        1656.0,\n",
      "        1322.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        88\n",
      "      ],\n",
      "      \"target\": [\n",
      "        596.0,\n",
      "        2250.0,\n",
      "        1813.0,\n",
      "        1303.0,\n",
      "        1343.0,\n",
      "        534.0,\n",
      "        655.0,\n",
      "        742.0,\n",
      "        2268.0,\n",
      "        1605.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        882.0,\n",
      "        520.0,\n",
      "        629.0,\n",
      "        2196.0,\n",
      "        1916.0,\n",
      "        1083.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        89\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2021.0,\n",
      "        1682.0,\n",
      "        1479.0,\n",
      "        959.0,\n",
      "        470.0,\n",
      "        530.0,\n",
      "        561.0,\n",
      "        2051.0,\n",
      "        1365.0,\n",
      "        673.0,\n",
      "        508.0,\n",
      "        507.0,\n",
      "        10.0,\n",
      "        560.0,\n",
      "        422.0,\n",
      "        460.0,\n",
      "        1867.0,\n",
      "        1533.0,\n",
      "        1117.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 16:00:00\",\n",
      "      \"cat\": [\n",
      "        90\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2401.0,\n",
      "        2048.0,\n",
      "        1532.0,\n",
      "        713.0,\n",
      "        499.0,\n",
      "        654.0,\n",
      "        749.0,\n",
      "        2536.0,\n",
      "        1623.0,\n",
      "        650.0,\n",
      "        546.0,\n",
      "        911.0,\n",
      "        497.0,\n",
      "        550.0,\n",
      "        2303.0,\n",
      "        1993.0,\n",
      "        1415.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        91\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2245.0,\n",
      "        2177.0,\n",
      "        1964.0,\n",
      "        1688.0,\n",
      "        884.0,\n",
      "        540.0,\n",
      "        706.0,\n",
      "        699.0,\n",
      "        2592.0,\n",
      "        1176.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        926.0,\n",
      "        683.0,\n",
      "        2141.0,\n",
      "        2241.0,\n",
      "        1698.0,\n",
      "        1378.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        92\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1887.0,\n",
      "        1889.0,\n",
      "        1709.0,\n",
      "        1319.0,\n",
      "        486.0,\n",
      "        463.0,\n",
      "        522.0,\n",
      "        505.0,\n",
      "        2054.0,\n",
      "        1022.0,\n",
      "        633.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        820.0,\n",
      "        450.0,\n",
      "        1489.0,\n",
      "        1826.0,\n",
      "        1636.0,\n",
      "        1242.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        93\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2368.0,\n",
      "        2793.0,\n",
      "        2257.0,\n",
      "        1617.0,\n",
      "        1038.0,\n",
      "        933.0,\n",
      "        1069.0,\n",
      "        1069.0,\n",
      "        2897.0,\n",
      "        1254.0,\n",
      "        756.0,\n",
      "        709.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        729.0,\n",
      "        651.0,\n",
      "        2136.0,\n",
      "        2496.0,\n",
      "        1696.0,\n",
      "        1469.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        94\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1970.0,\n",
      "        2417.0,\n",
      "        1877.0,\n",
      "        1597.0,\n",
      "        491.0,\n",
      "        557.0,\n",
      "        767.0,\n",
      "        841.0,\n",
      "        2643.0,\n",
      "        1608.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        606.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        629.0,\n",
      "        656.0,\n",
      "        610.0,\n",
      "        2284.0,\n",
      "        1720.0,\n",
      "        1376.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        95\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1675.0,\n",
      "        2250.0,\n",
      "        1962.0,\n",
      "        1510.0,\n",
      "        708.0,\n",
      "        585.0,\n",
      "        663.0,\n",
      "        733.0,\n",
      "        2640.0,\n",
      "        1484.0,\n",
      "        566.0,\n",
      "        587.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        9.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        923.0,\n",
      "        566.0,\n",
      "        1668.0,\n",
      "        2112.0,\n",
      "        1662.0,\n",
      "        1351.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        96\n",
      "      ],\n",
      "      \"target\": [\n",
      "        1722.0,\n",
      "        2080.0,\n",
      "        1841.0,\n",
      "        1549.0,\n",
      "        668.0,\n",
      "        614.0,\n",
      "        772.0,\n",
      "        901.0,\n",
      "        2502.0,\n",
      "        1706.0,\n",
      "        636.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        926.0,\n",
      "        489.0,\n",
      "        1584.0,\n",
      "        1914.0,\n",
      "        1711.0,\n",
      "        1213.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        97\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2002.0,\n",
      "        2200.0,\n",
      "        1996.0,\n",
      "        1557.0,\n",
      "        776.0,\n",
      "        580.0,\n",
      "        722.0,\n",
      "        848.0,\n",
      "        2774.0,\n",
      "        1241.0,\n",
      "        793.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        1046.0,\n",
      "        567.0,\n",
      "        1811.0,\n",
      "        2028.0,\n",
      "        1897.0,\n",
      "        1186.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        98\n",
      "      ],\n",
      "      \"target\": [\n",
      "        2006.0,\n",
      "        1987.0,\n",
      "        1732.0,\n",
      "        1386.0,\n",
      "        491.0,\n",
      "        474.0,\n",
      "        659.0,\n",
      "        773.0,\n",
      "        2424.0,\n",
      "        1548.0,\n",
      "        655.0,\n",
      "        9.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        505.0,\n",
      "        445.0,\n",
      "        1821.0,\n",
      "        1905.0,\n",
      "        1590.0,\n",
      "        1217.0\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"start\": \"2020-02-24 15:00:00\",\n",
      "      \"cat\": [\n",
      "        99\n",
      "      ],\n",
      "      \"target\": [\n",
      "        10.0,\n",
      "        2538.0,\n",
      "        2246.0,\n",
      "        1820.0,\n",
      "        1094.0,\n",
      "        725.0,\n",
      "        850.0,\n",
      "        884.0,\n",
      "        2698.0,\n",
      "        1843.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        20.0,\n",
      "        20.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        19.0,\n",
      "        22.0,\n",
      "        10.0,\n",
      "        10.0,\n",
      "        21.0,\n",
      "        10.0,\n",
      "        1254.0,\n",
      "        759.0,\n",
      "        865.0,\n",
      "        2463.0,\n",
      "        1921.0,\n",
      "        1535.0\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"configuration\": {\n",
      "    \"output_types\": [\n",
      "      \"mean\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "inference_json = json.dumps(inference, indent=2)\n",
    "print(inference_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.predictor.Predictor at 0x7fc57d60e610>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    dar_endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer())\n",
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'mean': [2156.4060058594,\n",
       "    1874.1242675781,\n",
       "    1427.0601806641,\n",
       "    730.9706420898]},\n",
       "  {'mean': [1518.8516845703, 1188.1329345703, 888.1737670898, 787.5779418945]},\n",
       "  {'mean': [1010.8931884766, 644.3718261719, 433.2434387207, 566.5250244141]},\n",
       "  {'mean': [864.7713012695, 748.9321899414, 654.4508056641, 762.6679077148]},\n",
       "  {'mean': [779.4497680664, 429.6017150879, 341.8963928223, 388.0269775391]},\n",
       "  {'mean': [718.8358764648, 562.6910400391, 637.9756469727, 1716.8004150391]},\n",
       "  {'mean': [1149.6647949219, 902.3166503906, 872.1148681641, 989.859375]},\n",
       "  {'mean': [687.3181762695, 467.9446411133, 463.7035217285, 711.005065918]},\n",
       "  {'mean': [1464.6351318359, 1074.5883789062, 823.7182617188, 853.4039916992]},\n",
       "  {'mean': [765.9538574219, 522.4611206055, 591.0625610352, 980.2604980469]},\n",
       "  {'mean': [1074.3918457031, 936.2238769531, 845.0233764648, 1000.8374023438]},\n",
       "  {'mean': [967.6097412109, 664.5266113281, 632.0560302734, 735.3997802734]},\n",
       "  {'mean': [728.045715332, 545.219543457, 586.4124145508, 1572.0998535156]},\n",
       "  {'mean': [1386.1036376953,\n",
       "    1165.4754638672,\n",
       "    992.6310424805,\n",
       "    1073.5567626953]},\n",
       "  {'mean': [813.3214111328, 595.287902832, 464.6274719238, 659.3503417969]},\n",
       "  {'mean': [882.7908325195, 581.0963134766, 408.3149719238, 523.8337402344]},\n",
       "  {'mean': [790.231262207, 530.9204101562, 354.2499694824, 485.744720459]},\n",
       "  {'mean': [742.8158569336, 541.0371704102, 653.4937133789, 1557.6123046875]},\n",
       "  {'mean': [1086.8737792969, 748.2253417969, 658.8736572266, 850.8174438477]},\n",
       "  {'mean': [1110.4187011719, 890.3902587891, 931.825012207, 1023.5877075195]},\n",
       "  {'mean': [994.9831542969, 662.2977294922, 485.7381896973, 692.0568237305]},\n",
       "  {'mean': [969.0663452148, 560.5673217773, 418.966217041, 547.1516113281]},\n",
       "  {'mean': [831.7184448242, 578.3269042969, 671.065246582, 1525.1762695312]},\n",
       "  {'mean': [1308.1743164062, 705.7723388672, 534.041809082, 961.9685668945]},\n",
       "  {'mean': [1352.5773925781,\n",
       "    1214.4906005859,\n",
       "    1290.4625244141,\n",
       "    1438.3107910156]},\n",
       "  {'mean': [795.8845214844, 533.0601196289, 606.9032592773, 1247.4259033203]},\n",
       "  {'mean': [1146.3371582031, 835.12890625, 692.0325927734, 767.6800537109]},\n",
       "  {'mean': [800.8723144531, 541.6865844727, 597.4515380859, 965.6804199219]},\n",
       "  {'mean': [763.4232177734, 573.5161743164, 566.7034301758, 895.7083740234]},\n",
       "  {'mean': [1537.4343261719, 835.4477539062, 342.9725341797, 245.8120727539]},\n",
       "  {'mean': [747.3016967773, 541.619140625, 415.0014038086, 543.6365966797]},\n",
       "  {'mean': [699.9165649414, 509.0484619141, 570.5170288086, 1692.0949707031]},\n",
       "  {'mean': [799.9417114258, 558.2297363281, 632.9596557617, 1324.7515869141]},\n",
       "  {'mean': [750.7995605469, 509.7164916992, 475.4618225098, 978.5061035156]},\n",
       "  {'mean': [1280.6342773438, 883.7028808594, 552.9947509766, 466.9019775391]},\n",
       "  {'mean': [780.3573608398, 519.6463623047, 487.4780883789, 984.7393798828]},\n",
       "  {'mean': [844.833984375, 592.7561035156, 702.0880737305, 1273.3879394531]},\n",
       "  {'mean': [1324.2607421875, 855.8992919922, 777.018371582, 675.264465332]},\n",
       "  {'mean': [932.0588989258, 410.8915710449, 451.7369384766, 719.8786621094]},\n",
       "  {'mean': [1183.3251953125, 813.7267456055, 866.6575927734, 932.7249755859]},\n",
       "  {'mean': [949.342956543, 619.0385742188, 470.559967041, 615.2276000977]},\n",
       "  {'mean': [836.1688232422, 573.2164306641, 576.7070922852, 887.6489868164]},\n",
       "  {'mean': [1291.0255126953, 914.3605957031, 910.1166381836, 789.8075561523]},\n",
       "  {'mean': [879.9436035156, 548.0329589844, 357.2543334961, 473.3058166504]},\n",
       "  {'mean': [799.5095825195, 587.4302978516, 630.1137695312, 1116.8586425781]},\n",
       "  {'mean': [941.2284545898, 703.21875, 707.3478393555, 808.2421875]},\n",
       "  {'mean': [703.3149414062, 474.4881286621, 574.9423217773, 1944.0456542969]},\n",
       "  {'mean': [838.2395019531, 610.3087768555, 521.609375, 735.3284912109]},\n",
       "  {'mean': [1184.6743164062, 995.112487793, 819.3078613281, 782.2831420898]},\n",
       "  {'mean': [879.987487793, 617.4589233398, 445.2604980469, 524.5550537109]},\n",
       "  {'mean': [620.7854614258, 328.7799072266, 281.3993835449, 370.1098937988]},\n",
       "  {'mean': [1275.9802246094, 688.7460327148, 546.2681274414, 828.3419799805]},\n",
       "  {'mean': [724.9929199219, 489.4036865234, 536.9184570312, 1477.6448974609]},\n",
       "  {'mean': [1461.5875244141, 1176.3447265625, 967.6513061523, 941.4403686523]},\n",
       "  {'mean': [1273.7299804688,\n",
       "    1044.0704345703,\n",
       "    909.1616210938,\n",
       "    1047.2609863281]},\n",
       "  {'mean': [1497.4353027344,\n",
       "    1201.3148193359,\n",
       "    951.4081420898,\n",
       "    1080.4610595703]},\n",
       "  {'mean': [1380.5623779297,\n",
       "    1191.2768554688,\n",
       "    953.2988891602,\n",
       "    1087.5491943359]},\n",
       "  {'mean': [795.5865478516, 551.5369873047, 457.7761230469, 598.5595092773]},\n",
       "  {'mean': [815.3720092773, 578.5378417969, 637.7817993164, 1207.1945800781]},\n",
       "  {'mean': [804.6284179688, 554.5170288086, 583.8999023438, 930.6718139648]},\n",
       "  {'mean': [724.9161987305, 486.1871032715, 548.8061523438, 1333.2038574219]},\n",
       "  {'mean': [839.3751831055, 619.0620117188, 509.1251831055, 700.0474853516]},\n",
       "  {'mean': [704.5404052734, 371.4104614258, 291.5810241699, 786.9045410156]},\n",
       "  {'mean': [808.7108764648, 481.2213745117, 450.5063171387, 850.5932617188]},\n",
       "  {'mean': [1086.9680175781, 857.0649414062, 835.9481811523, 918.2196655273]},\n",
       "  {'mean': [1552.9755859375, 1104.3171386719, 844.0016479492, 840.5310058594]},\n",
       "  {'mean': [1271.3265380859, 516.1990356445, 311.940246582, 305.5164489746]},\n",
       "  {'mean': [805.9371948242, 548.9978637695, 603.295715332, 1346.20703125]},\n",
       "  {'mean': [1201.7158203125, 882.1333007812, 674.3922119141, 787.9992675781]},\n",
       "  {'mean': [1047.6390380859, 440.5043334961, 229.7507171631, 367.8914489746]},\n",
       "  {'mean': [539.0766601562, 439.2762145996, 506.4172668457, 1804.2880859375]},\n",
       "  {'mean': [668.9049072266, 310.0480957031, 372.3226623535, 524.1795043945]},\n",
       "  {'mean': [837.2345581055, 678.1006469727, 496.2745666504, 697.5767211914]},\n",
       "  {'mean': [777.9017944336, 566.8073730469, 493.0223388672, 646.1001586914]},\n",
       "  {'mean': [1007.5186157227, 795.5903320312, 780.4986572266, 866.1395874023]},\n",
       "  {'mean': [758.4384155273, 543.9012451172, 601.5387573242, 1362.2211914062]},\n",
       "  {'mean': [667.4222412109, 350.6143493652, 356.9879760742, 1178.6821289062]},\n",
       "  {'mean': [967.0270996094, 653.2611083984, 665.7572631836, 1136.6037597656]},\n",
       "  {'mean': [1333.2930908203, 1012.033996582, 971.6171875, 1045.4653320312]},\n",
       "  {'mean': [1084.0131835938, 836.2162475586, 869.0653686523, 937.5548706055]},\n",
       "  {'mean': [887.6720581055, 586.7927856445, 535.5738525391, 1294.6469726562]},\n",
       "  {'mean': [1207.7537841797, 937.2754516602, 947.2595825195, 1091.1419677734]},\n",
       "  {'mean': [802.745300293, 553.6501464844, 386.963684082, 541.3399658203]},\n",
       "  {'mean': [978.9059448242, 478.7712097168, 298.9537963867, 392.9559326172]},\n",
       "  {'mean': [771.5347900391, 542.7760620117, 603.2408447266, 925.7052612305]},\n",
       "  {'mean': [1302.9227294922, 979.1819458008, 934.9338989258, 1035.9822998047]},\n",
       "  {'mean': [966.4517822266, 565.9705810547, 426.6315307617, 535.5412597656]},\n",
       "  {'mean': [788.4539794922, 609.8673706055, 648.3022460938, 1276.3544921875]},\n",
       "  {'mean': [935.1544799805, 596.7266845703, 476.241607666, 586.8709716797]},\n",
       "  {'mean': [1329.6938476562, 980.7309570312, 768.0213012695, 766.2487792969]},\n",
       "  {'mean': [1687.8338623047, 1334.4453125, 984.6289672852, 1059.9602050781]},\n",
       "  {'mean': [817.3392333984, 607.1127319336, 735.1821899414, 1826.8698730469]},\n",
       "  {'mean': [728.9080200195, 532.1326904297, 540.6739501953, 888.8319702148]},\n",
       "  {'mean': [862.3332519531, 592.1826782227, 672.0875244141, 1320.2550048828]},\n",
       "  {'mean': [914.828125, 453.4023742676, 320.9534301758, 440.4610595703]},\n",
       "  {'mean': [749.450012207, 438.6782836914, 397.2719421387, 668.0949707031]},\n",
       "  {'mean': [771.9657592773, 564.6421508789, 562.1381835938, 848.1264648438]},\n",
       "  {'mean': [793.173034668, 610.3241577148, 640.1180419922, 1258.1446533203]},\n",
       "  {'mean': [642.1848754883, 415.2267150879, 450.4442443848, 1041.0467529297]},\n",
       "  {'mean': [1185.6245117188, 687.3395385742, 346.4781494141, 409.1575012207]}]}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor.predict(inference)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2156.4060058594, 1874.1242675781, 1427.0601806641, 730.9706420898],\n",
       " [1518.8516845703, 1188.1329345703, 888.1737670898, 787.5779418945],\n",
       " [1010.8931884766, 644.3718261719, 433.2434387207, 566.5250244141],\n",
       " [864.7713012695, 748.9321899414, 654.4508056641, 762.6679077148],\n",
       " [779.4497680664, 429.6017150879, 341.8963928223, 388.0269775391],\n",
       " [718.8358764648, 562.6910400391, 637.9756469727, 1716.8004150391],\n",
       " [1149.6647949219, 902.3166503906, 872.1148681641, 989.859375],\n",
       " [687.3181762695, 467.9446411133, 463.7035217285, 711.005065918],\n",
       " [1464.6351318359, 1074.5883789062, 823.7182617188, 853.4039916992],\n",
       " [765.9538574219, 522.4611206055, 591.0625610352, 980.2604980469],\n",
       " [1074.3918457031, 936.2238769531, 845.0233764648, 1000.8374023438],\n",
       " [967.6097412109, 664.5266113281, 632.0560302734, 735.3997802734],\n",
       " [728.045715332, 545.219543457, 586.4124145508, 1572.0998535156],\n",
       " [1386.1036376953, 1165.4754638672, 992.6310424805, 1073.5567626953],\n",
       " [813.3214111328, 595.287902832, 464.6274719238, 659.3503417969],\n",
       " [882.7908325195, 581.0963134766, 408.3149719238, 523.8337402344],\n",
       " [790.231262207, 530.9204101562, 354.2499694824, 485.744720459],\n",
       " [742.8158569336, 541.0371704102, 653.4937133789, 1557.6123046875],\n",
       " [1086.8737792969, 748.2253417969, 658.8736572266, 850.8174438477],\n",
       " [1110.4187011719, 890.3902587891, 931.825012207, 1023.5877075195],\n",
       " [994.9831542969, 662.2977294922, 485.7381896973, 692.0568237305],\n",
       " [969.0663452148, 560.5673217773, 418.966217041, 547.1516113281],\n",
       " [831.7184448242, 578.3269042969, 671.065246582, 1525.1762695312],\n",
       " [1308.1743164062, 705.7723388672, 534.041809082, 961.9685668945],\n",
       " [1352.5773925781, 1214.4906005859, 1290.4625244141, 1438.3107910156],\n",
       " [795.8845214844, 533.0601196289, 606.9032592773, 1247.4259033203],\n",
       " [1146.3371582031, 835.12890625, 692.0325927734, 767.6800537109],\n",
       " [800.8723144531, 541.6865844727, 597.4515380859, 965.6804199219],\n",
       " [763.4232177734, 573.5161743164, 566.7034301758, 895.7083740234],\n",
       " [1537.4343261719, 835.4477539062, 342.9725341797, 245.8120727539],\n",
       " [747.3016967773, 541.619140625, 415.0014038086, 543.6365966797],\n",
       " [699.9165649414, 509.0484619141, 570.5170288086, 1692.0949707031],\n",
       " [799.9417114258, 558.2297363281, 632.9596557617, 1324.7515869141],\n",
       " [750.7995605469, 509.7164916992, 475.4618225098, 978.5061035156],\n",
       " [1280.6342773438, 883.7028808594, 552.9947509766, 466.9019775391],\n",
       " [780.3573608398, 519.6463623047, 487.4780883789, 984.7393798828],\n",
       " [844.833984375, 592.7561035156, 702.0880737305, 1273.3879394531],\n",
       " [1324.2607421875, 855.8992919922, 777.018371582, 675.264465332],\n",
       " [932.0588989258, 410.8915710449, 451.7369384766, 719.8786621094],\n",
       " [1183.3251953125, 813.7267456055, 866.6575927734, 932.7249755859],\n",
       " [949.342956543, 619.0385742188, 470.559967041, 615.2276000977],\n",
       " [836.1688232422, 573.2164306641, 576.7070922852, 887.6489868164],\n",
       " [1291.0255126953, 914.3605957031, 910.1166381836, 789.8075561523],\n",
       " [879.9436035156, 548.0329589844, 357.2543334961, 473.3058166504],\n",
       " [799.5095825195, 587.4302978516, 630.1137695312, 1116.8586425781],\n",
       " [941.2284545898, 703.21875, 707.3478393555, 808.2421875],\n",
       " [703.3149414062, 474.4881286621, 574.9423217773, 1944.0456542969],\n",
       " [838.2395019531, 610.3087768555, 521.609375, 735.3284912109],\n",
       " [1184.6743164062, 995.112487793, 819.3078613281, 782.2831420898],\n",
       " [879.987487793, 617.4589233398, 445.2604980469, 524.5550537109],\n",
       " [620.7854614258, 328.7799072266, 281.3993835449, 370.1098937988],\n",
       " [1275.9802246094, 688.7460327148, 546.2681274414, 828.3419799805],\n",
       " [724.9929199219, 489.4036865234, 536.9184570312, 1477.6448974609],\n",
       " [1461.5875244141, 1176.3447265625, 967.6513061523, 941.4403686523],\n",
       " [1273.7299804688, 1044.0704345703, 909.1616210938, 1047.2609863281],\n",
       " [1497.4353027344, 1201.3148193359, 951.4081420898, 1080.4610595703],\n",
       " [1380.5623779297, 1191.2768554688, 953.2988891602, 1087.5491943359],\n",
       " [795.5865478516, 551.5369873047, 457.7761230469, 598.5595092773],\n",
       " [815.3720092773, 578.5378417969, 637.7817993164, 1207.1945800781],\n",
       " [804.6284179688, 554.5170288086, 583.8999023438, 930.6718139648],\n",
       " [724.9161987305, 486.1871032715, 548.8061523438, 1333.2038574219],\n",
       " [839.3751831055, 619.0620117188, 509.1251831055, 700.0474853516],\n",
       " [704.5404052734, 371.4104614258, 291.5810241699, 786.9045410156],\n",
       " [808.7108764648, 481.2213745117, 450.5063171387, 850.5932617188],\n",
       " [1086.9680175781, 857.0649414062, 835.9481811523, 918.2196655273],\n",
       " [1552.9755859375, 1104.3171386719, 844.0016479492, 840.5310058594],\n",
       " [1271.3265380859, 516.1990356445, 311.940246582, 305.5164489746],\n",
       " [805.9371948242, 548.9978637695, 603.295715332, 1346.20703125],\n",
       " [1201.7158203125, 882.1333007812, 674.3922119141, 787.9992675781],\n",
       " [1047.6390380859, 440.5043334961, 229.7507171631, 367.8914489746],\n",
       " [539.0766601562, 439.2762145996, 506.4172668457, 1804.2880859375],\n",
       " [668.9049072266, 310.0480957031, 372.3226623535, 524.1795043945],\n",
       " [837.2345581055, 678.1006469727, 496.2745666504, 697.5767211914],\n",
       " [777.9017944336, 566.8073730469, 493.0223388672, 646.1001586914],\n",
       " [1007.5186157227, 795.5903320312, 780.4986572266, 866.1395874023],\n",
       " [758.4384155273, 543.9012451172, 601.5387573242, 1362.2211914062],\n",
       " [667.4222412109, 350.6143493652, 356.9879760742, 1178.6821289062],\n",
       " [967.0270996094, 653.2611083984, 665.7572631836, 1136.6037597656],\n",
       " [1333.2930908203, 1012.033996582, 971.6171875, 1045.4653320312],\n",
       " [1084.0131835938, 836.2162475586, 869.0653686523, 937.5548706055],\n",
       " [887.6720581055, 586.7927856445, 535.5738525391, 1294.6469726562],\n",
       " [1207.7537841797, 937.2754516602, 947.2595825195, 1091.1419677734],\n",
       " [802.745300293, 553.6501464844, 386.963684082, 541.3399658203],\n",
       " [978.9059448242, 478.7712097168, 298.9537963867, 392.9559326172],\n",
       " [771.5347900391, 542.7760620117, 603.2408447266, 925.7052612305],\n",
       " [1302.9227294922, 979.1819458008, 934.9338989258, 1035.9822998047],\n",
       " [966.4517822266, 565.9705810547, 426.6315307617, 535.5412597656],\n",
       " [788.4539794922, 609.8673706055, 648.3022460938, 1276.3544921875],\n",
       " [935.1544799805, 596.7266845703, 476.241607666, 586.8709716797],\n",
       " [1329.6938476562, 980.7309570312, 768.0213012695, 766.2487792969],\n",
       " [1687.8338623047, 1334.4453125, 984.6289672852, 1059.9602050781],\n",
       " [817.3392333984, 607.1127319336, 735.1821899414, 1826.8698730469],\n",
       " [728.9080200195, 532.1326904297, 540.6739501953, 888.8319702148],\n",
       " [862.3332519531, 592.1826782227, 672.0875244141, 1320.2550048828],\n",
       " [914.828125, 453.4023742676, 320.9534301758, 440.4610595703],\n",
       " [749.450012207, 438.6782836914, 397.2719421387, 668.0949707031],\n",
       " [771.9657592773, 564.6421508789, 562.1381835938, 848.1264648438],\n",
       " [793.173034668, 610.3241577148, 640.1180419922, 1258.1446533203],\n",
       " [642.1848754883, 415.2267150879, 450.4442443848, 1041.0467529297],\n",
       " [1185.6245117188, 687.3395385742, 346.4781494141, 409.1575012207]]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = prediction[\"predictions\"]\n",
    "predictions = [p[\"mean\"] for p in predictions]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Device 2 = 1 anomalies (max = 0.8768996912, cutoff = 0.8673524912516744)\n",
      " Device 4 = 1 anomalies (max = 1.1622519743, cutoff = 1.1242054237617012)\n",
      " Device 8 = 1 anomalies (max = 0.9263862384, cutoff = 0.9208593531369319)\n",
      " Device 10 = 1 anomalies (max = 0.8917608626, cutoff = 0.8906141494014859)\n",
      " Device 15 = 1 anomalies (max = 0.9101585938, cutoff = 0.909986048048814)\n",
      " Device 16 = 1 anomalies (max = 1.0280485887, cutoff = 1.0043840534885207)\n",
      " Device 21 = 1 anomalies (max = 0.8410018879, cutoff = 0.8382200674802354)\n",
      " Device 23 = 1 anomalies (max = 0.9511436509, cutoff = 0.9454823739544687)\n",
      " Device 25 = 1 anomalies (max = 0.9873395233, cutoff = 0.9762839693651011)\n",
      " Device 26 = 1 anomalies (max = 0.9436370366, cutoff = 0.9357432845104956)\n",
      " Device 28 = 1 anomalies (max = 0.9302511606, cutoff = 0.9255247689910323)\n",
      " Device 29 = 1 anomalies (max = 1.85024109, cutoff = 1.761965874605883)\n",
      " Device 30 = 1 anomalies (max = 0.8810684899, cutoff = 0.8792885687422496)\n",
      " Device 32 = 1 anomalies (max = 0.9465689895, cutoff = 0.9440069977156575)\n",
      " Device 37 = 1 anomalies (max = 0.9479599163, cutoff = 0.9372260247037989)\n",
      " Device 39 = 1 anomalies (max = 0.9572825254, cutoff = 0.9487978455340228)\n",
      " Device 40 = 1 anomalies (max = 0.8472417812, cutoff = 0.8444068718742385)\n",
      " Device 48 = 1 anomalies (max = 0.9557582236, cutoff = 0.9446177577633265)\n",
      " Device 49 = 1 anomalies (max = 0.8958285699, cutoff = 0.8849064612761044)\n",
      " Device 54 = 1 anomalies (max = 0.9616176272, cutoff = 0.9551780653705778)\n",
      " Device 57 = 1 anomalies (max = 0.8663964787, cutoff = 0.8573174280691344)\n",
      " Device 58 = 1 anomalies (max = 0.9742960227, cutoff = 0.9698985059996469)\n",
      " Device 62 = 1 anomalies (max = 1.5294811156, cutoff = 1.4486213587408456)\n",
      " Device 64 = 1 anomalies (max = 0.9168540749, cutoff = 0.9129257236862582)\n",
      " Device 65 = 1 anomalies (max = 0.9403455572, cutoff = 0.9357416944763152)\n",
      " Device 67 = 1 anomalies (max = 0.9619680961, cutoff = 0.9518155730441088)\n",
      " Device 68 = 1 anomalies (max = 0.9881545159, cutoff = 0.9779919117753608)\n",
      " Device 69 = 1 anomalies (max = 1.9643374064, cutoff = 1.828577822746002)\n",
      " Device 70 = 1 anomalies (max = 0.913790833, cutoff = 0.8951432147094098)\n",
      " Device 71 = 1 anomalies (max = 1.4237679822, cutoff = 1.3580158054562734)\n",
      " Device 73 = 1 anomalies (max = 0.857716808, cutoff = 0.8524685884999578)\n",
      " Device 74 = 1 anomalies (max = 0.8875891469, cutoff = 0.8865766790063235)\n",
      " Device 75 = 1 anomalies (max = 0.9684257594, cutoff = 0.9617340634965317)\n",
      " Device 77 = 1 anomalies (max = 0.9331799729, cutoff = 0.9265281798563244)\n",
      " Device 78 = 1 anomalies (max = 0.959290385, cutoff = 0.9486115224750267)\n",
      " Device 81 = 1 anomalies (max = 0.9737249034, cutoff = 0.9641969400854364)\n",
      " Device 83 = 1 anomalies (max = 1.4958514938, cutoff = 1.4125307364674757)\n",
      " Device 85 = 1 anomalies (max = 0.9649074718, cutoff = 0.9553633798970225)\n",
      " Device 86 = 1 anomalies (max = 0.8455407584, cutoff = 0.8371047144087695)\n",
      " Device 87 = 1 anomalies (max = 0.9590272033, cutoff = 0.9431057003847414)\n",
      " Device 88 = 1 anomalies (max = 0.8790187984, cutoff = 0.8649320442756421)\n",
      " Device 89 = 1 anomalies (max = 0.9607370582, cutoff = 0.9467176248930042)\n",
      " Device 90 = 1 anomalies (max = 0.9642345779, cutoff = 0.9623196515449993)\n",
      " Device 94 = 1 anomalies (max = 1.3664903082, cutoff = 1.3113060554870808)\n",
      " Device 97 = 1 anomalies (max = 0.9876671452, cutoff = 0.9798157674855282)\n",
      " Device 99 = 1 anomalies (max = 1.1079758384, cutoff = 1.0955425602665576)\n"
     ]
    }
   ],
   "source": [
    "sigmas = 1.25\n",
    "maintenance = []\n",
    "\n",
    "for i, preds in enumerate(predictions):\n",
    "    infer_data = [[t] for t in preds]\n",
    "    results = rcf_inference.predict(infer_data)\n",
    "    scores = results[\"scores\"]\n",
    "    scores = [score[\"score\"] for score in scores]\n",
    "    series = pd.Series(scores)\n",
    "    score_mean = series.mean()\n",
    "    score_max = series.max()\n",
    "    score_std = series.std()\n",
    "    score_cutoff = score_mean + sigmas*score_std\n",
    "    anomalies = series[series > score_cutoff ]\n",
    "    if not anomalies.empty:\n",
    "        maintenance.append(i)\n",
    "        print(\" Device {} = {} anomalies (max = {}, cutoff = {})\".format(i, len(anomalies), score_max, score_cutoff ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Requesting maintenance for 46 devices'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Requesting maintenance for {} devices\".format(len(maintenance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have saved a lot of trips to failed moontracer devices and made lunar energy more efficient and reliable.\n",
    "\n",
    "Don't forget to [delete unused resources](mt-cleanup.ipynb)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
